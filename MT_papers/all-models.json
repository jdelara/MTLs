[
  {
    "title": "Developing with UML - Some Pitfalls and \nWorkarounds",
    "date": 1998,
    "abstract": "The object-oriented modeling language UML offers various notations for all phases of application development. The user is left alone, however, when applying UML in up-to-date application development involving distribution, data management, and component-oriented mechanisms. Moreover, various shortcomings have been encountered, most notably w.r.t. refinement of model elements throughout the development life cycle and employment of interaction diagrams to formalize use cases. The paper will shed some light on how these issues may be handled with UML.",
    "keywords": []
  },
  {
    "title": "Supporting and Applying the UML Conceptual \nFramework",
    "date": 1998,
    "abstract": "The Unified Modelling Language (UML) ostensibly assumes a four level (meta) modelling framework, both for its definition and for the conceptual context in which its users operate. In practice, however, it is still dominated by the traditional two level (model + data) view of object modelling and neither supports nor applies the four level framework properly. This not only diminishes the clarity of the UML semantics, but also complicates the task of those users who do wish to fully embrace a multi-level approach. After outlining the characteristics of the intended conceptual framework, and the problems resulting from the UML’s current two-level bias, this paper presents three simple enhancements to the UML which provide the required expressive power for multi-level modelling. The paper then goes on to discuss issues in the application of the conceptual framework within the UML’s own definition.",
    "keywords": []
  },
  {
    "title": "Modeling: Is It Turning Informal into Formal?",
    "date": 1998,
    "abstract": "This work studies the meaning of the qualifier « semi-formal », which is usually attributed to design diagrams. Starting with a UML diagram as an example, the paper deals with the three modes of expressing things about the outside world: symbols, indexes and icons. The idea that the informational process consists in formalizing an informal given is discussed with regard to the supposed informal nature of the users’ requirements. It is also shown that a modeling language such as UML, although formalized in its inner constructions, can not strictly formalize the connection to the outside world it intends to model. This framework, arising from C. S. Peirce’s semiotics, allows to account for the modeling process as a effective interpretation reasoning on diagrams which are themselves made of signs. Thus we go beyond the apparent contradiction between the formal and the informal, using the concept of Interpretant. We can then envisage the study of design reasoning as dialogs between a model, its interpretants and the outside world or domain.",
    "keywords": []
  },
  {
    "title": "Best of Both Worlds -  \nA Mapping from EXPRESS-G to UML",
    "date": 1998,
    "abstract": "On the one hand, in the world of Product Data Technology (PDT), the ISO standard STEP (Standard for the Exchange of Product Model Data) gains more and more importance. STEP includes the information model specification language EXPRESS and its graphical notation EXPRESS-G. On the other hand, in the Software Engineering world in general, mainly other modelling languages are in use - particularly the Unified Modeling Language (UML), recently adopted to become a standard by the Object Management Group, will probably achieve broad acceptance. Despite a strong interconnection of PDT with the Software Engineering area, there is a lack of bridging elements concerning the modelling language level. This paper introduces a mapping between EXPRESS-G and UML in order to define a linking bridge and bring the best of both worlds together. Hereby the feasibility of a mapping is shown with representative examples; several problematic cases are discussed as well as possible solutions presented.",
    "keywords": []
  },
  {
    "title": "Making UML Models Interoperable with UXF",
    "date": 1998,
    "abstract": "Uniﬁed Modeling Language (UML) has been widely accepted in the software engineering area, because it provides most of the con- cepts and notations that are essential for documenting object-oriented models. However, UML does not have an explicit format to describe and interchange its model information intentionally. This paper addresses the UML model interchange and presents our eﬀorts to make UML highly in- teroperable. We developed an interchange format called UXF (UML eX- change Format) based on XML (Extensible Markup Language). UXF is a simple and well-structured format to encode UML models. It leverages the tool interoperability, team development and reuse of design models by interchanging the model information with the the XML standard. Also, we propose an open distribution platform for UML models, which provides multiple levels of interoperability of UML models. Our work shows an important step in the evolution for the interoperable UML.",
    "keywords": []
  },
  {
    "title": "Automation of Design Pattern : Concepts, Tools and \nPractices",
    "date": 1998,
    "abstract": "Model transformation is a technique that makes it possible to auto- mate design patterns. Applied to UML, the result is highly promising. However, model transformation rules have to be structured by a specific organization mechanism called viewpoint, and be coupled with the UML model extension features (tagged values, stereotypes, etc.). This has been done through a specific technique, called « hypergenericity », which is implemented by a case tool and used since 1994.",
    "keywords": []
  },
  {
    "title": "Informal Formality? The Object Constraint Language \nand Its Application in the UML Metamodel",
    "date": 1998,
    "abstract": "Within the field of object technology it is becoming recognised that constraints are a good way to produce more precise and formal specifications than with diagrams alone. Evidence of this is that UML incorporates a standard constraint language called OCL (Object Constraint Language). The availability of OCL will encourage UML users to add constraints to their UML models. This paper explains OCL and demonstrates its applicability. Probably the largest application of OCL to date was its use to define the metamodel of UML, and the experiences gained in this application are discussed.",
    "keywords": []
  },
  {
    "title": "On Using UML Class Diagrams for Object-Oriented Database Design Speciﬁcation of Integrity Constraints",
    "date": 1998,
    "abstract": "In the course of object-oriented software engineering, the UML class diagrams are used to specify the static structure of the system under study, such as classes, types and various kinds of static relation- ships among them. Objects of the persistent classes can be stored in object-oriented databases or in relational databases. In the former case, the UML class diagrams are actually used for conceptual object-oriented database designs. However, the standard UML class diagram lacks the ability to specify some inherent integrity constraints, such as keys and uniqueness, for object-oriented databases. This paper proposes an ex- tension to the UML metamodel, i.e., the introduction of two new model elements (key and IConstraint) and some new attributes to the existing metamodel, to accommodate further, additional features for constraint speciﬁcation. On the model level, a compartment CONSTRAINT of the class notation and some property strings for displaying the integrity con- straints are added. The database design is then mapped to the extended ODMG-ODL schema deﬁnition. Keywords: Conceptual Data Modeling, Integrity Constraints, Object- Oriented Database Design",
    "keywords": []
  },
  {
    "title": "Literate Modelling — Capturing Business Knowledge\nwith the UML",
    "date": 1998,
    "abstract": "At British Airways, we have found during several large OO projects documented using the UML that non-technical end-users, managers and busi- ness domain experts ﬁnd it difﬁcult to understand UML visual models. This leads to problems in requirement capture and review. To solve this problem, we have developed the technique of Literate Modelling. Literate Models are UML dia- grams that are embedded in texts explaining the models. In that way end-users, managers and domain experts gain useful understanding of the models, whilst object-oriented analysts see exactly and precisely how the models deﬁne business requirements and imperatives. We discuss some early experiences with Literate Modelling at British Airways where it was used extensively in their Enterprise Object Modelling initiative. We explain why Literate Modelling is viewed as one of the critical success factors for this signiﬁcant project. Finally, we propose that Literate Modelling may be a valuable extension to many other object-oriented and non object-oriented visual modelling languages.",
    "keywords": []
  },
  {
    "title": "Applying UML to Design an Inter-Domain Service \nManagement Application",
    "date": 1998,
    "abstract": "We present a component-oriented approach to demonstrate the use of the Unified Modeling Language (UML) and Open Distributed Processing (ODP) concepts to design service components of a telecommunications management system. This paper is based on the work done in the design phase of the ACTS project “TRUMPET” (Inter-Domain Management with Integrity). This project undertook to produce a service management architecture suitable for emerging liberalised telecommunications markets. The criteria where that the system should be highly distributed both technologically and administratively -- i.e., across many kinds of organisations. TRUMPET project presents a good model environment to develop not only the service architecture itself but also the methodologies for producing such designs. In our approach, we use the conceptual framework of ODP and discuss some methodological issues related to ODP-viewpoint modelling of distributed systems using UML notations. We conclude with recognising the power of combining UML and ODP so as to manage the complexity of the problem.",
    "keywords": []
  },
  {
    "title": "Booster*Process\nA Software Development Process Model\nIntegrating Business Object Technology and\nUML",
    "date": 1998,
    "abstract": "This paper describes a UML-based process model (called Booster*Process) for system development founded on business object technology. It integrates business and software engineering aspects, de- scribes the speciﬁc modeling activities needed for business and software system modeling and connects the various UML diagrams, particularly taking into consideration the requirements of business objects and their component character. It propagates a multi-level approach, starting with use case, activity and class modeling at the organizational level, and then shifting to analysis and design of business applications.",
    "keywords": []
  },
  {
    "title": "Hierarchical Context Diagrams with UML:  \nAn Experience Report \n on Satellite Ground System Analysis",
    "date": 1998,
    "abstract": "Although the UML was mainly designed for software development, we have introduced its use in the requirements analysis phase of the ground segment of a complete satellite system. In the first part of the paper, we present the subset of UML, consisting mainly in Use Cases and Interaction diagrams, that we have used for the requirements analysis phase. We insist on the need to define precisely the scope of the problem, its environment. We mostly assert that the \"Context diagram\" from traditional structured methods is still relevant in an object-oriented approach, and furthermore that it can be adequately represented by a special usage of the UML Collaboration diagram. This Context diagram can even take into account progressively the underlying physical architecture of satellite systems. The second part of the paper is more prospective: it aims at extracting Context diagrams patterns, and proposes specific stereotypes for satellite system analysis.",
    "keywords": []
  },
  {
    "title": "Extension of UML Sequence Diagrams for Real-Time \nSystems",
    "date": 1998,
    "abstract": "The behavior of real-time systems is specified by a number of interaction scenarios between tasks or active objects. Each scenario may be illustrated by a UML sequence diagram. We use the newly developed, textual language UMLscript-RT as input language for our tool AVUS, mainly a compiler, that automatically generates standard UML sequence diagrams. UMLscript-RT extends UML sequence diagrams in two aspects. Firstly, we introduce loops and suggest a graphical notation very similar to that used in Message Sequence Charts. Secondly we give a precise grammar for timing constraints which are mandatory for real-time applications. AVUS generates a directed graph whose vertices are the events and associates the constraints as weights to the arrows. Consistency of the timing constraints is then checked by examining the cycles of that graph.",
    "keywords": []
  },
  {
    "title": "UML and User Interface Modeling",
    "date": 1998,
    "abstract": "UML and traditional CASE tools still focus more on application internals and less on application usability aspects. A user interface (UI) is modeled in terms of its internal structure and objects comprising it, the same as the rest of the application. The adoption of use cases and interaction scenarios acknowledges the importance of recognizing user tasks when developing an application, but it is still used mainly as a starting point for designing software implementing usage scenarios rather than focusing on modeling user tasks to improve application usability. Explicit modeling of user interface domain knowledge can bring important benefits when utilized by a CASE tool: additional design assistance with exploring UI design alternatives, support for evaluating and critiquing UI designs, as well as increased reuse and easier maintenance. UML can provide a notation framework for integrating user interface modeling with mainstream software engineering OO modeling. The built-in extensibility mechanisms (stereotypes, tagged values and constraints) allow the introduction of new modeling constructs with specialized semantics for UI modeling while staying within UML. The paper identifies modeling constructs needed for UI modeling and proposes a direction for extending UML to better address UI design.",
    "keywords": []
  },
  {
    "title": "Structuring UML Design Deliverables",
    "date": 1998,
    "abstract": "The idea of using Unified Modeling Language (UML) appeals to people, but actually using it can be challenging. Many would like to use UML for software development, but do not know how to structure design models and what the relationships between various UML diagrams are. This paper introduces a structure for design deliverables that can be used for software development with UML. The structure is based on a pattern of four deliverables describing classifier relationships, interactions, responsibilities and state machines. The pattern can be applied to different levels of abstraction and to different views on a software product. The paper also discusses practical considerations for documenting software design in the project repository as well as cases in which UML may not be the most appropriate notation to use. The conference presentation with speaker notes is available at this address: www.navision.com (click services).",
    "keywords": []
  },
  {
    "title": "Considerations of and Suggestions for\na UML-Specific Process Model",
    "date": 1998,
    "abstract": "The developers of the Unified Modeling Language (UML) promote (but do not describe) a development process model that is use case-driven, architecture centric, and iterative and incremental. This paper analyzes these features and suggests some extra features needed in developing object- oriented client/server applications (including Internet). The paper is heavily based on practical experiences, where object-oriented client/server applica- tions have been built with the three mentioned requirements in mind. The pa- per outlines a process model that meets the stated features. In particular, it connects the roles of the development team and the tasks in the process model. KEYWORDS: Process model, modeling language, role.",
    "keywords": []
  },
  {
    "title": "The UML as a Formal Modeling Notation",
    "date": 1998,
    "abstract": "The Uniﬁed Modeling Language (UML) is rapidly emerging as a de-facto standard for modelling OO systems. Given this role, it is imperative that the UML needs a well-deﬁned, fully explored semantics. Such semantics is required in order to ensure that UML concepts are precisely stated and deﬁned. In this paper we motivate an approach to formalizing UML in which formal speciﬁcation techniques are used to gain insight into the semantics of UML notations and diagrams and describe a roadmap for this approach. The authors initiated the Precise UML (PUML) group in order to develop a precise semantic model for UML diagrams. The semantic model is to be used as the basis for a set of diagrammatical transformation rules, which enable formal deductions to be made about UML diagrams. A small example shows how these rules can be used to verify whether one class diagram is a valid deduction of another. Because these rules are presented at the diagrammatical level, it will be argued that UML can be successfully used as a formal modelling tool without the notational complexities that are commonly found in textual speciﬁcation techniques.",
    "keywords": []
  },
  {
    "title": "OML: Proposals to Enhance UML",
    "date": 1998,
    "abstract": "While the UML metamodel and notation aim to be comprehensive, there are a number of areas in which this modelling language is seen to be deficient. The proposals in OML (Firesmith et al., 1997) contain a number of advanced metamodelling and notational techniques which could also be of use in enhancing UML. In particular contributions can be made in the areas of modelling responsibilities and aggregations and in the provision of notational elements underpinned by semiotics and usability concerns. Other areas of potential contribution include a more consistent and thorough treatment of abstraction foci in terms of class versus type versus instance - applicable not only at the classifier level but also to packages, scenarios etc.; the ability to discriminate clearly between the various types of inheritance and to represent these notationally. It is critical that any standard support not only a use-case and a data-driven mindset but also that of a responsibility-driven modelling process and that the results of these modelling endeavours are communicated as effectively as possible both to other developers and to users.",
    "keywords": []
  },
  {
    "title": "Validating Distributed Software Modeled with\nthe Uniﬁed Modeling Language",
    "date": 1998,
    "abstract": "The development of correct OO distributed software is a daunting task as soon as the distributed interactions are not trivial. This is due to the inherent complexity of distributed systems (latency, error recovery, etc), leading to numerous problems such as deadlocks, race conditions, and many diﬃculties in trying to reproduce such error conditions and debug them. The OO technology is ill-equipped to deal with this dimension of the problem. On the other hand, the willingness of mastering this complexity in the context of telecommunication proto- cols gave birth to speciﬁc formal veriﬁcation and validation tools. The aim of this paper is to explore how the underlying technology of these tools could be made available to the designer of OO distributed software. We propose a framework allowing the integration of formal veriﬁcation and validation technology in a seamless OO life-cycle based on UML, the Uniﬁed Modeling Language.",
    "keywords": []
  },
  {
    "title": "Supporting Disciplined Reuse and Evolution \nof UML Models",
    "date": 1998,
    "abstract": "UML provides very little support for modelling evolvable or reusable specifications and designs. To cope with this problem, the UML needs to be extended with support for reuse and evolution of model components. As a first step, this paper enhances the UML metamodel with the “reuse contract” formalism to deal with evolution of collaborating class interfaces. Such a formal semantics for reuse allows us to detect evolution and composition conflicts automatically.",
    "keywords": []
  },
  {
    "title": "Applying UML Extensions to Facilitate Software Reuse",
    "date": 1998,
    "abstract": "The benefits from reuse during the analysis and design stages of software development are well understood. This paper examines the contribution which UML can make to such reuse through its ability to document reusable structures. In particular, the application of the UML concepts of stereotypes, tagged values, class compartments and association roles in the definition of search criteria for reuse candidates are explored. An iterative development process, within which UML can be used, is presented and discussed. An initial implementation in a CBR environment, and results from this experimental prototype, are also presented.",
    "keywords": []
  },
  {
    "title": "Extending Architectural Representation in UML with View Integration",
    "date": 1999,
    "abstract": "UML has established itself as the leading OO analysis and design methodology. Recently, it has also been increasingly used as a foundation for representing numerous (diagrammatic) views that are outside the standardized set of UML views. An example are architecture description languages. The main advantages of representing other types of views in UML are 1) a common data model and 2) a common set of tools that can be used to manipulate that model. However, attempts at representing additional views in UML usually fall short of their full integration with existing views. Integration extends represen- tation by also describing interactions among multiple views, thus capturing the inter-view relationships. Those inter-view relationships are essential to enable automated identification of consistency and conformance mismatches. This work describes a view integration framework and demonstrates how an archi- tecture description language, which was previously only represented in UML, can now be fully integrated into UML.",
    "keywords": []
  },
  {
    "title": "Enabling the Refinement of a Software Architecture ",
    "date": 1999,
    "abstract": "Software architecture research has thus far mainly addressed formal specification and analysis of coarse-grained software models. The formality of architectural descriptions, their lack of support for downstream development activities, and their poor integration with mainstream approaches have made them unattractive to a large segment of the development community. This paper demonstrates how a mainstream design notation, the Unified Modeling Language (UML), can help address these concerns. We describe a semi- automated approach developed to assist in refining a high-level architecture specified in an architecture description language (ADL) into a design described with UML. To this end, we have integrated DRADEL, an environment for architecture modeling and analysis, with Rational Rose®, a commercial off-the- shelf (COTS) UML modeling tool. We have defined a set of rules to transform an architectural representation into an initial UML model that can then be further refined. We believe this approach to be easily adaptable to different ADLs, to the changes in our understanding of UML, and to the changes in UML itself.",
    "keywords": []
  },
  {
    "title": "Using the UML for Architectural Description",
    "date": 1999,
    "abstract": "There is much interest in using the Uniﬁed Modeling Lan- guage (UML) for architectural description – those techniques by which architects sketch, capture, model, document and analyze architectural knowledge and decisions about software-intensive systems. IEEE P1471, the Recommended Practice for Architectural Description, represents an emerging consensus for specifying the content of an architectural descrip- tion for a software-intensive system. Like the UML, IEEE P1471 does not prescribe a particular architectural method or life cycle, but may be used within a variety of such processes. In this paper, I provide an overview of IEEE P1471, describe its conceptual framework, and investigate the issues of applying the UML to meet the requirements of IEEE P1471. Keywords: IEEE P1471, architectural description, multiple views, view- points, Uniﬁed Modeling Language",
    "keywords": []
  },
  {
    "title": "Viewing the OML as a Variant of the UML",
    "date": 1999,
    "abstract": "The OPEN Modelling Language, OML, was published dur- ing the standardization process which ﬁnally led to UML version 1.3. While being contributory to this process, there are still some features of the OML which have not been adopted in the current version of the UML. These features oﬀer capabilities which are complementary to those of the UML. This paper describes how these features of the OML can be made available to UML developers by viewing the OML as a variant of the UML.",
    "keywords": []
  },
  {
    "title": "A Comparison of the Business Object Notation\nand the Uniﬁed Modeling Language",
    "date": 1999,
    "abstract": "Seamlessness, reversibility, and software contracting have been pro- posed as important techniques to be supported by object-oriented methods. These techniques are used to provide a framework for the comparison of two model- ing languages, the Business Object Notation (BON) and the Uniﬁed Modeling Language (UML). Elements of the UML and its constraint language that do not support these techniques are discussed. Suggestions for further improvements to both BON and UML are described.",
    "keywords": []
  },
  {
    "title": "Formalizing the UML Class Diagram Using Object-Z",
    "date": 1999,
    "abstract": "To produce a precise and analyzable software model, it is essential for the modeling technique to have formality in the syntax and the semantics of its notation, and to allow rigorous analysis of its models. In this sense, UML is not yet a truly precise modeling technique. This paper presents a formal basis for the syntactic structures and semantics of core UML class constructs, and also provides a basis for reasoning about UML class dia- grams. The syntactic structures of UML class constructs and the rules for de- veloping a well-formed class diagram are precisely described using the Z no- tation. Based on this formal description, UML class constructs are then translated to Object-Z constructs. Proof techniques provided for Object-Z can be used for reasoning about these class diagrams.",
    "keywords": []
  },
  {
    "title": "A Formal Approach to Collaborations in the Uniﬁed Modeling Language",
    "date": 1999,
    "abstract": "In this paper we give a formal deﬁnition of the collaboration construct in the Uniﬁed Modeling Language (UML). We also state what it means that a use case is realized by a collaboration, and what the relationship is between the speciﬁcation part and the realization part of a subsystem in UML.",
    "keywords": []
  },
  {
    "title": "A Formal Semantics for UML Interactions",
    "date": 1999,
    "abstract": "The UML abstract syntax and semantics speciﬁcation distin- guishes between the statics and the dynamics of collaborations: the rˆole context and interactions. We propose a formal semantics of interactions based on the abstract syntax and directly reﬂecting the speciﬁcation. The semantics is both parametric in the notion of context and in se- mantic details that are intentionally left open by the speciﬁcation, but resolves true inconsistencies. The formalisation uses temporal logic for- mulae in the style of Manna and Pnueli. We illustrate the ﬂexibility of our semantics by discussing instantiations for a running example; its in- tuitiveness is substantiated by proving that the temporal formulae give rise to partial orders that also directly can be inferred from interactions.",
    "keywords": []
  },
  {
    "title": "UML 2.0 Architectural Crossroads: Sculpting or Mudpacking? Panel",
    "date": 1999,
    "abstract": "As the UML reaches the venerable age of four, both its proponents and critics are scanning the changes in the UML 1.3 revision and the proposed UML 2.0 roadmap. They are asking pointed questions, such as: Has the modeling language matured or bloated during the standardization process? Will UML be able to adapt to the changing requirements of software development? These questions and the strong emphasis of the UML Revision Task Force’s final report on architectural issues suggest that UML is approaching an architectural crossroads at the OMG and elsewhere. This panel explores the nature and the extent of the architectural challenges facing UML, and makes constructive recommendations to address them.",
    "keywords": []
  },
  {
    "title": "Core Meta-Modelling Semantics of UML: The pUML Approach",
    "date": 1999,
    "abstract": "The current UML semantics documentation has made a sig- niﬁcant step towards providing a precise description of the UML. How- ever, at present the semantic model it proposes only provides a descrip- tion of the language’s syntax and well-formedness rules. The meaning of the language, which is mainly described in English, is too informal and unstructured to provide a foundation for developing formal anal- ysis and development techniques. Another problem is the scope of the model, which is both complex and large. This paper describes work cur- rently being undertaken by the precise UML group (pUML), an interna- tional group of researchers and practitioners, to address these problems. A formalisation strategy is presented which concentrates on giving a pre- cise denotational semantics to core elements of UML. This is illustrated through the development of precise deﬁnitions of two important con- cepts: generalization and packages. Finally, a viewpoint architecture is proposed as a means of providing improved separation of concerns in the semantics deﬁnition.",
    "keywords": []
  },
  {
    "title": "A\nMetamo\ndel\nfor\nOCL",
    "date": 1999,
    "abstract": "The Ob ject Constrain t Language (OCL) allo ws the exten-",
    "keywords": []
  },
  {
    "title": "Tool-Supported Compression of UML Class Diagrams",
    "date": 1999,
    "abstract": "Techniques for tool-supported compression of UML class diagrams are developed. These techniques allow abstract representations of class diagrams by effacing (less essential) parts of the diagram. The hidden parts can be made again visible at selected points. The user can start examining a class diagram with only few main classes visible and refine the diagram gradually to the interesting directions, proceeding from abstract view to details. The proposed techniques help in managing large class diagrams and in extracting high-level views from object-oriented legacy systems, thus supporting the understanding of the overall architecture of the system. The construction of the compressed form of a class diagram can be either automatic or it can be controlled by a human. An algorithm is given for managing compressed class diagrams, and a prototype implementation is described.",
    "keywords": []
  },
  {
    "title": "A Pragmatic Approach for Building a User-Friendly and Flexible UML Model Repository",
    "date": 1999,
    "abstract": "In France Telecom research center in Lannion (France) we have been working for three years on OO modeling as a promising technology for unifying the representation of data. This has led us to develop a Model Repository Tool, which offers, as its default configuration, a full support for the UML 1.3 meta- model. The tool enables the manipulation of models by means of a Java or Py- thon API. It provides a rich and flexible registration capability based on an ex- plicit identification, relying on a two-leveled hierarchical naming space. The paper focuses on the design aspects of the repository tool and highlights its similarities and differences with the design principles of OMG Meta Object Fa- cility specification.",
    "keywords": []
  },
  {
    "title": "Modeling Dynamic Software Components in UML",
    "date": 1999,
    "abstract": "UML provides modeling support for static software compo- nents through hierarchical packages. We describe a small extension of UML for modeling dynamic software components which can be instan- tiated at runtime, customized, made persistent, migrated and be aggre- gated to larger components. For example, this extension can be used to describe systems built with JavaBeans, ActiveX-Controls, Voyager Agents or CORBA Objects by Value. With our extension, the lifecycle of a dynamic software component can be expressed in terms of UML. We can not only describe a system at design time, but also monitor its runtime behaviour. A re-engineering tool is presented that exploits our UML extension for a high-level visualization of the interaction between dynamic components in an object-oriented system.",
    "keywords": []
  },
  {
    "title": "Extending UML for\nModeling Reﬂective Software Components",
    "date": 1999,
    "abstract": "This paper describes our extension of the UML metamodel for specifying reﬂective software components. Reﬂection is a design prin- ciple that allows a system to have a representation of itself in the manner that makes it easy to adapt the system to a changing environment. It has matured to the point where it is used to address real-world problems in various areas. We describe how to document reﬂective components in the framework of UML. Our work allows for recognizing and understanding reﬂective components in the upper levels of abstraction at an earlier stage of the development process. It leverages the documentation, learning, vi- sual modeling, reuse and roundtrip development of metalevel designs. We also demonstrate the seamless model exchange between diﬀerent de- velopment tools and model continuity across development phases with application-neutral interchange formats.",
    "keywords": []
  },
  {
    "title": "A Classiﬁcation of Stereotypes for Object-Oriented Modeling Languages",
    "date": 1999,
    "abstract": "The Uniﬁed Modeling Language UML and the Open Modeling Lan- guage both have introduced stereotypes as a new means for user-deﬁned exten- sions of a given base language. Stereotypes are a very powerful feature. They allow modiﬁcations ranging from slight notational changes up to the redeﬁnition of the base language. However, the power of stereotypes entails risk. Badly designed stereotypes can do harm to a modeling language. In order to exploit the beneﬁts of stereotypes and to avoid their risks, a better understanding of the nature and the properties of stereotypes is necessary.",
    "keywords": []
  },
  {
    "title": "First-Class Extensibility for UML \u0000\nPackaging of Profiles, Stereotypes, Patterns",
    "date": 1999,
    "abstract": "We discuss a first-class extensibility mechanism for the UML based on Catalysis packages and frameworks [3]. Packages define and structure meta-model extensions for different modeling language \u0000profiles\u0000. Package frameworks support lightweight extensions like stereotypes as well as heavyweight extensions. OCL can be used to define constraints and rules for profiles and frameworks. Our approach rationalizes and consolidates some core concepts within the UML standard, uses a simple general mechanism for layering facilities onto that core in a precise and well-defined way, and offers a way to simplify and re- factor the UML specification.",
    "keywords": []
  },
  {
    "title": "UML-Based Fusion Analysis",
    "date": 1999,
    "abstract": "In recent times, there has been an increased requirement for soft- ware to be distributed. The well-known Fusion development method, how- ever, can only be used to develop sequential reactive systems, and certain restricted kinds of concurrent systems. In contrast, the Unified Modeling Lan- guage (UML) provides a rich set of notations that can be used to model sys- tems that are distributed. In addition, UML provides the ability to introduce rigor into diagrams through its constraint language OCL. In this paper, we present a UML-based Fusion analysis phase by way of a simple bank case study, and we discuss some enhancements that were made in addition to a mapping of notations; our proposal is the first step towards providing a Fusion-based analysis phase which supports high-level modeling of distrib- uted systems.",
    "keywords": [
      "Fusion",
      "UML",
      "Analysis",
      "Object-Oriented  Software Development."
    ]
  },
  {
    "title": "Framework for Describing UML Compatible Development Processes",
    "date": 1999,
    "abstract": "Have you ever tried to specify an accurate development process for your organization and later faced difficulties with the complexity of the description? Instead of describing a specific process, it might help to describe a process framework and reuse it by creating specific processes for specific needs. This paper describes the object-oriented framework of a development process, which considers software development artifacts as objects and evolution as collaborations between the objects. Such an object-oriented process definition can deal with the complexity of a development process in a better way than a traditional description based on workflow. This paper discusses features of such a process framework with an eye towards approaches such as Fusion, OPEN and the Rational Unified Process.",
    "keywords": []
  },
  {
    "title": "UML-RT as a Candidate for Modeling Embedded Real-Time Systems in the Telecommunication Domain",
    "date": 1999,
    "abstract": "UML-RT oﬀers a set of extensions to the UML, which are a basis for modeling real-time systems. Some investigations have shown that UML-RT provides concepts, which are close to the constructs used at Ericsson for designing mobile switching systems in the GSM (Global System for Mobile Communication) telecommunication domain. Tele- communication systems are some of the most challenging systems regard- ing size, complexity, and real-time constraints. This article describes the main constructs used at Ericsson, which display a robust framework for building real-time systems; and shows the mapping to UML-RT. An ad- dition to UML-RT is presented; it allows UML-RT to be a candidate for modeling embedded real-time systems in the telecommunication domain.",
    "keywords": []
  },
  {
    "title": "UML Based Performance Modeling Framework for Object-Oriented Distributed Systems1",
    "date": 1999,
    "abstract": "As object-oriented distributed systems, e.g. those based on CORBA, Java, and DCOM, are entering the mainstream of information technology, it is increasingly important to predict and understand their performance characteris- tics. To support this need, we describe a framework that allows UML diagrams to be used for building performance models for such systems. A mapping is proposed from the high-level UML notation to queuing networks with simulta- neous resource possessions, so that the models can be solved for the relevant performance metrics. The main goal of the framework is to support performance engineering and, thus, flexibility and ease of use have been emphasized.",
    "keywords": []
  },
  {
    "title": "Defining the Context of OCL Expressions",
    "date": 1999,
    "abstract": "Expressions written in Object Constraint Language (OCL) within a UML model assume a context, depending upon where they are written. Currently the exact nature of this context is not fully defined. Furthermore there is no mechanism for defining the context for OCL expressions in extensions to UML. This paper defines the context of OCL expressions, and proposes precise and flexible mechanisms for how to specify this context.",
    "keywords": []
  },
  {
    "title": "Mixing Visual and Textual Constraint Languages",
    "date": 1999,
    "abstract": "The Object Constraint Language (OCL) is a precise language for notating behavioural constraints on UML models. Constraint diagrams have been proposed as a means of notating similar constraints, but in a visual form. This paper explores the utility of these two notations for depicting constraints, and shows how they can be used effectively together. The goal of this work is to provide more intuitive and expressive languages to support the construction and presentation of rich and precise models.",
    "keywords": []
  },
  {
    "title": "Correct Realizations of Interface Constraints with OCL⋆",
    "date": 1999,
    "abstract": "We present an OCL-like formal notation for interface con- straints, called ICL, suited to describe the required observable behavior of any correct interface implementation (provided by some class). The semantics of the ICL notation is deﬁned by a translation to the obser- vational logic institution. For specifying constraints on classes we use a subset of OCL to express invariants and pre- and post-conditions on operations. The semantics of the OCL expressions is deﬁned by a transla- tion into an algebraic speciﬁcation. Using these semantic foundations we introduce a formal correctness notion for implementation relations be- tween interfaces and classes and we show how to prove implementation correctness by using observational proof techniques.",
    "keywords": []
  },
  {
    "title": "Generating Tests from UML Speciﬁcations",
    "date": 1999,
    "abstract": "Although most industry testing of complex software is con- ducted at the system level, most formal research has focused on the unit level. As a result, most system level testing techniques are only de- scribed informally. This paper presents a novel technique that adapts pre-deﬁned state-based speciﬁcation test data generation criteria to gen- erate test cases from UML statecharts. UML statecharts provide a solid basis for test generation in a form that can be easily manipulated. This technique includes coverage criteria that enable highly eﬀective tests to be developed. To demonstrate this technique, a tool has been developed that uses UML statecharts produced by Rational Software Corporation’s Rational Rose tool to generate test data. Experimental results from using this tool are presented.",
    "keywords": []
  },
  {
    "title": "F ormalisi ng UML State Mac hines for Mo del Chec king",
    "date": 1999,
    "abstract": "The pap er discusses a complete formalisation of UML state",
    "keywords": []
  },
  {
    "title": "UML Behavior: Inheritance and Implementation in Current Object-Oriented Languages",
    "date": 1999,
    "abstract": "The UML dynamic model is described using notions like state, event or active object that current object-oriented languages don't support. When the implementation is not done using a state machine interpreter, these notions had to be translated into the target language. This work aims to study how to translate as automatically as possible UML state diagrams into current object- oriented languages (OOLs), distinguishing sequential and concurrent execution. This translation requires to map UML notions onto OOLs ones, to adapt the abstract state machine, and to add information to state diagrams. Behavior inheritance is a key problem, and both theoretical and practical solutions are examined to ensure behavior substitutability. Then, two main ways for state representation are compared from the inheritance point of view, and automatic code generation is discussed.",
    "keywords": []
  },
  {
    "title": "UML Collaboration Diagrams and Their Transformation to Java",
    "date": 1999,
    "abstract": "UML provides a variety of diagram types for specifying both the structure and the behavior of a system. During the development process, models speciﬁed by use of these diagram types have to be trans- formed into corresponding code. In the past, mainly class diagrams and state diagrams have been considered for an automatic code generation. In this paper, we focus on collaboration diagrams. As an important pre- requisite for a consistent transformation into Java code, we ﬁrst provide methodical guidelines on how to deploy collaboration diagrams to model functional behavior. This understanding yields a reﬁned meta model and forms the base for the deﬁnition of a transformation algorithm. The au- tomatically generated Java code fragments build a substantial part of the functionality and prevent the loss of important information during the transition from a model to its implementation. Keywords: Collaboration diagram, methodical guidelines, code gener- ation, Java, pattern-based transformation algorithm",
    "keywords": []
  },
  {
    "title": "Typechecking UML Static Models",
    "date": 1999,
    "abstract": "UML static models are expressed using a mixture of class diagrams and OCL expressions. In a well formed static model, the OCL expressions and class diagrams are type consistent. Checking for type consistency of static models involves both inclusion and parametric poly- morphism. This paper deﬁnes a semantics of type consistency in terms of a type theory for UML static models. The type theory is shown to be correct with respect to a value semantics for OCL. The existence of a consistency checking algorithm for UML static models is established.",
    "keywords": []
  },
  {
    "title": "Analysing\nUML\nUse\nCases\nas\nCon\ntracts",
    "date": 1999,
    "abstract": "The Uni ed Mo deling Language (UML) consists in a set of",
    "keywords": []
  },
  {
    "title": "Closing the Gap between Object-Oriented Modeling of Structure and Behavior",
    "date": 1999,
    "abstract": "The UML as standardized language for visual object-oriented modeling allows to capture the requirements as well as the structure and behavior of complex software systems. With the increasing demands of todays systems, behavior aspects like concurrency, distribution and re- activity become more important. But the language concepts of the UML for describing behavioral aspects are weak compared to its concepts for describing structures. Besides a lack of visual expressiveness, a deeper integration with the structure speciﬁcation is missing. In order to close this gap, an expressive language for modeling object-oriented behavior is proposed with the OCoN approach. It describes contracts, object schedul- ing as well as control and data ﬂow of services in a Petri-net-like form. A seamless visual embedding of contract speciﬁcations into service and object scheduling speciﬁcations is provided by diﬀerent net types.",
    "keywords": []
  },
  {
    "title": "Black and White Diamonds",
    "date": 1999,
    "abstract": "This study of the semantics of UML’s shared aggregation and composition (black and white diamonds) is based on previous detailed analyses of the semantics of aggregation in object modelling in which primary axioms were identiﬁed. All forms of aggregation must comply with these primary axioms. We conclude that both kinds of UML Aggre- gation do not possess the full complement of primary characteristics and that their secondary characteristics, which deﬁne various “ﬂavours” of aggregation, are overlapping and incomplete. We recommend revisions to UML’s two kinds of aggregation: completion of the primary set of axiomatic characteristics and then careful selection of secondary charac- teristics for deﬁning black and white diamond aggregation.",
    "keywords": []
  },
  {
    "title": "Interconnecting Objects via Contracts",
    "date": 1999,
    "abstract": "The evolution of today's markets and the high volatility of business requirements put an increasing emphasis on the flexibility of sys- tems, i.e. on the ability for systems to accommodate the changes required by new or different organisational needs with a minimum impact on the imple- mented services. In this paper, we put forward an extension of UML with a semantic primitive – contract – for representing explicitly the rules that de- termine the way object interaction needs to be coordinated to satisfy busi- ness requirements, as well as the mechanisms that make it possible to reflect changes of the business requirements without having to modify the basic objects that compose the system. Contracts are proposed as extended forms of association classes whose semantics rely on principles that have been used in Software Architectures and Distributed System Design for supporting dynamic reconfiguration.",
    "keywords": []
  },
  {
    "title": "How Can a Subsystem Be Both a Package and a Classifier?",
    "date": 1999,
    "abstract": "The UML specifies that a subsystem is both a package and a classifier. This paper explores what that could possibly mean and explains why that was the right choice. It points out a key to the use of the concept in CASE tools, mentions the historical precedent for that key, and challenges CASE tools to support the flexibility that architects and designers need. Along the way, the paper reviews a method for discovering a good partition of a system into subsystems, describes a scheme for using UML to build a model of a system, and suggests some changes to the UML.",
    "keywords": []
  },
  {
    "title": "Using UML/OCL Constraints for Relational Database Design",
    "date": 1999,
    "abstract": "Integrating relational databases into object-oriented appli- cations is state of the art in software development practice. In database applications, it is beneﬁcial if constraints like business rules are encoded as part of the database schema and not in the application programs. The Object Constraint Language (OCL) as part of the Uniﬁed Mod- eling Language (UML) provides the posssibility to express constraints in a conceptual model unambiguously. We show how OCL, UML and SQL can be used in database constraint modeling, and discuss their ad- vantages and limitations. Furthermore, we present patterns for mapping OCL expressions to SQL code.",
    "keywords": []
  },
  {
    "title": "Towards a UML Extension for Hypermedia Design⋆",
    "date": 1999,
    "abstract": "The acceptance of UML as a de facto standard for the de- sign of object-oriented systems, together with the explosive growth of the World Wide Web has raised the need for UML extensions to model hy- permedia applications running on the Internet. In this paper we propose such an extension for modeling the navigation and the user interfaces of hypermedia systems. Similar to other design methods for hypermedia systems we view the design of hypermedia systems as consisting of three models: the conceptual, navigational and presentational model. The con- ceptual model consists of a class diagram identifying the objects of the problem domain and their relations. The navigational model describes the navigation structure of the hypermedia application by a class di- agram specifying which navigational nodes are deﬁned and an object diagram showing how these navigational nodes are visited. Finally, the presentational model describes the abstract user interface by composite objects and its dynamic behavior by state diagrams. Each model is built using the notations provided by the UML, applying the extension mech- anism of the UML, i.e. stereotypes and OCL constraints, when necessary. Keywords: Uniﬁed Modeling Language, Object-Oriented Design, Mul- timedia, Hypermedia, WWW.",
    "keywords": []
  },
  {
    "title": "Why Uniﬁed Is not Universal UML Shortcomings for Coping with Round-Trip Engineering",
    "date": 1999,
    "abstract": "UML is currently embraced as “the” standard in object- oriented modeling languages, the recent work of OMG on the Meta Object Facility (MOF) being the most noteworthy example. We wel- come these standardisation eﬀorts, yet warn against the tendency to use UML as the panacea for all exchange standards. In particular, we argue that UML is not suﬃcient to serve as a tool-interoperability stan- dard for integrating round-trip engineering tools, because one is forced to rely on UML’s built-in extension mechanisms to adequately model the reality in source-code. Consequently, we propose an alternative meta- model (named FAMIX), which serves as the tool interoperability stan- dard within the FAMOOS project and which includes a number of con- structive suggestions that we hope will inﬂuence future releases of the UML and MOF standards. Keywords: Meta model, uniﬁed modeling language (UML), meta-object facility (MOF), interoperability standard, famoos information exchange (FAMIX).",
    "keywords": []
  },
  {
    "title": "Timed Sequence Diagrams and T o ol-Based Analysis \u0015 A Case Study",
    "date": 1999,
    "abstract": "W e use UML timed Sequence Diagrams to sp ecify the real-",
    "keywords": []
  },
  {
    "title": "Timing Analysis of UML Sequence Diagrams",
    "date": 1999,
    "abstract": "For real-time systems, UML sequence diagrams describe in- teraction among objects, which show the scenarios of system behaviour. In this paper, we give the solution for timing analysis of simple UML sequence diagrams which describe exactly one scenario without any al- ternatives and loops, and develop an algorithm for checking the compo- sitions of UML sequence diagrams, which describe multiple scenarios, for timing consistency.",
    "keywords": []
  },
  {
    "title": "The Normal Object Form: \nBridging the Gap from Models to Code",
    "date": 1999,
    "abstract": "The value of graphical modeling within the analysis and design activities of object-oriented development is predicated on the assumption that the resulting models can be mapped correctly, optimally and efficiently into executable (normally textual) code. In practice, however, because of the large potential mismatch in abstraction levels, the mapping of graphical models into code is often one of the weakest and most error prone links in the chain of development steps. This paper describes a practical approach for addressing this problem based upon the definition of a restricted extension of the UML known as the Normal Object Form (NOF). The basic purpose of the NOF is to provide a set of UML modeling concepts which are \"semantically close\" to those found in object-oriented programming languages. Highly abstract UML models can then be mapped into corresponding executable code by means of a series of semantically small refinement (intra-UML) and translation (extra- UML) translation steps, rather than in one large (often ad hoc) step. This not only increases the chances of a correct and optimal mapping, but also signifi- cantly improves the traceability of UML constructs to and from code con- structs, with all the associated advantages for maintenance and reuse.",
    "keywords": []
  },
  {
    "title": "Modeling Exceptional Behavior",
    "date": 1999,
    "abstract": "While exception handling mechanisms are very useful for implementing systems, they are equally useful when building business models. The standard method of modeling exceptions in UML is to in- clude them in class diagrams as a kind of signal, as stereotyped classes. However this alone is insuﬃcient, since by the very nature of exceptions, the circumstances under which particular exceptions may be raised, as well as the details of what actions the class handling the exception will perform in doing so, tend to be rather complex and in general diﬃcult to express pictorially. In this paper, we consider how this information may be speciﬁed using the Object Constraint Language (OCL). We illustrate our approach by applying it to a simple example.",
    "keywords": []
  },
  {
    "title": "On the Extension of UML \nwith Use Case Maps Concepts",
    "date": 2000,
    "abstract": "Descriptions of reactive systems focus heavily on behavioral aspects, often in terms of scenarios. To cope with the increasing complexity of services provided by these systems, behavioral aspects need to be handled early in the design process with flexible and concise notations as well as expressive con- cepts. UML offers different notations and concepts that can help describe such services. However, several necessary concepts appear to be absent from UML, but present in the Use Case Map (UCM) scenario notation. In particular, Use Case Maps allow scenarios to be mapped to different architectures composed of various component types. The notation supports structured and incremental de- velopment of complex scenarios at a high level of abstraction, as well as their integration. UCMs specify variations of run-time behavior and scenario struc- tures through sub-maps \"pluggable\" into placeholders called stubs. This paper presents how UCM concepts could be used to extend the semantics and nota- tions of UML for the modeling of complex reactive systems. Adding a \"UCM view\" to the existing UML views can help bridging the gap separating require- ments and use cases from more detailed views (e.g. expressed with interaction diagrams and statechart diagrams). Examples from telecommunications systems are given and a corresponding design trajectory is also suggested.",
    "keywords": []
  },
  {
    "title": "HyperMSCs and Sequence Diagrams for Use Case Modelling and Testing",
    "date": 2000,
    "abstract": "UML-Sequence Diagrams can be seen as an object oriented variant of the ITU-T standard language Message Sequence Chart (MSC) which is very popular mainly in the telecommunication area. Both notations would benefit from a unification together with a further elaboration. A comparison of Sequence Diagrams and MSCs demonstrates the big advantage of MSCs con- cerning composition mechanisms, particularly with respect to the branching con- struct in Sequence Diagrams. Therefore, MSC inline expressions and High Level MSCs (HMSCs) are of special interest for the inclusion into Sequence Dia- grams. High Level MSCs may be employed for formalizing and structuring the construction of scenarios for Use Cases. In order to arrive at a most intuitive rep- resentation, HMSCs are re-interpreted in a way which has an analogy in hyper- text-like specifications. Because of this analogy, the notation ‘HyperMSC’ is introduced. The scenarios derived from Use Cases in form of HyperMSCs can be employed also as a basis for the specification of test cases.",
    "keywords": [
      ". UML",
      "MSC",
      "Sequence Diagrams",
      "Use Cases",
      "OO",
      "software engi- neering",
      "testing",
      "distributed systems",
      "real time systems",
      "telecommunication"
    ]
  },
  {
    "title": "Business-Oriented Constraint Language",
    "date": 2000,
    "abstract": "The Business-oriented Constraint Language (BCL) is proposed as a means of annotating diagrams in UML. BCL is grounded in the Object Con- straint Language (OCL) but is designed particularly to address the needs of people who are concerned with enterprise application integration (EAI), al- though it may be more widely applicable. EAI often requires a loosely coupled event-based architecture in which timing and statistical measures are important; these are described in another paper (1). BCL provides these features together with a syntax that is flexible and extensible. It is intended to be accessible to most practitioners, including those who do not have a mathematical back- ground.",
    "keywords": []
  },
  {
    "title": "Processes, Roles, and Events:\nUML Concepts for Enterprise Architecture",
    "date": 2000,
    "abstract": "This paper presents an integrated approach for modelling enterprise architectures using UML. To satisfy a need for a wide range of modelling choices, we provide a rich set of process-based and role-based modelling concepts, together with a flexible way of associating business events with business processes and roles. Our approach enriches Unified Modelling Language (UML) to support the requirements of enterprise distributed object computing (EDOC) systems and is currently being considered by the Object Management Group (OMG) for standardisation.",
    "keywords": []
  },
  {
    "title": "Statistical Constraints for EAI",
    "date": 2000,
    "abstract": "Enterprise Application Integration (EAI) often requires a loosely coupled event-based architecture in which timing and statistical measures are important. Statistical constraints are proposed to address some of these requirements, although they may well have broader applicability. This idea is extended to the use of approximate terms such as “some” that can be given a statistical interpretation, as in “Some fault reports give rise to subscriptions.” These can be a convenient way of expressing constraints that are important to the application architecture but are not absolute — abstraction through approximation. They may be used to annotate diagrams in UML and are based on the existing Object Constraint Language (OCL) (1). Some of the examples use a more flexible syntax that is the subject of another paper (2).",
    "keywords": []
  },
  {
    "title": "Towards a UML Profile for Interaction Design: The Wisdom Approach",
    "date": 2000,
    "abstract": "The UML is recognized to be the dominant diagrammatic modeling language in the software industry. However, it’s support for building interac- tive systems is still acknowledged to be insufficient. There is a common mis- conception that the same models developed to support the design of the appli- cation internals are also adequate to support interaction design, leveraging the usability aspects of the applications. In this paper we identify and discuss the major problems using the UML to document, specify and design interactive systems. Here we propose a UML profile for interactive systems development that leverages on human-computer interaction domain knowledge under the common notation and semantics of the UML. Our proposal integrates with ex- isting object-oriented software engineering best practice, fostering co- evolutionary development of interactive systems and enabling artifact change between software engineering and human-computer interaction.",
    "keywords": []
  },
  {
    "title": "UMLi: The Uniﬁed Modeling Language for Interactive Applications",
    "date": 2000,
    "abstract": "User interfaces (UIs) are essential components of most soft- ware systems, and signiﬁcantly aﬀect the eﬀectiveness of installed appli- cations. In addition, UIs often represent a signiﬁcant proportion of the code delivered by a development activity. However, despite this, there are no modelling languages and tools that support contract elaboration be- tween UI developers and application developers. The Uniﬁed Modeling Language (UML) has been widely accepted by application developers, but not so much by UI designers. For this reason, this paper introduces the notation of the Uniﬁed Modelling Language for Interactive Appli- cations (UMLi), that extends UML, to provide greater support for UI design. UI elements elicited in use cases and their scenarios can be used during the design of activities and UI presentations. A diagram notation for modelling user interface presentations is introduced. Activity diagram notation is extended to describe collaboration between interaction and domain objects. Further, a case study using UMLi notation and method is presented.",
    "keywords": []
  },
  {
    "title": "A Diagrammatic Tool for Representing User Interaction in UML",
    "date": 2000,
    "abstract": "The UML suggests the employment of use cases for capturing the requirements and for specifying the interaction between the users and the sys- tem being modeled. Use cases are easily understood by users since they are es- sentially textual descriptions, but lack the precision and the conciseness ac- complished by the other diagrammatic tools of UML. Besides, there is no sys- tematic method that helps the designer to obtain such UML diagrams from a set of use cases. In this paper we present a diagrammatic tool to represent the us- ers/system interaction called User Interaction Diagram (UID). UIDs have proven to be a valuable tool to gather requirements since they describe the ex- change of information between the system and the user in a high level of ab- straction, without considering specific user interface aspects and design details as in other UML diagrams. We show how UIDs can be incorporated into the requirements and analysis workflows of the Unified Process for software de- velopment.",
    "keywords": []
  },
  {
    "title": "UML Extension for ASAM-GDI Device Capability Description",
    "date": 2000,
    "abstract": "The ASAM standard has identiﬁed subsystems within au- tomation and measuring systems as well as standard interfaces between these subsystems. One of these interfaces, called GDI (Generic Device Interface), deﬁnes the connection to measurement devices and intelligent subsystems. ASAM-GDI ensures the interoperability of real-time subsys- tems by separating the implementation code of device drivers and their interface descriptions, called DCD (Device Capability Description). DCD describes an object-like interface of procedural real-time components (de- vice drivers) using the DCD language. In this paper it is shown how the DCD language and its constructs can be mapped to UML notation using the standard UML extension mechanisms. Advantages of modeling DCD using UML are numerous: uniform and standard graphical representa- tion of device capabilities, improvement in DCD development, straight- forward extension of DCD using UML notation, standard exchange text format of DCD documents using XMI (XML Metadata Interchange), etc. The deﬁnition of UML extensions for DCD contributes to the acceptance of the ASAM-GDI standard and simpliﬁes the development of ASAM- GDI tools in the future. It is also an example how similar constructs, i.e. blocks with inputs and outputs, can be speciﬁed using UML.",
    "keywords": []
  },
  {
    "title": "Swinging UML How to Make Class Diagrams and State Machines Amenable to Constraint Solving and Proving",
    "date": 2000,
    "abstract": "Swinging types (STs) provide a speciﬁcation and veriﬁcation formalism for designing software in terms of many-sorted logic. Current formalisms, be they set- or order-theoretic, algebraic or coalgebraic, rule- or net-based, handle either static system components (in terms of func- tions or relations) or dynamic ones (in terms of transition systems) and either structural or behavioral aspects, while STs combine equational, Horn and modal logic for the purpose of applying computation and proof rules from all three logics. UML provides a collection of object-oriented pictorial speciﬁcation tech- niques, equipped with an informal semantics, but hardly cares about consistency, i.e. the guarantee that a speciﬁcation has models and thus can be implemented. To achieve this goal and to make veriﬁcation possi- ble a formal semantics is indispensable. Swinging types have term models that are directly derived from the speciﬁcations. The paper takes ﬁrst steps towards a translation of class diagrams, OCL constraints and state machines into STs. Partly, we proceed along examples, partly we describe generally how, e.g., classes can be turned into signatures. Swinging types are particularly suitable for interpreting UML models because they integrate static and dynamic components. UML treats them separately, STs handle them within the same formalism. Hence, one may check, for instance, whether static operations are correctly reﬁned to local message passing primitives. A crucial point of a formal semantics of UML models is a reasonable notion of state. If constraints involve static data as well as states and state transitions, the modal-logic view on states as (implicit) predicates is less adequate than the ST representation as terms denoting tuples of attribute values, “histories” of object manipulations or compositions of substates (composite states).",
    "keywords": []
  },
  {
    "title": "UML Based Performance Modeling of Distributed Systems",
    "date": 2000,
    "abstract": "The development of distributed software systems satisfying performance requirements is achievable only spending careful attention to performance goals throughout the lifecycle, and especially from its very beginning. The aim of our approach is to encompass the perfor- mance validation task as an integrated activity within the development process of distributed systems. To this end we consider object oriented distributed systems based on UML, the Uniﬁed Modeling Language. We show how a system modeled by UML diagrams can be translated into a queueing network based performance model. The main contribution of this work consists of an extensive application to a case study of our methodological approach for the automatic generation of performance models. The considered case study falls in the domain of distributed software systems, where the proposed methodology suitably exploits and combines information derived from diﬀerent UML diagrams to generate a quite accurate performance model.",
    "keywords": []
  },
  {
    "title": "A Radical Revision of UML’s Role Concept",
    "date": 2000,
    "abstract": "UML’s current definition of the role concept comes with many problems, not the least being that it is difficult to understand and communi- cate. This paper proposes a revised UML metamodel building on a much sim- pler role definition. Moreover, it replaces the rather unusual notions of association role and association end role as well as the rarely used association generalization with the more popular concept of overloading, thereby leading to a considerable reduction in the number of modelling concepts. Despite the rather radical nature of the proposed alterations, no changes in UML notation become necessary. However, a notable change in modelling style including in particular a clearer separation of structure and interaction diagrams are among the likely effects of the proposed revision.",
    "keywords": []
  },
  {
    "title": "Ensuring Quality of Geographic Data with UML and OCL⋆",
    "date": 2000,
    "abstract": "Geographic data is the backbone of sophisticated applica- tions such as car navigation systems and Geographic Information Sys- tems (GIS). Complexity quickly arises in the production of geographic data when trying to ensure quality. We deﬁne quality as the integrity and well-formedness of the contents of the geographic data, usually enforced by external applications where constraints ensuring quality (referred to as quality constraints) are implicit, low-level and scattered throughout the application code. This has signiﬁcant consequences with respect to manageability, adaptability and reuse of these constraints. This paper explains our use of UML class diagrams as conceptual model for geographic data, and how we exploited the Object Constraint Lan- guage (OCL) for describing the quality constraints in an explicit, declar- ative and high-level way. As our use of OCL is slightly diﬀerent than it was originally intended, we present our adaptations and explain the main issues of evaluating the resulting OCL. We are conﬁdent that our speciﬁc application of OCL can be put to use in other domains where complex constraints need to be expressed in a knowledge-oriented domain.",
    "keywords": []
  },
  {
    "title": "Contextual Diagrams as Structuring Mechanisms for Designing Conﬁguration Knowledge Bases in UML",
    "date": 2000,
    "abstract": "Lower prices, shorter product cycles, and the customer indi- vidual production of highly variant products are the main reasons for the success of product conﬁguration systems in various application domains (telecommunication industry, automotive industry, computer industry). In this paper we show how to employ UML in order to design complex conﬁguration knowledge bases. We introduce the notion of contextual diagrams in order to cope with the intrinsic complexity of conﬁgura- tion knowledge. Since domain experts mostly think in terms of contexts, this approach leads to a more intuitive way of modeling conﬁguration knowledge.",
    "keywords": []
  },
  {
    "title": "The UML Family: Profiles, Prefaces and Packages",
    "date": 2000,
    "abstract": "This paper overviews the status of UML (Unified Modeling Language) considered as a family of languages, and reviews critically various approaches to defining variants of UML within this family.",
    "keywords": []
  },
  {
    "title": "Validating UML Models and OCL Constraints",
    "date": 2000,
    "abstract": "The UML has been widely accepted as a standard for mod- eling software systems and is supported by a great number of CASE tools. However, UML tools often provide only little support for vali- dating models early during the design stage. Also, there is generally no substantial support for constraints written in the Object Constraint Lan- guage (OCL). We present an approach for the validation of UML models and OCL constraints that is based on animation. The USE tool (UML- based Speciﬁcation Environment) supports developers in this process. It has an animator for simulating UML models and an OCL interpreter for constraint checking. Snapshots of a running system can be created, in- spected, and checked for conformance with the model. As a special case study, we have applied the tool to parts of the UML 1.3 metamodel and its well-formedness rules. The tool enabled a thorough and systematic check of the OCL well-formedness rules in the UML standard.",
    "keywords": []
  },
  {
    "title": "Modular Architecture for a Toolset Supporting OCL",
    "date": 2000,
    "abstract": "The practical application of the Object Constraint Language, which is part of the UML speciﬁcation since version 1.1, depends cru- cially on the existence of adequate tool support. This paper discusses general design issues for OCL tools. It is argued that the nature of OCL will lead to a large variety of tools, applied in combination with a variety of diﬀerent UML tools. Therefore, a ﬂexible modular architecture for a UML/OCL toolset is proposed. The paper reports on the ﬁrst results of an ongoing project which aims at the provision of such an OCL toolset for the public domain.",
    "keywords": []
  },
  {
    "title": "Consistency Checking and Visualization of OCL Constraints⋆",
    "date": 2000,
    "abstract": "Part of the success of the Uniﬁed Modeling Language (UML) as a speciﬁcation language is due to its diagrammatic nature. Its mean- ing is expressed by its meta model, a combination of class diagrams and constraints written in the Object Constraint Language (OCL), a textual language of expressions. Recent eﬀorts have tried to give a formal seman- tics to OCL in a classical way. In this paper, we propose a graph-based semantics for OCL and a systematic translation of OCL constraints into expressions over graph rules. Besides providing a semantical formaliza- tion of OCL, this translation can be employed to check the consistency of UML model instances wrt. the constraints , using a general purpose graph transformation machine like AGG or PROGRES. The translation of OCL constraints into graph rules suggests a way to express the con- straints in a more intuitive visual form.",
    "keywords": []
  },
  {
    "title": "Strict Profiles: Why and How",
    "date": 2000,
    "abstract": "The definition of a clean profile mechanism will play a crucial role in the UML's future in terms of how useful it will be to modellers and how well tool vendors may implement the new facilities. Unfortunately, in an attempt to restrict profile definitions to a single meta level, predefined modeling elements are currently specified exclusively at the meta-model level, and therefore can be applied solely through the mechanism of meta-instantiation. We identify the problems associated with such a restriction and explain why model level inheri- tance also has a role to play in the definition of predefined modeling elements. We point out the fundamental differences and relationships between the two mechanisms in the context of defining UML profiles and provide guidelines as to which mechanism should be used under which circumstance. We conclude by describing the necessity for the use of both mechanisms in the definition of UML profiles within a strict metamodeling framework.",
    "keywords": []
  },
  {
    "title": "Dynamic Meta Modeling: A Graphical Approach to the Operational Semantics of Behavioral Diagrams in UML",
    "date": 2000,
    "abstract": "In this paper, dynamic meta modeling is proposed as a new approach to the operational semantics of behavioral UML diagrams. The dynamic meta model extends the well-known static meta model by a speciﬁcation of the system’s dynamics by means of collaboration dia- grams. In this way, it is possible to deﬁne the behavior of UML diagrams within UML. The conceptual idea is inherited from Plotkin’s structured operational semantics (SOS) paradigm, a style of semantics speciﬁcation for concur- rent programming languages and process calculi: Collaboration diagrams are used as deduction rules to specify a goal-oriented interpreter for the language. The approach is exempliﬁed using a fragment of UML state- chart and object diagrams. Formally, collaboration diagrams are interpreted as graph transformation rules. In this way, dynamic UML semantics can be both mathematically rigorous so as to enable formal speciﬁcations and proofs and, due to the use of UML notation, understandable without prior knowledge of heavy mathematic machinery. Thus, it can be used as a reference by tool developers, teachers, and advanced users.",
    "keywords": [
      "UML meta model",
      "statechart diagrams",
      "precise behavioral semantics",
      "graph transformation"
    ]
  },
  {
    "title": "Interacting Subsystems in UML",
    "date": 2000,
    "abstract": "In this paper we give a description of the subsystem con- struct in the Uniﬁed Modeling Language, emphasizing its dynamic as- pects, thus giving a detailed description of the semantics of interaction with subsystems. Depending on whether the surroundings of the subsys- tem make use of public elements in the subsystem or not, the subsystem is considered to be open or closed, respectively. This leads to two diﬀer- ent ways to use the services of the subsystem: either importing it and directly accessing its public elements, or associating it and only com- municating with the subsystem itself. We also discuss some implications which closed subsystems have on collaborations.",
    "keywords": []
  },
  {
    "title": "Consistent Behaviour Representation in Activity and Sequence Diagrams",
    "date": 2000,
    "abstract": "The paper proposes a formal approach for constructing UML activity diagrams from sequence diagrams by using graph transformations. Activity diagrams are good at describing the overall flow of control in a system, as they provide support for conditional and parallel behaviour, but do not capture well object interactions. Activity diagrams are mostly used in the preliminary stages of analysis and design. As the design progresses, more detailed descriptions of object interactions become necessary, and interaction diagrams are used for this purpose. During the transition from a high level to a detailed design, the mapping between the behavior represented in activity diagrams and that described in interaction diagrams may be lost, and the two views may become inconsistent. By reconstructing the activity diagrams from sequence diagrams, consistency is re-enforced. Every activity block is cross-referenced with the corresponding sequence diagram messages, which helps designers to correlate the two views. The transformation from sequence to activity diagrams is based on PROGRES, a known visual language and environment for programming with graph rewriting systems.",
    "keywords": []
  },
  {
    "title": "Using UML Collaboration Diagrams for Static Checking and Test Generation",
    "date": 2000,
    "abstract": "Software testing can only be formalized and quantiﬁed when a solid basis for test generation can be deﬁned. Tests are commonly gen- erated from program source code, graphical models of software (such as control ﬂow graphs), and speciﬁcations/requirements. UML collabo- ration diagrams represent a signiﬁcant opportunity for testing because they precisely describe how the functions the software provides are con- nected in a form that can be easily manipulated by automated means. This paper presents novel test criteria that are based on UML collab- oration diagrams. The most novel aspect of this is that tests can be generated automatically from the software design, rather than the code or the speciﬁcations. Criteria are deﬁned for both static and dynamic testing of speciﬁcation-level and instance-level collaboration diagrams. These criteria allow a formal integration tests to be based on high level design notations, which can help lead to software that is signiﬁcantly more reliable.",
    "keywords": []
  },
  {
    "title": "Supporting Several Levels of Restriction in the UML",
    "date": 2000,
    "abstract": "The emergence of the Unified Modeling Language (UML) has provided software developers with an effective and efficient shared language. However, UML is often too restrictive in initial, informal, and creative modelling, and it is in some cases not restrictive enough, e.g., for code generation. Based on user studies, we propose that tool and meta-level support for several levels of restriction in diagrams and models is needed. We furthermore present a tool, Knight, which supports several levels of restriction as well as ways of transferring models from one level of restriction to another. This approach potentially increases the usability of the UML, and thus ultimately leads to greater quality and adoption of UML models.",
    "keywords": []
  },
  {
    "title": "A UML-Based Methodology for Hypermedia Design",
    "date": 2000,
    "abstract": "We propose a methodology for hypermedia design which is based on a UML profile for the hypermedia domain. Starting with a use case analysis and a conceptual model of the application we first provide guidelines for modeling the navigation space. From the navigation space model we can derive, in a next step, a navigational structure model which shows how to navigate through the navigation space using access elements like indexes, guided tours, queries and menus. Finally, a presentation model is constructed that can be directly implemented by HTML frames. The different models of the design process are represented by using a hypermedia extension of UML.",
    "keywords": []
  },
  {
    "title": "Object Oriented Methodology Based on UML for Urban Traffic System Modeling",
    "date": 2000,
    "abstract": "This paper proposes an object-oriented modeling methodology, which is based on global and structured UTS modeling approach, using UML We show how UML diagrams are used in our methodology and why. The first part of this paper is dedicated to the domain analysis (generic) and shows which diagram to use. In the second part, we deal with system dedicated analysis. We then present a real case study we have dealt with.",
    "keywords": []
  },
  {
    "title": "Extending OCL to Include Actions",
    "date": 2000,
    "abstract": "The UML’s Object Constraint Language provides the modeller of object-oriented systems with ways to express the semantics of a model in a precise and declarative manner. The constraints which can be expressed in this language, all state requirements on the static aspects of the system. The Object Constraint Language currently lacks a way to express that events have happened or will happen, that signals are or will be send, or that operations are or will be called.",
    "keywords": []
  },
  {
    "title": "A Structured Approach to Develop Concurrent Programs in UML ⋆",
    "date": 2000,
    "abstract": "This paper presents a methodology to develop synchroniza- tion code based on the global invariant (GI) approach in the context of the Uniﬁed Process in UML. This approach has the following advantages: (1) it is a formal approach that enables formal veriﬁcation of programs being developed, (2) the most important activity in the programming process lies at a high level; namely, speciﬁcation of GIs, (3) GIs are plat- form independent, and (4) existing GIs may be composed to produce GIs for more complex synchronization. We provide a set of useful GIs which work as basic patterns. Programmers can compose these GIs to produce appropriate GIs for speciﬁc applications.",
    "keywords": []
  },
  {
    "title": "Describing AI Analysis Patterns with UML",
    "date": 2000,
    "abstract": "We discuss the use of the UML to describe “Analysis Patterns” in AI, an area where OAD techniques are not widely used, in spite of the fact that some of the inspiration for the object approach can be traced to developments in this area. We study the relation between the notion of analysis pattern in the context of OO software development methods, and that of Generic Task in AI software development methods such as CommonKADS. Our interest is motivated by the belief that in the analysis and design of certain AI applications, particularly in Distributed AI, OO style patterns may be more appropriate than Generic Tasks. To illustrate the relation between these concepts, we provide a UML description of the heuristic multiattribute decision pattern, a corresponding Generic Task having already been proposed in the literature. We illustrate the wide applicability of this pattern by specialising it to obtain a therapy decision pattern. We discuss the suitability of the UML, together with OCL, for describing this and other analysis patterns arising in AI.",
    "keywords": []
  },
  {
    "title": "Precise Modeling of Design Patterns",
    "date": 2000,
    "abstract": "Design Patterns are now widely accepted as a useful con- cept for guiding and documenting the design of object-oriented software systems. Still the UML is ill-equipped for precisely representing design patterns. It is true that some graphical annotations related to parame- terized collaborations can be drawn on a UML model, but even the most classical GoF patterns, such as Observer, Composite or Visitor cannot be modeled precisely this way. We thus propose a minimal set of modiﬁ- cations to the UML 1.3 meta-model to make it possible to model design patterns and represent their occurrences in UML, opening the way for some automatic processing of pattern applications within CASE tools. We illustrate our proposal by showing how the Visitor and Observer patterns can be precisely modeled and combined together using our UM- LAUT tool. We conclude on the generality of our approach, as well as its perspectives in the context of the deﬁnition of UML 2.0.",
    "keywords": []
  },
  {
    "title": "Architectural Patterns for Metamodeling:  \nThe Hitchhiker’s Guide to the UML Metaverse",
    "date": 2000,
    "abstract": "Metamodels are playing an increasingly important role in the specification of distributed object and component architectures, such as CORBA, CORBA Component Model, Enterprise JavaBeans and DCOM/COM+. By recursively abstracting the details associated with implementation, metamodels improve rigor and facilitate system integration and interoperability. The uses of metamodels range from specifying modeling languages and metadata repositories to defining data interchange formats and software processes (methods).",
    "keywords": []
  },
  {
    "title": "Reconciling the Needs of Architectural Description with Object-Modeling Notations",
    "date": 2000,
    "abstract": "Complex software systems require expressive notations for representing their software architectures. Two competing paths have emerged. One is to use a specialized notation for architecture – or architecture description language (ADL). The other is to adapt a general-purpose modeling notation, such as UML. The latter has a number of benefits, including familiarity to developers, close mapping to im- plementations, and commercial tool support. However, it remains an open question as to how best to use object-oriented notations for architectural description, and, indeed, whether they are sufficiently expressive, as currently defined. In this paper we take a systematic look at these questions, examining the space of possible mappings from ADLs into object notations. Specifically, we describe (a) the principle strategies for representing architectural structure in UML; (b) the benefits and limitations of each strategy; and (c) aspects of architectural description that are intrinsically difficult to model in UML using the strategies.",
    "keywords": []
  },
  {
    "title": "Towards a UML Profile for Software Architecture Descriptions",
    "date": 2000,
    "abstract": "To formally describe architectures of software systems, specific lan- guages called Architecture Description Languages (ADLs) have been developed by academic institutions and research labs. However, more and more research and industrial projects are using the standard Unified Modeling Language (UML) for representing software architectures of systems. In this paper, we fo- cus on how to extend the UML by incorporating some key abstractions found in current ADLs, such as connectors, components and configurations, and how the UML can be used for modeling architectural viewpoints. Our approach is dem- onstrated by the software architecture of a video surveillance system. It is there- fore the purpose of the paper to show that a UML profile for software architec- ture abstractions is needed. Keywords: Software architecture abstractions, software architecture descrip- tion, architectural modeling, architectural viewpoint, architectural view, ADL, UML, connector, component, configuration.",
    "keywords": []
  },
  {
    "title": "Rewrite Rules and Operational Semantics for Model Checking UML Statecharts",
    "date": 2000,
    "abstract": "Model checking of UML statecharts is the main concern of this pa- per. To model check it, however, its description has to be translated into the in- put language of the model checker SMV. For the purpose of translating UML statecharts as closely as possible into SMV, we use rewrite rules and its opera- tional semantics.",
    "keywords": []
  },
  {
    "title": "Part-Whole Statecharts for the Explicit\nRepresentation of Compound Behaviours",
    "date": 2000,
    "abstract": "Although very eﬀective, the adoption of Statecharts in object- oriented software development methods poses many problems, since their way to compose behavioral abstractions can be framed in the general con- text of implicit composition. In particular, the need to embed references from one behavioral description to other ones has mayor drawbacks since the description of a single entity behaviour is not self-contained, and the global behaviour results implicitly deﬁned by following references from one entity to the other. In other words, both single and global behav- iors are diﬃcult to understand, modify and reuse. The paper proposes to overcome most of such problems by adopting Part-Whole Statecharts, whose primary policy for controlling complexity strictly enforces distinct layers for wholes and their parts. Since wholes may become parts of other aggregations, a recursive syntax and semantics can be given straightfor- wardly.",
    "keywords": []
  },
  {
    "title": "Modeling of Architectures with UML Panel",
    "date": 2000,
    "abstract": "A critical level of abstraction in the modeling of a large, complex system is its architecture. At an architectural level one models the principal system elements and their interaction. Architectural models are typically used to provide an intellectually tractable, birds-eye view of a system and to permit design-time reasoning about system-level concerns such as performance, reliability, portability, and conformance to external standards and architectural styles. In practice most architectural descriptions are informal documents. They are usually centered on box-and-line diagrams, with explanatory prose. Visual conventions are idiosyncratic, and usually project specific. As a result, architectural descriptions are only vaguely understood by developers, they cannot be analyzed for consistency or completeness, they are only hypothetically related to implementations, their properties cannot be enforced as a system evolves, and they cannot be supported by tools to help software architects with their tasks. There exist several architecture description languages, but we are interested in the use of UML. We aim to identify requirements on architectural modeling and how different modeling concepts of UML meet these requirements. This paper is not intended as a critique of the UML but as a discussion of approaches to modeling architectures that have been tried, more or less successfully.*",
    "keywords": []
  },
  {
    "title": "The Preacher at Arrakeen",
    "date": 2001,
    "abstract": "In the Dune novels, Paul Atreides ﬁghts a battle for sur- vival against nefarious forces and succeeds in uniting the Universe under his control. Eventually, however, a bureaucratic and militaristic religion grows up around his legend. Disillusioned by the atrocities committed in his name, Paul abandons his throne and returns in disguise as the mys- terious Preacher at Arrakeen to denounce the bureaucracy, fanaticism, and tyranny of his out-of-control followers. Sometimes that’s how I feel about UML. This talk (sermon?) will denounce the excesses of the UML cult and see if it can be saved from its friends.",
    "keywords": []
  },
  {
    "title": "An Action Semantics for MML",
    "date": 2001,
    "abstract": "This paper describes an action semantics for UML based on the Meta-Modelling Language (MML) - a precise meta-modelling lan- guage designed for developing families of UML languages. Actions are deﬁned as computational procedures with side-eﬀects. The action seman- tics are described in the MML style, with model, instance and semantic packages. Diﬀerent actions are described as specializations of the basic action in their own package. The aim is to show that by using a Cataly- sis like package extension mechanism, with precise mappings to a simple semantic domain, a well-structured and extensible model for an action language can be obtained.",
    "keywords": []
  },
  {
    "title": "The Essence of Multilevel Metamodeling",
    "date": 2001,
    "abstract": "As the UML attempts to make the transition from a sin- gle, albeit extensible, language to a framework for a family of languages, the nature and form of the underlying meta-modeling architecture will assume growing importance. It is generally recognized that without a simple, clean and intuitive theory of how metamodel levels are created and related to one another, the UML 2.0 vision of a coherent family of languages with a common core set of concepts will remain elusive. However, no entirely satisfactory metamodeling approach has yet been found. Current (meta-)modeling theories used or proposed for the UML all have at least one fundamental problem that makes them unsuitable in their present form. In this paper we bring these problems into focus, and present some fundamental principles for overcoming them. We be- lieve that these principles need to be embodied within the metamodeling framework ultimately adopted for the UML 2.0 standard.",
    "keywords": []
  },
  {
    "title": "Mapping between Levels in the Metamodel\nArchitecture",
    "date": 2001,
    "abstract": "The Meta-Modeling Language is a static object-oriented modeling language whose focus is the declarative definition of languages. It aims to enable the UML metamodel to be precisely defined, and to enable UML to evolve into a family of languages. This paper argues that although MML takes a metamodeling approach to language definition, it cannot be described as strict metamodeling. This has significant implications for the nature of the metamodel architecture it supports, yet without contravening the OMG’s requirements for the UML 2.0 infrastructure. In particular it supports a rich generic nested architecture as opposed to the linear architecture that strict metamodeling imposes. In this nested architecture, the transformation of any model between its representations at two adjacent metalevels can be described by an information preserving one-to-one mapping. This mapping, which can itself be defined in UML, provides the basis for a powerful area of functionality that any potential metamodeling tool should seek to exploit.",
    "keywords": []
  },
  {
    "title": "An Execution Algorithm for UML Activity Graphs",
    "date": 2001,
    "abstract": "We present a real-time execution semantics for UML activity graphs that is intended for workﬂow modelling. The semantics is deﬁned in terms of execution algorithms that deﬁne how components of a work- ﬂow system execute an activity graph. The semantics stays close to the semantics of UML state machines, but diﬀers from it in some minor points. Our semantics deals with real time. The semantics provides a basis for veriﬁcation of UML activity graphs, for example using model checking, and also for executing UML activity graphs using simulation tools. We illustrate an execution by means of a small example.",
    "keywords": []
  },
  {
    "title": "Timing Analysis of UML Activity Diagrams⋆",
    "date": 2001,
    "abstract": "UML activity diagrams can be used for modeling the dy- namic aspects of systems and for constructing executable systems through forward and reverse engineering. They are very suitable for de- scribing the model of program behaviour. In this paper, we extend UML activity diagrams by introducing timing constraints so that they can be used to model real-time software systems, and give the solution for tim- ing analysis of UML activity diagrams. We give the solution for timing analysis of simple UML activity diagrams (containing no loop) by linear programming, and present an algorithm for checking UML activity dia- grams using integer time veriﬁcation techniques. This work forms a base for veriﬁcation of real-time software systems.",
    "keywords": []
  },
  {
    "title": "UML Activity Diagrams as a Workﬂow Speciﬁcation Language",
    "date": 2001,
    "abstract": "If UML activity diagrams are to succeed as a standard in the area of organisational process modeling, they need to compare well to alternative languages such as those provided by commercial Workﬂow Management Systems. This paper examines the expressiveness and the adequacy of activity diagrams for workﬂow speciﬁcation, by systemati- cally evaluating their ability to capture a collection of workﬂow patterns. This analysis provides insights into the relative strengths and weaknesses of activity diagrams. In particular, it is shown that, given an appropriate clariﬁcation of their semantics, activity diagrams are able to capture situ- ations arising in practice, which cannot be captured by most commercial Workﬂow Management Systems. On the other hand, the study shows that activity diagrams fail to capture some useful situations, thereby suggesting directions for improvement.",
    "keywords": []
  },
  {
    "title": "On Querying UML Data Models with OCL",
    "date": 2001,
    "abstract": "UML is the de-facto standard language for Object-Oriented analysis and design of information systems. Persistent storage and extraction of data in such systems is supported by databases and query languages. UML sustains many aspects of software engineering; however, it does not provide explicit facility for writing queries. It is crucial for any such query language to have, at least, the expressive power of Relational Algebra, which serves as a benchmark for evaluating its expressiveness. The combination of UML and OCL can form queries with the required expressive power. However, certain extensions to OCL are essential if it is to be used effectively as a Query Language. The adoption of the ideas presented in this paper will enable query expressions to be written using OCL, that are elegant and ideally suited for use in conjunction with UML data models. This technique is illustrated by expressing the UML equivalent of an example Relational data model and associated query expressions.",
    "keywords": []
  },
  {
    "title": "OCL as a Speciﬁcation Language for Business Rules in Database Applications",
    "date": 2001,
    "abstract": "Business rules are often speciﬁed only implicitly by appli- cations to express user-deﬁned constraints. OCL provides the chance to explicitly and automatically deal with business rules when building object-oriented applications. We investigate how OCL constraints can be handled in database applications as one of the most important kind of business applications. Based on our OCL toolset prototype and ear- lier research work we particularly experiment with various strategies for the evaluation of OCL constraints in object-oriented applications which use relational databases. For this work, a ﬂexible SQL code generator is needed which can be used and adapted for diﬀerent relational database systems and diﬀerent object-to-table mappings. We implement such a database tool as an additional module for our OCL toolset using XML techniques.",
    "keywords": []
  },
  {
    "title": "A Formal Semantics for OCL 1.4",
    "date": 2001,
    "abstract": "The OCL 1.4 speciﬁcation introduces let-declarations for adding auxiliary class features in static structures of the UML. We pro- vide a type inference system and a big-step operational semantics for the OCL 1.4 that treat UML static structures and UML object models abstractly and accommodate for additional declarations; the operational semantics satisﬁes a subject reduction property with respect to the type inference system. We also discuss an alternative, non-operational inter- pretation of let-declarations as constraints.",
    "keywords": []
  },
  {
    "title": "Refactoring UML Models",
    "date": 2001,
    "abstract": "Software developers spend most of their time modifying and maintaining existing products. This is because systems, and consequently their design, are in perpetual evolution before they die. Nevertheless, dealing with this evolution is a complex task. Before evolving a sys- tem, structural modiﬁcations are often required. The goal of this kind of modiﬁcation is to make certain elements more extensible, permitting the addition of new features. However, designers are seldom able to evaluate the impact, on the whole model, of a single modiﬁcation. That is, they cannot precisely verify if a change modiﬁes the behavior of the modeled system. A possible solution for this problem is to provide designers with a set of basic transformations, which can ensure behavior preservation. These transformations, also known as refactorings, can then be used, step by step, to improve the design of the system. In this paper we present a set of refactorings and explain how they can be designed so as to preserve the behavior of a UML model. Some of these refactorings are illustrated with examples.",
    "keywords": []
  },
  {
    "title": "UML Support for Designing Software Systems as a\nComposition of Design Patterns",
    "date": 2001,
    "abstract": "Much of the research work on design patterns has primarily focused on discovering and documenting patterns. Design patterns promise early reuse benefits at the design stage. To reap the benefits of deploying these proven de- sign solutions, we need to develop techniques to construct applications using patterns. These techniques should define a composition mechanism by which patterns can be integrated and deployed in the design of software applications. Versatile design models should be used to model the patterns themselves as well as their composition. In this paper, we describe an approach called Pattern- Oriented Analysis and Design (POAD) that utilizes UML modeling capabilities to compose design patterns at various levels of abstractions. In POAD, the in- ternal details of the pattern structure are hidden at high design levels (pattern views) and are revealed at lower design levels (class views). We define three hierarchical traceable logical views based on UML models for developing pat- tern-oriented designs; namely the Pattern-Level view, the Pattern Interfaces view, and the Detailed Pattern-Level view. The discussion is illustrated by a case study of building a framework for feedback control systems.",
    "keywords": [
      "Pattern-Oriented Design",
      "Design Patterns",
      "and Pattern Composition."
    ]
  },
  {
    "title": "Integrating the ConcernBASE Approach with SADL",
    "date": 2001,
    "abstract": "We describe ConcernBASE, a UML-based approach that is an instanti- ation of the IEEE’s Conceptual Framework (Std 1471) for describing software architectures. We show how the approach supports advanced separation of con- cerns in software architecture by allowing one to identify and define multiple viewpoints, concern spaces and views of an architecture. Our work focuses on integrating the ConcernBASE approach with the Structural Architecture Descrip- tion Language (SADL) in order to make the verification capabilities of SADL available to those who develop in UML. The result is a UML profile for structural description of software architecture. The paper also presents a prototype tool that supports this UML profile.",
    "keywords": [
      "Software Architecture",
      "Unified Modeling Language",
      "UML",
      "Structural Architecture Description",
      "SADL",
      "Advanced Separation of Concerns."
    ]
  },
  {
    "title": "The Message Paradigm in Object-Oriented Analysis",
    "date": 2001,
    "abstract": "The message paradigm is one of the most specific concepts of object orientation. This paradigm works well as long as one object is involved. When more than one object is involved, a choice has to be made with which type the message will be associated. In our opinion, this choice has to be postponed during object-oriented analysis. We propose to extend the concept of the message paradigm to messages with more than one implicit argument. Postponing the choice results in one model for one reality. Another problem rises when no object is involved. In our opinion this issue can best be tackled by introducing a domain layer and a functionality layer.",
    "keywords": []
  },
  {
    "title": "A UML-Based Approach to System Testing",
    "date": 2001,
    "abstract": "System testing is concerned with testing an entire system based on its specifications. In the context of object-oriented, UML development, this means that system test requirements are derived from UML analysis artifacts such as use cases, their corresponding sequence and collaboration diagrams, class diagrams, and possibly the use of the Object Constraint Language across all these artifacts. Our goal is to support the derivation of test requirements, which will be transformed into test cases, test oracles, and test drivers once we have detailed design information. Another important issue we address is the one of testability. Testability requirements (or rules) need to be imposed on UML artifacts so as to be able to support system testing efficiently. Those testability requirements result from a trade-off between analysis and design overhead and improved testability. The potential for automation is also an overriding concern all across our work as the ultimate goal is to fully support testing activities with high-capability tools.",
    "keywords": []
  },
  {
    "title": "UML Modelling and Performance Analysis\nof Mobile Software Architectures",
    "date": 2001,
    "abstract": "Modern distributed software applications generally operate in complex and heterogeneous computing environments (like the World Wide Web). Different paradigms (client-server, mobility based, etc.) have been suggested and adopted to cope with the complexity of designing the software architecture of distributed applications for such environments, and deciding the \"best\" paradigm is a typical choice to be made in the very early software design phases. Several factors should drive this choice, one of them being the impact of the adopted paradigm on the application performance. Within this framework, the contribute of this paper is twofold: we suggest an extension of UML to best modeling the possible adoption of mobility-based paradigms in the software architecture of an application; we introduce a complete methodology that, starting from a software architecture described using this extended notation, generates a performance model (namely a Markov Reward or Decision Process) that allows the designer to evaluate the convenience of introducing logical mobility into a software application.",
    "keywords": [
      ".  Distributed  systems",
      "Architecture  modelling",
      "Extensions",
      "Performance analysis",
      "Mobile components"
    ]
  },
  {
    "title": "Extending UML for Object-Relational Database Design",
    "date": 2001,
    "abstract": "The most common way of designing databases is using de E/R model without taking into account other views of the system. However, new object-oriented design languages, such as UML (Unified Modelling Language), permit modelling the full system, including the database schema, in a uniform way. Besides, as UML is an extensible language, it allows introducing new stereotypes for specific applications if it is needed. There are some proposals to extend UML with stereotypes for database design but, unfortunately, they are focused on relational databases. However, new applications require representing complex objects related with complex relationships and object-relational databases are more appropriated to support the new application requirements. The framework of this paper is an Object- Relational Database Design Methodology. The methodology defines new UML stereotypes for Object-Relational Database Design and proposes some guidelines to translate an UML schema into an object-relational one. The guidelines are based on the SQL:1999 object-relational model and on Oracle8i as an example of product. In this paper we focus on the UML extensions required for object-relational database design.",
    "keywords": [
      "UML extensions",
      "Stereotypes",
      "Database Design",
      "Object- Relational Databases",
      "Design Methodology",
      "UML",
      "SQL1999",
      "Oracle8i"
    ]
  },
  {
    "title": "Understanding UML – Pains and Rewards",
    "date": 2001,
    "abstract": "UML is there – it’s accepted, it’s booming, and even more: it’s a standard. From telecom to train systems to avionics: using UML to capture the system is “in”. But do we really understand what we model? This talk takes for granted, that models are alive, are executable, are used to explore the design space, are used to communicate design decisions, and ultimately are evolving to target code. And it asks plenty of nasty questions about the meaning of all these diagrams, which are so intuitive, but which require clariﬁcation if viewed from the most rigorous possible perspective – that of a formal semantics. Formal Semantics are to modeling languages what X rays are to the human body: they bring to the surface problem spots not typically seen – and this process is painful. It shows, that what we see, is possibly far from what we expect: it highlights design decisions in giving a rigorous semantics to UML, which could have signiﬁcant impact on e.g. meeting timeliness requirements. But it also shows the rewards derivable from this painful exercise: giv- ing a rigorous semantics oﬀers the ﬂoor for powerful analysis techniques allowing to boost the quality of models.",
    "keywords": []
  },
  {
    "title": "A Formal Semantics of UML State Machines\nBased on Structured Graph Transformation⋆",
    "date": 2001,
    "abstract": "UML state machines are quite popular and useful to specify dynamic components of software systems. They have a formal static se- mantics but their execution semantics is described only informally. Graph transformation, on the other hand, constitutes a well-studied area with many theoretical results and practical application domains. In this paper, an operational semantics for a subset of UML state machines is proposed which is based on graph transformation. In more detail, a UML state ma- chine is described as a structured graph transformation system in such a way that the wellformedness rules of UML state machines are satisﬁed and the ﬁring of a (maximum) set of enabled non-conﬂicting transitions corresponds to the application of a graph transformation rule. The pre- sented approach uses the concept of transformation units, a recently developed modularization concept for graph transformation systems.",
    "keywords": []
  },
  {
    "title": "A Visualization of OCL Using Collaborations⋆",
    "date": 2001,
    "abstract": "We propose a visualization of OCL within the context of the UML meta model, so that OCL expressions are represented by extending collaboration diagrams. We exploit the OCL meta model introduced in [9] and further elaborated on in [1] and base the description of properties of objects on collaborations, while classiﬁer and association roles are used to describe navigation paths. Operations computing properties are described by interactions consisting of messages between classiﬁer roles. The introduction of new graphical core elements is kept to a minimum. New notation mainly concerns the predeﬁned operations in OCL and provides more convenient visual forms for the notation by interactions here. The proposed visualization is described in detail and is illustrated with examples taken from an industrial project under development.",
    "keywords": []
  },
  {
    "title": "Rule-Based Speciﬁcation of Behavioral\nConsistency Based on the UML Meta-model",
    "date": 2001,
    "abstract": "Object-oriented modeling favors the modeling of object behavior from diﬀerent viewpoints and at diﬀerent levels of abstrac- tion. This gives rise to consistency problems between overlapping or semantically related submodels. The absence of a formal semantics for the UML and the numerous ways of employing the language within the development process lead to a number of diﬀerent consistency notions. Therefore, general meta-level techniques are required for specifying, analyzing, and communicating consistency constraints. In this paper, we discuss the issue of consistency of behavioral models in the UML and present techniques for specifying and analyzing consistency. Using meta-model rules we transform elements of UML models into a semantic domain. Then, consistency constraints can by speciﬁed and validated using the language and the tools of the semantic domain. This general methodology is exempliﬁed by the problem of protocol statechart inheritance.",
    "keywords": [
      "meta modeling",
      "model veriﬁcation",
      "behavioral consistency"
    ]
  },
  {
    "title": "A New UML Profile for Real-Time System Formal\nDesign and Validation",
    "date": 2001,
    "abstract": "UML solutions in competition on the real-time system market share three common drawbacks: an incomplete formal semantics, temporal operators with limited expression and analysis power, and implementation-oriented tools with limited verification capabilities. To overcome these limitations, the paper proposes a UML profile designed with real-time system validation in mind. Extended class diagrams with associations attributed by composition operators give an explicit semantics to associations between classes. Enhanced activity diagrams with a deterministic delay, a non deterministic delay and a time- limited offering make it possible to work with temporal intervals in lieu of timers with fixed duration. The UML profile is given a precise semantics via its translation into the Formal Description Technique RT-LOTOS. A RT-LOTOS validation tool generates simulation chronograms and reachability graphs for RT-LOTOS specifications derived from UML class and activity diagrams. A coffee machine serves as example. The proposed profile is under evaluation on a satellite-based software reconfiguration system.",
    "keywords": []
  },
  {
    "title": "Representing Embedded System Sequence Diagrams as a\nFormal Language",
    "date": 2001,
    "abstract": "Sequence Diagrams (SDs) have proven useful for describing transaction-oriented systems, and can form a basis for creating statecharts. However, distributed embedded systems require special support for branching, state information, and composing SDs. Actors must traverse many SDs when using a complex embedded system. Current techniques are insufficiently rich to represent the behavior of real systems, such as elevators, without augmentation, and cannot identify the correct SD to execute next from any given state of the system. We propose the application of formal language theory to ensure that SDs (which can be thought of as specifying a grammar) have sufficient information to create statecharts (which implement the automata that recognize that grammar). A promising approach for SD to statechart synthesis then involves ‘compiling‘ SDs represented in an LL(1) grammar into statecharts, and permits us to bring the wealth of formal language and compiler theory to bear on this problem area.",
    "keywords": []
  },
  {
    "title": "Scenario-Based Monitoring and\nTesting of Real-Time UML Models",
    "date": 2001,
    "abstract": "In this paper it is shown how Sequence Diagrams can be used both for monitoring and testing functional and real-time requirements of an executable UML design. We show how this testing approach can be integrated in an UML-based development process. In addition, we will present how a prototype which implements the described monitoring and testing methods is integrated in a well known UML design tool.",
    "keywords": []
  },
  {
    "title": "Semantics of the Minimum Multiplicity in Ternary\nAssociations in UML",
    "date": 2001,
    "abstract": "The concept of multiplicity in UML derives from that of cardinality in entity-relationship modeling techniques. The UML documentation defines this concept but at the same time acknowledges some lack of obviousness in the specification of multiplicities for n-ary associations. This paper shows an ambiguity in the definition given by UML documentation and proposes a clarification to this definition, as well as a simple extension to the current notation to represent other multiplicity constraints, such as participation constraints, that are equally valuable in understanding n-ary associations.",
    "keywords": []
  },
  {
    "title": "Extending UML to Support Ontology Engineering for the Semantic Web",
    "date": 2001,
    "abstract": "There is rapidly growing momentum for web enabled agents that reason about and dynamically integrate the appropriate knowledge and services at run-time. The World Wide Web Consortium and the DARPA Agent Markup Language (DAML) program have been actively involved in furthering this trend. The dynamic integration of knowl- edge and services depends on the existence of explicit declarative seman- tic models (ontologies). DAML is an emerging language for specifying machine-readable ontologies on the web. DAML was designed to sup- port tractable reasoning.",
    "keywords": []
  },
  {
    "title": "On Associations in the Uniﬁed Modelling Language",
    "date": 2001,
    "abstract": "Associations between classiﬁers are among the most funda- mental of UML concepts. However, there is considerable room for dis- agreement concerning what an association is, semantically. These have implications for the modeller because they can result in serious misunder- standings of static structure diagrams; similarly, they have implications for tool developers. In this paper we describe and classify the variants which have implicitly or explicitly been described. We discuss the scope for, and diﬃculties in, understanding these as specialisations of a more general notion and we address the implications for future versions of UML.",
    "keywords": []
  },
  {
    "title": "iState: A Statechart Translator",
    "date": 2001,
    "abstract": "We describe formal steps in the design of iState, a tool for translating statecharts into programming languages. Currently iState generates code in either Pascal, Java, or the Abstract Machine Notation of the B method. The translation proceeds in several phases. The focus of this paper is the formal description of the intermediate representations, for which we use class diagrams together with their textual counterparts. We describe how the class diagrams are further reﬁned. The notions of representable, normalized, and legal statecharts are introduced, where normalized statecharts appear as an intermediate representation and code is generated only for legal statecharts.",
    "keywords": []
  },
  {
    "title": "Specifying Concurrent System Behavior and Timing \nConstraints Using OCL and UML",
    "date": 2001,
    "abstract": "Despite advances in implementation technologies for distributed sys- tems during the last few years, little attention has been given to distributed sys- tems within software development methodologies. The contribution of this paper is a UML-based approach for specifying concurrent behavior and timing con- straints—often inherent characteristics of distributed systems. We propose a novel approach for specifying concurrent behavior of reactive systems in OCL and several constructs for precisely describing timing constraints on UML state- machines. More precisely, we show how we enriched operation schemas—pre- and post- condition assertions of system operations written in OCL—by extending the cur- rent calculus with constructs for asserting synchronization on shared resources. Also, we describe how we use new and existing constructs for UML statema- chines to specify timing constraints on the system interface protocol (SIP)—a restricted form of UML protocol statemachine. Finally, we discuss how both the extended system operation and SIP models are complementary. Keywords: Unified Modeling Language (UML), Object Constraint Language (OCL), Pre- and Postcondition, Software System Specification, Concurrent Pro- gramming, Timing Constraints.",
    "keywords": []
  },
  {
    "title": "Formalization of UML-Statecharts",
    "date": 2001,
    "abstract": "The Uniﬁed Modeling Language (UML) has gained wide acceptance in very short time because of its variety of well-known and intuitive graphical notations. However, this comes at the prize of an unprecise and incomplete se- mantics deﬁnition. This insufﬁciency concerns single UML diagram notations on their own as well as their integration. In this paper, we focus on the notation of UML-Statecharts. Starting with a precise textual syntax deﬁnition, we develop quite a concise structured operational semantics (SOS) for UML-Statecharts based on labeled transition systems. Besides the support of interlevel transitions and in contrast to related work, our semantics deﬁnition supports characteristic UML- Statechart features like the history mechanism as well as entry and exit actions.",
    "keywords": []
  },
  {
    "title": "UML for Agent-Oriented Software Development:\nThe Tropos Proposal*",
    "date": 2001,
    "abstract": "We describe a software development methodology called Tropos for agent-oriented software systems. The methodology adopts the i* modeling framework [29], which offers the notions of actor, goal and (actor) dependency, and uses these as a foundation to model early and late requirements, architectural and detailed design. The paper outlines the methodology, and shows how the concepts of Tropos can be accommodated within UML. In addition, we also adopt recent proposals for extensions of UML to support design specifications for agent software. Finally the paper compares Tropos to other research on agent-oriented software development.",
    "keywords": []
  },
  {
    "title": "A UML Meta-model for Contract Aware Components⋆",
    "date": 2001,
    "abstract": "We present an extension to the UML meta-model which al- lows modelling of contract aware components. Contracts are a novel way of describing the functional and non-functional behaviour of components. The usage of contracts in component diagrams allows tools to check whether all requirements for a successful assembly and deployment of the components are fulﬁlled. Furthermore, we investigate how compo- nents can be used in the diﬀerent development phases and how design phase transitions can be managed.",
    "keywords": []
  },
  {
    "title": "A Speciﬁcation Model for Interface Suites⋆",
    "date": 2001,
    "abstract": "The paper describes a model and tool support for a UML- based speciﬁcation approach, extending UML with templates for struc- tured speciﬁcations deriving from the ISpec approach. The approach is component-oriented where the unit of description is an interface suite: a coherent collection of interfaces deﬁning interactions that transcend component boundaries. To handle complexity, descriptions from various points of view are necessary, expressed by UML diagrams, templates, etc. The issue is to ensure that the views are consistent. For this, we pro- vide a model to integrate the views. The model is sequence-based; the elements of the sequences are carefully designed tuples that reﬂect the interface suite approach. Abstractions from the model reﬂect the views. The model provides the underlying structure for tooling. We developed extensions to Rational Rose by customizing speciﬁcations, automating diagram generation and enabling some consistency checks.",
    "keywords": []
  },
  {
    "title": "Against Use Case Interleaving",
    "date": 2001,
    "abstract": "Use cases are a powerful and widely recognised tool for functional requirements elicitation and specification of prospective software applications. However, there still are major problems and misunderstandings about the use case approach. One of these is the troublesome notion of use case interleaving which is discussed in this work. Interleaving is still present in the current UML specification. A. Simons correctly realised that interleaving compares with goto/comefrom semantics that were already judged harmful by Dijkstra at the emergence of the Structured Programming era. Simons, thus, has requested the explicit dropping of interleaving semantics. The authors give further support for Simons´ request by showing that interleaving causes severe inconsistencies within UML and contradicts other proven and practically relevant use case concepts such as Goal-Based Use Cases of A. Cockburn, and contractual specifications of use cases expressed by pre- and postcondition approaches. Significant fixes to UML are proposed, in addition to those suggested by Simons. These will dramatically clarify prevailing problems and confusion with use cases and use case relationships among both practitioners and researchers.",
    "keywords": []
  },
  {
    "title": "Estimating Software Development Effort Based on Use\nCases – Experiences from Industry",
    "date": 2001,
    "abstract": "Use case models are used in object-oriented analysis for capturing and describing the functional requirements of a system. Several methods for estimating software development effort are based on attributes of a use case model. This paper reports the results of three industrial case studies on the application of a method for effort estimation based on use case points. The aim of this paper is to provide guidance for other organizations that want to improve their estimation process applying use cases. Our results support existing claims that use cases can be used successfully in estimating software development effort. The results indicate that the guidance provided by the use case points method can support expert knowledge in the estimation process. Our experience is also that the design of the use case models has a strong impact on the estimates.",
    "keywords": [
      "Use cases",
      "estimation",
      "industrial experience"
    ]
  },
  {
    "title": "Workshops and Tutorials at the UML 2001 Conference",
    "date": 2001,
    "abstract": "As part of the UML 2001 conference, nine tutorials and ﬁve workshops were held. In the following a brief summary of these events is given, including references for further information.",
    "keywords": []
  },
  {
    "title": "Descriptions in Software Development",
    "date": 2002,
    "abstract": "The central activity in software development is the creation and use of descriptions. We make descriptions to capture our understand- ing of requirements, to describe the properties of the problem domain, to design the behaviour and structure of the software we are building, and for many other purposes too. To work eﬀectively we must make our descriptions as exact as possible, and this is one goal of the designers of formal notations. But we must also be clear-headed about the purpose and subject matter of each descrip- tion. As John von Neumann observed: “There is no point in using exact methods where there is no clarity in the concepts and issues to which they are to be applied”. Without a clear understanding of the purpose and subject matter of each description we can easily lose much of the beneﬁt of eﬀective notations. This talk presents a view of software development based on the notion of problem frames. Each problem frame is associated with a class of simple problems, and with a set of concerns that arise in the solution of problems of the class. Making and using descriptions are seen as activities aimed at addressing those concerns.",
    "keywords": []
  },
  {
    "title": "A Metamodel for the Unified Modeling Language",
    "date": 2002,
    "abstract": "\u0006 \u00141\u0010\u0018\u0010,\u000e\u0006\u000f\u0014\u0018 \u000e \u0006%\u0010.5 %\u0006.5\u0010\u0011\u00060\u0014\u0018 \u0006* 0\u0014\u000f \u0006.5 \u0006\u0015 ,\u0006\u0010%.&/\u00100.\u000e \u0014/\u0006\u000e\u0014/.1\u0010% \u0006\u0018 9 \u0014\"\u000f \u0011.\u0003\u0006\u0013\u0014\u0011\u000e \b \u0011. , \u0006.5&\u000e\u0006%\u0010&\u000e \u000e\u0006.5 \u0006 9 \u0006\u0014/\u0006% \b &% \u0004 \u000f \u0011.\u000e\u0006/\u0014%\u0006\u000f\u0014\u0018 &\u0011'\u0006 \u0010\u0011' \u0010' \u000e\u0006\u0014\u0011\u000615&05\u0006\u000f\u0014\u0018 &\u0011'\u0006\"%\u00100.&.&\u0014\u0011 %\u000e\u0006\u000e5\u0014 \u0018 % ,\u0006&\u0011\u0006.5 &%\u00061\u0014%\u0015\u0003\u0006+\u0006\u000f&\u0011\u0014%\u0006&\u00110\u0014\u0011\u000e&\u000e. \u00110,\u0006\u0014/\u0006\u0010\u0006\u000f\u0014\u0018 &\u0011'\u0006 \u0010\u0011' \u0010' \u0006\u000f .\u0010\u0004 \u000f\u0014\u0018 \u0006 \u000f\u0010,\u0006 0\u0010 \u000e \u0006 \u000f\u0010:\u0014%\u0006 \"%\u0014* \u000f\u000e\u0006 &\u0011\u0006 .5 \u0006 \u0010\u0011' \u0010' \u0006 \u0010\"\" &0\u0010.&\u0014\u0011\u000e;\u0006 .5 \u000e 1&.5\u0006.5 \u0006\u000f\u0014\u0018 \u0006\u0018%&9 \u0011\u0006\u000e,\u000e. \u000f\u000e\u0006\u0018 9 \u0014\"\u000f \u0011.\u0006.5 \u0006\u000e\u0014 &\u0018\u0011 \u000e\u000e\u0006\u0014/\u0006\u000f\u0014\u0018 &\u0011' \u0010\u0011' \u0010' \u000e\u0006 \u000f .\u0010\u000f\u0014\u0018 \u000e\u0006 * 0\u0014\u000f \u000e\u0006 \"\u0010%.&0 \u0010% ,\u0006 &\u000f\"\u0014%.\u0010\u0011.\u0003\u0006 3\u0011\u0006 &.\u000e\u0006 0 %% \u0011. \u000e.\u0010. \u0006 .5 \u0006 \u001b\u0005 \u0006 \u000f .\u0010\u000f\u0014\u0018 \u0006 \u00109 \u000e\u0006 \u0010\u0006 \u000e&'\u0011&/&0\u0010\u0011.\u0006 \u0010% \u0010\u0006 /\u0014%\u0006 &\u000f\"%\u00149 \u000f \u0011.\u0003 - \u0006\"% \u000e \u0011.\u0006\u0010\u0011\u0006\u0010 . %\u0011\u0010.&9 \u0006\u000f .\u0010\u000f\u0014\u0018 \u0006.5\u0010.\u00061\u0010\u000e\u0006&\u0011\u000e\"&% \u0018\u0006*,\u0006.5 \u0006<\u0005\u0004=>7 \u000e.\u0010\u0011\u0018\u0010%\u0018\u0006 \u0010\u0011\u0018\u0006 .5\u0010.\u0006 \u000e\u0014 9 \u000e\u0006 .5 \u0006 \"%\u0014* \u000f\u000e\u0006 \u0014/\u0006 \u001b\u0005 \u0003\u0006 <\u0005\u0004=>7\u0006 1\u0010\u000e\u0006 \u000f \u0011\u0004 .&\u0014\u0011 \u0018\u0006 &\u0011\u0006 \u001b\u0005 \u0006 \u000e\" 0&/&0\u0010.&\u0014\u0011\u000e\u0006 \u0010\u000e\u0006 \u0010\u0006 /%\u0010\u000f 1\u0014%\u0015\u0006 .5\u0010.\u0006 5\u0010\u000e\u0006 \u0010 % \u0010\u0018,\u0006 &\u0011/ \u0004 \u00110 \u0018\u0006\u001b\u0005 \u0003\u0006= %\u0006\u000f .\u0010\u000f\u0014\u0018 \u00061\u0010\u000e\u0006/\u0014%\u000f\u0010 &\u0007 \u0018 \u0006.5 \u000e\u0006&.\u000e\u0006% \u000e .&\u0011'\u0006\u000f\u0014\u0018 \u000e 0\u0010\u0011\u0006* \u0006\u000e&\u000f \u0010. \u0018\u0006\u0010\u0011\u0018\u000605 0\u0015 \u0018\u0006/\u0014%\u00060\u0014\u0011\u000e&\u000e. \u00110,\u0003\u0006\u0012\u0014 \u0006\u0014 %\u0006\"%\u0014\"\u0014\u000e \u0018\u0006\u000e\u0014 \u0004 .&\u0014\u0011\u0006 1&.5\u0006 0\u0014\u0011\u000e.% 0.&9 \u0006 \"\u0014. \u0011.&\u0010 \u0006 .\u00141\u0010%\u0018\u000e\u0006 &\u000f\"%\u00149 \u000f \u0011.\u0006 \u0014/\u0006 .5 \u0006 \u001b\u0005 \u000f .\u0010\u000f\u0014\u0018 \u0006\u000f\u0010,\u00065\u00109 \u0006\u0010\u0006\u000e&'\u0011&/&0\u0010\u0011.\u0006\"%\u00100.&0\u0010 \u0006&\u000f\"\u00100.\u0006\u0014\u0011\u0006.5 \u0006\u001b\u0005 \u0006\u000e\" 0&\u0004 /&0\u0010.&\u0014\u0011\u000e\u0003",
    "keywords": []
  },
  {
    "title": "Metamodeling Mathematics:\nA Precise and Visual Framework\nfor Describing Semantics Domains\nof UML Models⋆",
    "date": 2002,
    "abstract": "As UML 2.0 is evolving into a family of languages with in- dividually speciﬁed semantics, there is an increasing need for automated and provenly correct model transformations that (i) assure the integra- tion of local views (diﬀerent diagrams) of the system into a consistent global view, and, (ii) provide a well–founded mapping from UML mod- els to diﬀerent semantic domains (Petri nets, Kripke automaton, pro- cess algebras, etc.) for formal analysis purposes as foreseen, for instance, in submissions for the OMG RFP for Schedulability, Performance and Time. However, such transformations into diﬀerent semantic domains typically require the deep understanding of the underlying mathemat- ics, which hinders the use of formal speciﬁcation techniques in industrial applications. In the paper, we propose a UML-based metamodeling tech- nique with precise static and dynamic semantics (based on a reﬁnement calculus and graph transformation) where the structure and operational semantics of mathematical models can be deﬁned in a UML notation without cumbersome mathematical formulae. Keywords: metamodeling, formal semantics, reﬁnement, model trans- formation, graph transformation",
    "keywords": []
  },
  {
    "title": "A Radical Reduction of UML’s Core Semantics",
    "date": 2002,
    "abstract": "UML’s current core semantics suffers both from excessive com- plexity and from being overly general. Resultant is a language definition that is difficult to master and to repair. This is the more disturbing as the current core and its extensions do very little to integrate statics and dynamics, even though the inseparability of these is a property of software from which many of the modelling difficulties arise. To better this unsatisfactory situation, we suggest a simple modelling core with few concepts that are easy to understand, yet cover most static and dynamic modelling aspects. We present our work, which is founded in elementary set theory, in natural language making it equally accessible for both practitioners and formalists.",
    "keywords": []
  },
  {
    "title": "Conﬁguration Knowledge Representation\nUsing UML/OCL",
    "date": 2002,
    "abstract": "Today’s economy is exhibiting a growing trend towards high- ly specialized solution providers cooperatively oﬀering conﬁgurable prod- ucts and services to their customers. In this context, knowledge based conﬁgurators which support the conﬁguration of complex products and services, must be enhanced with capabilities of knowledge sharing and distributed conﬁguration problem solving. In this paper we demonstrate how UML/OCL can be used as knowledge representation language sup- porting standardized knowledge interchange thus enabling cooperative problem solving by diﬀerent conﬁguration environments. We show the representation of conﬁguration domain speciﬁc types of constraints in OCL and present an OCL based knowledge acquisition workbench which enables conﬁguration knowledge base development, maintenance and in- terchange.",
    "keywords": []
  },
  {
    "title": "Using UML for Information Modeling in Industrial\nSystems with Multiple Hierarchies",
    "date": 2002,
    "abstract": "Traditionally, information models for industrial plants have been for- mulated based on domain-specific languages and tools satisfying the require- ments of given standards like IEC 750, IEC 61346 or the Power Station Designation System (KKS). There is however a trend in the automation industry to use common IT standards like XML and UML. The current paper shows our experiences in applying UML for information mod- eling of industrial plant applications, which typically consist of multiple struc- tural hierarchies. We introduce a meta-model, which describes, how the information models can be expressed in UML. Further, we discuss a simple case study, which applies this model in the context of ABB`s Industrial IT platform. Finally, we describe our experiences with UML-based modeling in this domain and discuss the differences between a UML-based representation and the con- cepts of IEC 61346.",
    "keywords": [
      ". Industrial experience",
      "Metamodelling",
      "Business modelling."
    ]
  },
  {
    "title": "Adapting the UML\nto Business Modelling’s Needs - Experiences\nin Situational Method Engineering",
    "date": 2002,
    "abstract": "In 1999 the Swiss Mobiliar Insurance Company (Mobiliar) started a program to transform to a process oriented organization. Based on reengineered business processes, the refocusing of the informa- tion system infrastructure was strived. To ensure a uniﬁed methodical procedure during this transformation a competence center was founded. It supports project speciﬁc needs by situational method engineering. At inception PROMET BPR and the Uniﬁed Modeling Language (UML) were chosen. During the ﬁrst projects, the requirements for method sup- port changed from being purely process engineered, to a focus of sup- porting process improvement. This paper characterizes the phases and the speciﬁc needs they raise. It shows the evolution and integration of the method fragments. Thereby, the main focus is to describe how the concepts of UML would be linked in particular to ratios of process man- agement in the meta-model of this reengineered method.",
    "keywords": [
      "linking business and technical requirements",
      "application and extensions of the UML",
      "situational method engineering"
    ]
  },
  {
    "title": "Analysis of UML Stereotypes\nwithin the UML Metamodel",
    "date": 2002,
    "abstract": "Stereotypes are a powerful and potentially expressive exten- sion mechanism in the Uniﬁed Modeling Language (UML). However, it seems that stereotypes are diﬃcult to handle because using stereotypes needs an understanding of the UML metamodel and, in particular, an un- derstanding of OCL constraints. Stereotypes are often applied in a wrong or at least sloppy way without proper declaration. There are also diﬀer- ences between the various versions of UML with respect to subtle details in the stereotype part. A graphical syntax for stereotypes including ex- amples has been introduced only late in UML 1.4. Other diﬃculties are that constraints are used in the stereotype context in two completely diﬀerent ways and that no full support of stereotypes is yet oﬀered by tools. The paper points out these diﬃculties in detail, analyses the UML metamodel part dealing with stereotypes, and makes various suggestions for improving the deﬁnition and use of stereotypes.",
    "keywords": []
  },
  {
    "title": "Stereotypical Encounters of the Third Kind",
    "date": 2002,
    "abstract": "As one of the UML’s main extension mechanisms, stereoty- pes play a crucial role in the UML’s ability to serve a wide and growing base of users. However, the precise meaning of stereotypes and their in- tended mode of use has never been entirely clear and has even generated much debate among experts. Two basic ways of using UML stereotypes have been observed in practice: one to support the classiﬁcation of classes as a means of emulating metamodel extensions, the other to support the classiﬁcation of objects as a means of assigning them certain properties. In this paper we analyze these two recognized stereotype usage scenarios and explain the rationale for explicitly identifying a third form of usage scenario. We propose some notational concepts which could be used to explicitly distinguish the three usage scenarios and provide heuristics as to when each should be used. Finally, we conclude by proposing enhan- cements to the UML which could support all three forms cleanly and concisely.",
    "keywords": []
  },
  {
    "title": "Digging into Use Case Relationships",
    "date": 2002,
    "abstract": "\u0006\u001b\u000e \u00060\u0010\u000e \u0006\u0018&\u0010'%\u0010\u000f\u000e\u0006\u0010% \u0006\u0014\u0011 \u0006\u0014/\u0006.5 \u0006\u0015 ,\u00060\u0014\u00110 \".\u000e\u0006&\u0011\u0006.5 \u0006\u001b\u0011&/& \u0018 \u0005\u0014\u0018 &\u0011'\u0006 \u0010\u0011' \u0010' \u0006* .\u0006.5 &%\u0006\u000e \u000f\u0010\u0011.&0\u000e\u0006\u0010\u0011\u0018\u0006\u0011\u0014.\u0010.&\u0014\u0011\u00065\u00109 \u0006\u000e\u0014\u000f \u0006'\u0010\"\u000e .5\u0010.\u0006 \u0010\u0018\u0006.\u0014\u0006/% \b \u0011.\u0006\u000f&\u000e \u0011\u0018 %\u000e.\u0010\u0011\u0018&\u0011'\u000e\u0006\u0010\u000f\u0014\u0011'\u0006\"%\u00100.&.&\u0014\u0011 %\u000e \u0006 9 \u0011\u0006\u0010*\u0014 . 9 %,\u0006*\u0010\u000e&0\u0006\b \u000e.&\u0014\u0011\u000e\u0003\u00063\u0011\u0006.5&\u000e\u0006\"\u0010\" %\u00061 \u0006\u0010\u0018\u0018% \u000e\u000e\u0006\u000e\u0014\u000f \u0006&\u000e\u000e \u000e\u0006% '\u0010%\u0018&\u0011'\u0006.5 % \u0010.&\u0014\u0011\u000e5&\"\u000e\u0006&\u0011\u000615&05\u0006 \u000e \u00060\u0010\u000e \u000e\u0006\u000f\u0010,\u0006.\u0010\u0015 \u0006\"\u0010%.\u0003\u000645 \u00063\u00110 \u0018 \u0006\u0010\u0011\u0018\u0006\u0017?. \u0011\u0018 % \u0010.&\u0014\u0011\u000e5&\"\u000e\u0006 * .1 \u0011\u0006 .1\u0014\u0006 \u000e \u0006 0\u0010\u000e \u000e\u0006 5\u00109 \u0006 \"% \u000e \u0011. ,\u0006 \u0010\u0011\u0006 &\u00110\u0014\u0011\u000e&\u000e. \u0011. \u0018 /&\u0011&.&\u0014\u0011 \u0006\u000e&\u00110 \u0006.5 ,\u0006\u0010% \u0006% \"% \u000e \u0011. \u0018\u0006\u0010\u000e\u0006\u000e. % \u0014.,\" \u0018\u0006\u0018 \" \u0011\u0018 \u00110& \u000e \u0006* . .5 ,\u0006\u0010% \u0006\u0011\u0014.\u0006.% \u0006\u0018 \" \u0011\u0018 \u00110& \u000e\u0006&\u0011\u0006.5 \u0006\u000f .\u0010\u000f\u0014\u0018 \u0003\u0006) \u000e&\u0018 \u000e \u0006.5 \u0006\u0018&% 0.&\u0014\u0011 \u0014/\u0006.5 \u0006\u0018 \" \u0011\u0018 \u00110,\u0006\u0010%%\u00141\u0006&\u0011\u0006.5 \u0006\u0017?. \u0011\u0018\u0006% \u0010.&\u0014\u0011\u000e5&\"\u00060\u0010\u0011\u0006* \u0006\u000f&\u000e \u0010\u0018&\u0011' \u0011\u0011\u0010. %\u0010 \u0006 \u0010\u0011\u0018\u0006 \u0018&//&0 .\u0006 .\u0014\u0006 \u0011\u0018 %\u000e.\u0010\u0011\u0018\u0006 /\u0014%\u0006 .5 \u0006 0\u0014\u000f\u000f\u0014\u0011\u0006 \"%\u00100.&.&\u0014\u0011 %\u0003 2&\u0011\u0010 , \u00061 \u0006\u000e5\u00141\u0006\u0010 \u000e\u0014\u0006\u000e\u0014\u000f \u00060\u0014\u00110 \". \u0010 \u0006\"%\u0014* \u000f\u000e\u0006% '\u0010%\u0018&\u0011'\u0006.5 \u0006&\u00110 \u0018 \u0018 \u0014%\u0006 ?. \u0011\u0018&\u0011'\u0006 \u000e \u00060\u0010\u000e \u000e \u000615&05\u0006&\u0011\u0006\u0014 %\u0006\u0014\"&\u0011&\u0014\u0011\u0006\u0010% \u0006\u0011\u0014.\u0006.% \u0006 \u000e \u00060\u0010\u000e \u000e\u0003",
    "keywords": []
  },
  {
    "title": "Practical Experiences in the Application of MDA",
    "date": 2002,
    "abstract": "\u0006 > %&\u0011'\u0006 .5 \u0006 \u0010\u000e.\u0006 . \u0011\u0006 , \u0010%\u000e\u0006 \u0010\u0006 \u0014.\u0006 \u0014/\u0006 \u0006 0\u0014\u00110 \".\u000e\u0006 5\u00109 \u0006 \u000f %' \u0018 /%\u0014\u000f\u0006\u000e\u0014/.1\u0010% \u0006 \u0011'&\u0011 %&\u0011'\u0003\u0006\u0005\u0014\u000e.\u0006\u0014/\u0006.5 \u000f\u0006.%,\u0006.\u0014\u0006/\u0014%\u000f\u0010 &\u0007 \u0006\u0010\u0011\u0018\u0006\u0014%'\u0010\u0011&\u0007 \u000e\u0014/.1\u0010% \u0006 \u0011'&\u0011 %&\u0011'\u0006\u0015\u0011\u00141 \u0018' \u0006\u0010.\u0006\u0010\u00065&'5 %\u0006 9 \u0006\u0014/\u0006\u0010*\u000e.%\u00100.&\u0014\u0011 \u0006'&9&\u0011' 0\u0014\u0018 \u0006\u0010\u0006\u000e 0\u0014\u0011\u0018\u0010%,\u0006%\u0014 \u0003\u0006\u0005\u0014\u0018 \u0006>%&9 \u0011\u0006+%05&. 0. % \u0006\u0016\u0005>+\u0019 \u0006\" ..&\u0011'\u0006.5 0\u0014\u00110 \".\u0006\u0014/\u0006.5 \u0006\u000f\u0014\u0018 \u0006\u0014\u0011\u0006.5 \u00060%&.&0\u0010 \u0006\"\u0010.5\u0006\u0014/\u0006\u000e\u0014/.1\u0010% \u0006\u0018 9 \u0014\"\u000f \u0011. \u0006&\u000e \u0010*\u0014 .\u0006.\u0014\u000605\u0010\u0011' \u0006.5&\u000e\u0006\u000e&. \u0010.&\u0014\u0011 \u0006. %\u0011&\u0011'\u0006.5 \u0006%\u0014 \u0006\u0014/\u0006\u000f\u0014\u0018 \u000e\u0006/%\u0014\u000f\u00060\u0014\u0011. \u000f\u0004 \" \u0010.&9 \u0006.\u0014\u0006\"%\u0014\u0018 0.&9 \u0003\u000645&\u000e\u0006\"\u0010\" %\u0006&\u0011.%\u0014\u0018 0 \u000e\u0006\u000e\u0014\u000f \u0006\"%\u0014* \u000f\u000e\u0006\u0018 . 0. \u0018\u0006&\u0011 .5 \u0006\"%\u00140 \u000e\u000e\u0006\u0014/\u0006\u0010\u0018\u0014\".&\u0014\u0011\u0006\u0014/\u0006\u0005>+\u0006\u000f .5\u0014\u0018\u000e\u0003\u000645 \u0006\u0010\"\" &0\u0010.&\u0014\u0011\u0006\u0014/\u0006\u0005>+\u0006/\u0014% \u0010\u0006\u000e\" 0&/&0\u0006\u0018\u0014\u000f\u0010&\u0011 \u0006. 05\u0011&\b \u0006\u0014%\u0006. 05\u0011\u0014 \u0014',\u0006% \b &% \u000e\u0006.5 \u0006Description of Specialized Modeling Language\u0003\u000641\u0014\u0006\u000f\u0010&\u0011\u0006. 05\u0011&\b \u000e\u0006\"%\u00149&\u0018 \u0006\u000e \"\"\u0014%. /\u0014%\u0006 .5 \u0006 \u0018 \u000e0%&\".&\u0014\u0011\u0006 \u0014/\u0006 \u001b\u0005 \u0006 ?. \u0011\u000e&\u0014\u0011\u000e \u0006 MOF meta-models\u0006 \u0010\u0011\u0018\u0006 UML profiles\u0003\u000645 \u0006Process of Mapping Description\u0006% \b &% \u000e\u0006'\u0014\u0014\u0018\u0006\u000e \"\"\u0014%.\u0006.\u0014 &\u0018 \u0011.&/,\u0006.5 \u0006 \u000f \u0011.\u000e\u0006\u0014/\u0006.5 \u0006\u000e\u0014 %0 \u0006\u000f\u0014\u0018 &\u0011'\u0006 \u0010\u0011' \u0010' \u0006.5\u0010.\u0006\u0010% \u0006\u000f\u0010\"\" \u0018 \u0010\u0011\u0018\u0006.5 \u0006\u000f\u0014\u0018 \u0006 \u000f \u0011.\u000e\u0006\u0014/\u0006.5 \u0006\u0018 \u000e.&\u0011\u0010.&\u0014\u0011\u0006\u000f\u0014\u0018 &\u0011'\u0006 \u0010\u0011' \u0010' \u0006.5\u0010.\u00060\u0014%% \u0004 \u000e\"\u0014\u0011\u0018\u0006.\u0014\u0006.5 \u0006\u000e\u0014 %0 \u0006 \u000f \u0011.\u000e\u0003\u000645&\u000e\u0006\"%\u00140 \u000e\u000e\u0006% \b &% \u0006\u000e\" 0&/&0\u0006\u000e\u0014 .&\u0014\u0011\u000e\u0003",
    "keywords": []
  },
  {
    "title": "Executable Design Models\nfor a Pervasive Healthcare Middleware System",
    "date": 2002,
    "abstract": "UML is applied in the design of a pervasive healthcare mid- dleware system for the hospitals in Aarhus County, Denmark. It works well for the modelling of static aspects of the system, but with respect to describing the behaviour, UML is not suﬃcient. This paper explains why and, as a remedy, suggests to supplement the UML models with behaviour descriptions in the modelling language Coloured Petri Nets, CPN. CPN models are executable and ﬁne-grained, and a combined use of UML and CPN thus supports design-time investigation of the detailed behaviour of system components. In this way, the behavioural conse- quences of alternative design proposals may be evaluated and compared, based on models and prior to implementation.",
    "keywords": [
      "Executable models",
      "detailed behaviour",
      "Petri nets",
      "CPN",
      "system design",
      "middleware",
      "pervasive and mobile computing",
      "supple- menting UML."
    ]
  },
  {
    "title": "Generating Code from UML\nwith Velocity Templates",
    "date": 2002,
    "abstract": "The value of automated code generation is increasingly rec- ognized, and the application model becomes the central artefact in the software development process. Model-driven development requires a rapid and ﬂexible code generation mechanism. This paper discusses code generation based on templates that actively access UML model in- formation to ﬁll an implementation skeleton. Diﬀerent templates result in diﬀerent generated code, providing a highly ﬂexible generation mecha- nism. Along with a discussion on the potential of such a code generation, an existing framework for code generation with templates is presented.",
    "keywords": []
  },
  {
    "title": "Does Your Software Creak as It Runs?",
    "date": 2002,
    "abstract": "We are often so overwhelmed with the diﬃculty of writing logically correct software that we tend to underplay or even ignore the inﬂuence of the underlying computing platform. In some cases, this negli- gence has been raised to the level of a design principle, based on a danger- ously naive interpretation of the idea of “platform independence”. After all, it is the platform that gives life to our logic and, as we demonstrate, its eﬀect on software can be profound. We argue that software is not as far removed from physics as many imagine (or hope), that quantity can aﬀect quality, and that, paradoxically, true platform independence cannot be achieved unless the platform is properly factored into design. We then outline a general approach that addresses this issue and show how it can be realized with UML.",
    "keywords": []
  },
  {
    "title": "Integrating the Synchronous Paradigm into\nUML: Application to Control-Dominated\nSystems",
    "date": 2002,
    "abstract": "The Synchronous Paradigm proposes an abstract model in- tegrating concurrency and communication, deterministic thus simple, semantically well-founded thus suitable to formal analysis, producing safe and eﬃcient code. However combining this model with the object- oriented approach is still challenging. This paper explores how an UML- based methodology can be set up, making it possible to use the Syn- chronous Paradigm in combination with other (more classical) techniques to develop control-dominated systems. It addresses the issue of represent- ing behavior in a semantically sound way using the synchronous mod- els, of relating behavior and structure, and of mixing synchronous and asynchronous behavior though an extended notion of (ROOM-like) “cap- sules”, the synchronous islets. We also brieﬂy mention the extensions and modiﬁcations in the UML meta-model necessary to support this method- ology.",
    "keywords": []
  },
  {
    "title": "A UML Proﬁle for Real-Time Constraints\nwith the OCL",
    "date": 2002,
    "abstract": "This article presents a UML proﬁle for an OCL extension that enables modelers to specify behavioral, state-oriented real-time con- straints in OCL. In order to perform a seamless integration into the upcoming UML2.0 standard, we take the latest OCL2.0 metamodel pro- posal by Warmer et al. [22] as a basis. A formal semantics of our temporal OCL extension is given by a mapping to time-annotated temporal logics formulae. To give an example of the applicability of our extension, we consider a modeling approach for manufacturing systems called MFERT. We present a corresponding UML proﬁle for that approach and combine both proﬁles for formal veriﬁcation by real-time model checking.",
    "keywords": []
  },
  {
    "title": "HOL-OCL: Experiences, Consequences\nand Design Choices",
    "date": 2002,
    "abstract": "Based on experiences gained from an embedding of the Ob- ject Constraint Language (OCL) in higher-order logic [3], we explore several key issues of the design of a formal semantics of the OCL. These issues comprise the question of the interpretation of invariants, pre- and postconditions, an executable sub-language and the possibilities of reﬁne- ment notions. A particular emphasize is put on the issue of mechanized deduction in UML/OCL speciﬁcation. Keywords: OCL, formal semantics, constraint languages, reﬁnement",
    "keywords": []
  },
  {
    "title": "Consistency-Preserving Model Evolution\nthrough Transformations",
    "date": 2002,
    "abstract": "With model-based development being on the verge of becom- ing an industrial standard, the topic of research of statically checking the consistency of a model made up of several submodels has already received increasing attention. The evolution of models within software engineer- ing requires support for incremental consistency analysis techniques of a new version of the model after evolution, thereby avoiding a complete reiteration of all consistency tests. In this paper, we discuss the problem of preserving consistency within model-based evolution focusing on UML-RT models. We introduce the concept of a model transformation rule that captures an evolution step. Composition of several evolution steps leads to a complex evolution of a model. For each evolution step, we study the eﬀects on the consistency of the overall model and provide localized consistency checks for those parts of the model that have changed. For a complex evolution of a model, consistency can then be established by incrementally performing those localized consistency checks associated to the transformation rules applied within the evolution.",
    "keywords": []
  },
  {
    "title": "Transformations\nand Software Modeling Languages:\nAutomating Transformations in UML",
    "date": 2002,
    "abstract": "This paper investigates the role of transformations in the Uniﬁed Modeling Language, speciﬁcally UML class diagrams with OCL constraints. To date, the use of transformations in software modeling and design has not been fully explored. A framework for expressing trans- formations is presented along with concrete examples that, for exam- ple, infer new inheritance links, or transform constraints. In particular, a technique for checking that two UML class diagrams are refactorings of each other is described.",
    "keywords": []
  },
  {
    "title": "A Relational Approach to Defining Transformations\nin a Metamodel",
    "date": 2002,
    "abstract": "\u0006 \u0005 .\u0010\u000f\u0014\u0018 &\u0011'\u0006 &\u000e\u0006 * 0\u0014\u000f&\u0011'\u0006 \u0010\u0006 \u000e.\u0010\u0011\u0018\u0010%\u0018\u0006 1\u0010,\u0006 \u0014/\u0006 \u0018 /&\u0011&\u0011' \u0010\u0011' \u0010' \u000e\u0006 \u000e 05\u0006 \u0010\u000e\u0006 .5 \u0006 \u001b\u0005 \u0003\u0006 +\u0006 \u0010\u0011' \u0010' \u0006 \u0018 /&\u0011&.&\u0014\u0011\u0006 \u0018&\u000e.&\u0011' &\u000e5 \u000e * .1 \u0011\u0006 0\u0014\u00110% . \u0006 \u000e,\u0011.\u0010? \u0006 \u0010*\u000e.%\u00100.\u0006 \u000e,\u0011.\u0010?\u0006 \u0010\u0011\u0018\u0006 \u000e \u000f\u0010\u0011.&0\u000e\u0006 \u0018\u0014\u000f\u0010&\u0011\u0003\u0006 3.\u0006 &\u000e \"\u0014\u000e\u000e&* \u0006.\u0014\u0006\u0018 /&\u0011 \u0006\u0010 \u0006.5% \u0006 \u000e&\u0011'\u0006\u0010\u0006 \u000f .\u0010\u000f\u0014\u0018 &\u0011'\u0006\u0010\"\"%\u0014\u001005 \u0006* .\u0006&.\u0006 &\u000e \u000e\u000e\u00060 \u0010%\u00065\u00141\u0006.\u0014\u0006\u0018 /&\u0011 \u0006.5 \u0006.%\u0010\u0011\u000e/\u0014%\u000f\u0010.&\u0014\u0011\u000e\u0006* .1 \u0011\u0006.5 \u000f\u0003\u000645&\u000e\u0006\"\u0010\" % \"%\u0014\"\u0014\u000e \u000e\u0006\u0010\u0011\u0006\u0010\"\"%\u0014\u001005\u000615&05\u0006 \u000e \u000e\u0006\u000f .\u0010\u000f\u0014\u0018 &\u0011'\u0006\"\u0010.. %\u0011\u000e\u0006.5\u0010.\u00060\u0010\". % .5 \u0006 \u000e\u000e \u00110 \u0006\u0014/\u0006\u000f\u0010.5 \u000f\u0010.&0\u0010 \u0006% \u0010.&\u0014\u0011\u000e\u0003\u00063.\u0006\u000e5\u00141\u000e\u00065\u00141\u0006.5 \u000e \u0006\"\u0010.. %\u0011\u000e\u00060\u0010\u0011 * \u0006 \u000e \u0018\u0006 .\u0014\u0006 \u0018 /&\u0011 \u0006 *\u0014.5\u0006 .5 \u0006 % \u0010.&\u0014\u0011\u000e5&\"\u0006 * .1 \u0011\u0006 0\u0014\u00110% . \u0006 \u000e,\u0011.\u0010?\u0006 \u0010\u0011\u0018 \u0010*\u000e.%\u00100.\u0006\u000e,\u0011.\u0010? \u0006\u0010\u0011\u0018\u0006* .1 \u0011\u0006\u0010*\u000e.%\u00100.\u0006\u000e,\u0011.\u0010?\u0006\u0010\u0011\u0018\u0006\u000e \u000f\u0010\u0011.&0\u000e\u0006\u0018\u0014\u000f\u0010&\u0011 \u0006/\u0014% \u0010\u0006/%\u0010'\u000f \u0011.\u0006\u0014/\u0006\u001b\u0005 \u0003\u0006+\u0006'\u0014\u0010 \u0006\u0014/\u0006.5 \u0006\u0010\"\"%\u0014\u001005\u0006&\u000e\u0006.\u0014\u0006\"%\u00149&\u0018 \u0006\u0010\u00060\u0014\u000f\" . \u000e\" 0&/&0\u0010.&\u0014\u0011\u0006 \u0014/\u0006 \u0010\u0006 \u0010\u0011' \u0010' \u0006 /%\u0014\u000f\u0006 15&05\u0006 &\u0011. &' \u0011.\u0006 .\u0014\u0014 \u000e\u0006 0\u0010\u0011\u0006 * ' \u0011 %\u0010. \u0018\u0003\u0006 45 \u0006 ?. \u0011.\u0006 .\u0014\u0006 15&05\u0006 .5 \u0006 \u0010\"\"%\u0014\u001005\u0006 \u000f .\u000e\u0006 .5&\u000e\u0006 '\u0014\u0010 \u0006 &\u000e \u0018&\u000e0 \u000e\u000e \u0018\u0006&\u0011\u0006.5 \u0006\"\u0010\" %\u0003",
    "keywords": []
  },
  {
    "title": "On Customizing the UML for Modeling\nPerformance-Oriented Applications⋆",
    "date": 2002,
    "abstract": "Modeling of parallel and distributed applications was a pre- occupation of numerous research groups in the past. The increasing im- portance of applications that mix shared memory parallelism with mes- sage passing has complicated the modeling eﬀort. Despite the fact that UML represents the de-facto standard modeling language, little work has been done to investigate whether UML can be employed to model performance-oriented parallel and distributed applications. This paper provides a critical look at the utility of UML to model shared mem- ory and message passing applications by employing the UML extension mechanisms. The basic idea is to develop UML building blocks for the most important sequential, shared memory, and message passing con- structs. These building blocks can be enriched with additional infor- mation, for instance, performance and control ﬂow data. Subsequently, building blocks are combined to represent basically arbitrary complex applications. We will further describe how to model the mapping of ap- plications onto process topologies.",
    "keywords": []
  },
  {
    "title": "Extending the UML for Multidimensional\nModeling⋆",
    "date": 2002,
    "abstract": "Multidimensional (MD) modeling is the foundation of data warehouses, MD databases, and On-Line Analytical Processing (OLAP) applications. In the past few years, there have been some proposals for representing the main MD properties at the conceptual level providing their own notations. In this paper, we present an extension of the Uni- ed Modeling Language (UML), by means of stereotypes, to elegantly represent main structural and dynamic MD properties at the conceptual level. We make use of the Object Constraint Language (OCL) to specify the constraints attached to the de ned stereotypes, thereby avoiding an arbitrary use of these stereotypes. The main advantage of our proposal is that it is based on a well-known standard modeling language, thereby designers can avoid learning a new speci c notation or language for MD systems. Finally, we show how to use these stereotypes in Rational Rose 2000 for MD modeling.",
    "keywords": [
      "UML",
      "UML extensions",
      "multidimensional modeling",
      "OCL",
      "Ra- tional Rose"
    ]
  },
  {
    "title": "A Metamodel for Package Extension with Renaming",
    "date": 2002,
    "abstract": "7\u00100\u0015\u0010' \u0006 ?. \u0011\u000e&\u0014\u0011\u0006\u0010\u0011\u0018\u0006. \u000f\" \u0010. \u0006\u000f 05\u0010\u0011&\u000e\u000f\u000e\u00061 % \u0006\u0014%&'&\u0011\u0010 , \"%\u0014\"\u0014\u000e \u0018\u0006\u0010\u000e\u0006\"\u0010%.\u0006\u0014/\u0006.5 \u0006\u0013\u0010.\u0010 ,\u000e&\u000e\u0006\u000f .5\u0014\u0018\u0003\u00063.\u00065\u0010\u000e\u0006\u000e&\u00110 \u0006* \u0011\u0006\u000e '' \u000e. \u0018 .5\u0010.\u0006 .5 ,\u0006 0\u0010\u0011\u0006 * \u0006 \u000e \u0018\u0006 .\u0014\u0006 0\u0010\". % \u0006 \"\u0010.. %\u0011\u000e\u0006 \u0010\u0011\u0018\u0006 /\u0014%\u0006 \u0010\u000e\" 0.\u0004\u0014%& \u0011. \u0018 \u000f\u0014\u0018 &\u0011'\u0006 \u0010\u0011\u0018\u0006 \u000f .\u0010\u000f\u0014\u0018 &\u0011'\u0003\u0006 45&\u000e\u0006 \"\u0010\" %\u0006 \"%\u00149&\u0018 \u000e\u0006 \u0010\u0006 %&'\u0014%\u0014 \u000e \u000f .\u0010\u000f\u0014\u0018 \u0006\u0018 /&\u0011&.&\u0014\u0011\u0006\u0014/\u0006.5 \u0006\"\u00100\u0015\u0010' \u0006 ?. \u0011\u000e&\u0014\u0011\u0006\u000f 05\u0010\u0011&\u000e\u000f\u0003\u00063.\u0006. %\u0011\u000e\u0006\u0014 . .5\u0010.\u0006.5 \u0006\u0018 /&\u0011&.&\u0014\u0011\u0006&\u000e\u0006\u000f\u0014% \u0006\u000e *. \u0006.5\u0010\u0011\u0006\u0014\u0011 \u0006\u000f&'5.\u0006\u0010.\u0006/&%\u000e.\u0006.5&\u0011\u0015 \u0006\u0010\u0011\u0018\u0006\u000e\u0014\u000f \u0014/\u0006.5 \u0006\u000e *. .& \u000e\u0006\u0010% \u0006 ?\"\u0014\u000e \u0018\u0006&\u0011\u0006.5 \u0006\"\u0010\" %\u0003\u000645 \u0006\"\u0010\" %\u00060\u0014\u00110 \u0018 \u000e\u00061&.5\u0006\u0010\u0011 \u00149 %9& 1\u0006 \u0014/\u0006 5\u00141\u0006 .5 \u0006 0\u0014% \u0006 \u0018 /&\u0011&.&\u0014\u0011\u0006 \u000f\u0010,\u0006 * \u0006 ?\"\u0010\u0011\u0018 \u0018\u0006 .\u0014\u0006 &\u00110 \u0018 . \u000f\" \u0010. \u000e\u0006\u0010\u0011\u0018\u0006.\u0014\u0006\u0018 \u0010 \u00061&.5\u0006\u0010\u0006%&05 %\u0006*\u0010\u000e \u0006 \u0010\u0011' \u0010' \u0003\u00064\u0014\u0014 \u0006&\u000f\" \u000f \u0011.\u0010.&\u0014\u0011 &\u000e\u0006\u0010 \u000e\u0014\u0006\u0018&\u000e0 \u000e\u000e \u0018\u0003",
    "keywords": []
  },
  {
    "title": "Applying MDA Concepts to Develop\na Domain CORBA Facility for E-learning",
    "date": 2002,
    "abstract": "A well-conceived service or facility is always based on an underlying semantic model that is independent of the target platform. However, the model may not be distilled explicitly, and this is the case with OMG’s vertical domain speciﬁcations because the model is not ex- pressed separately from its IDL interfaces. Therefore, these services and facilities have not received the recognition and use that they deserve out- side of the CORBA environment. This paper reports on the application of MDA concepts on the development of a draft proposal for a Domain CORBA Facility for e-learning. In order to maximize the utility and im- pact of the domain facility in the MDA, it was modelled in the form of a normative Platform Independent Model (PIM) expressed using UML, augmented by a normative Platform Speciﬁc Model (PSM) expressed using the UML proﬁle for CORBA and IDL interface deﬁnitions.",
    "keywords": []
  },
  {
    "title": "Rapid Development of Modular Dynamic Web Sites Using UML Tim Schattkowsky1, Marc Lohmann2",
    "date": 2002,
    "abstract": "Development of dynamic Web sites is often performed by teams consisting of graphic designers and software developers. Communication between these different team members has to be supported with a simple modeling approach that considers their different academical backgrounds. Dynamic Web sites can contain multiple modules that may reappear on different pages. Reuse of both business logic and visual design modules would be desirable. Furthermore, a considerable amount of time is usually consumed by the implementation of data flows that are already defined in the model. Rapid development is enabled by providing roundtrip engineering capabilities with support for automatic code generation. We propose a simple subset of the UML adapted to the problem domain by means of stereotypes as well as a strategy for generating code templates from such models. These templates are tailored to the tasks of each team member. This enables parallel work and automated reintegration of results.",
    "keywords": [
      "Unified Modeling Language",
      "Hypermedia",
      "WWW",
      "Object-Oriented  Design",
      "Code Generation"
    ]
  },
  {
    "title": "Software, Heal Thyself!",
    "date": 2002,
    "abstract": "Traditional software engineering is predicated on the dis- tinction between development time (when a software system is designed, built, and tested) and run time (when a software system is deployed and executed). However, increasingly software systems are expected to run continuously, adapting as they execute to changes in environment and even user requirements. For such systems the traditional distinctions break down. In this talk I explore the role of development-time models in making it possible for systems to adapt at run time. In particular, I will argue that architectural models of software systems have a pivotal part to play as an enabler for self-adaptive and self-healing systems.",
    "keywords": []
  },
  {
    "title": "The Speciﬁcation of UML Collaborations as\nInteraction Components",
    "date": 2002,
    "abstract": "One of the touchstones of Object-Oriented Design is that the management of complexity is seldom located within any single object. It should instead be an emerging property of the collaborations within a society of objects, each one of these being as simple as possible. These collaborations can easily be speciﬁed using UML collaboration diagrams. We propose to reify UML collaborations as interaction components. This allows the easy handling and reusing of interaction abstractions among components at both speciﬁcation and implementation levels. This paper focuses on the speciﬁcation of these components. We propose criteria to deﬁne the type and the “frontier” of an interaction abstrac- tion. We present a UML collaboration speciﬁcation methodology that deals with the constraints of component speciﬁcation.",
    "keywords": [
      "UML collaborations",
      "speciﬁcation methodology",
      "interaction abstractions",
      "interaction components"
    ]
  },
  {
    "title": "Measuring OO Design Metrics from UML",
    "date": 2002,
    "abstract": "\u00060 \u000e&'\u0011\u0006\u000f .%&/\u000e\u0006\u0010% \u0006 \u000e 5 \u0006\u000f \u0010\u0011\u000e\u00065\u0014%\u0006&\u000f\"%\u00146&\u0011'\u0006.- \u0006\b \u0010 &.3\u0006\u00145 \u000e\u00145.,\u0010% \u0003\u00062\u0006\u0011 \u000f* %\u0006\u00145\u0006\u0014*7 /.\u0004\u0014%& \u0011. \u0018\u0006\u000f .%&/\u000e\u0006-\u00106 \u0006* \u0011\u0006\u000e '' \u000e. \u0018\u0006\u0010\u000e * &\u0011'\u0006 - \"5 \u0006 5\u0014%\u0006 % \u000e\u0014 %/ \u0006 \u0010 \u0014/\u0010.&\u0014\u0011\u0006 &\u0011\u0006 \u000e\u00145.,\u0010% \u0006 \u0018 6 \u0014\"\u000f \u0011.\u0003\u0006 +- \u000e \u000f .%&/\u000e\u0006\u0010% \u0006\"\u0010%.&/ \u0010% 3\u0006 \u000e 5 \u00065\u0014%\u0006&\u0018 \u0011.&53&\u0011'\u00065\u0010 .\u0004\"%\u0014\u0011 \u0006/ \u0010\u000e\u000e \u000e\u0006\u0010\u0011\u0018\u00065\u0014% \"% \u0018&/.&\u0011'\u0006 % \b &% \u0018\u0006 \u000f\u0010&\u0011. \u0011\u0010\u0011/ \u0006 55\u0014%.\u000e \u0006 \"%\u0014\u0018 /.&6&.3 \u0006 \u0010\u0011\u0018\u0006 % ,\u0014%\u0015\u0006 5\u0004 5\u0014%.\u000e\u0003\u0006+\u0014\u0006\u0014*.\u0010&\u0011\u0006.- \u0006\u0018 \u000e&'\u0011\u0006\u000f .%&/\u000e\u0006\u00145\u0006.- \u0006\u000e\u00145.,\u0010% \u0006 \u0011\u0018 %\u0006\u0018 6 \u0014\"\u000f \u0011. \u000f\u0014\u000e.\u0006 8&\u000e.&\u0011'\u0006 \u0010\"\"%\u0014\u0010/- \u000e\u0006 \u000f \u0010\u000e % \u0006 .- \u0006 \u000f .%&/\u000e\u0006 *3\u0006 \"\u0010%\u000e&\u0011'\u0006 .- \u0006 \u000e\u0014 %/ /\u0014\u0018 \u0006\u00145\u0006.- \u0006\u000e\u00145.,\u0010% \u0003\u0006\u0012 /-\u0006\u0010\"\"%\u0014\u0010/- \u000e\u0006/\u0010\u0011\u0006\u0014\u0011 3\u0006* \u0006\" %5\u0014%\u000f \u0018\u0006&\u0011\u0006\u0010\u0006 \u0010. \"-\u0010\u000e \u0006\u00145\u0006\u000e\u00145.,\u0010% \u0006\u0018 6 \u0014\"\u000f \u0011. \u0006.- \u000e\u0006 &\u000f&.&\u0011'\u0006.- \u0006 \u000e 5 \u0011 \u000e\u000e\u0006\u00145\u0006.- \u0006\u0018 \u0004 \u000e&'\u0011\u0006\u000f .%&/\u000e\u0006&\u0011\u0006% \u000e\u0014 %/ \u0006\u0010 \u0014/\u0010.&\u0014\u0011\u0003\u00069\u0011\u0006.-&\u000e\u0006\"\u0010\" % \u0006, \u0006\"% \u000e \u0011.\u0006\u0010\u0006\u000f .-\u0014\u0018\u0004 \u0014 \u0014'3\u0006 .-\u0010.\u0006 /\u0014\u000f\"& \u000e\u0006 \u001b\u0005 \u0006 \u000e\" /&5&/\u0010.&\u0014\u0011\u000e\u0006 .\u0014\u0006 \u0014*.\u0010&\u0011\u0006 \u0018 \u000e&'\u0011\u0006 &\u00115\u0014%\u000f\u0010.&\u0014\u0011 \u0010\u0011\u0018\u0006.\u0014\u0006/\u0014\u000f\" . \u0006.- \u0006\u0018 \u000e&'\u0011\u0006\u000f .%&/\u000e\u0006\u0010.\u0006\u0010\u0011\u0006 \u0010% 3\u0006\u000e.\u0010' \u0006\u00145\u0006\u000e\u00145.,\u0010% \u0006\u0018 6 \u0004 \u0014\"\u000f \u0011.\u0003\u0006+- \u0006/ %% \u0011.\u00066 %\u000e&\u0014\u0011\u0006\u00145\u0006\u0014 %\u0006.\u0014\u0014 \u0006 \u000e \u000e\u0006\u0018&\u0010'%\u0010\u000f\u000e\u0006\"%\u0014\u0018 / \u0018\u0006*3\u0006.- :\u0010.&\u0014\u0011\u0010 \u0006:\u0014\u000e \u0006.\u0014\u0014 \u0006\u0010\u0011\u0018\u0006/\u0014\u000f\" . \u000e\u0006;;\u0006\u000f .%&/\u000e\u0006.-\u0010.\u0006-\u00106 \u0006* \u0011\u0006\u000e '' \u000e. \u0018 \u0010\u000e\u0006 * &\u0011'\u0006 '\u0014\u0014\u0018\u0006 &\u0011\u0018&/\u0010.\u0014%\u000e\u0006 5\u0014%\u0006 &\u0018 \u0011.&53&\u0011'\u0006 5\u0010 .\u000e\u0006 % \u0010. \u0018\u0006 .\u0014\u0006 ;*7 /.\u0004 ;%& \u0011. \u0018\u0006 5 \u0010. % \u000e\u0003\u0006 ; %\u0006 . /-\u0011&\b \u0006 \u0010\u00186\u0010\u0011/ \u000e\u0006 .- \u0006 \u000e.\u0010. \u0006 \u00145\u0006 .- \u0006 \u000f .%&/\u000e \u000f \u0010\u000e %&\u0011'\u0006\"%\u0014/ \u000e\u000e<\u0006.- \u000e\u0006&.\u0006&\u000e\u0006 8\" /. \u0018\u0006.\u0014\u0006\u000e.%\u0014\u0011' 3\u0006\"%\u0014\u000f\u0014. \u0006.- \u0006 \u000e \u0006\u00145\u0006\u0018 \u0004 \u000e&'\u0011\u0006\u000f .%&/\u000e\u0006\u0010\u0011\u0018\u0006\u000e&'\u0011&5&/\u0010\u0011. 3\u0006&\u0011/% \u0010\u000e \u0006.- &%\u0006&\u000f\"\u0010/.\u0006\u0014\u0011\u0006&\u000f\"%\u00146&\u0011'\u0006\u000e\u00145.\u0004 ,\u0010% \u0006\b \u0010 &.3\u0003",
    "keywords": []
  },
  {
    "title": "The Cow_Suite Approach to Planning\nand Deriving Test Suites in UML Projects",
    "date": 2002,
    "abstract": "\u0006\u0013\u0014,L\u0012 &. \u0006\"%\u00146&\u0018 \u000e\u0006\u0010\u0011\u0006&\u0011. '%\u0010. \u0018\u0006\u0010\u0011\u0018\u0006\"%\u0010/.&/\u0010 \u0006\u0010\"\"%\u0014\u0010/-\u0006.\u0014 .- \u0006\u000e.%\u0010. '&/\u0006' \u0011 %\u0010.&\u0014\u0011\u0006\u0010\u0011\u0018\u0006\" \u0010\u0011\u0011&\u0011'\u0006\u00145\u0006\u001b\u0005 \u0004*\u0010\u000e \u0018\u0006. \u000e.\u0006\u000e &. \u000e \u0006\u000e&\u0011/ .- \u0006 \u0010% 3\u0006 \u000e.\u0010' \u000e\u0006 \u00145\u0006 \u000e3\u000e. \u000f\u0006 \u0010\u0011\u0010 3\u000e&\u000e\u0006 \u0010\u0011\u0018\u0006 \u000f\u0014\u0018 &\u0011'\u0003\u0006 9.\u0006 /\u0014\u0011\u000e&\u000e.\u000e\u0006 \u00145\u0006 .,\u0014 \u0014%&'&\u0011\u0010 \u0006 /\u0014\u000f\"\u0014\u0011 \u0011.\u000e\u0006 ,\u0014%\u0015&\u0011'\u0006 &\u0011\u0006 /\u0014\u000f*&\u0011\u0010.&\u0014\u0011\u001a\u0006 .- \u0006 \u0013\u0014,. \u000e.\u0006 \u000e.%\u0010. '3 ,-&/-\u0006 \u0014%'\u0010\u0011&\u0007 \u000e\u0006 .- \u0006 . \u000e.&\u0011'\u0006 \"%\u0014/ \u000e\u000e\u0006 \u0010\u0011\u0018\u0006 - \"\u000e\u0006 .- \u0006 \u000f\u0010\u0011\u0010' %\u0006 .\u0014\u0006 \u000e /. \u0010\u000f\u0014\u0011'\u0006 .- \u0006 \u000f\u0010\u00113\u0006 \"\u0014. \u0011.&\u0010 \u0006 . \u000e.\u0006 /\u0010\u000e \u000e \u0006 \u0010\u0011\u0018\u0006 .- \u0006 \u001b9+\u0006 \u000f .-\u0014\u0018 \u0006 ,-&/- \" %5\u0014%\u000f\u000e\u0006 .- \u0006 \u0010 .\u0014\u000f\u0010. \u0018\u0006 ' \u0011 %\u0010.&\u0014\u0011\u0006 \u00145\u0006 . \u000e.\u0006 /\u0010\u000e \u000e\u0006 5%\u0014\u000f\u0006 .- \u0006 \u001b\u0005 \u0018&\u0010'%\u0010\u000f\u000e\u0003\u0006+- \u0006\u0010\"\"%\u0014\u0010/-\u0006/\u0010\u0011\u0006* \u0006 \u000e \u0018\u0006&\u0011\u0006&\u0011/% \u000f \u0011.\u0010 \u0006,\u00103 \u0006\u000e.\u0010%.&\u0011'\u00065%\u0014\u000f .- \u0006 \"% &\u000f&\u0011\u0010%3\u0006 \u0016 6 \u0011\u0006 &\u0011/\u0014\u000f\" . \u0019\u0006 \u001b\u0005 \u0006 \u0018&\u0010'%\u0010\u000f\u000e \u0006 \u0010\u0011\u0018\u0006 &\u000e\u0006 \u0010\"\" & \u0018\u0006 .\u0014 &\u0011. '%\u0010.&\u0014\u0011\u0006 \u000e *\u000e3\u000e. \u000f\u000e \u0006 \u0010\u000e\u0006 &\u0011. %\u0010/.&6 3\u0006 \u000e /. \u0018\u0006 *3\u0006 .- \u0006 . \u000e. %\u0003\u0006 +- \u000f\"-\u0010\u000e&\u000e\u0006&\u000e\u0006\u0014\u0011\u0006 \u000e\u0010*& &.3 \u0006&\u0011\u0006.-\u0010.\u0006, \u0006 \u000e \u0006 8\u0010/. 3\u0006.- \u0006\u000e\u0010\u000f \u0006\u001b\u0005 \u0006\u0018&\u0010'%\u0010\u000f\u000e \u0018 6 \u0014\" \u0018\u0006 5\u0014%\u0006 \u0010\u0011\u0010 3\u000e&\u000e\u0006 \u0010\u0011\u0018\u0006 \u0018 \u000e&'\u0011 \u0006 ,&.-\u0014 .\u0006 % \b &%&\u0011'\u0006 \u0010\u00113\u0006 \u0010\u0018\u0018&.&\u0014\u0011\u0010 5\u0014%\u000f\u0010 &\u000e\u000f\u0006\u0014%\u0006\u0010\u0018\u0004-\u0014/\u0006 55\u0014%.\u0006\u000e\" /&5&/\u0010 3\u00065\u0014%\u0006. \u000e.&\u0011'\u0006\" %\"\u0014\u000e \u000e\u0003\u0006\u0013\u0014,L\u0012 &. -\u0010\u000e\u0006 * \u0011\u0006 &\u000f\" \u000f \u0011. \u0018\u0006 &\u0011\u0006 \u0010\u0006 \"%\u0014.\u0014.3\" \u0006 .\u0014\u0014 \u0006 \u0010\u0011\u0018\u0006 &\u000e\u0006 / %% \u0011. 3\u0006 * &\u0011' 6\u0010 &\u0018\u0010. \u0018\u0006&\u0011\u0006\u0010\u0011\u0006&\u0011\u0018 \u000e.%&\u0010 \u0006\u0018 6 \u0014\"\u000f \u0011.\u0006 \u00116&%\u0014\u0011\u000f \u0011.\u0003",
    "keywords": []
  },
  {
    "title": "Diagram Interchange for UML",
    "date": 2002,
    "abstract": "XMI is a standardized mechanism for exchanging UML mod- els. However, this mechanism does not suﬃciently fulﬁll the goal of a model interchange: it does not include the exchange of diagram in- formation. XMI as deﬁned for UML 1.x is only capable of transporting information on the elements in an UML model but not information as to how these elements are represented and laid out in diagrams. This paper proposes an extension to the UML metamodel to represent di- agram information in a graph-oriented manner. The approach presented is able to ﬁx the deﬁciency for UML 1.x and solve the problem for UML 2.0. The approach was handed in for standardization to the OMG in response to the Diagram Interchange RFP.",
    "keywords": []
  },
  {
    "title": "UMLsec: Extending UML\nfor Secure Systems Development⋆",
    "date": 2002,
    "abstract": "Developing secure-critical systems is diﬃcult and there are many well-known examples of security weaknesses exploited in practice. Thus a sound methodology supporting secure systems development is urgently needed. Our aim is to aid the diﬃcult task of developing security-critical systems in an approach based on the notation of the Uniﬁed Modeling Language. We present the extension UMLsec of UML that allows to express security- relevant information within the diagrams in a system speciﬁcation. UMLsec is deﬁned in form of a UML proﬁle using the standard UML extension mechanisms. In particular, the associated constraints give cri- teria to evaluate the security aspects of a system design, by referring to a formal semantics of a simpliﬁed fragment of UML. We demonstrate the concepts with examples.",
    "keywords": []
  },
  {
    "title": "SecureUML: A UML-Based Modeling Language\nfor Model-Driven Security⋆",
    "date": 2002,
    "abstract": "We present a modeling language for the model-driven de- velopment of secure, distributed systems based on the Uniﬁed Model- ing Language (UML). Our approach is based on role-based access con- trol with additional support for specifying authorization constraints. We show how UML can be used to specify information related to access control in the overall design of an application and how this information can be used to automatically generate complete access control infras- tructures. Our approach can be used to improve productivity during the development of secure distributed systems and the quality of the result- ing systems.",
    "keywords": []
  },
  {
    "title": "Workshops and Tutorials\nat the UML 2002 Conference",
    "date": 2002,
    "abstract": "As part of the UML 2002 conference, six tutorials and ﬁve workshops were held. In the following, a brief summary of these events is given, including references for further information.",
    "keywords": []
  },
  {
    "title": "Agile Processes: Developing Your Own “Secret\nRecipes”",
    "date": 2003,
    "abstract": "Every enterprise competes with its software-development processes, its ”recipes” for building better software. In this session, you’ll gain understanding regarding the recipes and mini-recipes advocated within Uniﬁed Process (UP), Feature-Driven Development (FDD), and Extreme Programming (XP). You’ll discover recipes and mini-recipes that could be more eﬀective and appealing and eﬀective for your team, your company, your risks, and your challenges–and gain insights into how to incrementally advance your own ”secret recipes” for competitive advantage.",
    "keywords": []
  },
  {
    "title": "Diﬀerence and Union of Models",
    "date": 2003,
    "abstract": "This paper discusses the diﬀerence and union of models in the context of a version control system. We show three metamodel- independent algorithms that calculate the diﬀerence between two models, merge a model with the diﬀerence of two models and calculate the union of two models. We show how to detect union conﬂicts and how they can be resolved either automatically or manually. We present an application of these algorithms in a version control system for MOF-based models.",
    "keywords": [
      "metamodelling",
      "delta calculation",
      "revision control",
      "UML."
    ]
  },
  {
    "title": "GREAT: UML Transformation Tool for Porting\nMiddleware Applications",
    "date": 2003,
    "abstract": "Design and maintenance of enterprise applications is compli- cated due to dependencies on technical requirements of the middleware framework. Especially, porting enterprise applications to another middle- ware layer or even new versions thereof requires a lot of handiwork and coding, since abstraction-, transformation-, and reﬁnement steps have to be performed. Transformations should be assisted by a tool set which facilitates the migration process from one to another middleware plat- form. This paper presents GREAT, a rule-based transformation frame- work which facilitates transformations among models on the same or diﬀerent abstraction levels. The feasibility of GREAT is shown by the transformation of a real world application conforming to EJB standard 1.1 into a version which complies to EJB standard 2.0.",
    "keywords": []
  },
  {
    "title": "Model-Centric Engineering with the Evolution\nand Validation Environment",
    "date": 2003,
    "abstract": "Reuse is an important aspect of software engineering that promises advantages like faster time-to-market, cost reduction, better maintainability etc. The software industry focuses on components as commercials oﬀ-the-shelf in order to gain reusable assets. However, reuse on the design level usually is not addressed. If we come to perceive mod- els as assets of the software process, then the design moves from the periphery of software engineering to the center. This implies several ad- vantages, like an improved system’s overview and insight, because of greater abstraction and easier comprehension of the design concepts. Current modeling tools primarily provide a conﬁned work-place for the deﬁnition of models including proprietary services like code generation. This paper proposes separation of services and modeling tools to enable independent reuse of services. Thereby the eﬃciency of the modeling pro- cess increases as services become globally shared assets. Also the models, which are expressed in an open available format - independent of a par- ticular modeling tool - facilitate exchange and reuse. As a result, a user community grows and the quality of model artifacts improves because of frequent use, correction and peer review. This paper describes how these ideas are reﬂected in the design and func- tionality of the Evolution and Validation Environment EVE. EVE pro- vides an interoperability platform for model exchange. It consists solely of components which adhere to open speciﬁcations, such as XMI, UML, and OCL. EVE is designed as a loosely coupled system, which allows users to execute and combine services locally or over the Internet in arbitrary ways.",
    "keywords": []
  },
  {
    "title": "Representing Temporal Information in UML",
    "date": 2003,
    "abstract": "The UML is a non-temporal conceptual modeling language. Con- ceptual schemas in the UML assume that the information base contains the cur- rent instances of entity and relationship types. For many information systems, the above assumption is acceptable. However, there are some information sys- tems for which that assumption is a severe limitation. This happens when the functions of the information system require the knowledge of past states of the information base. In this paper we extend the UML to define a set of temporal features of entity and relationship types, and to provide notational devices to refer to any past state of the information base. Using this extension, a designer may use the UML/OCL as if it were a temporal conceptual modeling language. We also present a method for the transformation of a conceptual schema in this ex- tended language into a conventional one. The method can be automated, and we describe an implementation. The result of our transformation method is a conceptual schema that can be processed by ordinary CASE tools.",
    "keywords": []
  },
  {
    "title": "Formal Semantics of UML with Real-Time\nConstructs⋆",
    "date": 2003,
    "abstract": "This paper describes a formal framework for expressing the semantics of UML augmented with real-time constraints. Supported parts of UML include concurrent interacting statecharts and sequence di- agrams, both with real-time constraints. The approach is compositional in the sense that semantics of real-time behavior is captured indepen- dently from traditional statechart semantics, thus allowing for simple adaptation to other semantic variations. This compositionality is sup- ported through the use of a two-dimensional temporal logic to indepen- dently capture ﬂow of control as well as ﬂow of time. The paper deﬁnes this logic, and shows how the UML diagrams can be translated into this formalism. The goal is to provide a simple and intuitive compositional semantics that can be validated and used for further formal analysis.",
    "keywords": []
  },
  {
    "title": "A QoS-Oriented Extension of UML Statecharts⋆",
    "date": 2003,
    "abstract": "Performance, dependability and quality of service (QoS) are prime aspects of the UML modeling domain. To capture these aspects eﬀectively in a modeling language requires easy-to-use support for the speciﬁcation and analysis of randomly varying behaviors. This paper introduces an extension of UML statecharts with randomly varying du- rations, by enriching a speciﬁc syntactic construct: The “after” operator is equipped with (discrete or continuous) probability distributions, deter- mining the duration of the delay caused by this operator. The semantics of this extension is given in terms of a variant of stochastic automata. It is shown how existing model-checking tools can be used to calculate model- inherent QoS characteristics automatically. We study a UML model of an automatic teller machine scenario using this approach.",
    "keywords": []
  },
  {
    "title": "CheckVML: A Tool for Model Checking Visual\nModeling Languages",
    "date": 2003,
    "abstract": "In the paper, we present a tool for model checking dynamic consistency properties in arbitrary well-formed instance models of any modeling language deﬁned visually by metamodeling and graph transformation techniques. Our tool ﬁrst translates such high-level speciﬁcations into a tool independent abstract representation of transition systems deﬁned by a corresponding metamodel. From this intermediate representation the input language of the back-end model checker tool (i.e., SPIN in our case) is generated automatically.",
    "keywords": [
      "visual modeling languages",
      "metamodeling",
      "graph transforma- tion",
      "model checking",
      "formal veriﬁcation."
    ]
  },
  {
    "title": "ProGUM-Web: Tool Support for Model-Based\nDevelopment of Web Applications",
    "date": 2003,
    "abstract": "ProGUM-Web is a tool that supports model-based development of Web applications using an extension of UML. It accounts for the characteristics of Web applications and their specific development. Code templates are gener- ated from the model for both graphic designers and software developers. These code templates can iteratively and independently be advanced and are re- integrated within ProGUM-Web. Prototypes of Web applications can automati- cally be generated throughout the development.",
    "keywords": []
  },
  {
    "title": "106",
    "date": 2003,
    "abstract": "The success of object-oriented software modelling depends to a large extent on the ability to create adequate abstractions. While abstraction itself must remain an intellectual process, a modelling language can support or hinder this process by offering different kinds or dimensions of abstraction. For in- stance, adhering to the object-oriented paradigm UML incorporates classifica- tion and generalization as its key abstraction mechanisms. When it comes to taking the complexity out of real systems, however, we argue that classification and generalization alone are ill-suited to produce abstractions that are both manageable and meaningful. As a remedy, we propose to regard composition as an alternative form of abstraction, and find that it naturally comes with proper- ties that are practically needed. We contrast our view of composition with that of it being a special kind of association, with the composition of deployable elements, and with UML’s model management constructs such as packaging.",
    "keywords": []
  },
  {
    "title": "Compositional and Relational Reasoning during Class\nAbstraction",
    "date": 2003,
    "abstract": "Class diagrams are among the most widely used object-oriented de- sign techniques. They are effective in modeling the structure of software sys- tems at any stages of the software life cycle. Still, class diagrams can become as complex and overwhelming as the software systems they describe. This paper describes a technique for abstracting lower-level class structures into higher- level ones by ‘collapsing’ lower-level class patterns into single, higher-level classes and relationships. This paper is an extension to an existing technique that re-interprets the transitive meaning of lower-level classes into higher-level relationships (relational reasoning). The existing technique is briefly summa- rized. The extensions proposed in this paper are two-fold: This paper augments the set of abstraction rules to also collapse class patterns into higher-level classes (compositional reasoning). While this augmentation is simple and in sync with traditional views of refinement and abstraction, it has drawbacks in defining class features like methods and attributes. This paper thus also demon- strates how to filter low-level class features during abstraction. Our approach requires some human guidance in deciding when to use compositional or rela- tional reasoning but is otherwise fully automated. Our approach is conservative in its results guaranteeing completeness but at the expense of some false posi- tives (i.e., the filter errs in favor of not eliminating in case of doubt). The pro- posed technique is applicable to model understanding, inconsistency detection, and reverse engineering.",
    "keywords": []
  },
  {
    "title": "UML/MDA Reality Check: Heterogenous\nArchitecture Style",
    "date": 2003,
    "abstract": "This talk looks at the OMG’s Model-Driven Architecture initiative and at UML from the perspective of an innovative approach to engineering software for space missions at NASA’s Jet Propulsion Lab- oratory (JPL). The Mission Data System (MDS) project at JPL breaks the conventional mold of space m¨oission software blending two heteroge- nous software architecture styles: state analysis (the idea that ”state”, operations involving state and expressions of intent about state are at the core of all space-based systems and therefore must form the central ba- sis for engineering such systems) and explicit software architecture (the idea that component architecture establishes the elements of software design and of their coherent integration.) From a modeling perspective, state analysis is a domain-speciﬁc software architecture style just like component architecture is an engineering-speciﬁc software architecture style. The heterogenous composition of multiple styles in MDS is an ex- ample of extreme architecture engineering. This talk will describe how this approach stretches in many ways the current state of practice and tool support in UML and MDA into the realm of bleeding edge software engineering research.",
    "keywords": []
  },
  {
    "title": "Towards Automating Source-Consistent UML\nRefactorings",
    "date": 2003,
    "abstract": "With the increased interest in refactoring, UML tool vendors seek ways to support software developers in applying a (sequence of) refactoring(s). The problem with such tools is that the UML metamodel – on which their repository is based – is inadequate to maintain the consistency between the model and the code while one of them gets refactored. Therefore, we propose a set of minimal extensions to the UML metamodel, which is sufﬁcient to reason about refactoring for all common OO languages. For instance, by specifying pre- and postconditions in OCL, we are able to compose primitive refactorings, verify preservation of program behavior, and trigger refactorings based on code smells. This way, we provide future MDA tools with the ability to improve existing UML designs, yet keeping them in synch with the underlying code base.",
    "keywords": []
  },
  {
    "title": "Model Refactorings as Rule-Based Update\nTransformations",
    "date": 2003,
    "abstract": "A model refactoring is a model transformation that improves the design described in the model. A refactoring should only aﬀect a pre- viously chosen subset of the original model. In this paper, we discuss how to deﬁne and execute model refactorings as rule-based transformations. We also present an experimental tool to execute these transformations.",
    "keywords": []
  },
  {
    "title": "Reﬂective Model Driven Engineering",
    "date": 2003,
    "abstract": "In many large organizations, the model transformations allowing the engineers to more or less automatically go from platform- independent models (PIM) to platform-speciﬁc models (PSM) are increasingly seen as vital assets. As tools evolve, it is critical that these transformations are not prisoners of a given CASE tool. Considering in this paper that a CASE tool can be seen as a platform for processing a model transformation, we propose to reﬂectively apply the MDA to itself. We propose to describe models of transformations that are CASE tool independent (platform-independent transformations or PIT) and from them to derive platform-speciﬁc transformations (PST). We show how this approach might help in reaching a consensus in the RFP on MOF QVT, including a solution for the declarative/imperative dilemma. We ﬁnally explore the consequences of this approach on the development life-cycle.",
    "keywords": [
      "model-driven engineering",
      "model transformation."
    ]
  },
  {
    "title": "A Model-Driven Runtime Environment for Web\nApplications",
    "date": 2003,
    "abstract": "A large part of software development these days deals with building so-called Web applications. Many of these applications are data- base-powered and exhibit a page layout and navigational structure that is close to the class structure of the entities being managed by the sys- tem. Also, there is often only limited application-speciﬁc business logic. This makes the usual three-tier architectural approach unappealing, be- cause it results in a lot of unnecessary overhead. One possible solution to this problem is the use of model-driven architecture (MDA). A simple platform-independent domain model describing only the entity structure of interest could be transformed into a platform-speciﬁc model that in- corporates a persistence mechanism and a user interface. Yet, this raises a number of additional problems caused by the one-way, multi-transform- ational nature of the MDA process. To cope with these problems, the authors propose the notion of a model-driven runtime (MDR) environ- ment that is able to execute a platform-independent model for a speciﬁc purpose instead of transforming it. The paper explains the concepts of an MDR that interprets OCL-annotated class diagrams and state machines to realize Web applications. It shows the authors’ implementation of the approach, the Infolayer system, which is already used by a number of applications. Experiences from these applications are described, and the approach is compared to others.",
    "keywords": []
  },
  {
    "title": "Using UML and XMI for Generating Adaptive\nNavigation Sequences in Web-Based Systems",
    "date": 2003,
    "abstract": "In this paper we discuss a method for modelling and generating adap- tive navigation sequences from the UML state diagrams. The method is discussed on a case of adaptive e-course. Latest advances in UML model representation by means of XML based metadata interchange format can be successfully utilized for adaptive generation of the adaptive navigation sequences and can speed up a prototyping of navigation support in adaptive web-based systems. Adaptive generation means that generator can be parametrized. The generator can generate modiﬁed navigation support and appearance of information based on the observed user features according to the parameters . The widely accepted standard based means and tools for XML technology are used for implementing a method for transforming UML state diagrams into web site graph and visualization of that graph.",
    "keywords": [
      "adaptive web-based systems",
      "generator",
      "the UML state diagrams",
      "XMI."
    ]
  },
  {
    "title": "Platform Independent Web Application Modeling",
    "date": 2003,
    "abstract": "This paper discusses platform independent web application modeling in the context of model-driven engineering. A specific metamodel (and associ- ated notation), companion of the UML metamodel, is introduced and motivated for the modeling of dynamic web specific concerns. Web applications are rep- resented in three independent aspects (business, hypertext and presentation). A kind of action language (based on OCL and Java) is used throughout these as- pects to write methods and actions, specify constraints and express conditions. The concepts described in the paper have been implemented in a tool and op- erational model-driven web information systems have been successfully de- ployed.",
    "keywords": [
      "model-driven engineering",
      "MDA",
      "web",
      "metamodel",
      "PIM."
    ]
  },
  {
    "title": "Rigorous Testing by Merging Structural and\nBehavioral UML Representations",
    "date": 2003,
    "abstract": "Error detection and correction in the design phase can re- duce total costs and time to market. Yet, testing of design models usually consists of walk-throughs and inspections both of which lack the rigor of systematic testing. Test adequacy criteria for UML models help de- ﬁne necessary objectives during the process of test creation. These test criteria require coverage of various parts of UML models, such as struc- tural (Class Diagram) and behavioral (Sequence Diagram) views. Test criteria are speciﬁc to a particular UML view. Test cases on the other hand should cover parts of multiple views. To understand testing needs better, it is useful to be able to observe the eﬀect of tests on both Class Diagrams and Sequence Diagrams. We propose a new graph that en- capsulates the many paths that exist between objects via their method calls as a directed acyclic graph (OMDAG). We also introduce the object method execution table (OMET) that captures both execution sequence and associated attribute values by merging the UML views. The merging process is deﬁned in an algorithm that generates and executes tests.",
    "keywords": []
  },
  {
    "title": "Towards Automated Support for Deriving Test Data\nfrom UML Statecharts",
    "date": 2003,
    "abstract": "Many statechart-based testing strategies result in specifying a set of paths to be executed through a (flattened) statechart. These techniques can usually be easily automated so that the tester does not have to go through the tedious procedure of deriving paths manually to comply with a coverage criterion. The next step is then to take each test path individually and derive test data, i.e., fully specified test cases. This requires that we determine the system state required for each event/transition that is part of the path to be tested and the input parameter values for all events and actions on the transitions. We propose here a methodology to automate this procedure, which is based on a careful normalization and analysis of event/action contracts and transition guards written with the Object Constraint Language (OCL). It is illustrated by a case study that exemplifies the steps and provides an initial validation. Though many of the steps are automated, some inputs are still required from the modeler and tester and further work is necessary to push the automation even further and solve a number of remaining issues. This paper is a first attempt at clarifying the issues and identifying the analysis steps required in such an endeavor.",
    "keywords": []
  },
  {
    "title": "Validation of UML and OCL Models by\nAutomatic Snapshot Generation",
    "date": 2003,
    "abstract": "We study the testing and certiﬁcation of UML and OCL models as supported by the validation tool USE. We extend the available USE features by introducing a language for deﬁning properties of desired snapshots and by showing how such snapshots are generated. Within the approach, it is possible to treat test cases and validation cases. Test cases show that snapshots having desired properties can be constructed. Vali- dation cases show that given properties are consequences of the original UML and OCL model.",
    "keywords": []
  },
  {
    "title": "A Critique of UML’s Deﬁnition of the Use-Case\nClass",
    "date": 2003,
    "abstract": "UML is revealed to contain three diﬀerent defects concern- ing the use-case class that were buried in OOSE and handed over to it. These defects are: 1) the use-case class and its instance are unusu- ally deﬁned, 2) a conjecture that is against the deﬁnition of the class is introduced without any reasons, and 3) the execution procedure of a use-case instance does not actually work because of some ﬂaws concern- ing the execution control. These defects have been causing unnecessary confusion in UML’s speciﬁcation of the use-case class. An object-oriented real-world model is built that represents a typical situation of using a use case in the analysis and design stages, and another deﬁnition of the use-case class is constructed that successfully solves the problems.",
    "keywords": []
  },
  {
    "title": "Modelling Database Views with Derived Classes in the\nUML/OCL-Framework",
    "date": 2003,
    "abstract": "One of the central notions in database modelling is the notion of a database view. A database view closely corresponds to the notion of derived class in UML. This paper will show how the notion of a relational database view can be correctly expressed as a derived class in UML/OCL (version 2.0). A central part of our investigation concerns the generality of our manner of rep- resenting relational views in OCL. Since, in general terms, a database view closely corresponds to the notion of a named query, an important problem that we address in our paper is the expressiveness of OCL as a query language. In particular, we will discuss the relational completeness of OCL (w.r.t the rela- tional algebra). We will show that OCL (version 2.0) is relationally complete in a minimal sense, but not in a (desired) maximal sense. As a consequence, we will argue for certain language extensions in OCL in order to achieve that OCL is maximally relationally complete.",
    "keywords": []
  },
  {
    "title": "An OCL Extension for Low-Coupling Preserving\nContracts",
    "date": 2003,
    "abstract": "Design by contract, as introduced by B.Meyer, is of increasing im- portance to the OO community in the specification, reuse, and monitoring of classes. We strongly feel that class libraries of all programming languages should be equipped with contracts, insofar as these constitute a powerful and simple interface definition. Very powerful and expressive contracts can be written using the OCL language, although for operations with many effects on the system state, these contracts can become unmanageable and incomprehen- sible. In order to maintain contracts at a manageable level of complexity, we claim that the OCL powerful mechanism of navigation through associations should be used moderately when building contracts, and that the effects of non- query operations should be allowed to be referred to within pre- and post- conditions. To achieve that purpose, we propose an extension to OCL and pres- ent a formal semantics for it.",
    "keywords": []
  },
  {
    "title": "325",
    "date": 2003,
    "abstract": "One of the challenges of the UML is that it means diﬀerent things to diﬀerent people, and the priorities of those who develop the UML are not the same as all the UML’s users. In this talk I’ll talk about these purposes of the UML and what I think these mean for the UML’s future.",
    "keywords": []
  },
  {
    "title": "Using Description Logic to Maintain\nConsistency between UML Models",
    "date": 2003,
    "abstract": "A software design is often modelled as a collection of UML diagrams. There is an inherent need to preserve consistency between these diagrams. Moreover, through evolution those diagrams get mod- iﬁed leading to possible inconsistency between diﬀerent versions of the diagrams. State-of-the-art UML CASE tools provide poor support for consistency maintenance. To solve this problem, an extension of the UML metamodel enabling support for consistency maintenance and a classi- ﬁcation of inconsistency problems is proposed. To achieve the detection and resolution of consistency conﬂicts, the use of description logic (DL) is presented. DL has the important property of being a decidable frag- ment of ﬁrst-order predicate logic. By means of a number of concrete experiments in Loom, we show the feasibility of using this formalism for the purpose of maintaining consistency between (evolving) UML models.",
    "keywords": []
  },
  {
    "title": "Modeling and Testing Legacy Data Consistency\nRequirements",
    "date": 2003,
    "abstract": "An increasing number of data sources are available on the Internet, many of which oﬀer semantically overlapping data, but based on diﬀerent schemas, or models. While it is often of interest to integrate such data sources, the lack of consistency among them makes this inte- gration diﬃcult. This paper addresses the need for new techniques that enable the modeling and consistency checking for legacy data sources. Speciﬁcally, the paper contributes to the development of a framework that enables consistency testing of data coming from diﬀerent types of data sources. The vehicle is UML and its accompanying XMI. The paper presents techniques for modeling consistency requirements using OCL and other UML modeling elements: it studies how models that describe the required consistencies among instances of legacy models can be de- signed in standard UML tools that support XMI. The paper also con- siders the automatic checking of consistency in the context of one of the modeling techniques. The legacy model instances that are inputs to the consistency check must be represented in XMI.",
    "keywords": []
  },
  {
    "title": "The Consistency Workbench: A Tool for\nConsistency Management in UML-Based\nDevelopment⋆",
    "date": 2003,
    "abstract": "With the Uniﬁed Modeling Language becoming applied in diverse contexts, the ability of deﬁning and checking customized con- sistency conditions is gaining increasing importance. In this paper, we introduce the Consistency Workbench for deﬁning and establishing con- sistency in a UML-based development process.",
    "keywords": []
  },
  {
    "title": "Developing Safety-Critical Systems with UML",
    "date": 2003,
    "abstract": "Safety-critical systems have to be developed carefully to pre- vent loss of life and resources due to system failures. Some of their mech- anisms (for example, providing fault-tolerance) can be complicated to design and use correctly in the system context and are thus error-prone. We show how one can use UML for model-based development of safety- critical systems with the aim to increase the quality of the developed systems without an unacceptable increase in cost and time-to-market. Speciﬁcally, we describe how to use the UML extension mechanisms to include safety-requirements in a UML model which is then analyzed for satisfaction of the requirements. The approach can thus be used to en- capsulate safety engineering knowledge. It is supported by a prototypical XMI-based tool performing the analysis.",
    "keywords": []
  },
  {
    "title": "Consistent and Complete Access Control Policies in Use\nCases",
    "date": 2003,
    "abstract": "Security requirements of a software product need to receive attention throughout its development life cycle. This paper proposes several design arti- facts that specify the details of access control policies formally and precisely in the requirement and analysis phases. The work is based on extending the use cases in Unified Modeling Language, with access control schemas and tables. In addition, we propose a methodology to resolve several issues such as con- sistency and completeness of access control specifications that are not totally resolved before.",
    "keywords": [
      "access control policies",
      "security engineering",
      "use cases",
      "and formal methods."
    ]
  },
  {
    "title": "STAIRS – Steps to Analyze Interactions with Refinement\nSemantics",
    "date": 2003,
    "abstract": "The paper presents STAIRS, an approach to the compositional de- velopment of UML interactions supporting the specification of mandatory as well as potential behavior. STAIRS has been designed to facilitate the use of interactions for requirement capture as well as test specification. STAIRS as- signs a precise interpretation to the various steps in incremental system devel- opment based on an approach to refinement known from the field of formal methods, and provides thereby a foundation for compositional analysis. An in- teraction may characterize three main kinds of traces. A trace may be (1) posi- tive in the sense that it is valid, legal or desirable, (2) negative meaning that it is invalid, illegal or undesirable, or (3) considered irrelevant for the interaction in question. This categorization corresponds well with that of testing where the verdict of a test execution is either pass, fail or inconclusive. The basic incre- ments in system development are structured into three kinds referred to as sup- plementing, narrowing and detailing. Supplementing categorizes inconclusive traces as either positive or negative. Narrowing reduces the set of positive traces to capture new design decisions or to match the problem more adequately. De- tailing involves introducing a more detailed description without significantly altering the externally observable behavior.",
    "keywords": []
  },
  {
    "title": "Workshops at the UML 2003 Conference",
    "date": 2003,
    "abstract": "This year the UML conference hosts nine one-day work- shops.These selected workshops cover a wide range of topics related to the Uniﬁed Modeling Language. The high number of workshop propos- als received is a reﬂection of the attention that the conference is getting from both the academia and the industry.",
    "keywords": []
  },
  {
    "title": "Tutorials at the UML 2003 Conference",
    "date": 2003,
    "abstract": "The UML 2003 conference provides ﬁve half-day tutorials on advanced topics related to UML, presented by recognized worldwide experts. A short summary of each tutorial and a list of its respective presenters are given, as follows.",
    "keywords": []
  },
  {
    "title": "Empirically Driven Use Case Metamodel Evolution⋆",
    "date": 2004,
    "abstract": "Metamodel evolution is rarely driven by empirical evidences of meta- model drawbacks. In this paper, the evolution of the use case metamodel used by the publicly available requirements management tool REM is presented. This evolution has been driven by the analysis of empirical data obtained during the assessment of several metrics–based veriﬁcation heuristics for use cases devel- oped by some of the authors and previously presented in other international fora. The empirical analysis has made evident that some common defects found in use cases developed by software engineering students were caused not only by their lack of experience but also by the expressive limitations imposed by the un- derlying use case metamodel used in REM. Once these limitations were clearly identiﬁed, a number of evolutionary changes were proposed to the REM use case metamodel in order to increase use case quality, i.e. to avoid those situations in which the metamodel were the cause of defects in use case speciﬁcations.",
    "keywords": [
      "metamodel evolution",
      "use cases",
      "empirical software engineering"
    ]
  },
  {
    "title": "Applying OO Metrics to Assess UML Meta-models",
    "date": 2004,
    "abstract": "UML has been coming of age through more than seven years devel- opment, in which there are not only minor revision like from UML 1.1 to UML 1.2, but also significant improvement like final adoption of UML 2.0 submis- sions. However there is so far lack of an objective assessment to UML meta- models, which can be used to control and predict the evolution of the UML. In this paper we regard UML meta-models as the equivalent of Object-Oriented (OO) design models. Therefore, we can adapt OO design metrics and criteria as a method to assess UML meta-models. Our method conducts the assessment of stability and design quality to UML meta-models in versions of 1.1, 1.3, 1.4 (with Action Semantics), 1.5, and 2.0. Based on the results we analyze the evo- lution of the UML versions and provide the applicability suggestions to the method.",
    "keywords": []
  },
  {
    "title": "An OCL Formulation of UML2 Template\nBinding",
    "date": 2004,
    "abstract": "After being considered only as documentation for a long time, models are gaining more and more importance in the software development lifecycle, as full software artefacts. The UML standard con- tributes a lot to this mutation, with the identiﬁcation and the structura- tion of models space dimensions and constructs. Models can nowadays be explicitly manipulated through metamodeling techniques, dedicated tools or processes such as model transformation chains. This is ”Model Driven Engineering”. Once it is clear that models are full software ingre- dients, we are faced with new problems (needs!) such as the possibility of their reusability and composability. As a consequence, speciﬁc constructs are introduced in order to facilitate this, such as the template notion ini- tiated by UML1.3. Applications of this notion are growing more and more so that it was deeply revisited and strengthened in UML2. Though, its speciﬁcation still lacks precision, particularly concerning the ”binding” mechanism that allows to obtain models from templates. We propose a set of OCL constraints which strengthens the deﬁnition and helps in verifying the correctness of resulting models. These constraints apply to the UML2 metamodel and were implemented in an OCL veriﬁer that we integrated in the Eclipse environment.",
    "keywords": []
  },
  {
    "title": "A Metamodel for Generating Performance Models from \nUML Designs",
    "date": 2004,
    "abstract": "Several different kinds of performance models can be generated from sets of scenarios that describe typical responses of a system, and their use of re- sources. The Core Scenario Model described here integrates the scenario and resource elements defined in a UML model with performance annotations, pre- paratory to generating performance models. It is based on, and aligned with the UML Profile for Schedulability, Performance and Time, and supports the gen- eration of predictive performance models using queueing networks, layered queueing, or timed Petri nets. It is proposed to develop it as an intermediate language for all performance formalisms.",
    "keywords": []
  },
  {
    "title": "On the Classification of UML’s Meta Model Extension \nMechanism",
    "date": 2004,
    "abstract": "Although the UML meta model extension mechanism has been used in many modeling fields in which extension of UML is needed, UML specification has little necessary classification and application guidance on the meta model extension mechanism. This paper defines four levels of UML’s meta model extension mechanism, and discusses the readability, expression capability, use scope and tool support on the basis of precise definitions of each level. The work on the paper reinforces the maneuverability of the UML meta model extension mechanism, and provides a reliable theoretical base for the development of modeling tools that support meta model extension.",
    "keywords": []
  },
  {
    "title": "Modeling Business Processes in Web Applications\nwith ArgoUWE⋆",
    "date": 2004,
    "abstract": "The CASE tool ArgoUWE supports the systematic design of Web ap- plications using the UML-based Web Engineering (UWE) approach. The design methodology of UWE is based on a metamodel which is deﬁned as a lightweight extension of the UML metamodel in the form of a proﬁle and comprises the sep- arate modeling of the different aspects of a Web application: content, structure, layout, and business logic. ArgoUWE is implemented as a plugin into the open- source tool ArgoUML. In this paper, we focus on the latest improvements of the ArgoUWE tool: On the one hand, ArgoUWE supports the design of workﬂow- driven Web applications where business logic can be captured by process struc- ture and process ﬂow models. On the other hand, ArgoUML’s design critic mech- anism has been extended to indicate deﬁciencies and inconsistencies in UWE models based on the UWE metamodel and its OCL well-formedness rules.",
    "keywords": []
  },
  {
    "title": "Model Composition Directives",
    "date": 2004,
    "abstract": "An aspect-oriented design model consists of a set of aspect models and a primary model. Each of these models consists of a number of different kinds of UML diagrams. The models must be composed to identify conflicts and analyze the system as a whole. We have developed a systematic approach for composing class diagrams in which a default composition procedure based on name matching can be customized by user-defined composition directives. This paper describes a set of composition directives that constrain how class diagrams are composed.",
    "keywords": []
  },
  {
    "title": "Query Models",
    "date": 2004,
    "abstract": "The need for querying software artifacts is a new emerging design issue in modern software development. Novel techniques such as Model-Driven Architecture or Aspect-Oriented Software Development heavily depend on powerful designation means to allocate elements in software artifacts, which are then either modified by transformation or enhanced by weaving processes. In this paper we present a new modeling notation for representing queries using the UML. We introduce special symbols for common selection purposes and specify their OCL selection semantics, which may be executed on existing UML models in order to allocate all selected model elements therein. By doing so, we aim to give forth the advantages of modeling to query design: Our query models facilitate the specification of queries independent from particular programming languages, ease their comprehension, and support their validation in a modeling context.",
    "keywords": []
  },
  {
    "title": "Specifying Cross-Cutting Requirement Concerns",
    "date": 2004,
    "abstract": "Addressing non-orthogonal software concerns that arise from requirements can significantly contribute to the complexity of developing large systems. Difficulties arise from the need to: locate related requirements, reason about the software concerns they represent, and analyze the impact of changing requirements. We address these issues through the use of requirements aspects. We present a method to identify requirements aspects from viewpoints, to associate requirements aspects with generic design solutions based on domain experience, and to specify the generic solutions using the UML. We demonstrate these techniques using a smart home controller application.",
    "keywords": [
      "cross-cutting concerns",
      "requirements aspects",
      "specification",
      "UML"
    ]
  },
  {
    "title": "A UML Proﬁle to Model Mobile Systems",
    "date": 2004,
    "abstract": "The introduction of adaptation features in the design of ap- plications that operate in a mobile computing environment has been suggested as a viable solution to cope with the high heterogeneity and variability of this environment. Mobile code paradigms can be used to this purpose, since they allow to dynamically modify the load of the host- ing nodes and the internode traﬃc, to adapt to the resources available in the nodes and to the condition of the (often wireless) network link. In this paper we propose a UML proﬁle to deal with all the relevant issues of a mobile system, concerning the mobility of both physical (e.g. com- puting nodes) and logical (e.g. software components) entities. The proﬁle is deﬁned as a lightweight customization of the UML 2.0 metamodel, so remaining fully compliant with it. In the deﬁnition of this proﬁle, the underlying idea has been to model mobility (in both physical and logical sense) as a feature that can be “plugged” into a pre-existing architecture, to ease the modelling of both diﬀerent physical mobility scenarios, and of diﬀerent adaptation strategies based on code mobility. Besides deﬁning the proﬁle, we give some examples of use of its features.",
    "keywords": [
      "mobile computing",
      "code mobility",
      "UML proﬁle."
    ]
  },
  {
    "title": "Experimental Evaluation of the UML Proﬁle for\nSchedulability, Performance, and Time",
    "date": 2004,
    "abstract": "We present a performance engineering methodology based upon the construction and solution of performance models generated me- chanically from UML sequence diagrams, annotated using the UML Pro- ﬁle for Schedulability, Performance and Time (SPT). The target platform for the performance analysis is the Labelled Transition System Analyser (LTSA) tool which supports model solution via discrete-event simula- tion. Simultaneously, LTSA allows functional properties of a system to be explored formally, and we show how this can be used to detect func- tional anomalies, such as unnecessary sequentialisation and deadlock, prior to analysing the performance aspects of a system. The approach is evaluated with reference to a case study – a simple robot-based man- ufacturing system. The main objective is to explore the ways in which UML, the SPT proﬁle and the LTSA tool can be used to design systems that satisfy speciﬁed behavioural and performance properties, through successive reﬁnement.",
    "keywords": []
  },
  {
    "title": "A UML Profile for Executable and Incremental \nSpecification-Level Modeling",
    "date": 2004,
    "abstract": "Model executability is widely considered an important enabling fac- tor for model driven development. However, executability of Unified Modeling Language (UML) models tends to imply quite a low level of abstraction, which causes executable models to resemble diagrammatically structured program code. In this article, a UML profile that enables executable specification-level modeling using an incremental approach is proposed. The profile employs the Object Constraint Language (OCL) with multi-object joint actions to declara- tively specify behavior on a higher level of abstraction than sequences of mes- sages between objects. A nondeterministic mode of execution removes the need for explicit control flow, greatly simplifying the models. A variant of superpo- sition is used to construct specification models incrementally, utilizing aspect- oriented layers, and preserving safety properties. The proposed mechanism also aims at bridging the gap between use cases and design level specifications. As the profile is based on ideas taken from the DisCo modeling language, origi- nally designed for formal specification of reactive systems, there is a straight- forward mapping that enables use of existing DisCo tools for animation, verifi- cation and synthesis. A running example is presented to illustrate the use of the proposed approach.",
    "keywords": []
  },
  {
    "title": "Applying Refactoring Techniques to UML/OCL Models",
    "date": 2004,
    "abstract": "The Object Constraint Language (OCL) plays an important role in the elaboration of precise UML models. Although OCL was designed to be both formal and simple, UML/OCL models may be difficult to understand and evolve, particularly when constraints containing complex or duplicate expressions are present. Moreover, the evaluation of how changes in the definition of the underlying classes impact the OCL part of a model may be a difficult and time-consuming task. In this paper, we discuss how refactoring techniques can be applied in order to improve the understandability of a UML/OCL model and how to support its evolution. In particular, we present a collection of refactorings and discuss how they can be specified and automated. We also show how the model animation features can be used to increase our confidence that the semantics of a model is preserved when a refactoring is manually performed.",
    "keywords": []
  },
  {
    "title": "Detecting OCL Traps\nin the UML 2.0 Superstructure:\nAn Experience Report",
    "date": 2004,
    "abstract": "Currently, the OMG is developing a new version of the Uni- ﬁed Modeling Language (UML), UML 2.0, which involves major innova- tions in its metamodel. As for previous versions of the UML, the Object Constraint Language (OCL) is employed to give restrictions on the use of UML and for the formulation of additional operations. It seems that the OCL expressions in the current version of the UML 2.0 Superstructure have not been checked with a tool. In this paper we report on an experi- ment in checking and validating the well-formedness rules and operation deﬁnitions of the UML 2.0 Superstructure w.r.t. syntax and type check- ing by using our tool USE (UML-based Speciﬁcation Environment). For this purpose we classify the errors detected by USE in appropriate error categories. We develop statistical information on error frequencies w.r.t. package location and error category. All errors detected by USE and their detailed description are made available in a separate EXCEL ﬁle.",
    "keywords": []
  },
  {
    "title": "From Informal to Formal Speciﬁcations in UML",
    "date": 2004,
    "abstract": "In this paper, we consider a way of bridging informal and for- mal speciﬁcation. Most projects have a need for an informal description of the requirements of the system which all people involved can understand. At the same time, there is a need to make some of the requirements more formal. We present a way to relate informal requirements, in form of use cases, to more formal speciﬁcations, written in the Object Constraint Language (OCL). Our approach gives the customers of software systems a way of guiding the development of formal speciﬁcations. Conversely, the formal speciﬁcation can improve the informal understanding of the system by exposing gaps and ambiguities in the informal speciﬁcation.",
    "keywords": []
  },
  {
    "title": "Building Precise UML Constructs to Model\nConcurrency Using OCL",
    "date": 2004,
    "abstract": "The UML has established itself as the main tool for build- ing software designs. However, one area that hasn’t been completely ex- plored is the semantically precise speciﬁcation of behavior for concurrent programs. We have studied the feasibility of creating precise, unambigu- ous UML concurrency speciﬁcations using the Object Constraint Lan- guage (OCL) as a cornerstone, particularly focusing on constructs for concurrent access to shared variables. In this paper, we show that such speciﬁcations are possible, and that we can create basic concurrency ab- stractions that are precise, speciﬁcally semaphores and monitors. These constructs can be successfully applied to model solutions to classic con- current problems, as we show in a monitor-based solution to the Sleeping Barber problem.",
    "keywords": []
  },
  {
    "title": "An ASM Deﬁnition of the Dynamic OCL 2.0 Semantics",
    "date": 2004,
    "abstract": "The recently adopted OCL 2.0 speciﬁcation comes with a formal se- mantics that is based on set theory with a notion of an object model and system states. System states keep the runtime information relevant for the evaluation of OCL expressions. However, not all new language concepts of OCL 2.0 are al- ready addressed in that formal semantics. We show how to overcome this by introducing new components to the object model and system states deﬁning a dynamic semantics of OCL. In order to give precise rules that determine when the current system state has to be updated according to a change in the referred UML model, we make use of adequate mathematical means, namely Abstract State Machines (ASMs). Though our ASM speciﬁcation also gives a clear def- inition for the evaluation of OCL constraints, it leaves sufﬁcient ﬂexibility for application speciﬁc implementations that have to determine when constraints are to be checked.",
    "keywords": []
  },
  {
    "title": "Towards a Framework for Mapping Between \nUML/OCL and XML/XQuery",
    "date": 2004,
    "abstract": "The Unified Modeling Language is the standard language for modeling systems. UML has been extended to model web applications. At the same time, Web technology has become largely relying on XML documents. The structure of XML documents, namely the XML schema or DTD for these documents can be modeled using UML data structures. UML tools are usually concerned with the generation of the structure and behavior of the system that is captured by models in their equivalents in the selected platform. In this paper we introduce a novel approach for the integration between UML and XML families of technologies. We model the structure of XML using UML class diagrams and based on this, we study how queries on XML documents, namely XQuery expressions can be described using UML techniques. Here we show that modeling of XML documents and its queries represented by XQuery expressions is possible using the querying capabilities of UML Class diagram and the Object Constraint Language (OCL). As a result, we see how these two technologies compare, what the advantages of both technologies are and how they can be combined.",
    "keywords": []
  },
  {
    "title": "Model-Driven Architecture for Automatic-Control:      \nAn Experience Report",
    "date": 2004,
    "abstract": "In the context of teaching distributed and embedded process-control it is difficult to bring students to perform efficient practical work, because the low-level underlying software technologies require too much time investment. Object-oriented modeling together with model-driven architecture provides a good solution to simplify such practical work, by automating the generation of the low-level code directly from the specifications of the process-control application. To support this approach, we have developed a model-driven application framework of about 130 distributed and embedded real-time components for RISC microcontrollers. This way, students can focus on the process-control side of their work, without having to dive (and often get lost) in the platform complexity.",
    "keywords": []
  },
  {
    "title": "Model-Driven Development for Non-functional\nProperties: Reﬁnement Through Model Transformation",
    "date": 2004,
    "abstract": "Model driven architecture (MDA) views application development as a continuous transformation of models of the target system. We propose a method- ology which extends this view to non-functional properties. Our basic idea is the separation of two different roles in the development process: the role of the mea- surement designer and the role of the application designer. The former provides a library of measurement deﬁnitions which is later used by the latter to anno- tate functional application models with non-functional property speciﬁcations. In this paper we deﬁne the notion of context models to allow the measurement designer to provide measurement deﬁnitions at different levels of abstraction in- dependently of concrete applications. Requiring the measurement designer to deﬁne transformations between context models and applying them to measurement deﬁnitions, enables us to provide tool support for reﬁnement of non-functional constraints to the application designer. The concepts presented in this paper form the basis of a tool which we are cur- rently developing.",
    "keywords": []
  },
  {
    "title": "Generic and Meta-transformations for\nModel Transformation Engineering⋆",
    "date": 2004,
    "abstract": "The Model Driven Architecture necessitates not only the application of software engineering disciplines to the speciﬁcation of modeling languages (language-ware) but also to design inter and intra- language model transformations (transformation-ware). Although many model transformation approaches exist, their focus is almost exclusively put on functional correctness and intuitive description language while the importance of engineering issues such as reusability, maintainabil- ity, performance or compactness are neglected. To tackle these prob- lems following the MDA philosophy, we argue in the paper that model transformations should also be regarded as models (i.e., as data). More speciﬁcally, we demonstrate (i) how generic transformations can provide a very compact description of certain transformation problems and (ii) how meta-transformations can be designed that yield eﬃcient transfor- mations as their output model. Keywords: model transformation, metamodeling, meta-transformation, generic transformation.",
    "keywords": []
  },
  {
    "title": "Supporting Model Refactorings Through\nBehaviour Inheritance Consistencies",
    "date": 2004,
    "abstract": "This paper addresses the problem of consistency preserva- tion in model-driven software development. Software models typically embody many diﬀerent views that need to be kept consistent. In the context of consistency within a model, behaviour inheritance consisten- cies restrict the way the behaviour of a subclass can specialize the be- haviour of a superclass. In the context of model evolution, model refac- torings restructure a model while preserving its behavioural properties. It is still an open research question how to deﬁne behaviour preservation properties for model refactorings. We claim that behaviour inheritance consistencies correspond, in an evolution context, to the preservation of behavioural properties between model versions. To illustrate this claim, we implemented consistency rules and preservation behaviour rules in Racer, a reasoning engine for description logics. We show how the same logic rules can be used to detect behaviour inheritance inconsistencies in a model and to detect the preservation of call behaviour properties during model refactoring.",
    "keywords": []
  },
  {
    "title": "Determining the Structural Events That May Violate an \nIntegrity Constraint",
    "date": 2004,
    "abstract": "Any implementation of an information system must ensure that an operation is only applied if its execution does not lead to a violation of any of the integrity constraints defined in its conceptual schema. In this paper we propose a method to automatically determine the operations that may potentially violate an OCL integrity constraint in conceptual schemas defined in the UML. This is done by determining the structural events that may violate the constraint and checking whether those events appear in the operation specification. In this way, our method helps to improve efficiency of integrity checking since its results can be used to discard many irrelevant tests.",
    "keywords": []
  },
  {
    "title": "Deductive Veriﬁcation of UML Models in\nTLPVS⋆",
    "date": 2004,
    "abstract": "In recent years, UML has been applied to the development of reactive safety-critical systems, in which the quality of the developed software is a key factor. In this paper we present an approach for the deductive veriﬁcation of such systems using the PVS interactive theorem prover. Using a PVS speciﬁcation of a UML kernel language semantics, we generate a formal representation of the UML model. This represen- tation is then veriﬁed using tlpvs, our PVS-based implementation of linear temporal logic and some of its proof rules. We apply our method by verifying two examples, demonstrating the feasibility of our approach on models with unbounded event queues, object creation, and variables of unbounded domain. We deﬁne a notion of fairness for UML systems, allowing us to verify both safety and liveness properties.",
    "keywords": [
      "Formal Veriﬁcation",
      "Deductive Veriﬁcation",
      "PVS",
      "UML",
      "State Machines",
      "Semantics",
      "Temporal Logic"
    ]
  },
  {
    "title": "Integrating a Security Requirement Language\nwith UML",
    "date": 2004,
    "abstract": "We present an approach that integrates a language for pre- cise and high-level speciﬁcation of application security requirements, the Security Requirement Language (SRL), with an existing modeling tech- nique, namely, the Uniﬁed Modeling Language (UML). SRL is based on ﬁrst-order logic extended with a small set of modal operators and a syntactic abstraction mechanism. It oﬀers extensibility in that new application/domain-speciﬁc requirements can be deﬁned and reused. The focus of SRL is the security of communication in distributed systems. The integrated framework enables developers to add to system models secu- rity requirements, such as conﬁdentiality, non-repudiation, and authenti- cation, at an early stage of development, making security an integral part of the system development process. We illustrate the practical usability of our approach by presenting an example, and discuss the experiences that the users of our approach, i.e., system developers, have reported.",
    "keywords": []
  },
  {
    "title": "Automated Veriﬁcation of UMLsec Models\nfor Security Requirements",
    "date": 2004,
    "abstract": "For model-based development to be a success in practice, it needs to have a convincing added-value associated with its use. Our goal is to provide such added-value by developing tool-support for the anal- ysis of UML models against diﬃcult system requirements. Towards this goal, we describe a UML veriﬁcation framework supporting the construc- tion of automated requirements analysis tools for UML diagrams. The framework is connected to industrial CASE tools using XMI and allows convenient access to this data and to the human user. As a particular example for usage of this framework, we present veri- ﬁcation routines for verifying models of the security extension UMLsec of UML. These plug-ins should not only contribute towards usage of UMLsec in practice by oﬀering automated analysis routines connected to popular CASE tools. The veriﬁcation framework should also allow advanced users of the UMLsec approach to themselves implement veri- ﬁcation routines for the constraints of self-deﬁned stereotypes, in a way that allows them to concentrate on the veriﬁcation logic. In particular, we focus on an analysis plug-in that utilises the model-checker Spin to verify security properties of UMLsec models which make use of cryptography (such as cryptographic protocols).",
    "keywords": []
  },
  {
    "title": "Extending OCL for Secure Database Development",
    "date": 2004,
    "abstract": "The Model Driven Architecture (MDA) is becoming an important aspect of software development, since it considers languages and models that can represent an information system at different abstraction levels, and makes it possible a coherent transformation of the system from the domain context into the machine context. In this paper, we present the Object Security Constraint Language V.2. (OSCL2), which is based on the well-known Object Constraint Language V.2. (OCL) of the Unified Modeling Language (UML), and which needs an extension of the UML1 metamodel. This language is defined to be used in secure database development process, incorporating security informa- tion and constraints in a Platform Independent Model (UML class model). This security information and constraints are then translated into a Platform Specific Model (multilevel relational model). Finally, they are implemented in a particu- lar Database Management System (DBMS), such as Oracle9i Label Security. These transformations can be done automatically or semi-automatically using OSCL2 compilers. Keywords: OCL, security constraints, multilevel databases, UML, confidentiality.",
    "keywords": []
  },
  {
    "title": "Test Driven Development of UML Models\nwith SMART Modeling System",
    "date": 2004,
    "abstract": "We are developing a methodology for Test-Driven Develop- ment of Models (TDDM) based on an experimental UML 2.0 modeling tool SMART. Our experience shows that TDDM is quite useful for agile model developments. SMART provides guidance on how to build models based on compiler errors of testcases, something similar to what Quick Fix of Eclipse does. It also provides such guidance from failures of test- cases, which seems diﬃcult in the case of TDD of programs.",
    "keywords": []
  },
  {
    "title": "Behavioral Domain Analysis – The Application-Based \nDomain Modeling Approach",
    "date": 2004,
    "abstract": "Being part of domain engineering, domain analysis enables identifying domains and capturing their ontologies in order to assist and guide system developers to design domain-specific applications. Domain analysis should consider commonalities and differences of systems in a domain, organize an understanding of the relationships between the various elements in that domain, and represent this understanding in a formal, yet easy to use, way. Several studies suggest using metamodeling techniques for modeling domains and their constraints. These metamodels are basically structural and present static constraints only. We propose an Application-based DOmain Modeling (ADOM) approach for domain analysis. This approach treats a domain as a regular application that needs to be modeled before systems of that domain are specified and designed. This way, the domain structure and behavior are modeled, enforcing static and dynamic constraints on the relevant application models. The ADOM approach consists of three-layers: the language layer handles modeling language ontologies and their constraints, the domain layer holds the building elements of domains and the relations among them, and the application layer consists of domain-specific systems. Furthermore, the ADOM approach defines dependency and enforcement relations between these layers. In this paper we focus on applying the ADOM approach to UML and especially to its class and sequence diagrams.",
    "keywords": []
  },
  {
    "title": "Using UML-based Feature Models and UML\nCollaboration Diagrams to Information Modelling for\nWeb-Based Applications",
    "date": 2004,
    "abstract": "Web oriented software technology has provided access to informa- tion serving environments for a broad audience. This situation requires web- based software applications which satisfy increasing variety of requirements of the broad audience. Such variability can be found in requirements for informa- tion but also for environment which is serving the information. In this paper, we discuss a method which utilizes the UML-based feature modelling to support the need to model the variability. The information and environment conﬁgurations are modelled as common and variable features of application domain and en- vironment concepts. Separation of feature models into application domain and environment allows us to select several conﬁgurations of environments to deliver particular information. The UML collaboration diagrams model collaborations between the application domain and environment concept and feature instances as an abstraction for presented information fragments in a web application.",
    "keywords": [
      "Feature modelling",
      "information modelling",
      "web-based application",
      "UML collaboration diagrams"
    ]
  },
  {
    "title": "Workshops at the UML 2004 Conference",
    "date": 2004,
    "abstract": "UML 2004 conference hosts twelve workshops. These selected events cover a wide range of hot topics related to the Uniﬁed Modeling Language. In the following, a brief summary of each workshop, along with the list of organizers and references for further information are given.",
    "keywords": []
  },
  {
    "title": "Tutorials at the UML 2004 Conference",
    "date": 2004,
    "abstract": "The UML 2004 conference provides six half-day tutorials on advanced topics related to UML, presented by recognized worldwide ex- perts. A short summary of each tutorial and a list of its respective pre- senters are given in section 2.",
    "keywords": []
  },
  {
    "title": "Activity Diagram Patterns for Modeling Quality \nConstraints in Business Processes",
    "date": 2005,
    "abstract": "Quality management is an important aspect of business processes. Organizations must implement quality requirements, e.g., according to standards like ISO 9001. Existing approaches on business process modeling provide no explicit means to enforce such requirements. UML Activity Diagrams are a well recognized way of representing those business processes. In this paper, we present an approach for enforcing quality requirements in such business processes through the application of process quality patterns to Activity Diagrams. These patterns are defined using a pattern description language, being a light-weight extension of UML Activity Diagrams. Accordingly, such patterns can be used in forward-engineering of business processes that incorporate quality constraints right from the beginning.",
    "keywords": [
      "UML Activity Diagrams",
      "Business Process",
      "Process Quality",
      "ISO 9001"
    ]
  },
  {
    "title": "UML4SPM: A UML2.0-Based Metamodel for Software \nProcess Modelling1",
    "date": 2005,
    "abstract": "In the context of Model Driven Development, models play a central role. Since models can nowadays be executed, they are used not only for description but also for production [32][30][24]. In the field of software process modelling, the current version of the OMG SPEM standard (ver1.1) has not yet reached the level required for the specification of executable models. The purpose of SPEM1.1 was limited at providing process descriptions to be read by humans and to be supported by tools, but not to be executed. Therefore, the OMG issued a new RFP in order to improve SPEM1.1 [35]. Since we intend to participate in the next major revision of SPEM, namely SPEM2.0, in this work, we: 1) compare SPEM1.1 both with primary process model elements (i.e. Activity, Product, Role,…) and with basic requirements that any Process Modelling Language should support (i.e. expressiveness, understandability, executability,…); 2) identify its major limitations and advantages and 3) propose a new UML2.0-based metamodel for software process modelling named: UML4SPM. It extends a subset of UML2.0 concepts - with no impact on the standard - in order to fit software process modelling.",
    "keywords": [
      "MDD",
      "Software Process Modelling",
      "Process Modelling  Languages",
      "SP Metamodel."
    ]
  },
  {
    "title": "Realizing Model Driven Security for  \nInter-organizational Workflows with WS-CDL and \n UML 2.0 \nBringing Web Services, Security and UML Together",
    "date": 2005,
    "abstract": "The growing popularity of standards related to Web services, Web services security and workflows boosted the implementation of powerful infrastructures supporting interoperability for inter-organizational workflows. Nevertheless, the realization of such workflows is a very complex task, in many aspects still bound to low-level technical knowledge and error-prone. We provide a framework for the realization and the management of security-critical workflows based on the paradigm of Model Driven Security. The framework complies with a hierarchical stack of Web services specifications and related technologies. In this paper, we introduce a UML based approach for the modeling of security-critical inter-organizational workflows and map it to the Web Services Choreography Description Language. Our approach is based on a set of security patterns, which are integrated into UML class and activity diagrams. A tool translates the models into executable artifacts configuring a reference architecture based on Web services.",
    "keywords": []
  },
  {
    "title": "Code Generation from UML Models with Semantic Variation Points⋆",
    "date": 2005,
    "abstract": "UML semantic variation points provide intentional degrees of freedom for the interpretation of the metamodel semantics. The inter- est of semantic variation points is that UML now becomes a family of languages sharing lot of commonalities and some variabilities that one can customize for a given application domain. In this paper, we propose to reify the various semantic variation points of UML 2.0 statecharts into models of their own to avoid hardcoding the semantic choices in the tools. We do the same for various implementation choices. Then, along the line of the OMG’s Model Driven Architecture, these semantic and implementation models are processed along with a source UML model (that can be seen as a PIM) to provide a target UML model (a PSM) where all semantic and implementation choice are made explicit. This target model can in turn serve as a basis for a consistent use of code generation, simulation, model-checking or test generation tools.",
    "keywords": []
  },
  {
    "title": "Composing Domain-Specific Languages for                  \nWide-Scope Software Engineering Applications",
    "date": 2005,
    "abstract": "Domain-Specific Languages (DSL) offer many advantages over gen- eral languages, but their narrow scope makes them really effective only in very focused domains, for example Product Lines. The recent Model Driven Engi- neering (MDE) approach seeks to provide a technology to compose and com- bine models coming from different metamodels. Adapted to DSL, it means that it should be possible to compose “programs” written in different DSLs, which will enable the use of the DSL approach to build applications spanning different domains. The paper presents the Mélusine environment, where such a composi- tion technology has been developed and experimented.",
    "keywords": []
  },
  {
    "title": "Model Typing for Improving Reuse in\nModel-Driven Engineering",
    "date": 2005,
    "abstract": "Where object-oriented languages deal with objects as de- scribed by classes, model-driven development uses models, as graphs of interconnected objects, described by metamodels. A number of new lan- guages have been and continue to be developed for this model-based paradigm, both for model transformation and for general programming using models. Many of these use single-object approaches to typing, de- rived from solutions found in object-oriented systems, while others use metamodels as model types, but without a clear notion of polymorphism. Both of these approaches lead to brittle and overly restrictive reuse char- acteristics. In this paper we propose a simple extension to object-oriented typing to better cater for a model-oriented context, including a simple strategy for typing models as a collection of interconnected objects. Us- ing a simple example we show how this extended approach permits more ﬂexible reuse, while preserving type safety.",
    "keywords": []
  },
  {
    "title": "UML Vs. Classical Vs. Rhapsody Statecharts:\nNot All Models Are Created Equal",
    "date": 2005,
    "abstract": "State machines, represented by statecharts or statechart dia- grams, are an important formalism for behavioural modelling. According to the research literature, the most popular statechart formalisms ap- pear to be Classical, UML, and that implemented by Rhapsody. These three formalisms seem to be very similar; however, there are several key syntactic and semantic diﬀerences. These diﬀerences are enough that a model written in one formalism could be ill-formed in another formalism. Worse, a model from one formalism might actually be well-formed in an- other, but be interpreted diﬀerently due to the semantic diﬀerences. This paper summarizes the results of a comparative study of these three for- malisms with the help of several illustrative examples. Then, we present a classiﬁcation of the diﬀerences together with a comprehensive overview.",
    "keywords": []
  },
  {
    "title": "Evaluating the Effect of Composite States on the \nUnderstandability of UML Statechart Diagrams",
    "date": 2005,
    "abstract": "UML statechart diagrams have become an important technique for describing the dynamic behavior of a software system. They are also a signifi- cant element of OO design, especially in code generation frameworks such as Model Driven Architecture (MDA). In previous works we have defined a set of metrics for evaluating structural properties of UML statechart diagrams and have validated them as early understandability indicators, through a family of controlled experiments. Those experiments have also revealed that the number of composite states had, apparently, no influence on the understandability of the diagrams. This fact seemed a bit suspicious to us and we decided to go a step further. So in this work we present a controlled experiment and a replication, focusing on the effect of composite states on the understandability of UML statechart diagrams. The results of the experiment confirm, to some extent, our intuition that the use of composite states improves the understandability of the diagrams, so long as the subjects of the experiment have had some previous ex- perience in using them. There are educational implications here, as our results justify giving extra emphasis to the use of composite states in UML statechart diagrams in Software Engineering courses.",
    "keywords": []
  },
  {
    "title": "Computing Refactorings of Behavior Models",
    "date": 2005,
    "abstract": "For given behavior models expressed in statechart-like for- malisms, we show how to compute semantically equivalent but struc- turally diﬀerent models. These refactorings are deﬁned by user-provided logical predicates that partition the system’s state space and that char- acterize coherent parts—modes or control states—of the behavior.",
    "keywords": []
  },
  {
    "title": "Dynamic Secure Aspect Modeling with UML: From Models to Code",
    "date": 2005,
    "abstract": "Security engineering deals with modeling, analysis, and im- plementation of complex security mechanisms. The dynamic nature of such mechanisms makes it diﬃcult to anticipate undesirable emergent behavior. In this work, we propose an approach to develop and analyze security-critical speciﬁcations and implementations using aspect-oriented modeling. Since we focus on the dynamic views of a system, our work is complementary to existing approaches to security aspects mostly con- cerned with static views. Our approach includes a link to implementa- tions in so far as the code which is constructed from the models can be analyzed automatically for satisfaction of the security requirements stated in the UML diagrams. We present tool support for our approach.",
    "keywords": []
  },
  {
    "title": "Performance Analysis of UML Models Using                \nAspect-Oriented Modeling Techniques",
    "date": 2005,
    "abstract": "Aspect-Oriented Modeling (AOM) techniques allow software de- signers to isolate and address separately solutions for crosscutting concerns (such as security, reliability, new functional features, etc.) This paper proposes an approach for analyzing the performance effects of a given aspect on the overall system performance, after the composition of the aspect model with the primary model of a system. Performance analysis of UML models is enabled by the \"UML Performance Profile for Schedulability, Performance and Time\" (SPT) standardized by OMG, which defines a set of quantitative performance annotations to be added to a UML model. The first step of the proposed ap- proach is to add performance annotations to both the primary model and to the aspect model(s). An aspect model is generic at first, and therefore its perform- ance annotations must be parameterized. A generic model will be converted into a context-specific aspect model with concrete values assigned to its per- formance annotations. The latter is composed with the primary model, generat- ing a complete annotated UML model. By using existing techniques, the com- plete model is transformed automatically into a Layered Queueing Network (LQN) performance model, which can be analyzed with existing solvers. The proposed approach is illustrated with a case study system, whose primary model is enhanced with some security features by using AOM. The LQN model of the primary system was validated against measurements in previous work. The per- formance effects of the security aspect under consideration are analyzed in two design alternatives by using the LQN model of the composed system.",
    "keywords": []
  },
  {
    "title": "Domain Models Are Aspect Free",
    "date": 2005,
    "abstract": "Proponents of aspect orientation have successfully seeded the im- pression that aspects—like objects—are so fundamental a notion that they should pervade all phases and artefacts of the software development process. Aspect orientation has therefore proliferated from programming to design to analysis to requirements, sparing neither software processes nor their favourite languages. Since modelling plays an important role in software engineering, much effort is currently being invested in making modelling languages aspect ready. However, based on an observed lack of examples for domain level (or functional) aspects this paper argues the case against the omnipresence of as- pects, particularly the existence of aspects in domain models, and offers some informal arguments as well as a semiformal proof in favour of the claims made.",
    "keywords": []
  },
  {
    "title": "Representing and Applying Design Patterns:              \nWhat Is the Problem?",
    "date": 2005,
    "abstract": "Design patterns embody proven solutions to recurring design problems. Ever since the gang of four popularized the concept, researchers have been trying to develop methods for representing design patterns, and applying them to modeling problems. To the best of our knowledge, none of the approaches proposed so far represents the design problem that the pattern is meant to solve, explicitly. An explicit representation of the problem has several advantages, including 1) a better characterization of the problem space addressed by the pattern—better than the textual description embodied in pattern documentation templates, 2) a more natural representation of the transformations embodied in the application of the pattern, and 3) a better handle on the automatic detection and application of patterns. In this paper, we describe the principles underlying our approach, and the current implementation in the Eclipse Modeling Framework™.",
    "keywords": []
  },
  {
    "title": "Properties of Stereotypes from the Perspective of Their \nRole in Designs",
    "date": 2005,
    "abstract": "Stereotypes in object-oriented software development can be perceived in various ways and they can be used for various purposes. As a consequence of these variations, assessing quality of stereotypes needs to be purpose-specific. In this paper we identify eight types of stereotypes and provide a set of criteria for assessing quality of stereotypes. The criteria for each type are formed by a set of properties that characterizes its stereotypes. The identified types are based on the purpose of each stereotype (its role in designs) and its expressiveness. We identified the types of stereotypes and their properties in an empirical way by investigating stereotypes from UML profiles used in industrial software development. The properties are intended to be used in our further research for developing guidelines for creating and using stereotypes in a more efficient way.",
    "keywords": []
  },
  {
    "title": "A Modelling and Simulation Based Approach to\nDependable System Design",
    "date": 2005,
    "abstract": "Complex real-time system design needs to address dependability re- quirements, such as safety, reliability, and security. We introduce a modelling and simulation based approach which allows for the analysis and prediction of dependability constraints. Dependability can be improved by making use of fault tolerance techniques. The de-facto example in the real-time system literature of a pump control system in a mining environment is used to demonstrate our model- based approach. In particular, the system is modelled using the Discrete EVent system Speciﬁcation (DEVS) formalism, and then extended to incorporate fault tolerance mechanisms. The modularity of the DEVS formalism facilitates this extension. The simulation demonstrates that the employed fault tolerance tech- niques are effective. That is, the system performs satisfactorily despite the pres- ence of faults. This approach also makes it possible to make an informed choice between different fault tolerance techniques. Performance metrics are used to measure the reliability and safety of the system, and to evaluate the dependabil- ity achieved by the design. In our model-based development process, modelling, simulation and eventual deployment of the system are seamlessly integrated.",
    "keywords": []
  },
  {
    "title": "Extending Profiles with  \nStereotypes for Composite Concepts1",
    "date": 2005,
    "abstract": "This paper proposes an extension of the UML 2.0 profiling mecha- nism. This extension facilitates a language designer to introduce composite concepts as separate conceptual and notational elements in a modelling lan- guage. Composite concepts are compositions of existing concepts. To facilitate the introduction of composite concepts, the notion of stereotype is extended. This extension defines how a composite concept can be specified and added to a language’s metamodel, without modifying the existing metamodel. From the definition of the stereotype, rules can be derived for transforming a language element that represents a composite concept into a composition of language elements that represent the concepts that constitute the composite. Such a trans- formation facilitates tool developers to introduce tool support for composite concepts, e.g., by re-using existing tools that support the constituent concepts. To illustrate our ideas, example definitions of stereotypes and transformations for composite concepts are presented.",
    "keywords": []
  },
  {
    "title": "Transformation from CIM to PIM: A Feature-Oriented \nComponent-Based Approach",
    "date": 2005,
    "abstract": "Model Transformation is a crucial part of Model-Driven Architecture (MDA). However, most of the current researches only focus on the transforma- tion from PIM to PSM, and pay little attention to the CIM-to-PIM transforma- tion. One of the results is that converting CIM to PIM will depend much on de- signers’ personal experience or creativity, and thus the quality of PIM can not be well controlled. This paper presents a feature-oriented component-based ap- proach to the CIM-to-PIM transformation. In this approach, features and com- ponents are adopted as the key elements of CIM and PIM, respectively. One important characteristic of this approach is that it provides a method to decom- pose the n-to-n relations between features and components into two groups of 1-to-n relations. The other important characteristic is that this approach pro- poses a way to create components by clustering responsibilities which are op- erationalized from features. These two characteristics partially resolve two ba- sic problems related to the CIM-to-PIM transformation: one is the traceability problem between CIM and PIM, the other is the problem of CIM-based PIM construction.",
    "keywords": []
  },
  {
    "title": "Weaving Executability into                                       \nObject-Oriented Meta-languages",
    "date": 2005,
    "abstract": "Nowadays, object-oriented meta-languages such as MOF (Meta- Object Facility) are increasingly used to specify domain-specific languages in the model-driven engineering community. However, these meta-languages focus on structural specifications and have no built-in support for specifications of operational semantics. In this paper we explore the idea of using aspect- oriented modeling to add precise action specifications with static type checking and genericity at the meta level, and examine related issues and possible solutions. We believe that such a combination would bring significant benefits to the community, such as the specification, simulation and testing of operational semantics of metamodels. We present requirements for such statically-typed meta-languages and rationales for the aforementioned benefits.",
    "keywords": []
  },
  {
    "title": "Refactoring OCL Annotated UML Class Diagrams⋆",
    "date": 2005,
    "abstract": "Refactoring of UML class diagrams is an emerging research topic and heavily inspired by refactoring of program code written in object-oriented implementation languages. Current class diagram refac- toring techniques concentrate on the diagrammatic part but neglect OCL constraints that might become syntactically incorrect by changing the underlying class diagram. This paper formalizes the most important refactoring rules for class diagrams and classiﬁes them with respect to their impact on annotated OCL constraints. For refactoring rules, whose application on class diagrams could make attached OCL constraints in- correct, we formally describe how the OCL constraints have to be refac- tored to preserve their syntactical correctness. Our refactoring rules are deﬁned in the graph-grammar based formalism proposed by the QVT Merge Group for the speciﬁcation of model transformations.",
    "keywords": []
  },
  {
    "title": "Replicators: Transformations to Address Model \nScalability",
    "date": 2005,
    "abstract": "In Model Integrated Computing, it is desirable to evaluate different design alternatives as they relate to issues of scalability. A typical approach to address scalability is to create a base model that captures the key interactions of various components (i.e., the essential properties and connections among modeling entities). A collection of base models can be adorned with necessary information to characterize their replication. In current practice, replication is accomplished by scaling the base model manually. This is a time-consuming process that represents a source of error, especially when there are deep interactions between model components. As an alternative to the manual process, this paper presents the idea of a replicator, which is a model transformation that expands the number of elements from the base model and makes the correct connections among the generated modeling elements. The paper motivates the need for replicators through case studies taken from models supporting different domains.",
    "keywords": []
  },
  {
    "title": "Simplifying Transformations of OCL Constraints",
    "date": 2005,
    "abstract": "With the advent of Model Driven Architecture, OCL con- straints are no longer necessarily written by humans. They can be part of models that emerge from a chain of transformations. They might be the result of instantiating templates, of combining prefabricated parts, or of more general computation. Such generated speciﬁcations will of- ten contain redundancies that reduce their readability. In this paper, we explore the possibilities of transforming OCL formulae to a simpler form through the repeated application of simple rules. We discuss the diﬀerent kinds of rules that are needed, and we describe a prototypical implementation of the approach.",
    "keywords": []
  },
  {
    "title": "Lessons Learned from Automated Analysis of Industrial UML Class Models (An Experience Report) ⋆⋆⋆",
    "date": 2005,
    "abstract": "Automated analysis of object-oriented design models can provide insight into the quality of a given software design. Data obtained from automated analysis, however, is often too complex to be easily un- derstood by a designer. This paper examines the use of an automated analysis tool on industrial software UML class models, where one set of models was created as part of the design process and the other was obtained from reverse engineering code. The analysis was performed by DesignAdvisor, a tool developed by Siemens Corporate Research, that supports metrics-based analysis and detection of design guideline viola- tions. The paper describes the lessons learned from using the automated analysis techniques to assess the quality of these models. We also assess the impact of design pattern use in the overall quality of the models. Based on our lessons learned, identify design guidelines that would min- imize the occurrence of these errors.",
    "keywords": []
  },
  {
    "title": "Reliability Prediction in Model-Driven Development",
    "date": 2005,
    "abstract": "Evaluating the implications of an architecture design early in the soft- ware development lifecycle is important in order to reduce costs of development. Reliability is an important concern with regard to the correct delivery of software system service. Recently, the UML Proﬁle for Modeling Quality of Service has deﬁned a set of UML extensions to represent dependability concerns (including reliability) and other non-functional requirements in early stages of the software development lifecycle. Our research has shown that these extensions are not com- prehensive enough to support reliability analysis for model-driven software engi- neering, because the description of reliability characteristics in this proﬁle lacks support for certain dynamic aspects that are essential in modeling reliability. In this work, we deﬁne a proﬁle for reliability analysis by extending the UML 2.0 speciﬁcation to support reliability prediction based on scenario speciﬁcations. A UML model speciﬁed using the proﬁle is translated to a labelled transition system (LTS), which is used for automated reliability prediction and identiﬁcation of im- plied scenarios; the results of this analysis are then fed back to the UML model. The result is a comprehensive framework for addressing software reliability mod- eling, including analysis and evolution of reliability predictions. We exemplify our approach using the Boiler System used in previous work and demonstrate how reliability analysis results can be integrated into UML models.",
    "keywords": []
  },
  {
    "title": "Model-Based Scalability Estimation in Inception-Phase \nSoftware Architecture",
    "date": 2005,
    "abstract": "Scalability is one of the crucial nonfunctional requirements that must be evaluated in the Inception Phase of the Rational Unified Process [9]. This is the phase in which the least information is generally available to form a principled evaluation. We demonstrate how an estimate of user scalability can be formed using sequence diagrams of the common user scenarios, together with experimentation (ranging from simple timing measurements to more complex architectural prototypes), published study data, and performance data from baseline systems. Despite being quite inexpensive, the techniques used by our team enabled us to identify and guide corrective actions for major bottlenecks before they became serious design flaws in the Elaboration and Construction phases of the Unified Process. The same techniques also allowed us to quickly evaluate the effects of high-level architecture and technology alternatives on user scalability and response time.",
    "keywords": []
  },
  {
    "title": "Explicit Platform Models for MDA",
    "date": 2005,
    "abstract": "The main drive for Model-Driven Architecture is that many software applications have to be deployed on a variety of platforms. The way MDA achieves this is by transforming a platform-independent model of the software to a platform-speciﬁc model, given a platform model. In current MDA approaches, the model transformations implicitly represent this platform model. Therefore, the number of diﬀerent target platforms is limited to the number of supported model transformations. We pro- pose a separate platform model, based on description logics, that can can be used to automatically select and conﬁgure a number of reusable model transformations for a concrete platform. This platform model can be extended to describe the relevant platform information, including con- crete platform instances as well as platform constraints for each model transformation. This separates the model transformation concern from the platform concern and, since the model transformations are no longer limited to targeting one platform, more platforms can be supported with the same set of transformations.",
    "keywords": []
  },
  {
    "title": "Integrated Model-Based Software Development,\nData Access, and Data Migration",
    "date": 2005,
    "abstract": "In this paper we describe a framework for robust system maintenance that addresses speciﬁc challenges of data-centric applica- tions. We show that for data-centric applications, classical simultaneous roundtrip engineering approaches are not suﬃcient. Instead we propose an architecture that is an integrated model-based approach for software development, database access and data migration. We explain the canon- ical development process to exploit its features. We explain how the approach ﬁts into the model-driven architecture vision. We report on ex- periences with the approach in the IMIS environmental mass database project.",
    "keywords": []
  },
  {
    "title": "Concepts for Comparing Modeling Tool Architectures",
    "date": 2005,
    "abstract": "As model-driven development techniques grow in importance so do the capabilities and features of the tools that support them, especially tools that allow users to customize their modeling language. Superficially, many model- ing tools seem to offer similar functionality, but under the surface there are important differences that can have an impact on tool builders and users depen- ding on the tool architecture chosen. At present, however, there is no estab- lished conceptual framework for characterizing and comparing different tool architectures. In this paper we address this problem by first introducing a con- ceptual framework for capturing tool architectures, and then—using this framework—discuss the choices available to designers of tools. We then com- pare and contrast the main canonical architectures in use today.",
    "keywords": []
  },
  {
    "title": "Scenario Construction Tool Based on Extended UML Metamodel",
    "date": 2005,
    "abstract": "Scenario based notations are becoming more and more popu- lar as means for user requirements elicitation. They can be used in more formal speciﬁcations as part of detailed use case templates or in agile processes to capture informal user stories. Despite their signiﬁcance in software engineering, scenarios seem not to be properly supported by appropriate tools. This paper describes a scenario construction tool that oﬀers clear separation of the actual story from notions used therein. The tool is constructed as an extension to visual notation of UML’s use cases. It is based on an extended UML metamodel in the area of activi- ties and classiﬁers. This formal basis makes the tool capable of supplying the existing UML tools with an additional layer of requirements models based on scenarios and notions. This layer makes it possible to trans- form requirements directly into design-level models. The tool oﬀers such transformation capabilities based on a simple model mapping. This trans- formation supports human eﬀorts to keep the system’s design consistent with the user’s needs expressed through scenarios.",
    "keywords": []
  },
  {
    "title": "The Impact of UML 2.0 on Existing UML 1.4 Models",
    "date": 2005,
    "abstract": "The Unified Modeling Language (UML) is the accepted standard for object-oriented modeling across the software design industry. Version 2.0 of the UML represents a major new revision to this standard and includes many changes to the current industry state of the practice (UML 1.4). These revisions include the removal or renaming of some existing features as well as the addition of several new capabilities. As tool vendors and software engineers begin to adopt UML 2.0, there is a potential to greatly impact legacy systems and practitioners employing UML 1.4. This report aims at providing an understanding of the changes made in UML 2.0 and their potential impacts, both positive and negative, to the UML 1.4 modeling community.",
    "keywords": []
  },
  {
    "title": "Towards UML 2 Extensions for Compact\nModeling of Regular Complex Topologies",
    "date": 2005,
    "abstract": "The MARTE RFP (Modeling and Analysis of Real-Time and Embedded systems) was issued by the OMG in February 2005. This request for proposals solicits submissions for a UML proﬁle that adds ca- pabilities for modeling Real Time and Embedded Systems (RTES), and for analyzing schedulability and performance properties of UML speciﬁ- cations. One of the particular request of this RFP concerns the deﬁnition of common high-level modeling constructs for factorizing repetitive struc- tures, for software, hardware and allocation modeling of RTES. We pro- pose an answer to this particular requirement, based on the introduction of multi-dimensional multiplicities and mechanisms for the description of regular connection patterns between model elements. This proposition is domain independent. We illustrate the use of these mechanisms in an in- tensive computation embedded system co-design methodology. We focus on what these factorization mechanisms can bring for each of the aspects of the co-design: application, hardware architecture, and allocation.",
    "keywords": []
  },
  {
    "title": "Using UML 2.0 Collaborations for Compositional\nService Speciﬁcation",
    "date": 2005,
    "abstract": "Collaborations and collaboration uses are features new to UML 2.0. They possess many properties that support rapid and compositional service en- gineering. The notion of collaboration corresponds well with the notion of a ser- vice, and it seems promising to use them for service speciﬁcation. We present an approach where collaborations are used to specify services, and show how col- laborations enable high level feature composition by means of collaboration uses. We also show how service goals can be combined with behavior descriptions of collaborations to form what we call semantic interfaces. Semantic interfaces can be used to ensure compatibility when binding roles to classes and when compos- ing systems from components. Various ways to compose collaboration behaviors are outlined and illustrated with telephony services.",
    "keywords": []
  },
  {
    "title": "Model-Driven Engineering in a Large Industrial\nContext — Motorola Case Study",
    "date": 2005,
    "abstract": "In an ongoing eﬀort to reduce development costs in spite of increasing system complexity, Motorola has been a long-time adopter of Model-Driven Engineering (MDE) practices. The foundation of this approach is the creation of rigorous models throughout the development process, thereby enabling the introduction of automation. In this paper we present our experiences within Motorola in deploying a top-down approach to MDE for more than 15 years. We describe some of the key competencies that have been developed and the impact of MDE within the organization. Next we present some of the main issues encountered during MDE deployment, together with some possible resolutions.",
    "keywords": []
  },
  {
    "title": "Using a Domain-Speciﬁc Language and Custom Tools to Model a Multi-tier Service-Oriented Application — Experiences and Challenges",
    "date": 2005,
    "abstract": "A commercial Customer Relationship Management applica- tion of approx. 1.5 MLOC of C++ code is being reimplemented, in stages, as a service-oriented, multi-tier application in C# on Microsoft .NET. We have chosen to use a domain-speciﬁc language both to model the external service-oriented interfaces, and to manage the transition to the internal, object-oriented implementation. Generic UML constructs such as class diagrams do not capture enough semantics to model these con- cepts. By deﬁning a UML Proﬁle that incorporates the concepts we wish to model, we have in eﬀect created a Domain-Speciﬁc Language for our application. The models are edited using Rational XDE, but we have sub- stituted our own code generator. This generator is a relatively generic text-substitution engine, which takes a template text and performs sub- stitutions based on the model. The generator uses reﬂection to convert the UML and Proﬁle concepts into substitution tags, which are in turn used in the template text. In this way, we can translate the semantics of the model into executable code, WSDL or other formats in a ﬂexible way. We have successfully used this approach on a prototype scale, and are now transitioning to full-scale development.",
    "keywords": []
  },
  {
    "title": "Uniform Support for Modeling Crosscutting Structure",
    "date": 2005,
    "abstract": "We propose bottom-up support for modeling crosscutting structure in UML by adding a simple join point model to the meta-model. This supports built-in crosscutting modeling constructs such as sequence diagrams. It also facilitates adding new kinds of crosscutting modeling constructs such as role bindings, inter-type declarations, and advice. A simple weaver produces a uniform representation of the crosscutting structure, which can then be displayed or analyzed in a variety of ways.",
    "keywords": []
  },
  {
    "title": "Modeling Crosscutting Services with UML Sequence \nDiagrams",
    "date": 2005,
    "abstract": "Current software systems increasingly consist of distributed interact- ing components. The use of web services and similar middleware technologies strongly fosters such architectures. The complexity resulting from a high degree of interaction between distributed components – that we face with web service orchestration for example – poses severe problems. A promising approach to handle this intricacy is service-oriented development; in particular with a do- main-unspecific service notion based on interaction patterns. Here, a service is defined by the interplay of distributed system entities, which can be modeled using UML Sequence Diagrams. However, we often face functionality that af- fects or is spanned across the behavior of other services; a similar concept to aspects in Aspect-Oriented Programming. In the service-oriented world, such aspects form crosscutting services. In this paper we show how to model those; we introduce aspect-oriented modeling techniques for UML Sequence Dia- grams and show their usefulness by means of a running example.",
    "keywords": []
  },
  {
    "title": "A Formal Enforcement Framework for\nRole-Based Access Control Using\nAspect-Oriented Programming",
    "date": 2005,
    "abstract": "Many of today’s software applications require a high-level of security, deﬁned by a detailed policy and attained via mechanisms such as role-based access control (RBAC), mandatory access control, digital signatures, etc. The integration of the design/implementation processes of access-control policies with runtime enforcement mechanisms is crucial to achieve an acceptable level of security for a software application. Our prior research focused on formalizing the concept of a role slice, which is a uniﬁed modeling language (UML) artifact that captures RBAC security requirements by deﬁning permissions in the form of allowable or prohib- ited methods, and by specifying roles as specialized class diagrams that contain those methods. This paper augments this eﬀort by introducing a formal framework for the security of software applications that supports the automatic translation of a role-slice access-control policy (RBAC re- quirements) into aspect-oriented programming (AOP) enforcement code that is seamlessly integrated with the application. The formal framework provides the necessary underpinnings to automate the integration of se- curity policies into software. A prototyping eﬀort based on Borland’s UML tool Together Control Center for deﬁning role-slice diagrams and the associated AOP code generator is under development.",
    "keywords": []
  },
  {
    "title": "A Domain Model for Dynamic System Reconfiguration",
    "date": 2005,
    "abstract": "In this paper, a domain model of dynamic system reconfiguration is presented. The intent of this model is to provide a comprehensive conceptual framework within which to address problems and solutions related to dynamically reconfigurable systems in a systematic and consistent manner. The model identifies and categorizes the various types of change that may be required, the relationship between those types, and the key factors that need to be considered and actions to be performed when such changes take place. A rigorous formal methodology, based on the Alloy language and tools, is employed to specify precisely and formally the detailed relationships between various parts of the model.",
    "keywords": []
  },
  {
    "title": "Exceptional Use Cases",
    "date": 2005,
    "abstract": "Many exceptional situations arise during the execution of an application. When developing dependable software, the ﬁrst step is to foresee these exceptional situations and document how the system should deal with them. This paper outlines an approach that extends use case based requirements elicitation with ideas from the exception handling world. After deﬁning the actors and the goals they pursue when inter- acting with the system, our approach leads a developer to systematically investigate all possible exceptional situations that the system may be ex- posed to: exceptional situations arising in the environment that change user goals and system-related exceptional situations that threaten to fail user goals. Means are deﬁned for detecting the occurrence of all ex- ceptional situations, and the exceptional interaction between the actors and the system necessary to recover from such situations is described in handler use cases. To conclude the requirements phase, an extended UML use case diagram summarizes the standard use cases, exceptions, handlers and their relationships.",
    "keywords": []
  },
  {
    "title": "Modeling Turnpike Frontend System: A Model-Driven \nDevelopment Framework Leveraging UML \nMetamodeling and Attribute-Oriented Programming*",
    "date": 2005,
    "abstract": "This paper describes and empirically evaluates a new model-driven development framework, called Modeling Turnpike (or mTurnpike). It allows developers to model and program domain-specific concepts (ideas and mechanisms specific to a particular business or technology domain) and to transform them to the final (compilable) source code. By leveraging UML metamodeling and attribute-oriented programming, mTurnpike provides an abstraction to represent domain-specific concepts at the modeling and programming layers simultaneously. The mTurnpike frontend system transforms domain-specific concepts from the modeling layer to programming layer, and vise versa, in a seamless manner. Its backend system combines domain-specific models and programs, and transforms them to the final (compilable) source code. This paper focuses on the frontend system of mTurnpike, and describes its design, implementation and performance implications. In order to demonstrate how to exploit mTurnpike in application development, this paper also shows a development process using an example DSL (domain specific language) to specify service-oriented distributed systems.",
    "keywords": []
  },
  {
    "title": "Simplifying Autonomic Enterprise Java Bean \nApplications Via Model-Driven Development:  \nA Case Study",
    "date": 2005,
    "abstract": "Autonomic computer systems aim to reduce the configuration, op- erational, and maintenance costs of distributed applications by enabling them to self-manage, self-heal, self-optimize, self-configure, and self-protect. This pa- per provides two contributions to the model-driven development (MDD) of autonomic computing systems using Enterprise Java Beans (EJBs). First, we describe the structure and functionality of an MDD tool that formally captures the design of EJB applications, their quality of service (QoS) requirements, and the autonomic properties applied to the EJBs to support the rapid development of autonomic EJB applications via code generation, automatic checking of model correctness, and visualization of complex QoS and autonomic properties. Second, the paper describes how MDD tools can generate code to plug EJBs into a Java component framework that provides an autonomic structure to monitor, configure, and execute EJBs and their adaptation strategies at run- time. We present a case study that evaluates how these tools and frameworks work to reduce the complexity of developing autonomic applications.",
    "keywords": []
  },
  {
    "title": "Automated Invariant Maintenance Via OCL Compilation",
    "date": 2005,
    "abstract": "UML design models, specifically their declarative OCL invariants, must be refined into delivered code. A key problem is the need to integrate this logic with programmer-written code in a non-intrusive way. We recently developed an approach, called mode components, for compiling OCL con- straints into modules that implement logic for transparently maintaining these constraints at run time. Specifically, mode components are implemented as nested C++ class template instantiations. The approach makes use of a key device—status variables. The attributes of a component to which other components are sensitive are called its status. A status variable is a lightweight wrapper on a status attribute that detects changes to its value and transparently invokes a method to handle announcements to dependent components. A mode component is a wrapped code unit containing one or more status variables. The contribution of this paper is a technique for achieving this integration using metaprogramming techniques.",
    "keywords": []
  },
  {
    "title": "SelfSync: A Dynamic Round-Trip Engineering\nEnvironment",
    "date": 2005,
    "abstract": "Model-Driven Engineering (MDE) advocates the generation of software applications from models, which are views on certain aspects of the software. In this paper, we focus on a particular setup which con- sists of a graphical data modeling view and a view on an object-oriented implementation, which can be either textual or graphical. A challenge that arizes in the context of MDE is the notion of Round-Trip Engineer- ing (RTE), where elements from both views can be manipulated and thus need to be synchronized. We systematically identify four funda- mental RTE scenarios. In this paper, we employ the framework of these scenarios for explaining SelfSync, our approach and tool for providing dynamic support for RTE. In SelfSync, the entities of the data model- ing view and the corresponding implementation objects are one and the same. Additionally, we present a comparison with related work accom- panied by an extensive discussion.",
    "keywords": []
  },
  {
    "title": "UML for Document Modeling: \nDesigning Document Structures for Massive and \nSystematic Production of XML-based Web Contents",
    "date": 2005,
    "abstract": "This paper discusses the applicability of modeling methods originally meant for business applications, on the design of the complex markup vocabularies used for XML Web-content production.",
    "keywords": []
  },
  {
    "title": "Metamodel Reuse with MOF",
    "date": 2005,
    "abstract": "As model-driven development promotes metamodels as key assets it raises the issue of their reuse throughout a model-driven product line life cycle. One recurrent reuse need occurs when metamodeling integrated multi-language platforms: one construct from one language is integrated to constructs from other languages by generalizing it, making it more expressive. None of the metamodel assembly facilities provided by MOF and UML (import, merge and combine) or others proposed in previous work adequately addresses this need. We thus propose a new reuse and generalize facility for such purpose.",
    "keywords": []
  },
  {
    "title": "Modeling the User Interface of\nMultimedia Applications",
    "date": 2005,
    "abstract": "Multimedia applications are a branch of software develop- ment with growing importance. Typical application areas are training applications and simulations, infotainment systems - e.g. in cars - or computer games. However, there is still a lack of tailored concepts for a structured development of this kind of application. The current pa- per proposes a modeling approach for the user interface of multimedia applications with the goal of a model-driven development. We identify the special properties of multimedia application development and the resulting aspects to be covered by the user interface model. Existing conventional user interface modeling approaches are not suﬃcient, as they do not cover the media-speciﬁc aspects of the application. However, a multimedia application usually includes conventional user interface el- ements as well. Thus, we ﬁrst propose a solution for the media-speciﬁc part. Second, we elaborate an integration of our approach with existing conventional approaches. Finally, we discuss the overall model-driven de- velopment approach and outline its beneﬁts.",
    "keywords": []
  },
  {
    "title": "An Ontology-Based Approach for Evaluating the Domain \nAppropriateness and Comprehensibility Appropriateness of \nModeling Languages",
    "date": 2005,
    "abstract": "In this paper we present a framework for the evaluation and (re)design of modeling languages. We focus here on the evaluation of the suit- ability of a language to model a set of real-world phenomena in a given domain. In our approach, this property can be systematically evaluated by comparing the level of homomorphism between a concrete representation of the worldview underlying the language (captured in a metamodel of the language), with an ex- plicit and formal representation of a conceptualization of that domain (a refer- ence ontology). The framework proposed comprises a number of properties that must be reinforced for an isomorphism to take place between these two entities. In order to illustrate the approach proposed, we evaluate and extend a fragment of the UML static metamodel for the purpose of conceptual modeling, by com- paring it with an excerpt of a philosophically and cognitive well-founded refer- ence ontology.",
    "keywords": []
  },
  {
    "title": "Tutorials at the MODELS 2005 Conference",
    "date": 2005,
    "abstract": "The MoDELS 2005 conference provides six half-day tutorials on advanced topics related to model-driven engineering, presented by recognized worldwide experts. Here, there is a short summary of each tutorial and the list of presenters.",
    "keywords": []
  },
  {
    "title": "9th International Workshop on  \nAspect-Oriented Modeling",
    "date": 2006,
    "abstract": "This report summarizes the outcomes of the 9th Workshop on Aspect-Oriented Modeling (AOM) held in conjunction with the 9th International Conference on Model Driven Engineering Languages and Systems – MoDELS 2006 – in Genoa, Italy, on the 1st of October 2006. The workshop brought together approximately 25 researchers and practitioners from two communities: aspect-oriented software development and software model engineering. It provided a forum for discussing the state of the art in modeling crosscutting concerns at different stages of the software development process: requirements elicitation and analysis, software architecture, detailed design, and mapping to aspect-oriented programming constructs. This paper gives an overview of the accepted submissions and summarizes the results of the different discussion groups. Papers and presentation slides of the workshop are available at http://www.aspect-modeling.org/.",
    "keywords": []
  },
  {
    "title": "Modeling Features in Aspect-Based Product \nLines with Use Case Slices: \nAn Exploratory Case Study",
    "date": 2006,
    "abstract": "A significant number of techniques that exploit aspects in software design have been proposed in recent years. One technique is use case slices by Jacobson and Ng, that builds upon the success of use cases as a common modeling practice. A use case slice modularizes the implementation of a use case and typically consists of a set of aspects, classes, and interfaces. Work on Feature Oriented Programming (FOP) has shown how features, increments in program functionality, can be modularized and algebraically modeled for the synthesis of product lines. When AspectJ is used in FOP, the structure of feature modules resembles that of use case slices. In this paper, we explore the relations between use case slices modeling and FOP program synthesis and describe their potential synergy for modeling and synthesizing aspect-based product lines.",
    "keywords": []
  },
  {
    "title": "Join Point Patterns:\nA High-Level Join Point Selection Mechanism",
    "date": 2006,
    "abstract": "Aspect-Oriented Programming is a powerful technique to better mod- ularize object-oriented programs by introducing crosscutting concerns in a safe and noninvasive way. Unfortunately, most of the current join point models are too coupled with the application code. This fact hinders the concerns separability and reusability since each aspect is strictly tailored on the base application. This work proposes a possible solution to this problem based on modeling the join points selection mechanism at a higher level of abstraction. In our view, the aspect designer does not need to know the inner details of the application such as a speciﬁc implementation or the used name conventions rather he exclusively needs to know the application behavior to apply his/her aspects. In the paper, we present a novel join point model with a join point selection mechanism based on a high-level program representation. This high-level view of the application decouples the aspects deﬁnition from the base program structure and syntax. The separation between aspects and base program will render the aspects more reusable and independent of the manipulated application.",
    "keywords": []
  },
  {
    "title": "Critical Systems Development Using Modeling \nLanguages – CSDUML 2006 Workshop Report",
    "date": 2006,
    "abstract": "The CSDUML 2006 workshop is a continuation of the series regarding development of critical systems using modeling languages. The report summarizes papers presented and discussion at the workshop.",
    "keywords": []
  },
  {
    "title": "Modeling an Electronic Throttle Controller Using the\nTimed Abstract State Machine Language and Toolset",
    "date": 2006,
    "abstract": "In this paper, we present an integrated toolset that implements the features of the Timed Abstract State Machine (TASM) language, a novel speciﬁ- cation language for embedded real-time systems. The toolset enables the creation of executable speciﬁcations with well-deﬁned execution semantics, abstraction mechanisms, and composition semantics. The features of the toolset are demon- strated using an Electronic Throttle Controller (ETC) from a major automotive vendor. The TASM toolset is used to analyze the resource consumption resulting from the mode switching logic of the ETC, and to verify the completeness and consistency of the speciﬁcation.",
    "keywords": [
      "Formal Speciﬁcation",
      "Modeling",
      "Simulation",
      "Real-Time Systems",
      "Embedded Systems."
    ]
  },
  {
    "title": "Model Checking of UML 2.0 Interactions",
    "date": 2006,
    "abstract": "The UML 2.0 integrates a dialect of High-Level Message Sequence Charts (HMSCs) for interaction modelling. We describe a translation of UML 2.0 interactions into automata for model checking whether an interaction can be sat- isﬁed by a given set of message exchanging UML state machines. The translation supports basic interactions, state invariants, strict and weak sequencing, alterna- tives, ignores, and loops as well as forbidden interaction fragments. The transla- tion is integrated into the UML model checking tool HUGO/RT.",
    "keywords": [
      "Scenarios",
      "UML 2.0 interactions",
      "model checking."
    ]
  },
  {
    "title": "A Unified Ontology-Based Process Model for Software \nMaintenance and Comprehension",
    "date": 2006,
    "abstract": "In this paper, we present a formal process model to support the com- prehension and maintenance of software systems. The model provides a formal ontological representation that supports the use of reasoning services across dif- ferent knowledge resources. In the presented approach, we employ our Descrip- tion Logic knowledge base to support the maintenance process management, as well as detailed analyses among resources, e.g., the traceability between various software artifacts. The resulting unified process model provides users with ac- tive guidance in selecting and utilizing these resources that are context-sensitive to a particular comprehension task. We illustrate both, the technical foundation based on our existing SOUND environment, as well as the general objectives and goals of our process model.",
    "keywords": [
      "Software maintenance",
      "process modeling",
      "ontological reasoning",
      "software comprehension",
      "traceability",
      "text mining."
    ]
  },
  {
    "title": "Formalizing the Well-Formedness Rules of EJB3QL in UML + OCL",
    "date": 2006,
    "abstract": "This paper reports the application of language metamodel- ing techniques to EJB3QL, the object-oriented query language for Java Persistence recently standardized in JSR-220. Five years from now, to- day’s EJB3 applications will be legacy. We see our metamodel as an enabler for increasing the eﬃciency of reverse engineering activities. It has already proven useful in uncovering spots where the EJB3QL spec is vague. The case study reported in this paper involved (a) expressing the abstract syntax and well-formedness rules of EJB3QL in UML and OCL respectively; (b) deriving from that metamodel software artifacts required for several language-processing tasks, targeting two modeling platforms (Eclipse EMF and Octopus); and (c) comparing the gener- ated artifacts with their counterparts in the reference implementation of EJB3 (which was not developed following a language-metamodeling approach). The metamodel of EJB3QL constitutes the basis for apply- ing model-checkers to aid in assuring conformance of tools claiming to support the speciﬁcation.",
    "keywords": [
      "Metamodel",
      "OCL",
      "Static semantics",
      "EJB3QL."
    ]
  },
  {
    "title": "Consistency of Business Process Models and Object Life Cycles",
    "date": 2006,
    "abstract": "Business process models and object life cycles can provide two diﬀerent views on behavior of the same system, requiring that these models are consistent with each other. However, it is diﬃcult to reason about consistency of these two types of models since their relation is not well-understood. We clarify this relation and propose an approach to establishing the required consistency. Object state changes are ﬁrst made explicit in a business process model and then the process model is used to generate life cycles for each object type used in the process. We deﬁne two consistency notions for a process model and an object life cycle and express these in terms of conditions that must hold between a given life cycle and a life cycle generated from the process model.",
    "keywords": [
      "consistency",
      "business process model",
      "object life cycle",
      "activ- ity diagram",
      "state machine",
      "UML."
    ]
  },
  {
    "title": "A Qualitative Investigation of UML Modeling Conventions",
    "date": 2006,
    "abstract": "Analogue to the more familiar notion of coding conventions, modeling conventions attempt to ensure uniformity and prevent common modeling defects. While it has been shown that modeling conventions can decrease defect density, it is currently unclear whether this decreased de- fect density results in higher model quality, i.e., whether models created with modeling conventions exhibit higher ﬁtness for purpose.",
    "keywords": []
  },
  {
    "title": "Model Driven Development of Advanced User Interfaces (MDDAUI) – MDDAUI’06 Workshop Report",
    "date": 2006,
    "abstract": "This paper reports on the 2nd Workshop on Model Driven Development of Advanced User Interfaces (MDDAUI’06) held on Octo- ber 2nd, 2006 at the MoDELS’06 conference in Genova, Italy. It brieﬂy describes the workshop topic and provides a short overview on the work- shop structure. In the main part it introduces the four topics discussed in the workshop’s afternoon sessions and summarizes the discussion results.",
    "keywords": []
  },
  {
    "title": "A Model-Driven Approach to the Engineering of Multiple User Interfaces",
    "date": 2006,
    "abstract": "In this paper, we describe MANTRA1, a model-driven ap- proach to the development of multiple consistent user interfaces for one application. The common essence of these user interfaces is captured in an abstract UI model (AUI) which is annotated with constraints to the dialogue ﬂow. We consider in particular how the user interface can be adapted on the AUI level by deriving and tailoring dialogue struc- tures which take into account constraints imposed by front-end platforms or inexperienced users. With this input we use model transformations described in ATL (Atlas Transformation Language) to derive concrete, platform-speciﬁc UI models (CUI). These can be used to generate im- plementation code for several UI platforms including GUI applications, dynamic web sites and mobile applications. The generated user interfaces are integrated with a multi tier application by referencing WSDL-based interface descriptions and communicating with the application core over web service protocols.",
    "keywords": [
      "Model-driven",
      "multiple user interfaces",
      "multiple front-ends",
      "user interface engineering",
      "user interface modelling",
      "model transforma- tion",
      "ATL",
      "Atlas Transformation Language."
    ]
  },
  {
    "title": "Model-Driven Dynamic Generation of\nContext-Adaptive Web User Interfaces",
    "date": 2006,
    "abstract": "The systematic development of user interfaces that enhance interaction quality by adapting to the context of use is a desirable, but also highly challenging task. This paper examines to which extent contex- tual knowledge can be systematically incorporated in the model-driven dynamic generation of Web user interfaces that provide interaction for operational features. Three parts of the generation process are distin- guished: selection, parameterization, and presentation. A semantically enriched service-oriented approach is presented that is based on the Cat- walk framework for model interpretation and generation of adaptive, context-aware Web applications. Automation possibilities are addressed and an exemplary case study is presented.",
    "keywords": [
      "Context-aware Web User Interfaces",
      "Web Service Integration",
      "Ontology-based Modeling",
      "Model Interpretation",
      "Model-Driven User In- terface Generation",
      "Parameterization",
      "Semantically Enriched SOA."
    ]
  },
  {
    "title": "Modelling and Analysis of Real Time and Embedded \nSystems – Using UML",
    "date": 2006,
    "abstract": "This paper presents an overview on the outcomes of the workshop MARTES on Modelling and Analysis of Real Time and Embedded Systems that has taken place for the second time in association with the MoDELS/UML 2006 conference. Important themes discussed at this workshop concerned (1) tools for analysis and model transformation and (2) concepts for modelling quantitative aspects with the perspective of analysis.",
    "keywords": [
      "Modelling",
      "Analysis",
      "Real Time",
      "Embedded Systems."
    ]
  },
  {
    "title": "Time Exceptions in Sequence Diagrams",
    "date": 2006,
    "abstract": "UML sequence diagrams partially describe a system. We show how the description may be augmented with exceptions triggered by the violation of timing constraints and compare our approach to those of the UML 2.1 simple time model, the UML Testing Proﬁle and the UML proﬁle for Schedulability, Performance and Time. We give a for- mal deﬁnition of time exceptions in sequence diagrams and show that the concepts are compositional. An ATM example is used to explain and motivate the concepts.",
    "keywords": [
      "speciﬁcation",
      "time constraints",
      "exception handling",
      "formal semantics",
      "reﬁnement."
    ]
  },
  {
    "title": "Applying Model Intelligence Frameworks for Deployment Problem in Real-Time and Embedded Systems",
    "date": 2006,
    "abstract": "There are many application domains, such as distributed real-time and embedded (DRE) systems, where the domain constraints are so restrictive and the solution spaces so large that it is infeasible for modelers to produce correct solution manually using a conventional graphical model-based approach. In DRE systems the available resources, such as memory, CPU, and bandwidth, must be managed carefully to ensure a certain level of quality of service. This paper provides three contributions to simplify modeling of complex application domains: (1) we present our approach of combining model intelligence and domain- speciﬁc solvers with model-driven engineering (MDE) environments, (2) we show techniques for automatically guiding modelers to correct solu- tions and how to support the speciﬁcation of large and complex systems using intelligent mechanisms to complete partially speciﬁed models, and (3) we present the results of applying an MDE tool that maps software components to Electronic Control Units (ECUs) using the typical auto- motive modeling and middleware infrastructure.",
    "keywords": [
      "modeling",
      "Prolog",
      "constraint solver",
      "model completion",
      "model checking",
      "automotive."
    ]
  },
  {
    "title": "OCL for (Meta-)Models in Multiple Application Domains",
    "date": 2006,
    "abstract": "The workshop OCLApps 2006 was organized as a part of MoDELS/UML Conference in Genova, Italy. It continues the series of ﬁve OCL (Object Constraint Language) workshops held at previous UML/MoDELS conferences between 2000 - 2005. Similar to its predeces- sors, the workshop addressed both people from academia and industry. The advent of the MDA (Model Driven Architecture) vision and the rapid acceptance of MDE (Model Driven Engineering) approaches em- phasize new application domains (like Semantic Web or Domain Speciﬁc Languages) and call for new OCL functionalities. In this context, the OCLApps 2006 Workshop, was conceived as a forum enabling researchers and industry experts to present and debate how the OCL could support these new requirements.",
    "keywords": []
  },
  {
    "title": "OCL-Based Validation of a Railway Domain Proﬁle",
    "date": 2006,
    "abstract": "Domain-speciﬁc languages become more and more important these days as they facilitate the close collaboration of domain experts and software developers. One eﬀect of this general tendency is the increasing number of UML proﬁles. UML itself as a popular modeling language is capable of modeling all kinds of systems but it is often ineﬃcient due to its wide-spectrum approach. Proﬁles tailor the UML to a speciﬁc domain and can hence be seen as domain-speciﬁc dialects of UML. At the mo- ment, they mainly introduce new terminology, often in combination with OCL constraints which describe the new constructs more precisely. As most tools do not support validation of OCL expressions let alone supple- menting proﬁles with OCL constraints, it is diﬃcult to check if models based on a proﬁle comply to this proﬁle. A related problem is check- ing whether constraints in the proﬁle contradict constraints in the UML speciﬁcation. In this paper, it is shown how to complete these tasks with the tool USE. As an example, a proﬁle from the railway control systems domain is taken which describes the use of its modeling elements strictly my means of OCL. Models based on this proﬁle serve as a foundation for automated code generation and require unambiguous meaning.",
    "keywords": []
  },
  {
    "title": "OCL Support in an Industrial Environment",
    "date": 2006,
    "abstract": "In this paper, we report on our experiences integrating OCL evaluation support in an industrial-strength (meta-)modeling infrastruc- ture. We focus on the approach taken to improve eﬃciency through what we call impact analysis of model changes to decrease the number of nec- essary (re-)evaluations. We show how requirements derived from appli- cation scenarios have led to design decisions that depart from or resp. extend solutions found in (academic) literature.",
    "keywords": []
  },
  {
    "title": "Report on the 3rd MoDeVa Workshop – Model Design and Validation",
    "date": 2006,
    "abstract": "Software systems are becoming increasingly large and com- plex, and run the risk of serious failures from unforeseen behaviour. Model driven development (MDD) is emerging as a solution with strong potential for dealing with these diﬃculties using models and model trans- formations. However, eﬀective validiation and veriﬁcation techniques are required to take full advantage of the expected beneﬁts of MDD.",
    "keywords": []
  },
  {
    "title": "Towards Model-Driven Unit Testing",
    "date": 2006,
    "abstract": "The Model-Driven Architecture (MDA) approach for constructing software systems advocates a stepwise reﬁnement and transformation process starting from high-level models to concrete program code. In contrast to numer- ous research efforts that try to generate executable function code from models, we propose a novel approach termed model-driven monitoring. On the model level the behavior of an operation is speciﬁed with a pair of UML composite struc- ture diagrams (visual contract), a visual notation for pre- and post-conditions. The speciﬁed behavior is implemented by a programmer manually. An automatic translation from our visual contracts to JML assertions allows for monitoring the hand-coded programs during their execution.",
    "keywords": []
  },
  {
    "title": "Validation of Model Transformations – First Experiences Using a White Box Approach",
    "date": 2006,
    "abstract": "Validation of model transformations is important for ensur- ing their quality. Successful validation must take into account the char- acteristics of model transformations and develop a suitable fault model on which test case generation can be based. In this paper, we report our experiences in validating a number of model transformations and pro- pose three techniques that can be used for constructing test cases.",
    "keywords": [
      "Model transformations",
      "Testing."
    ]
  },
  {
    "title": "Summary of the 2006 Model Size Metrics Workshop",
    "date": 2006,
    "abstract": "A standardized and consistent means of determining the size of an artifact is fundamental to the ability to collect metrics such as de- fect density and productivity about the artifact. For example, source lines of code is often used as the size metric for C code. However, the concept of lines of code does not readily apply to modeling languages such as UML and SDL. This report summarizes the presentations and discussions on this topic from the 2006 Model Size Metrics workshop.",
    "keywords": [
      "Model Size Metrics",
      "Model-Driven Engineering",
      "UML",
      "SDL."
    ]
  },
  {
    "title": "Model Size Matters",
    "date": 2006,
    "abstract": "Size is an important attribute of software artefacts; for most artefact types exists a body of measurement knowledge. As software en- gineering is becoming more and more model-centric, it is surprising that there exists only little work on model size metrics (MoSMe). In this po- sition paper we identify the goals justifying the need for MoSMe, such as prediction, description and progress measurement. Additionally, we iden- tify challenges that make it diﬃcult to measure the size of UML models and that MoSMe have to deal with. Finally, we propose a classiﬁcation of MoSMe and concrete examples of metrics for the size of UML models.",
    "keywords": [
      "Models",
      "UML",
      "Size",
      "Metrics",
      "Measurement",
      "Prediction",
      "GQM."
    ]
  },
  {
    "title": "On the Application of Software Metrics to UML Models",
    "date": 2006,
    "abstract": "In this position paper we discuss a number of issues relating to model metrics, with particular emphasis on metrics for UML models. Our discussion is presented as a series of nine observations where we examine some of the existing work on applying metrics to UML models, present some of our own work in this area, and specify some topics for future research that we regard as important. Furthermore, we identify three categories of challeges for model metrics and describe how our nine observations can be partitioned into these categories.",
    "keywords": [
      "software metrics",
      "object-oriented systems",
      "UML",
      "metamodels."
    ]
  },
  {
    "title": "Summary of the Workshop Models@run.time at \nMoDELS 2006",
    "date": 2006,
    "abstract": "The first edition of the workshop Models@run.time was co-located with the ACM/IEEE 9th International Conference on Model Driven Engineering Languages and Systems (formerly the UML series of conferences). The workshop took place in the antique city of Genoa, Italy, on the 1st of October, 2006. The workshop was organised by Gordon Blair, Robert France, and Nelly Bencomo. This summary gives an overview an account of the presentations and lively discussions that took place during the workshop.",
    "keywords": [
      "model-driven engineering",
      "reflection",
      "run-time systems."
    ]
  },
  {
    "title": "Using Runtime Models to Unify and Structure the Handling of Meta-information in Reﬂective Middleware⋆",
    "date": 2006,
    "abstract": "Reﬂection plays an important role in the ﬂexibilisation of middleware platforms. Through dynamic inspection, middleware inter- faces can be discovered and invoked at runtime, and through adaptation the structure and behaviour of the platform can be modiﬁed on-the- ﬂy to meet new user or environment demands. Metamodeling, on the other hand, has shown its value for the static conﬁguration of middle- ware and other types of system as well. Both techniques have in common the pervasive use of meta-information as the means to provide the sys- tem’s self-representation. However similar they are, these two techniques usually fall on diﬀerent sides of a gap, namely development time and runtime, with little interplay between them. In this paper, we review our approach for the combination of reﬂection and metamodeling, presenting some concrete applications of the concept in the context of distributed systems middleware, as well as propossing further potential applications.",
    "keywords": [
      "Runtime metamodels",
      "Structural reﬂection",
      "Reﬂective middleware."
    ]
  },
  {
    "title": "Applying OMG D&C Speciﬁcation and ECA Rules for Autonomous Distributed Component-Based Systems",
    "date": 2006,
    "abstract": "Manual administration of complex distributed applications is almost impossible to achieve. On the one side, work in autonomic computing focuses on systems that maintain themselves, driven by high- level policies. Such a self-administration relies on the concept of a control loop. The autonomic computing control loop involves an abstract repre- sentation of the system to analyze the situation and to adapt it properly. On the other side, models are currently used to ease design of complex distributed systems. Nevertheless, at runtime, models remain useless, be- cause they are decoupled from the running system, which dynamically evolves. Our proposal, named Dacar, introduces models in the control loop. Using adequate models, it is possible to design and execute both the distributed systems and their autonomic policies. The metamodel suggested in this paper mixes both OMG Deployment and Conﬁgura- tion (OMG D&C) speciﬁcation and the Event-Condition-Action (ECA) metamodels. This paper addresses the diﬀerent concerns involved in the control loop and focuses on the metamodel concepts that are required to express entities of the control loop. This paper also gives an overview of our Dacar prototype and illustrates it on a ubiquitous application case study.",
    "keywords": []
  },
  {
    "title": "Summary of the Workshop on Multi-Paradigm Modeling: Concepts and Tools",
    "date": 2006,
    "abstract": "This paper reports on the ﬁndings of the ﬁrst Workshop on Multi-Paradigm Modeling: Concepts and Tools. It contains an overview of the presented papers and of the results of three working groups which addressed multiple views, abstraction, and evolution. Besides this, a def- inition of the problem space, the main concepts, and an appropriate ter- minology for multi-paradigm modeling as presented and discussed during the workshop are provided.",
    "keywords": [
      "Modeling",
      "Meta-modeling",
      "Multi-Paradgim Modeling",
      "Multi-Formalism."
    ]
  },
  {
    "title": "Think Global, Act Local:\nImplementing Model Management with\nDomain-Speciﬁc Integration Languages⋆",
    "date": 2006,
    "abstract": "In recent years a number of model transformation languages have emerged that deal with ﬁne-grained, local transformation speciﬁca- tions, commonly known as programming in the small [13]. To be able to develop complex transformation systems in a scalable way, mechanisms to work directly on the global model level are desirable, referred to as programming in the large [26]. In this paper we show how domain speciﬁc model integration languages can be deﬁned, and how they can be com- posed in order to achieve complex model management tasks. Thereby, we base our approach on the deﬁnition of declarative model integration languages, of which implementing transformations are derived. We give a categorization of these transformations and rely on an object-oriented mechanism to realize complex model management tasks.",
    "keywords": []
  },
  {
    "title": "Model Driven Security Engineering for the Realization of Dynamic Security Requirements in Collaborative Systems",
    "date": 2006,
    "abstract": "Service Oriented Architectures with underlying technologies like web services and web services orchestration have opened the door to a wide range of novel application scenarios, especially in the context of inter-organizational cooperation. One of the remaining obstacles for a wide-spread use of these techniques is security. Companies and organiza- tions open their systems and core business processes to partners only if a high level of trust can be guaranteed. The emergence of web services secu- rity standards provides a valuable and eﬀective paradigm for addressing the security issues arising in the context of inter-organizational cooper- ation. The low level of abstraction of these standards is, however, still an unresolved issue which makes them inaccessible to the domain expert and remains a major obstacle when aligning security objectives with the customer needs. Their complexity makes implementation easily prone of error. This paper provides a bird eye view of a doctoral work, where an eﬀort is made to develop a conceptual framework – called SECTET in order to apply model driven security engineering techniques for the realization of high-level security requirements.",
    "keywords": []
  },
  {
    "title": "If You’re Not Modeling, You’re Just Programming: \nModeling Throughout an Undergraduate Software \nEngineering Program",
    "date": 2006,
    "abstract": "Modeling is a hallmark of the practice of engineering. Through centuries, engineers have used models ranging from informal “back of the envelope” scribbles to formal, verifiable mathematical models. Whether circuit models in electrical engineering, heat-transfer models in mechanical engineering, or queuing theory models in industrial engineering, modeling makes it possible to perform rigorous analysis that is the cornerstone of modern engineering. By considering software development as fundamentally an engineering endeavor, RIT’s software engineering program strives to instill a culture of engineering practice by exposing our students to both formal and informal modeling of software systems throughout the entire curriculum. This paper describes how we have placed modeling in most aspects of our curriculum. The paper also details the specific pedagogy that we use in several courses to teach our students how to create, analyze and implement models of software systems.",
    "keywords": []
  },
  {
    "title": "Teaching Software Modeling in a Simulated Project Environment",
    "date": 2006,
    "abstract": "Teaching software engineering in the academia always faces the problem of inability to show problems of real life development projects. The courses seem to be unable to properly show the need of us- ing software modeling as important means of coping with complexity and handling communication within the project. The paper presents format of a course that tries to overcome this. It focuses on application of mod- eling tools in a realistic software engineering environment. The objective is to teach best practices of software design and implementation with the use of UML. The students can practice design and communication tech- niques based around CASE tools in teams of 12 to 14 people. The paper summarizes 5 years of experience in teaching modeling with CASE tools. Authors present a concept of how to simulate the roles of architects, de- signers and programmers as close to reality as possible. The paper also discusses the problems of organizing laboratory work for a large group of students. Authors present the tasks and their arrangement during the course.",
    "keywords": [
      "software modeling",
      "education",
      "CASE tools",
      "project commu- nication",
      "UML."
    ]
  },
  {
    "title": "Repository for Model Driven Development (ReMoDD)",
    "date": 2006,
    "abstract": "The Repository for MDD (ReMoDD) project is concerned with devel- oping a repository that will contain artifacts that support research and education in model-driven development (MDD). The ReMoDD platform will also provide interfaces and interchange mechanisms that will enable a variety of tools to re- trieve artifacts from the repository and submit candidate artifacts to the reposi- tory. ReMoDD artifacts will include documented MDD case studies, examples of models reﬂecting good and bad modeling practices, reference models (including metamodels) that can be used as the basis for comparing and evaluating MDD techniques, generic models and transformation reﬂecting reusable modeling ex- perience, descriptions of modeling techniques, practices and experiences, and modeling exercises and problems that can be used to develop classroom assign- ments and projects. In this paper we outline plans for developing ReMoDD.",
    "keywords": []
  },
  {
    "title": "2nd UML 2 Semantics Symposium: Formal Semantics for UML",
    "date": 2006,
    "abstract": "The purpose of this symposium, held in conjunction with MoDELS 2006, was to present the current state of research of the UML 2 Semantics Project. Equally important to receiving feedback from an au- dience of experts was the opportunity to invite researchers in the ﬁeld to discuss their own work related to a formal semantics for the Uniﬁed Modeling Language. This symposium is a follow-on to our ﬁrst workshop, held in conjunction with ECMDA 2005.",
    "keywords": [
      "UML",
      "Formal Semantics."
    ]
  },
  {
    "title": "Analysis of UML Activities with\nDynamic Meta Modeling Techniques",
    "date": 2006,
    "abstract": "Based on a semantics of UML Activities speciﬁed with the Dynamic Meta Modeling approach, we analyze the dynamic semantics of Activities at modeling time.",
    "keywords": [
      "UML",
      "semantics",
      "behavior",
      "veriﬁcation",
      "DMM."
    ]
  },
  {
    "title": "Bidirectional Model Transformations in QVT: Semantic Issues and Open Questions",
    "date": 2007,
    "abstract": "We consider the OMG’s Queries, Views and Transforma- tions (QVT) standard as applied to the speciﬁcation of bidirectional transformations between models. We discuss what is meant by bidirec- tional transformations, and the model-driven development scenarios in which they are needed. We analyse the fundamental requirements on tools which support such transformations, and discuss some semantic issues which arise. We argue that a considerable amount of basic re- search is needed before suitable tools will be fully realisable, and suggest directions for this future research.",
    "keywords": [
      "bidirectional model transformation",
      "QVT."
    ]
  },
  {
    "title": "Reconciling TGGs with QVT",
    "date": 2007,
    "abstract": "The Model Driven Architecture (MDA) is an approach to develop software based on different models. There are separate models for the business logic and for platform specific details. Moreover, code can be generated automatically from these models. This makes transformations a core technology for MDA. QVT (Query/View/Transformation) is the transformation technology recently proposed for this purpose by the OMG.",
    "keywords": []
  },
  {
    "title": "UniTI: A Uniﬁed Transformation Infrastructure⋆",
    "date": 2007,
    "abstract": "A model transformation can be decomposed into a sequence of sub- transformations, i.e. a transformation chain, each addressing a limited set of con- cerns. However, with current transformation technologies it is hard to (re)use and compose subtransformations without being very familiar with their implemen- tation details. Furthermore, the difﬁculty of combining different transformation technologies often thwarts choosing the most appropriate technology for each subtransformation. In this paper we propose a model-based approach to reuse and compose subtransformations in a technology-independent fashion. This is accom- plished by developing a uniﬁed representation of transformations and facilitating detailed transformation speciﬁcations. We have implemented our approach in a tool called UniTI, which also provides a transformation chain editor. We have evaluated our approach by comparing it to alternative approaches.",
    "keywords": []
  },
  {
    "title": "Guided Development with Multiple Domain-Speciﬁc Languages",
    "date": 2007,
    "abstract": "We study the Apache Open for Business (OFBiz), an industrial-strength platform for enterprise applications. OFBiz is an example of a substantial project using model-driven development with multiple domain-speciﬁc languages (DSLs). We identify consistency management as one of its key challenges. To address this challenge, we present SmartEMF, which is an extension of the Eclipse Modeling Frame- work that provides support for representing, checking, and maintaining constraints in the context of multiple loosely-coupled DSLs. SmartEMF provides a simple form of user guidance by computing the valid set of editing operations that are available in a given context. We evaluate the prototype by applying it to the OFBiz project.",
    "keywords": []
  },
  {
    "title": "Model-Driven, Network-Context Sensitive Intrusion \nDetection",
    "date": 2007,
    "abstract": "Intrusion Detection Systems (IDSs) have the reputation of generating many false positives. Recent approaches, known as stateful IDSs, take the state of communication sessions into account to address this issue. A substantial reduction of false positives, however, requires some correlation between the state of the session, known vulnerabilities, and the gathering of more network context information by the IDS than what is currently done (e.g., configuration of a node, its operating system, running applications). In this paper we present an IDS approach that attempts to decrease the number of false positives by collecting more network context and combining this information with known vulnerabilities. The approach is model-driven as it relies on the modeling of packet and network information as UML class diagrams, and the definition of intrusion detection rules as OCL expressions constraining these diagrams. The approach is evaluated using real attacks on real systems, and appears to be promising.",
    "keywords": [
      "Intrusion Detection",
      "UML modeling",
      "OCL constraints."
    ]
  },
  {
    "title": "An Empirical Study of the Impact of OCL Smells and \nRefactorings on the Understandability of OCL \nSpecifications",
    "date": 2007,
    "abstract": "The Object Constraint Language (OCL) is a OMG standard that plays an important role in the elaboration of precise models. However, it is not hard to find models and metamodels containing overly complex OCL expressions. Refactoring is a technique that can be used in this context since its goal is to reduce complexity by incrementally improving the internal software quality. Indeed several refactorings have already been proposed to improve the quality of OCL expressions. This paper presents the results of an empirical study that investigates the impact of poor OCL constructs, also known as OCL Smells, and OCL refactorings on the understandability of OCL expressions. Current results show that most refactorings significantly improve the understandability of OCL specifications.",
    "keywords": []
  },
  {
    "title": "On Metamodeling in Megamodels",
    "date": 2007,
    "abstract": "Model-Driven Engineering (MDE) introduced the notion of metamodeling as the main means for defining modeling languages. As a well organized engineering discipline, MDE should also have its theory clearly defined in terms of the relationships between key MDE concepts. Following the spirit of MDE, where models are first class citizens, even the MDE theory can be defined by models, or so called megamodels. In this paper, we use Favre’s megamodel that was already used for defining linguistic metamodeling. Starting from the premise that this megamodel can also be used for defining other MDE concepts, we use it to specify the notion of ontological metamodeling. Here, we show that in order for this megamodel to be able to fully capture all the concepts of ontological metamodeling, some refinements should be applied to its definition. We also show how these new changes are in the same direction with the work of Kühne in defining linguistic and ontological metamodels.",
    "keywords": []
  },
  {
    "title": "Magritte – A Meta-driven Approach to Empower Developers and End Users",
    "date": 2007,
    "abstract": "Model-driven engineering is a powerful approach to build large-scale applications. However, an application’s metamodel often re- mains static after the initial development phase and cannot be changed unless a new development eﬀort occurs. Yet, end users often need to rapidly adapt their applications to new needs. In many cases, end users would know how to make the required adaptations, if only the application would let them do so. In this paper we present how we built a runtime- dynamic meta-environment into Smalltalk’s reﬂective language model. Our solution oﬀers the best of both worlds: developers can develop their applications using the same tools they are used to and gain the power of meta-programming. We show in particular that our approach is suitable to support end user customization without writing new code: the adap- tive model of Magritte not only describes existing classes, but also lets end users build their own metamodels on the ﬂy.",
    "keywords": [
      "Meta-Modeling",
      "Meta-Data",
      "Adaptive Object Model",
      "Busi- ness Application Development",
      "Smalltalk."
    ]
  },
  {
    "title": "Matching Model-Snippets",
    "date": 2007,
    "abstract": "An important demand in Model-Driven Development is the simple and eﬃcient expression of model patterns. Current approaches tend to distinguish the language they use to express patterns from the one for modelling. Consequently, productivity is reduced by dealing with a distinct new language, and new intermediate steps are introduced in order to support pattern-matching. In this paper we propose a frame- work for expressing patterns as model-snippets. We present how model- snippets are speciﬁed upon concepts in a given domain (meta-model), and how we perform pattern-matching with model-snippets, whatever the meta-model. We also provide an implementation which is well inte- grated with existing technologies, such as Eclipse Modelling Framework.",
    "keywords": []
  },
  {
    "title": "Improving Inconsistency Resolution with Side-Eﬀect Evaluation and Costs",
    "date": 2007,
    "abstract": "Consistency management is a major requirement in software engineering. Although this problem has attracted signiﬁcant attention in the literature, support for inconsistency resolution is still not standard for modeling tools. In this paper, we introduce explicit side-eﬀect expres- sions for each inconsistency resolution and costs for each inconsistency type. This allows a ﬁne-grained evaluation of each possible inconsistency resolution for a particular inconsistent model. We further show how an inconsistency resolution module for a modeling tool can be designed and implemented based on our approach. We demonstrate the applicability of our approach for resolution of inconsistencies between object life cycles and process models.",
    "keywords": []
  },
  {
    "title": "Model Composition in Product Lines and Feature \nInteraction Detection Using Critical Pair Analysis",
    "date": 2007,
    "abstract": "Software product lines (SPL) are an established technology for developing families of systems. In particular, they focus on modeling commonality and variability, that is, they are based on identifying features common to all members of the family and variable features that appear only in some members. Model-based development methods for product lines advocate the construction of SPL requirements, analysis and design models for features. This paper describes an approach for maintaining feature separation during modeling using a UML composition language based on graph transformations. This allows models of features to be reused more easily. The language can be used to compose the SPL models for a given set of features. Furthermore, critical pair analysis is used to detect dependencies and conflicts between features during analysis and design modeling. The approach is supported by a tool that allows automated composition of UML models of features and detection of some kinds of feature interactions.",
    "keywords": [
      "Software product lines",
      "model transformation",
      "feature interaction."
    ]
  },
  {
    "title": "Automated Semantic Analysis of Design Models",
    "date": 2007,
    "abstract": "Based on several years of experience in generating code from large SDL and UML models in the telecommunications domain, it has become apparent that model analysis must be used to augment more traditional validation and testing techniques. While model correctness is extremely important, the diﬃculty of use and non-scalability of most formal veriﬁcation techniques when applied to large-scale design models renders them insuﬃcient for most applications. We have also repeat- edly seen that even the most complete test coverage fails to ﬁnd many problems. In contrast, sophisticated model analysis techniques can be applied without human interaction to large-scale models. A discussion of the model analysis techniques and the model defects that they can detect is provided, along with some real-world examples of defects that have been caught.",
    "keywords": []
  },
  {
    "title": "Piecewise Modelling with State Subtypes",
    "date": 2007,
    "abstract": "Models addressing both structure and behaviour of a system are usu- ally quite complex. Much of the complexity is caused by the necessity to distin- guish between different cases, such as legal vs. illegal constellations of objects, typical vs. rare scenarios, and normal vs. exceptional flows of control. The re- sult is an explosion of cases causing large and deeply nested case analyses. While those based on the kinds of objects involved can be tackled with standard dynamic dispatch, possibilities for differentiations based on the state of objects have not yet been considered for modelling. We show how the handling of class and state-induced distinctions can be unified under a common subtyping scheme, and how this scheme allows the simplification of models by splitting them into piecewise definitions. Using a running example, we demonstrate the potential of our approach and explain how it serves the consistent integration of static and dynamic specifications.",
    "keywords": []
  },
  {
    "title": "Deriving Operation Contracts from UML Class Diagrams",
    "date": 2007,
    "abstract": "Class diagrams must be complemented with a set of system operations that describes how users can modify and evolve the system state. To be useful, such a set must be complete (i.e. through these operations, users should be able to modify the population of all elements in the class diagram) and executable (i.e. for each operation, there must exist a system state over which the operation can be successfully applied). Manual specification of these operations is an error-prone and time-consuming activity. Therefore, the goal of this paper is to automatically provide a basic set of system operations that verify these two properties. Operations are drawn from the elements (classes, attributes, etc) of the class diagram and take into account the possible dependencies between the different change events (i.e. inserts/updates/deletes) that may be applied to them. Afterwards, the designer could reuse our proposal to build up more complex operations.",
    "keywords": []
  },
  {
    "title": "Finding the Pattern You Need: The Design Pattern Intent Ontology",
    "date": 2007,
    "abstract": "Since the seminal book by the Gang of Four, design pat- terns have proven an important tool in software development. Over time, more and more patterns have been discovered and developed. The sheer amount of patterns available makes it hard to ﬁnd patterns useful for solving a speciﬁc design problem. Hence, tools supporting searching and ﬁnding design patterns appropriate to a certain problem are required. To develop such tooling, design patterns must be described formally such that they can be queryed by the problem to be solved. Current ap- proaches to formalising design patterns focus on the solution structure of the pattern rather than on the problems solved. In this paper, we present a formalisation of the intent of the 23 patterns from the Gang-of-Four book. Based on this formalisation we have developed a Design Pattern Wizard that proposes applicable design patterns based on a description of a design problem.",
    "keywords": []
  },
  {
    "title": "Model-Driven Approach for Managing \nHuman Interface Design Life Cycle",
    "date": 2007,
    "abstract": "Designing a large application user interface is an iterative process. Commonly used tools lack models to support this iterative process. Research on model-driven UI design has over the years focused on modeling UI at a higher level of abstraction but lacked support during in the iteration process. This paper briefly presents the context of our research – transforming a business model into a base UI model for further customization. Specifically, we present a feature that helps reflect changes from the business model in the user interface design tool. We designed it so that the human designers can choose to react to these changes as they see appropriate. The technique is one of our attempts to apply the model-drive approach to better support design iteration through requirement changes.",
    "keywords": [
      "User Interface Model",
      "Human Computer Interaction Model",
      "User- Centered Design",
      "User Interface Modeling Tools",
      "Model Transformations",
      "Model Engineering Methodologies."
    ]
  },
  {
    "title": "Integrating Heterogeneous Tools into Model-Centric Development of Interactive Applications",
    "date": 2007,
    "abstract": "The development of successful interactive applications often requires high eﬀorts in creative design tasks to build high quality user interfaces. Such creative development tasks – such as user interface design or design of speciﬁc features like 3D objects – are usually performed using diﬀerent tools optimized for the respective task. For example, in early development stages, tools like Photoshop or Flash are established for creating user interface prototypes. 3D graphics is usually developed using 3D authoring tools.",
    "keywords": []
  },
  {
    "title": "A Business-Process-Driven Approach for Generating  \nE-Commerce User Interfaces",
    "date": 2007,
    "abstract": "A business process contains a set of interdependent activities that describe operations provided by an organization. E-commerce applications are designed to automate business processes. A business process specification (i.e., a workflow) is defined by a business analyst from the viewpoint of the end- users. The process encapsulates the knowledge related to the natural work rhythms that a business user would follow when using an e-commerce application. In this paper, we analyze the information embedded in business process specifications, and infer the functional and usability requirements. We use the inferred information in a model-driven approach to automatically generate user interfaces (UIs) from a business process specification through a set of transformations. To improve the usability of UIs for the e-commerce applications, each transformation is guided by usability principles.",
    "keywords": [
      "Business process",
      "User interface generation",
      "Usability",
      "Model  driven engineering",
      "Task model",
      "Dialog model",
      "Presentation model."
    ]
  },
  {
    "title": "Enhancing UML Extensions with Operational Semantics Behaviored Proﬁles with Templates",
    "date": 2007,
    "abstract": "The objective of the ongoing OMG standard about a foun- dational UML subset semantics (fUML) is twofold: providing operational semantics for a UML subset, and ease unambiguous and automatic model exploitations. Its impact could however be limited if usual UML proﬁl- ing practices do not evolve. Proﬁles are the traditional way to specialize UML semantics and handle semantic variation points. However, they are usually deﬁned in a way that only informally addresses the semantic issue, potentially limiting the beneﬁts that fUML could bring in UML based methodologies. UML proﬁling practices must evolve: we propose to explicitly encapsulate operational semantics into stereotype opera- tions, and provide a way to intuitively handle semantic variation points through template parameters. We illustrate the usage of these mecha- nisms and demonstrate their potential beneﬁts. We also show that no UML metamodel modiﬁcations are required to support them, so that their implementation in L3-compliant UML tools is straightforward1.",
    "keywords": []
  },
  {
    "title": "Integrated Deﬁnition of Abstract and Concrete Syntax for Textual Languages",
    "date": 2007,
    "abstract": "An understandable concrete syntax and a comprehensible abstract syntax are two central aspects of deﬁning a modeling language. Both representations of a language signiﬁcantly overlap in their structure and also information, but may also diﬀer in parts of the information. To avoid discrepancies and problems while handling the language, concrete and abstract syntax need to be consistently deﬁned. This will become an even bigger problem, when domain speciﬁc languages will become used to a larger extent. In this paper we present an extended grammar for- mat that avoids redundancy between concrete and abstract syntax by allowing an integrated deﬁnition of both for textual modeling languages. For an amendment of the usability of the abstract syntax it furthermore integrates meta-modeling concepts like associations and inheritance into a well-understood grammar-based approach. This forms a sound foun- dation for an extensible grammar and therefore language deﬁnition.",
    "keywords": []
  },
  {
    "title": "Architectural Aspects in UML",
    "date": 2007,
    "abstract": "Architecture descriptions are important for reasoning about system properties in order to make the right architectural decisions for building systems with adequate quality. Modularising concerns at the architecture description level may ease system conﬁgurability and cater for variations in architectural require- ments. We devise a technique for modularising and composing complex architec- tural connectors described in UML using structured classes. We deﬁne a binding language with lexical and graphical syntax to support the composition. Finally, we discuss the relationship with standard UML constructs.",
    "keywords": []
  },
  {
    "title": "Domain Speciﬁc Modeling Methodology for Reconﬁgurable Networked Systems",
    "date": 2007,
    "abstract": "Our empirical study shows that reconﬁgurable networked systems ex- ecuting software components deployed on interconnected heterogeneous hard- ware nodes highly beneﬁt from an effective framework and a normative design methodology relying on domain speciﬁc models supporting both application and platform domains. The approach is based on building metamodels for various expert domains to enable precise knowledge codiﬁcation in the form of inter- pretable and analyzable information frameworks. The core platform architecture is characterized by interlinked on-the-ﬂy reconﬁgurable communicating compo- nents whose behavior is speciﬁed by ﬁnite state machine model of computation. The proposed methodology covers the whole development and operation life cycle.",
    "keywords": []
  },
  {
    "title": "A Modelling Method for Rigorous and Automated Design of Large-Scale Industrial Systems",
    "date": 2007,
    "abstract": "Compositional architecture-driven and model-based system design holds huge potential to increase design eﬃciency and improve de- sign quality for large-scale industrial systems. Transition to such design paradigm is hampered by the lack of domain-speciﬁc methods and tools that give adequate support for both behavioral and structural modeling and development automation. This paper introduces an enhancement to Lyra, a rigorous service-oriented modeling method for the design of communicating distributed systems that brings process algebraic think- ing into industrial system speciﬁcation with particular focus on behav- ior. This enhancement oﬀers a sound basis for implementing the ideas of MDA in automation of system design, functional veriﬁcation and confor- mance testing. The Lyra method and its enhancement are exempliﬁed using UML2 to model a critical and complex part of the mobile WiMAX wireless system.",
    "keywords": [
      "model-based system design",
      "MDA",
      "UML2",
      "design automa- tion",
      "formal methods."
    ]
  },
  {
    "title": "Relating Navigation and Request Routing Models in Web \nApplications",
    "date": 2007,
    "abstract": "A navigation model describes the possible sequences of web pages a user can visit, and a request routing model describes how server side compo- nents handle each request. Earlier we developed formal models and analysis operations for such models. While each is useful independently, their utility is greatly improved by relating the models, which is the contribution described in this paper. We describe mappings between the models, and show that the map- pings preserve navigation behavior and are bijective, thus supporting traceabil- ity and allowing the models to be used in round-trip engineering. With these mappings built into our Model Helper tool, it is now possible to automatically determine whether a Request Routing model conforms to the navigation design, and to automatically generate a Request Routing model from a navigation model. Finally, we describe one of a number of case studies where we used Model Helper in a round-trip engineering scenario.",
    "keywords": []
  },
  {
    "title": "A UML2 Profile for Service Modeling",
    "date": 2007,
    "abstract": "In this article we provide an embedding of an interaction-based service notion into UML2. Such an embedding is needed, because to this date, UML2 has only limited support for services – they are certainly not first-class modeling elements of the notation. This is despite the ever increasing importance of services as an integration paradigm for ultra large scale systems. The embedding we provide rests on two observations: (i) services are fundamentally defined by component collaborations; (ii) to support a seamless development process, the service notion must span both logical and deployment architecture. To satisfy (i) and (ii) we introduce modifications to the UML that focus on interaction modeling, and the mapping from logical to deployment service architectures. The result is a novel and comprehensive UML2 profile for service-oriented systems.",
    "keywords": [
      "Rich Services",
      "Service-oriented Architectures",
      "Web Services",
      "Model Driven Architectures."
    ]
  },
  {
    "title": "Automatic Generation of  \nWorkflow-Extended Domain Models",
    "date": 2007,
    "abstract": "The specification of business processes is becoming a more and more critical aspect for organizations. Such processes are specified as workflow models expressing the logical precedence among the different business activi- ties (i.e. the units of work). Up to now, workflow models have been commonly managed through specific subsystems, called workflow management systems. In this paper we advocate for the integration of the workflow specification in the system domain model. This workflow-extended domain model is automati- cally derived from the initial workflow specification. Then, model-driven development methods may depart from the extended domain model to auto- matically generate an implementation of the system enforcing the business processes in any final technology platform, thus avoiding the need of basing the implementation on a dedicated workflow engine.",
    "keywords": []
  },
  {
    "title": "A Practical Perspective on the Design and \nImplementation of Service-Oriented Solutions",
    "date": 2007,
    "abstract": "Business-driven development is an approach that focuses on automating the path from business understanding to IT solution. IBM’s experiences with customers taking a business-driven approach to develop services-oriented solutions are highlighting a number of best practices that are important to share and discuss. This paper focuses on how companies adopting a service-oriented approach are assembling the appropriate environment to be successful. The paper identifies three design techniques for SOA and describes when each of them can be used in practice, depending on the business and IT drivers and the organization’s maturity. We then highlight how to use structured enterprise models together with the tools and methods to automate the design of service-oriented solutions. These scenarios and examples are playing an important role in the development of future method content and tooling requirements for IBM Rational tools.",
    "keywords": []
  },
  {
    "title": "Constructive Techniques for Meta- and Model-Level Reasoning",
    "date": 2007,
    "abstract": "The structural semantics of UML-based metamodeling were recently explored[1], providing a characterization of the models adher- ing to a metamodel. In particular, metamodels can be converted to a set of constraints expressed in a decidable subset of ﬁrst-order logic, an extended Horn logic. We augment the constructive techniques found in logic programming, which are also based on an extended Horn logic, to produce constructive techniques for reasoning about models and meta- models. These methods have a number of practical applications: At the meta-level, it can be decided if a (composite) metamodel characterizes a non-empty set of models, and a member can be automatically con- structed. At the model-level, it can be decided if a submodel has an embedding in a well-formed model, and the larger model can be con- structed. This amounts to automatic model construction from an in- complete model. We describe the concrete algorithms for constructively solving these problems, and provide concrete examples.",
    "keywords": []
  },
  {
    "title": "A Metamodel-Based Approach for Analyzing Security-Design Models",
    "date": 2007,
    "abstract": "We have previously proposed an expressive UML-based lan- guage for constructing and transforming security-design models, which are models that combine design speciﬁcations for distributed systems with speciﬁcations of their security policies. Here we show how the same framework can be used to analyze these models: queries about proper- ties of the security policy modeled are expressed as formulas in UML’s Object Constraint Language and evaluated over the metamodel of the security-design language. We show how this can be done in a semanti- cally precise and meaningful way and demonstrate, through examples, that this approach can be used to formalize and check non-trivial se- curity properties of security-design models. The approach and examples presented have been implemented and checked in the SecureMOVA tool.",
    "keywords": []
  },
  {
    "title": "UML2Alloy: A Challenging Model Transformation",
    "date": 2007,
    "abstract": "Alloy is a formal language, which has been applied to mod- elling of systems in a wide range of application domains. It is supported by Alloy Analyzer, a tool, which allows fully automated analysis. As a result, creating Alloy code from a UML model provides the opportunity to exploit analysis capabilities of the Alloy Analyzer to discover possible design ﬂaws at early stages of the software development. Our research makes use of model based techniques for the automated transformation of UML class diagrams with OCL constraints to Alloy code. The paper demonstrates challenging aspects of the model transformation, which originate in fundamental diﬀerences between UML and Alloy. We shall discuss some of the diﬀerences and illustrate their implications on the model transformation process. The presented approach is explained via an example of a secure e-business system.",
    "keywords": []
  },
  {
    "title": "i2MAP: An Incremental and Iterative Modeling and Analysis Process⋆",
    "date": 2007,
    "abstract": "Detecting errors early within the development process for an embedded system assists a developer in avoiding excessive error correc- tion costs and minimizing catastrophic losses resulting from failures in deployed systems. Towards that end, this paper presents i2MAP, an iter- ative and incremental goal-driven process for constructing an analysis- level UML model of an embedded system. The UML model is formally analyzed for adherence to the behavioral properties captured in a com- panion goal model. The process uses goal modeling to capture the requirements of the system, and uses UML to capture analysis-level structural and behavioral information. Both types of i2MAP models can be used to drive a rigorous approach to model-driven development of embedded systems. In this paper, we illustrate the i2MAP process and the accompanying tool suite in the development of an embedded system model for an adaptive light control system.",
    "keywords": []
  },
  {
    "title": "A Model-Driven Measurement Procedure for Sizing Web \nApplications: Design, Automation and Validation*",
    "date": 2007,
    "abstract": "This paper introduces the Object-Oriented Hypermedia Function Points (OO-HFP), which is a functional size measurement procedure for Web projects developed using the Object-Oriented Hypermedia (OO-H) method. This method provides model-driven and transformation-based support for the development of Web applications. Using OO-HFP, a size measure is obtained once a Web application’s conceptual model is completed. We follow the steps of a process model for software measurement in order to detail the design and automation of OO-HFP. Finally, we present the validation of OO-HFP for Web effort estimation by comparing the prediction accuracy that it provides to the accuracy provided by another set of validated size measures (the Tukutuku measures) that was found to be a good effort predictor. The results of a study using industrial data show that the effort estimates obtained for projects that are sized using OO-HFP were similar to those using the Tukutuku measures, thus suggesting that the OO-HFP is a suitable effort predictor.",
    "keywords": [
      "Model-driven development",
      "Web Engineering",
      "Functional Size  Measurement",
      "Web Effort Estimation",
      "OO-H."
    ]
  },
  {
    "title": "Model-Driven Engineering for Software\nMigration in a Large Industrial Context",
    "date": 2007,
    "abstract": "As development techniques, paradigms and platforms evolve far more quickly than domain applications, software modernization and migration, is a constant challenge to software engineers. For more than ten years now, the Sodifrance company has been intensively using Model- Driven Engineering (MDE) for both development and migration projects. In this paper we report on the use of MDE as an eﬃcient, ﬂexible and reliable approach for a migration process (reverse-engineering, transfor- mation and code generation). Moreover, we discuss how MDE is eco- nomically proﬁtable and is cost-eﬀective over the migration through out-sourced manual re-development. The paper is illustrated with the migration of a large-scale banking system from Mainframe to J2EE.",
    "keywords": []
  },
  {
    "title": "Introducing Variability into Aspect-Oriented Modeling Approaches",
    "date": 2007,
    "abstract": "Aspect-Oriented Modeling (AOM) approaches propose to model reusable aspects, or cross-cutting concerns, that can be composed in diﬀerent systems at a model or code level. Building complex systems with reusable aspects helps managing software complexity. But in gen- eral, reusability of an aspect is limited to a particular context. On the one hand, if the target model does not match the template point-to-point, the aspect cannot be applied. On the other hand, even when it is actually applied, it is woven into the target model always in the same way. In this paper1, we point out the needs of variability in the AOM approaches and introduce seamless variability mechanisms in an existing AOM approach to improve reusability. Our aspects can ﬁt various contexts and can be composed into the base model in diﬀerent ways. Introducing variability into AOM approaches will turn standard aspects into highly reusable aspects.",
    "keywords": []
  },
  {
    "title": "An Expressive Aspect Composition Language for UML \nState Diagrams",
    "date": 2007,
    "abstract": "The goal of aspect-oriented software development is to maintain a clear separation of concerns throughout the software lifecycle. Concerns that are separated, however, must be composed at some point. The hypothesis in this paper is that existing aspect-oriented modeling composition methods are not expressive enough for composing state-dependent behavioral models. The paper presents a new aspect composition language, SDMATA, for UML state diagrams. SDMATA supports a richer form of model composition than previous approaches to aspect-oriented modeling. Firstly, pointcuts are given as patterns which allows for sequence pointcuts, loop pointcuts, etc. Secondly, SDMATA supports rich forms of composition including parallel composition and alternative composition. The language is applied to the use case slice technique of Jacobson and Ng. The findings are that it is possible to maintain the separation of state-dependent models during software design and that expressive model composition methods are necessary to do this in practice.",
    "keywords": [
      "aspect-oriented development",
      "state machines",
      "use cases."
    ]
  },
  {
    "title": "Enhancing UML State Machines with Aspects",
    "date": 2007,
    "abstract": "Separation of Concerns (SoC) is an important issue to reduce the com- plexity of software. Recent advances in programming language research show that Aspect-Oriented Programming (AOP) may be helpful for enhancing the SoC in software systems: AOP provides a means for describing concerns which are normally spread throughout the whole program at one location. The arguments for introducing aspects into programming languages also hold for modeling lan- guages. In particular, modeling state-crosscutting behavior is insufﬁciently sup- ported by UML state machines. This often leads to model elements addressing the same concern scattered all over the state machine. We present an approach to aspect-oriented state machines, which show considerably better modularity in modeling state-crosscutting behavior than standard UML state machines.",
    "keywords": []
  },
  {
    "title": "Complementary Use Case Scenario\nRepresentations Based on Domain Vocabularies",
    "date": 2007,
    "abstract": "Use cases are commonly used as notation for capturing func- tional requirements through scenarios. The problem is that there is no universal notation for use case contents which is capable of accommodat- ing all the needs of software project participants. Business analysts and stakeholders need understandability and informality, while for architects and designers, precision and unambiguity are the most crucial features. In this paper we propose a metamodel and concrete syntax for three com- plementary representations of use case scenarios. These representations present the same information, but put emphasis on diﬀerent aspects of it thus accommodating for diﬀerent readers. This metamodel utilises the idea of separation of requirements as such from their representations as well as the idea of clear distinction between description of the system’s behaviour and of the problem domain.",
    "keywords": [
      "use cases",
      "requirements",
      "scenarios",
      "activity diagrams",
      "inter- action diagrams."
    ]
  },
  {
    "title": "Modeling Time(s)",
    "date": 2007,
    "abstract": "Time and timing features are an important aspect of mod- ern electronic systems, often of embedded nature. We argue here that in early design phases, time is often of logical (rather than physical) nature, even possibly multiform. The compilation/synthesis of heterogeneous ap- plications onto architecture platforms then largely amounts to adjusting the former logical time(s) demands onto the latter physical time abili- ties. Many distributed scheduling techniques pertain to this approach of “time reﬁnement”.",
    "keywords": []
  },
  {
    "title": "A UML Profile for Developing Airworthiness-Compliant \n(RTCA DO-178B), Safety-Critical Software",
    "date": 2007,
    "abstract": "Many safety-related, certification standards exist for developing safety-critical systems. System safety assessments are common practice and system certification according to a standard requires submitting relevant software safety information to appropriate authorities. The airworthiness standard, RTCA DO-178B, is the de-facto standard for certifying aerospace systems containing software. This research introduces an approach to improve communication and collaboration among safety engineers and software engineers by proposing a Unified Modeling Language (UML) profile that allows software engineers to model safety-related concepts and properties in UML, the de-facto software modeling language. Key safety-related concepts are extracted from RTCA DO-178B, and then a UML profile is defined to enable their precise modeling. We show that the profile improves the line of communication between safety engineers and software engineers, for instance by allowing the automated generation of certification-related information from UML models. This is illustrated through a case study on developing an aircraft’s navigation controller subsystem.",
    "keywords": [
      "UML",
      "UML Profile",
      "Airworthiness",
      "RTCA DO-178B",
      "Safety",
      "Safety-Critical",
      "Safety Assessment",
      "Certification",
      "Certification Authority."
    ]
  },
  {
    "title": "Forensic Debugging of Model Transformations",
    "date": 2007,
    "abstract": "Software bugs occur in model-driven development, just as they do with traditional development techniques. We explore the types of bugs that occur in model transformations and identify debugging ap- proaches that can be applied or adapted to a model-driven context. In- vestigation shows that the detailed source-to-target traceability avail- able with model transformations enables eﬀective post-hoc, or forensic, debugging. Forensic debugging techniques are introduced for automated bug localisation in model transformations. The methods discussed are grounded with examples using the Eclipse Modeling Framework (EMF) and Tefkat, a declarative model transformation engine.",
    "keywords": []
  },
  {
    "title": "Runtime Debugging Using Reverse-Engineered UML",
    "date": 2007,
    "abstract": "Finding runtime faults in object-oriented code can be very difﬁcult even with the aid of modern runtime debuggers. Failures may manifest them- selves due to decisions in the code that were executed much earlier in the pro- gram. Tracing execution paths and values backward from a failure to the faulty code can be a daunting task. We propose a fault ﬁnding approach that uses unit tests to exercise source code in order to trace object-method execution paths. This is similar to reverse-engineering techniques used to create Sequence Dia- grams from code. It is often too complex to debug a program using a large set of reverse-engineered Sequence Diagrams each obtained from an individual ex- ecution. Therefore, our approach partitions and aggregates individual execution paths into into fault and non-fault revealing categories. By examining the differ- ences between fault and non-fault paths, we are left with a simpliﬁed graph. The graph can then be transformed into a useful Sequence Diagram that may reveal the location of the faulty code.",
    "keywords": []
  },
  {
    "title": "Formally Deﬁning a Graphical Language for\nMonitoring and Checking Object Interactions",
    "date": 2007,
    "abstract": "Monitoring and checking object interactions is an impor- tant activity for testing/debugging scenario implementation in an object- oriented system. In our previous work, we proposed behavior view diagrams (BVD) as a graphical language for writing programs that auto- mate such monitoring and checking process. In this paper, we illustrate the formal deﬁnition of the syntax and the semantics of an extended ver- sion of BVD that can also be used to describe multi-threaded scenarios. This formal deﬁnition provides a critical foundation both for understand- ing the language and for building its tool support.",
    "keywords": []
  },
  {
    "title": "Statechart Development Beyond WYSIWYG",
    "date": 2007,
    "abstract": "Modeling systems based on semi-formal graphical formalisms, such as Statecharts, have become standard practice in the design of reactive embedded devices. Statecharts are often more intuitively under- standable than equivalent textual descriptions, and their animated simu- lation can help to visualize complex behaviors. However, in terms of editing speed, project management, and meta-modeling, textual descrip- tions have advantages.",
    "keywords": []
  },
  {
    "title": "Model-Based Design of Computer-Controlled Game Character Behavior",
    "date": 2007,
    "abstract": "Recently, the complexity of modern, real-time computer games has increased drastically. The need for sophisticated game AI, in particular for Non-Player Characters, grows with the demand for re- alistic games. Writing consistent, re-useable and eﬃcient AI code has become hard. We demonstrate how modeling game AI at an appropri- ate abstraction level using an appropriate modeling language has many advantages. A variant of Rhapsody Statecharts is proposed as an ap- propriate formalism. The Tank Wars game by Electronic Arts (EA) is used to demonstrate our concrete approach. We show how the use of the Statecharts formalism leads quite naturally to layered modeling of game AI and allows modelers to abstract away from choices between, for example, time-slicing and discrete-event time management. Finally, our custom tools are used to synthesize eﬃcient C++ code to insert into the Tank Wars main game loop.",
    "keywords": []
  },
  {
    "title": "Model-Driven Construction of Certiﬁed Binaries",
    "date": 2007,
    "abstract": "Proof-Carrying Code (PCC) and Certifying Model Checking (CMC) are established paradigms for certifying the run-time behavior of programs. While PCC allows us to certify low-level binary code against relatively simple (e.g., memory-safety) policies, CMC enables the certiﬁ- cation of a richer class of temporal logic policies, but is typically restricted to high-level (e.g., source) descriptions. In this paper, we present an auto- mated approach to generate certiﬁed software component binaries from UML Statechart speciﬁcations. The proof certiﬁcates are constructed us- ing information that is generated via CMC at the speciﬁcation level and transformed, along with the component, to the binary level. Our tech- nique combines the strengths of PCC and CMC, and demonstrates that formal certiﬁcation technology is compatible with, and can indeed ex- ploit, model-driven approaches to software development. We describe an implementation of our approach that targets the Pin component tech- nology, and present experimental results on a collection of benchmarks.",
    "keywords": []
  },
  {
    "title": "Tutorials at MODELS 2007",
    "date": 2007,
    "abstract": "The MODELS 2007 conference offered four high-quality tutorials from leading experts in the area of model-driven engineering. Each tutorial was presented as a half-day event that was organized during the first two days of the conference. This short overview provides an introduction to the tutorials program and a summary of each tutorial as submitted by the presenters.",
    "keywords": []
  },
  {
    "title": "The Objects and Arrows of Computational Design",
    "date": 2008,
    "abstract": "Computational Design (CD) is a paradigm where both program de- sign and program synthesis are computations. CD merges Model Driven Engi- neering (MDE) which synthesizes programs by transforming models, with Software Product Lines (SPL) where programs are synthesized by composing transformations called features. In this paper, basic relationships between MDE and SPL are explored using the language of modern mathematics.",
    "keywords": []
  },
  {
    "title": "Algebraic Models for Bidirectional Model Synchronization⋆",
    "date": 2008,
    "abstract": "The paper presents several algebraic models for semantics of bidirectional model synchronization and transformation. Diﬀerent pat- terns of model synchronization are analyzed (including view updates and incremental synchronization), and this analysis motivates the formal de- ﬁnitions. Relationships between the formal models are precisely speciﬁed and discussed. A new formal model of updates is proposed.",
    "keywords": []
  },
  {
    "title": "An Invariant-Based Method for the Analysis of Declarative Model-to-Model Transformations",
    "date": 2008,
    "abstract": "In this paper we propose a method to derive OCL invari- ants from declarative speciﬁcations of model-to-model transformations. In particular we consider two of the most prominent approaches for speci- fying such transformations: Triple Graph Grammars and QVT. Once the speciﬁcation is expressed in the form of invariants, the transformation developer can use such description to verify properties of the original transformation (e.g. whether it deﬁnes a total, surjective or injective function), and to validate the transformation by the automatic genera- tion of valid pairs of source and target models.",
    "keywords": []
  },
  {
    "title": "Precise Semantics of EMF Model Transformations by Graph Transformation",
    "date": 2008,
    "abstract": "Model transformation is one of the key activities in model-driven soft- ware development. An increasingly popular technology to deﬁne modeling lan- guages is provided by the Eclipse Modeling Framework (EMF). Several EMF model transformation approaches have been developed, focusing on different transformation aspects. To validate model transformations wrt. functional behav- ior and correctness, a formal foundation is needed. In this paper, we deﬁne EMF model transformations as a special kind of typed graph transformations using node type inheritance. Containment constraints of EMF model transformations are translated to a special kind of EMF model transformation rules such that their application leads to consistent transformation results only. Thus, we identify a kind of EMF model transformations which behave like algebraic graph trans- formations. As a consequence, the rich theory of algebraic graph transformation can be applied to these EMF model transformations to show functional behavior and correctness. We illustrate our approach by selected refactorings of simpliﬁed statechart models.",
    "keywords": [
      "Model-driven software development",
      "Eclipse Modeling Framework",
      "model transformation",
      "graph transformation."
    ]
  },
  {
    "title": "A Formal Metamodel for Problem Frames",
    "date": 2008,
    "abstract": "Problem frames are patterns for analyzing, structuring, and character- izing software development problems. This paper presents a formal metamodel for problem frames expressed in UML class diagrams and using the formal spec- iﬁcation notation OCL. That metamodel clariﬁes the nature of the different syn- tactical elements of problem frames, as well as the relations between them. It provides a framework for syntactical analysis and semantic validation of newly deﬁned problem frames, and it prepares the ground for tool support for the prob- lem frame approach.",
    "keywords": []
  },
  {
    "title": "Visualization of Use Cases through Automatically Generated Activity Diagrams",
    "date": 2008,
    "abstract": "Functional requirements are often written using use cases formatted by textual templates. This textual approach has the advantage to be easy to adopt, but the requirements can then hardly be processed for further purposes like test generation. In this paper, we propose to generate automatically through a model transformation an activity diagram modeling the use case scenario. Such an activity diagram allows us to guess in a glimpse the global behavior of a use case, and can easily be processed. The transformation is defined using the QVT-Relational language, and is illustrated on a case study using a supporting tool.",
    "keywords": []
  },
  {
    "title": "Requirements Modeling and Validation Using Bi-layer Use Case Descriptions",
    "date": 2008,
    "abstract": "Extension of the modeling notations and formal languages for use case description are the commonly suggested solutions for adding precision to use case models. Practitioners have often argued against adoption of such techniques citing reasons like the steep learning curve for formal languages; and the quickness in using imprecise use case de- scriptions for communicating to diﬀerent stake-holders of the system. In this paper we introduce the Archetest modeling environment, which through a unique bi-layer approach accepts use case descriptions in their imprecise form and then assists in adding precision through a wizard driven process. Thereby, it lends itself to both quick and precise mod- eling. Also the two forms of the use case models are self contained and cross-linked. This allows diﬀerent modelers, the precise and the impre- cise, to collaborate and also supports stake-holder speciﬁc feedbacks of the automated analysis. We describe the structure of Archetest’s use case models, and show how these models are amenable to automated process- ing. We present a case study which reports on typical modeling times using Archetest and demonstrates its scalability.",
    "keywords": []
  },
  {
    "title": "WebWorkFlow: An Object-Oriented Workﬂow Modeling Language for Web Applications",
    "date": 2008,
    "abstract": "Workﬂow languages are designed for the high-level descrip- tion of processes and are typically not suitable for the generation of complete applications. In this paper, we present WebWorkFlow, an object-oriented workﬂow modeling language for the high-level descrip- tion of workﬂows in web applications. Workﬂow descriptions deﬁne pro- cedures operating on domain objects. Procedures are composed using sequential and concurrent process combinators. WebWorkFlow is an em- bedded language, extending WebDSL, a domain-speciﬁc language for web application development, with workﬂow abstractions. The extension is implemented by means of model-to-model transformations. Rather than providing an exclusive workﬂow language, WebWorkFlow supports inter- action with the underlying WebDSL language. WebWorkFlow supports most of the basic workﬂow control patterns.",
    "keywords": []
  },
  {
    "title": "The Future of Train Signaling",
    "date": 2008,
    "abstract": "Producing the source code for a railway interlocking system based on the description of a station has traditionally been a multistage manual process. We show how this process can be automated and made less error-prone by in- troducing model-driven development (MDD). This paper addresses the exp erience of developing a Domain Specific Language (DSL) to describe railway stations, Train Control Language (TCL), and tools to support this language. In the railroad domain where there are extreme safety requirements, it is essential to show that consistency and completeness can be assured. We address how the model is used to generate several different representations for different pur- poses. We look at advantages and challenges with our approach, and we discuss improvements to existing technologies to support our case better.",
    "keywords": [
      "Train",
      "signaling",
      "interlocking",
      "DSL",
      "model-driven development",
      "MoSiS."
    ]
  },
  {
    "title": "NAOMI – An Experimental Platform for Multi–modeling",
    "date": 2008,
    "abstract": "Domain-speciﬁc modeling languages (DSMLs) are designed to pro- vide precise abstractions of domain-speciﬁc constructs. However, models for complex systems typically do not ﬁt neatly within a single domain and capturing all important aspects of such a system requires developing multiple models using different DSMLs. Combining these models into multi-models presents difﬁcult challenges, most importantly those of integrating the various models and keeping both the models and their associated data synchronized. To this end, we present NAOMI, an experimental platform for enabling multiple models, developed in different DSMLs, to work together. NAOMI analyzes model dependencies to de- termine the impact of changes to one model on other dependent models and co- ordinates the propagation of necessary model changes. NAOMI also serves as a useful testbed for exploring how diverse modeling paradigms can be combined.",
    "keywords": []
  },
  {
    "title": "Abstraction and Modelling — A Complementary Partnership",
    "date": 2008,
    "abstract": "Why is it that some software engineers are able to produce clear, elegant designs and programs, while others cannot? Is it purely a matter of intelligence? One hypothesis is that the answer lies in ab- straction: the ability to exhibit abstraction skills and perform abstract thinking and reasoning. Abstraction is a cognitive means by which en- gineers, mathematicians and others deal with complexity. It covers both aspects of removing detail as well as the identiﬁcation of generalisations or common features, and has been identiﬁed as a crucial skill for software engineering professionals. Is it possible to improve the skills and abilities of those less able through further education and training? Are there any means by which we can measure the abstraction skills of an individual? In this talk, we explore these questions, and argue that abstraction and modelling are complementary partners: that abstraction is the key skill for modelling and that modelling provides a sound means for practising and improving abstraction skills.",
    "keywords": []
  },
  {
    "title": "Model Transformation as an Optimization Problem",
    "date": 2008,
    "abstract": "Most of the available work on model transformation is based on the hypothesis that transformation rules exist and that the important issue is how to express them. But in real life, the rules may be diﬃcult to deﬁne; this is often the case when the source and/or target formalisms are not widely used or proprietary. In this paper, we consider the trans- formation mechanism as a combinatorial optimization problem where the goal is to ﬁnd a good transformation starting from a small set of available examples. Our approach, named model transformation as optimization by examples (MOTOE), combines transformation blocks extracted from examples to generate a target model. To that end, we use an adapted version of particle swarm optimization (PSO) where transformation so- lutions are modeled as particles that exchange transformation blocks to converge towards an optimal transformation solution. MOTOE has two main advantages: It proposes a transformation without the need to de- rive transformation rules ﬁrst, and it can operate independently from the source and target metamodels.",
    "keywords": []
  },
  {
    "title": "Example-Based Program Transformation",
    "date": 2008,
    "abstract": "Software changes. During their life cycle, software systems experi- ence a wide spectrum of changes, from minor modiﬁcations to major architectural shifts. Small-scale changes are usually performed with text editing and refactor- ings, while large-scale transformations require dedicated program transformation languages. For medium-scale transformations, both approaches have disadvan- tages. Manual modiﬁcations may require a myriad of similar yet not identical edits, leading to errors and omissions, while program transformation languages have a steep learning curve, and thus only pay off for large-scale transformations.",
    "keywords": []
  },
  {
    "title": "Detecting Patterns of Poor Design Solutions Using Constraint Propagation",
    "date": 2008,
    "abstract": "We are proposing an approach for applying design patterns that con- sists of recognizing occurrences of the modeling problem solved by the design pattern (problem pattern) in input models, which are then transformed accord- ing to the solution proposed by the design pattern (solution pattern). In this pa- per, we look at the issue of identifying instances of problem patterns in input models, and marking the appropriate entities so that the appropriate transforma- tions can be applied. Model marking within the context of MDA is a notori- ously difficult problem, in part because of the structural complexity of the patterns that we look for, and in part because of the required design knowledge- - and expertise. Our representation of design problem patterns makes it rela- tively easy to express the pattern matching problem as a constraint satisfaction problem. In this paper, we present our representation of design problem pat- terns, show how matching such patterns can be expressed as a constraint satis- faction problem, and present an implementation using ILOG JSolver, a commercial CSP solver.",
    "keywords": [
      "Marking models",
      "constraint satisfaction problems",
      "transformations",
      "design patterns."
    ]
  },
  {
    "title": "A General Approach for Scenario Integration⋆",
    "date": 2008,
    "abstract": "An approach to integrating UML Sequence Diagrams is pre- sented. It rests on a well-established theory, is generalizable to a large class of requirements engineering models, and supports many diﬀerent kinds of scenario integration operations. An implementation of the ap- proach as an Eclipse extension is described. Lessons learned from the implementation and during ﬁrst, preliminary experiments to study the practical aspects of the approach, are discussed.",
    "keywords": []
  },
  {
    "title": "Behavioral Modelling and Composition of Object Slices Using Event Observation",
    "date": 2008,
    "abstract": "Some analysis and design methods for complex software sys- tems lead to the speciﬁcation of components (classes) by slices. It is the case of the use-case slicing technique proposed by Jacobson and Ng, and of view-based modelling proposed by Nassar et al. The composition of class slices is known from the literature to be closer to aspect composi- tion than to traditional interface-based composition, but remains largely an open problem.",
    "keywords": []
  },
  {
    "title": "Scenario-Based Static Analysis of UML Class Models",
    "date": 2008,
    "abstract": "Static analysis tools, such as OCLE and USE, can be used to analyze structural properties of class models. The USE tool also provides support for analyzing specified operations through interactive simulations in which users provide operation parameters, and manually assign values to state elements to reflect the effect of an operation. In this paper we describe an approach to stati- cally analyzing behavior that does not require a user to manually simulate be- havior. The approach involves transforming a class model into a static model of behavior, called a Snapshot Model. A Snapshot Model characterizes se- quences of snapshots, where a snapshot describes an application state. A sce- nario describing a sequence of operation invocations can be verified against a Snapshot Model using tools such as USE and OCLE. We illustrate our ap- proach by verifying a scenario against a Snapshot Model that describes the be- havior of some operations in a role-based access control (RBAC) application.",
    "keywords": [
      "UML",
      "Model Analysis",
      "Behavioral Properties",
      "Snapshot."
    ]
  },
  {
    "title": "Constructing Models with the Human-Usable Textual Notation",
    "date": 2008,
    "abstract": "We present an implementation of the OMG’s Human-Usable Textual Notation (HUTN) [6] that provides a generic concrete syntax for MOF-based metamodels. The notation is summarised. Ways in which HUTN can be applied in order to improve the productivity of Model- Driven Engineering are identiﬁed. The use of HUTN to improve the quality of test suites for verifying model management operations (such as model-to-model transformation) is described. We also present a com- parison of generic and domain-speciﬁc concrete syntax with HUTN.",
    "keywords": []
  },
  {
    "title": "X3D-UML: 3D UML State Machine Diagrams",
    "date": 2008,
    "abstract": "X3D-UML utilises X3D (eXtensible 3D) to enable standards-based advanced 3D UML visualisations. Using X3D-UML, 3D UML State Machine Diagrams have been evaluated against actual user tasks and data, using the Se- quential Evaluation methodology. The results of User Task Analysis, Heuristic Evaluation and Formative Evaluation phases provide clear evidence that the use of UML extended with 3D is a practical solution for visualising complex sys- tem behaviour. RoseRT model metrics show between 56%-90% of state ma- chine diagram work would benefit from such 3D UML extensions; hence the 3D improvement can deliver considerable benefit to organisations.",
    "keywords": [
      "X3D-UML",
      "3D UML",
      "X3D",
      "3D Software Visualization",
      "VRML."
    ]
  },
  {
    "title": "Assessing the Influence of Stereotypes on the  Comprehension of UML Sequence Diagrams: A Controlled Experiment",
    "date": 2008,
    "abstract": "The main goal of this paper is to provide empirical evidence, through a controlled experiment, of the influence of stereotypes when modelers, devel- opers, and maintainers have to comprehend UML sequence diagrams. The comprehension of UML sequence diagrams with and without stereotypes was analyzed from three different perspectives: semantic comprehension, retention and transfer. The experiment was carried out with 77 fourth year undergraduate students of Computer Science from the University of Bari in Italy. The results obtained show a slight tendency in favor of the use of stereotypes in facilitating the comprehension of UML sequence diagrams, although it is not statistically significant. Further replications are needed to obtain more conclusive results.",
    "keywords": []
  },
  {
    "title": "3D Parametric Models for Aeroplanes — From Idea to Design",
    "date": 2008,
    "abstract": "The early design phase of an aircraft is characterized by a large variation of studies in a short period of time. In order to support the variation of aircraft shapes, an approach is taken in which the diﬀer- ent aircraft component models are deﬁned by a limited set of parameters. The challenge lies in fulﬁlling numerous and partially conﬂicting engi- neering requirements. Models should be as ﬂexible as possible so that virtually “any” aircraft shape can be represented, in parallel the model should address the needs of diﬀerent engineering disciplines located on diﬀerent sites and in diﬀerent countries. On the other hand each engineer- ing discipline re-quests simple models with the smallest set of parameters possible to address their speciﬁc need. Finally, aircraft design is not only geometric and interfaces with the numerical world need to be established. During this talk we will be exploring the challenges and identiﬁed solu- tions for abstracting the aircraft geometry in a set of parametric models that can be shared and commonly used; we will see how dedicated CAD tools support the engineer and how the geometric models can be linked with the numerical (e.g. systems) world.",
    "keywords": []
  },
  {
    "title": "MOOGLE: A Model Search Engine",
    "date": 2008,
    "abstract": "Models are becoming increasingly important in the software process. As a consequence, the number of models being used is increasing, and so is the need for eﬃcient mechanisms to search them. Various exist- ing search engines could be used for this purpose, but they lack features to properly search models, mainly because they are strongly focused on text-based search. This paper presents Moogle, a model search engine that uses metamodeling information to create richer search indexes and to allow more complex queries to be performed. The paper also presents the results of an evaluation of Moogle, which showed that the metamodel information improves the accuracy of the search.",
    "keywords": [
      "Model Search",
      "Software Reuse",
      "Model-Driven Development."
    ]
  },
  {
    "title": "Managing Model Conﬂicts in Distributed Development",
    "date": 2008,
    "abstract": "The growing complexity of current software systems naturally con- veyed their development toward incremental and distributed approaches to speed up the process. Several developers update the same artefact operating concurrent manipulations which need to be coherently combined. The interaction among those changes inevitably involves conﬂicts which must be detected and recon- ciled.",
    "keywords": []
  },
  {
    "title": "Metamodel Matching for Automatic Model Transformation Generation⋆",
    "date": 2008,
    "abstract": "Applying Model-Driven Engineering (MDE) leads to the cre- ation of a large number of metamodels, since MDE recommends an in- tensive use of models deﬁned by metamodels. Metamodels with similar objectives are then inescapably created. A recurrent issue is thus to turn compatible models conforming to similar metamodels, for example to use them in the same tool. The issue is classically solved developing ad hoc model transformations. In this paper, we propose an approach that au- tomatically detects mappings between two metamodels and uses them to generate an alignment between those metamodels. This alignment needs to be manually checked and can then be used to generate a model trans- formation. Our approach is built on the Similarity Flooding algorithm used in the ﬁelds of schema matching and ontology alignment. Experi- mental results comparing the eﬀectiveness of the application of various implementations of this approach on real-world metamodels are given.",
    "keywords": []
  },
  {
    "title": "Sufﬁcient Criteria for Consistent Behavior Modeling with Reﬁned Activity Diagrams",
    "date": 2008,
    "abstract": "In use case-driven approaches to requirements modeling, UML ac- tivity diagrams are a wide-spread means for reﬁning the functional view of use cases. Early consistency validation of activity diagrams is therefore desirable but difﬁcult due to the semi-formal nature of activity diagrams. In this paper, we specify well-structured activity diagrams and deﬁne activities more precisely by pre- and post- conditions. They can be modeled by interrelated pairs of object di- agrams based on a domain class diagram. This activity reﬁnement is based on the theory of graph transformation and paves the ground for a consistency analysis of the required system behavior. A formal semantics for activity diagrams reﬁned by pre- and post-conditions allows us to establish sufﬁcient criteria for consistency. The semi-automatic checking of these criteria is supported by a tool for graph transformation.",
    "keywords": []
  },
  {
    "title": "Implementation of the Conformance Relation for\nIncremental Development of Behavioural Models",
    "date": 2008,
    "abstract": "In this paper, we show how to implement the conformance relation on transition systems. The computability of this relation relies on the composition of two operators: the reduction relation whose computability has been proven in our previous work, and the merge function of acceptance graphs associated with transition systems under comparison. It is formally demonstrated, and illus- trated through a case study whose analysis is performed by a JAVA prototype we have developed. This research work is developed in order to be applied in a larger context: our goal is to support modelers to develop UML state machines through an incremental modelling method which is able to guarantee that model upgrad- ing does not introduce inconsistencies. Hence, these works lead to a semantics for the specialisation relation between UML State Machines.",
    "keywords": []
  },
  {
    "title": "A Model-Based Framework for Statically and\nDynamically Checking Component Interactions⋆",
    "date": 2008,
    "abstract": "Building applications by assembling software components requires analyses of Architecture Description (AD) models for checking that component interactions respect the application and runtime context requirements. Most ex- isting interaction model analyses are static: they do not take into account runtime information, e.g., parameter values.",
    "keywords": []
  },
  {
    "title": "Formal Deﬁnition of MOF 2.0 Metamodel Components and Composition",
    "date": 2008,
    "abstract": "The Meta Object Facility (MOF) is one of the most fre- quently used languages for the deﬁnition of a DSL’s abstract syntax. However, its lack of sophisticated modularization concepts in compari- son to GPLs such as Ada or component-oriented ADLs makes it hard to maintain a large number of complex metamodels. MOF 2.0 packages can be used to a certain extent to deﬁne, reﬁne, and compose language descriptions, but do not oﬀer appropriate support for information hiding as well as for the speciﬁcation of parametrizable metamodeling compo- nents. Motivated by a running example we, therefore, extend MOF 2.0 with concepts for the speciﬁcation of proper metamodel components with provided export and required import interfaces. Furthermore, we present a formalization of a metamodel component composition operator based on graph morphisms. The resulting component-oriented version of MOF allows language developers to describe reoccurring, parametrizable sub- languages once and instantiate them diﬀerently in several metamodels.",
    "keywords": [
      "Metamodeling",
      "MOF 2.0",
      "software components",
      "reusability."
    ]
  },
  {
    "title": "Interfaces and Metainterfaces for Models and Metamodels",
    "date": 2008,
    "abstract": "Evolution and customization of component-based systems require an explicit understanding of component inter-dependencies. Im- plicit assumptions, poor documentation and hidden dependencies turn even simple changes into challenges. The problem is exacerbated in XML- intensive projects due to the use of soft references and the lack of infor- mation hiding. We address this with dependency tracking interface types for models and metamodels. We provide automatic compatibility checks and a heuristic inference procedure for our interfaces, which allows easy and incremental adoption of our technique even in mature projects. We have implemented a prototype and applied it to two large cases: an en- terprise resource planning system and a healthcare information system.",
    "keywords": []
  },
  {
    "title": "Model&Metamodel, Metadata and Document\nRepository for Software and Data Integration",
    "date": 2008,
    "abstract": "Model-based software engineering (MBSE) projects require and generate numerous artifacts. While MBSE methodology and design tools have reached certain maturity level, the issue of artifact persistence and management has been somewhat left in the background. We present design and implementation of the repository that supports storing and managing of artifacts such as metamodels, models, constraints, meta- data, speciﬁcations, transformation rules, code, templates, conﬁguration or documentation, and their metadata.",
    "keywords": []
  },
  {
    "title": "Model Construction with External Constraints:\nAn Interactive Journey from Semantics to Syntax",
    "date": 2008,
    "abstract": "Mainstream development environments have recently assimilated guidance technologies based on constraint satisfaction. We investigate one class of such technologies, namely, interactive guided derivation of models, where the editing system assists a designer by providing hints about valid editing operations that maintain global cor- rectness. We provide a semantics-based classiﬁcation of such guidance systems and investigate concrete guidance algorithms for two kinds of modeling languages: a simple subset of class-diagram-like language and for feature models. Both algorithms are eﬃcient and provide exhaustive guidance.",
    "keywords": []
  },
  {
    "title": "A Benchmark for OCL Engine\nAccuracy, Determinateness, and Eﬃciency",
    "date": 2008,
    "abstract": "The Object Constraint Language (OCL) is a central element in modeling and transformation languages like UML, MOF, and QVT. Consequently approaches for MDE (Model-Driven Engineering) depend on OCL. However, OCL is present not only in these areas inﬂuenced by the OMG but also in the Eclipse Modeling Framework (EMF). Thus the quality of OCL and its realization in tools seems to be crucial for the suc- cess of model-driven development. Surprisingly, up to now a benchmark for OCL to measure quality properties has not been proposed. This pa- per puts forward in the ﬁrst part the concepts of a comprehensive OCL benchmark. Our benchmark covers (A) OCL engine accuracy (e.g., for the undeﬁned value and the use of variables), (B) OCL engine determi- nateness properties (e.g., for the collection operations any and ﬂatten), and (C) OCL engine eﬃciency (for data type and user-deﬁned opera- tions). In the second part, this paper empirically evaluates the proposed benchmark concepts by examining a number of OCL tools. The paper discusses several diﬀerences in handling particular OCL language fea- tures and underspeciﬁcations in the OCL standard.",
    "keywords": []
  },
  {
    "title": "Contrary-to-Duties Constraints: From UML to Relational Model",
    "date": 2008,
    "abstract": "Sometimes, because of an atypical situation, an important mandatory association between classes in a UML Class Diagram must be replaced by an optional one. That semantic and functional impoverishment happens because the mandatory constraint must have a boolean value. In this paper we analyze the use of soft constraints in the UML Class Diagram, and their automatic re- percussion in the corresponding Relational Model. The soft (deontic) con- straints allow the formal representation of requirements, which ideally should always be fulfilled, but can be violated in atypical situations. In this paper we enrich a previous deontic approach, by introducing the ability to explicitly rep- resent the so called Contrary-To-Duties requirements, i.e., domain integrity requirements that emerge as a consequence of an unfulfilled mandatory con- straint. We support our approach with the UML/OCL language.",
    "keywords": [
      "UML",
      "Contrary-To-Duties",
      "Relational Model",
      "Deontic Constraints."
    ]
  },
  {
    "title": "A UML/SPT Model Analysis Methodology for \nConcurrent Systems Based on Genetic Algorithms",
    "date": 2008,
    "abstract": "Concurrency problems, such as deadlocks, should be identified early in the design process. This is made increasingly difficult as larger and more complex concurrent systems are being developed. We propose here an ap- proach, based on the analysis of specific models expressed in the Unified Mod- eling Language (UML) that uses a specifically designed genetic algorithm to detect deadlocks. Our main motivations are (1) to devise practical solutions that are applicable in the context of UML design without requiring additional modeling and (2) to achieve scalable automation. All relevant concurrency in- formation is extracted from systems’ UML models that comply with the UML Schedulability, Performance and Time profile, a standardized specialization of UML for real-time, concurrent systems. Our genetic algorithm is then used to search for execution sequences exhibiting deadlocks. Results on three case stud- ies show that our approach can achieve efficient results.",
    "keywords": [
      "MDD",
      "deadlocks",
      "model analysis",
      "concurrent systems",
      "UML",
      "SPT",
      "genetic algorithms."
    ]
  },
  {
    "title": "Integrating Performance Analysis in the Model Driven Development of Software Product Lines",
    "date": 2008,
    "abstract": "The paper proposes to integrate performance analysis in the early phases of the model-driven development process for Software Product Lines (SPL). We start by adding generic performance annotations to the UML model representing the set of core reusable SPL assets. The annotations are generic and use the MARTE Profile recently adopted by OMG. A first model transfor- mation realized in the Atlas Transformation Language (ATL), which is the fo- cus of this paper, derives the UML model of a specific product with concrete MARTE performance annotations from the SPL model. A second transforma- tion generates a Layered Queueing Network performance model for the given product by applying an existing transformation approach named PUMA, developed in previous work. The proposed technique is illustrated with an e- commerce case study that models the commonality and variability in both struc- tural and behavioural SPL views. A product is derived and the performance of two design alternatives is compared.",
    "keywords": [
      "Software Product Line",
      "Performance Analysis",
      "Model to model  Transformation",
      "UML",
      "MARTE",
      "ATL."
    ]
  },
  {
    "title": "A Model-Driven Measurement Approach",
    "date": 2008,
    "abstract": "Companies using domain speciﬁc languages in a model-driven development process need to measure their models. However, developing and maintaining a measurement software for each domain speciﬁc model- ing language is costly. Our contribution is a model-driven measurement approach. This measurement approach is model-driven from two view- points: 1) it measures models of a model-driven development process; 2) it uses models as unique and consistent metric speciﬁcations, w.r.t a metric speciﬁcation metamodel. This declarative speciﬁcation of metrics is then used to generate a fully ﬂedged implementation. The beneﬁt from apply- ing the approach is evaluated by two applications. They indicate that this approach reduces the domain-speciﬁc measurement software development cost.",
    "keywords": []
  },
  {
    "title": "Specifying Service Composition Using UML 2.x and Composition Policies",
    "date": 2008,
    "abstract": "In the current and future service environment, service parts are being developed separately while being dynamically combined at run- time. In this paper we address the problem of deﬁning a model-driven process for enabling dynamic composition of services. Composition poli- cies are used to deﬁne choices in behaviour under which service roles involved in a composite service can be dynamically combined at run- time. We model policy-ruled choreography of collaboration components using a policy enforcement state machine (PESM). We also deﬁne trans- formation rules for translating a global PESM diagram into a set of local PESM diagrams, one for each role. As an example, we consider the case of dynamically composing an existing service with a set of authentication and authorization collaborations. The approach is supported by a formal syntax and semantics.",
    "keywords": []
  },
  {
    "title": "A Model-Based Framework for Security Policy Specification, Deployment and Testing",
    "date": 2008,
    "abstract": "In this paper, we propose a model-driven approach for specifying, deploying and testing security policies in Java applications. First, a security policy is specified independently of the underlying access control language (OrBAC, RBAC). It is based on a generic security meta-model which can be used for early consistency checks in the security policy. This model is then automatically transformed into security policy for the XACML platform and in- tegrated in the application using aspect-oriented programming. To qualify test cases that validate the security policy in the application, we inject faults into the policy. The fault model and the fault injection process are defined at the meta- model level, making the qualification process language-independent. Empirical results on 3 case studies explore both the feasibility of the approach and the ef- ficiency of a full design & test MDE process.",
    "keywords": [
      "Metamodeling",
      "Model-driven engineering methodology",
      "Security."
    ]
  },
  {
    "title": "A Pattern Language Veriﬁer\nfor Web-Based Enterprise Applications",
    "date": 2008,
    "abstract": "The Pattern Language Veriﬁer (PLV) is a process for verify- ing the application of a pattern language in a design. The PLV process focuses on a pattern language for the design of web-based enterprise applications. We show how PLV exploits the ideas of programming lan- guage compilers to detect the structural, syntactic, and semantic errors in a design model and then guides the designer in ﬁxing the problems. To provide tool support, we integrate PLV into the ArgoUML modeling tool. We use the tool to design a simple student registration system as a case study, and show how the process ﬁnds the mistakes in the model and helps the designer in repairing the detected problems.",
    "keywords": [
      "Pattern Language",
      "Model Driven Engineering",
      "Proﬁle."
    ]
  },
  {
    "title": "Automatically Generating Behavioral Models of Adaptive Systems to Address Uncertainty⋆",
    "date": 2008,
    "abstract": "Increasingly, high-assurance applications rely on dynami- cally adaptive systems (DASs) to respond to environmental changes, while satisfying functional requirements and non-functional preferences. Examples include critical infrastructure protection and transportation systems. A DAS comprises a collection of (non-adaptive) target systems (represented as UML models) and a set of adaptations that realize tran- sitions among target systems. Two sources of uncertainty inherent to DASs are: (1) predicting the future execution environment, and (2) us- ing functional and non-functional trade-oﬀs to respond to the changing environment. To address this uncertainty, we are inspired by living or- ganisms that are astonishingly adept at adapting to changing environ- mental conditions using evolution. In this paper, we describe a digital evolution-based approach to generating models that represent possible target systems suitable for diﬀerent environmental conditions, enabling the developer to identify the functional and non-functional trade-oﬀs be- tween the models, and then assisting the developer in selecting target systems for the DAS.",
    "keywords": []
  },
  {
    "title": "Autonomic Management Policy Speciﬁcation: From UML to DSML⋆",
    "date": 2008,
    "abstract": "Autonomic computing is recognized as one of the most promizing solutions to address the increasingly complex task of distributed environments’ administration. In this context, many projects relied on software components and architectures to provide autonomic management frameworks. We designed such a component-based autonomic management framework, but observed that the in- terfaces of a component model are too low-level and difﬁcult to use. Therefore, we introduced UML diagrams for the modeling of deployment and management policies. However, we had to adapt/twist the UML semantics in order to meet our requirements, which led us to deﬁne DSMLs. In this paper, we present our experience in designing the Tune system and its support for management policy speciﬁcation, relying on UML diagrams and on DSMLs. We analyse these two approaches, pinpointing the beneﬁts of DSMLs over UML.",
    "keywords": []
  },
  {
    "title": "Empirical Analysis of the Relation between Level of Detail in UML Models and Defect Density",
    "date": 2008,
    "abstract": "This paper investigates the relation between the level of detail (LoD) in UML models and defect density of the associated im- plementation. We propose LoD measures that are applicable to both class- and sequence diagrams. Based on empirical data from an indus- trial software project we have found that classes with higher LoD, calcu- lated using sequence diagram LoD metrics, correlates with lower defect density. Overall, this paper discusses a novel and practical approach to measure LoD in UML models and describes its application to a signiﬁ- cant industrial case study.",
    "keywords": [
      "Uniﬁed Modeling Language",
      "Design Metrics",
      "Quality Mea- sure",
      "Correlation Analyses."
    ]
  },
  {
    "title": "An Empirical Investigation on Dynamic Modeling in Requirements Engineering",
    "date": 2008,
    "abstract": "Modeling is a fundamental activity within the requirements engineering process concerning the construction of abstract descriptions of system requirements that are amenable to interpretation and vali- dation. In this paper we report on a controlled experiment aimed at assessing whether dynamic modeling of system requirements provides an accurate account of stakeholders’ requirements. The context is con- stituted of second year Bachelor students in Computer Science at the University of Basilicata. The data analysis reveals that there is not sig- niﬁcant diﬀerence in the comprehension of system requirements achieved by using or not dynamic modeling.",
    "keywords": []
  },
  {
    "title": "Heterogeneous Coupled Evolution of Software Languages",
    "date": 2008,
    "abstract": "As most software artifacts, meta-models can evolve. Their evolution requires conforming models to co-evolve along with them. Coupled evolution supports this. Its applicability is not limited to the modeling domain. Other do- mains are for example evolving grammars or database schemas. Existing ap- proaches to coupled evolution focus on a single, homogeneous domain. They solve the co-evolution problems locally and repeatedly. In this paper we present a systematic, heterogeneous approach to coupled evolution. It provides an auto- matically derived domain speciﬁc transformation language; a means of executing transformations at the top level; a derivation of the coupled bottom level trans- formation; and it allows for generic abstractions from elementary transforma- tions. The feasibility of the architecture is evaluated by applying it to data model evolution.",
    "keywords": []
  },
  {
    "title": "Automatability of Coupled Evolution of Metamodels and Models in Practice",
    "date": 2008,
    "abstract": "Model-based software development promises to increase pro- ductivity by oﬀering modeling languages tailored to a problem domain. Such modeling languages are often deﬁned by a metamodel. In conse- quence of changing requirements and technological progress, these modeling languages and thus their metamodels are subject to change. Manually migrating models to a new version of their metamodel is te- dious, error-prone and heavily hampers cost-eﬃcient model-based devel- opment practice. Automating model migration in response to metamodel adaptation promises to substantially reduce eﬀort. Unfortunately, little is known about the types of changes occurring during metamodel adap- tation in practice and, consequently, to which degree reconciling model migration can be automated. We analyzed the changes that occurred during the evolution history of two industrial metamodels and classi- ﬁed them according to their level of potential automation. Based on the results, we present a list of requirements for eﬀective tool support for coupled evolution of metamodels and models in practice.",
    "keywords": []
  },
  {
    "title": "Enriching Reverse Engineering with Annotations",
    "date": 2008,
    "abstract": "Much of the knowledge about software systems is implicit, and therefore diﬃcult to recover by purely automated techniques. Archi- tectural layers and the externally visible features of software systems are two examples of information that can be diﬃcult to detect from source code alone, and that would beneﬁt from additional human knowledge. Typical approaches to reasoning about data involve encoding an explicit meta-model and expressing analyses at that level. Due to its informal na- ture, however, human knowledge can be diﬃcult to characterize up-front and integrate into such a meta-model. We propose a generic, annotation- based approach to capture such knowledge during the reverse engineering process. Annotation types can be iteratively deﬁned, reﬁned and trans- formed, without requiring a ﬁxed meta-model to be deﬁned in advance. We show how our approach supports reverse engineering by implement- ing it in a tool called Metanool and by applying it to (i) analyzing archi- tectural layering, (ii) tracking reengineering tasks, (iii) detecting design ﬂaws, and (iv) analyzing features.",
    "keywords": []
  },
  {
    "title": "Towards a Formal Account of a Foundational Subset for Executable UML Models",
    "date": 2008,
    "abstract": "A current Request for Proposal [1] from the OMG describes the requirements for an “Executable UML Foundation”. This subset of UML 2 would serve as a shared foundation for higher-level modeling concepts, such as activities, state machines, and interactions. In a sense, this subset would deﬁne a basic virtual machine for UML, allowing the execution and analysis of runtime behavior of models. Regardless of the executable subset chosen, a precise deﬁnition of execution semantics of UML actions is required. To the best of our knowledge, no formal se- mantics of such a subset yet exists. We present our work on clarifying the semantics and pragmatics of UML actions. In particular, we sketch a formalization of a subset of UML actions and discuss common usage scenarios for the most complex actions, identifying usage assumptions that are not explicit in the UML 2 speciﬁcation.",
    "keywords": [
      "Executable UML",
      "actions",
      "activities",
      "formal mapping",
      "se- mantics",
      "Model-driven Engineering."
    ]
  },
  {
    "title": "A Lightweight Approach for Deﬁning the Formal Semantics of a Modeling Language",
    "date": 2008,
    "abstract": "To deﬁne the formal semantics of a modeling language, one normally starts from the abstract syntax and then deﬁnes the static se- mantics and dynamic semantics. Having a formal semantics is important for reasoning about the language but also for building tools for the lan- guage. In this paper we propose a novel approach for this task based on the Alloy language. With the help of a concrete example language, we contrast this approach with traditional methods based on formal lan- guages, type checking, meta-modeling and operational semantics. Al- though both Alloy and traditional techniques yield a formal semantics of the language, the Alloy-based approach has two key advantages: a uni- form notation, and immediate automatic analyzability using the Alloy analyzer. Together with the simplicity of Alloy, our approach oﬀers the prospect of making formal deﬁnitions easier, hopefully paving the way for a wider adoption of formal techniques in the deﬁnition of modeling languages.",
    "keywords": []
  },
  {
    "title": "Semantically Conﬁgurable Code Generation",
    "date": 2008,
    "abstract": "In model-driven engineering (MDE), software development is centred around a formal description (model) of the proposed software system, and other software artifacts are derived directly from the model. We are investigating semantically conﬁgurable MDE, in which speciﬁers are able to conﬁgure the semantics of their models. The goal of this work is to provide a modelling environment that oﬀers ﬂexible, conﬁgurable modelling notations, so that speciﬁers are better able to represent their ideas, and yet still provides the types of analysis tools and code genera- tors normally associated with model-driven engineering. In this paper, we present a semantically conﬁgurable code-generator generator, which cre- ates a Java-code generator for a modelling notation given the notation’s semantics expressed as a set of parameter values. We are able to simu- late multiple diﬀerent model-based code generators, though at present the performance of our generated code is about an order of magnitude slower than that produced by commercial-grade generators.",
    "keywords": []
  },
  {
    "title": "Safety Hazard Identification by Misuse Cases: \nExperimental Comparison of Text and Diagrams",
    "date": 2008,
    "abstract": "In general, diagrams and text are both considered to have their ad- vantages and disadvantages for the representation of use case models, but this is rarely investigated experimentally. This paper describes a controlled experiment where we compare safety hazard identification by means of misuse cases based on use case diagrams and textual use cases. The experiment participants found use case diagrams and textual use cases equally easy to use. In most cases those who used textual use cases were able to identify more failure modes or threats. The main reason for this seems to be that use cases encourage analysts to spe- cifically focus on threats related to the functions mentioned in the use case, and textual use cases include more functional details than diagrams. The focus is decided by information in each use case which will thus decide the number of threats identified.",
    "keywords": [
      "Use cases",
      "misuse cases",
      "safety hazards",
      "experiment."
    ]
  },
  {
    "title": "Adding Dependability Analysis Capabilities to the MARTE Proﬁle⋆",
    "date": 2008,
    "abstract": "Dependability is a non-functional property that should be assessed early in the software lifecycle. Although several UML proﬁles exist for quantitative annotations of non-functional properties, none of them provides concrete capabilities for dependability analysis of UML system models. In this paper, we propose a dependability analysis and modeling proﬁle. The objective is twofold: to reuse proposals from the literature on deriving dependability models from UML annotated speci- ﬁcations and to be compliant with the recently adopted MARTE proﬁle, which provides a framework for general quantitative analysis concepts that can be specialized to a particular analysis domain. The proﬁle def- inition process was done in several steps. Firstly, an in depth analysis of the literature has been carried out to collect the information requirements for the proﬁle. Secondly, a domain model for dependability analysis was deﬁned independently of UML. Thirdly, the domain model was mapped to UML extensions by specializing MARTE.",
    "keywords": []
  },
  {
    "title": "Visual ScatterUnit: A Visual Model-Driven Testing \nFramework of Wireless Sensor Networks Applications",
    "date": 2008,
    "abstract": "We present a model-driven test environment called Visual Scatter- Unit, which optimizes the application testing process of wireless sensor net- works. Instead of having to implement the test case completely manually, the model-driven test environment allows the abstract modeling of the test process. At the same time the test case’s technical implementation requirements are kept hidden from the user.",
    "keywords": []
  },
  {
    "title": "Aspect-Oriented Model Weaving  \nBeyond Model Composition and Model Transformation*",
    "date": 2008,
    "abstract": "Research in Aspect-Oriented Software Development (AOSD) has brought up powerful abstractions in order to specify under which conditions an aspect affects the base software. So far, Model-Driven Development (MDD) approaches to AOSD have mostly concentrated on the weaving process and, as a result, they have come up with manifold ways to compose aspect models and base models. All too often, however, the approaches disregard the benefits that the aspect-oriented abstractions can bring to software development, though. This paper discusses the implications that such negligence has on the specifica- tion of aspect-oriented models in MDD. Furthermore, it presents a weaver that is able to cope with sophisticated join point selection abstractions, as they are known from many aspect-oriented programming languages, and which go far beyond the selection capabilities provided by current model weavers. By means of this weaver, models can realize both a higher separation of concerns as well as a higher level of abstraction.",
    "keywords": []
  },
  {
    "title": "An Aspect-Oriented and Model-Driven Approach for Managing Dynamic Variability⋆",
    "date": 2008,
    "abstract": "Constructing and executing distributed systems that can adapt to their operating context in order to sustain provided services and the service qualities are complex tasks. Managing adaptation of multiple, interacting services is par- ticularly difﬁcult since these services tend to be distributed across the system, interdependent and sometimes tangled with other services. Furthermore, the ex- ponential growth of the number of potential system conﬁgurations derived from the variabilities of each service need to be handled. Current practices of writing low-level reconﬁguration scripts as part of the system code to handle run time adaptation are both error prone and time consuming and make adaptive systems difﬁcult to validate and evolve. In this paper, we propose to combine model driven and aspect oriented techniques to better cope with the complexities of adaptive systems construction and execution, and to handle the problem of exponential growth of the number of possible conﬁgurations. Combining these techniques allows us to use high level domain abstractions, simplify the representation of variants and limit the problem pertaining to the combinatorial explosion of pos- sible conﬁgurations. In our approach we also use models at runtime to generate the adaptation logic by comparing the current conﬁguration of the system to a composed model representing the conﬁguration we want to reach.",
    "keywords": []
  },
  {
    "title": "Managing Variability Complexity in Aspect-Oriented Modeling⋆",
    "date": 2008,
    "abstract": "Aspect-Oriented Modeling (AOM) approaches propose to model reusable aspects that can be applied to diﬀerent systems at the model level. To improve reusability, several contributions have pointed out the needs of variability in the AOM approaches. Nevertheless, the support of variability makes the aspect design more complex and the introduction of several dimensions of variability (advice, pointcut and weaving) creates a combinatorial explosion of variants and a risk of in- consistency in the aspect model. As the integration of an aspect model may be a complex task, the AOM framework has to be a support for the designer to ensure the consistency of the resulting model. This pa- per presents an approach describing how to ensure that an aspect model with variability can be safely integrated into an existing model. Veriﬁ- cation includes static checking of aspect model consistency and dynamic checking through testing with a focus on the parts of the model that are impacted by the aspect.",
    "keywords": []
  },
  {
    "title": "Mapping the UML2 Semantics of Associations to a Java Code Generation Model",
    "date": 2008,
    "abstract": "It is state of the art to provide UML modeling by means of class diagrams and code generation from there. But whereas drawing di- agrams is most often well supported, code generation is limited in scope. Association classes, multiplicities, aggregation and composition are not correctly or not at all processed by most code generators. One reason may be that the UML semantics is not formally deﬁned in the UML speciﬁcation. As a result of that, associations are usually transformed into code by using properties of the same type as the associated classes or corresponding typed sets. This approach must fail although the UML2 Superstructure Speciﬁcation considers association ends owned by a class to be equal to a property of the owning class. In this paper, we describe why associations should be implemented as classes when generating code from class diagrams.",
    "keywords": [
      "UML",
      "Associations",
      "Code Generation",
      "Java."
    ]
  },
  {
    "title": "Meaningful Composite Structures On the Semantics of Ports in UML2",
    "date": 2008,
    "abstract": "UML2 composite structures are a natural solution for the basic modeling issues associated with component-oriented approaches. They provide mechanisms for deﬁning reusable \"pieces\" of design, which are well-encapsulated through explicit interaction ports. While intuitive in principle, the semantics of request propagation across ports may cause semantic ambiguities if the composition mechanisms are not used con- sistently, thus leading to meaningless composite structures (that cannot be safely reused within the context of a particular environment). To en- sure consistent usage, this article proposes an empirical study that pro- vides an intuitive description of composite structure semantics focusing on request propagations across ports. It supplements this description by highlighting cases conducive to semantic ambiguities and oﬀers practical solutions and a rationale for building composite structures that avoid them. Among possible solutions, the opportuneness of encapsulating ex- plicit behaviors in ports is discussed.",
    "keywords": []
  },
  {
    "title": "A Systematic Approach to Connectors in a Multi-level Modeling Environment",
    "date": 2008,
    "abstract": "The advantage of supporting a uniform modeling approach across multiple, logical (or ontological) instantiation levels has been well documented in the literature. However, the published approaches for achieving this have fo- cused on making it possible for classes and objects to be treated uniformly across multiple instantiation levels, but have neglected the problems involved in doing the same thing for “connectors” (i.e. concepts rendered as edges in graph based depiction of models rather than nodes). On closer examination, this turns out to be a significant problem, because without an effective strategy for model- ing connectors in a uniform way, multi-level modeling as a whole is not possi- ble. In this paper we describe the problems arising from the way in which connectors (e.g. associations, links, generalizations etc.) are currently supported in mainstream modeling languages such as the UML and why they are incom- patible with multi-level modeling. We then define three fundamental connector rendering and representation principles that rectify the identified problems.",
    "keywords": [
      "Metamodeling",
      "Multi-Level Modeling",
      "Connector",
      "Association."
    ]
  },
  {
    "title": "Model-Based Quality Assurance of Automotive Software⋆",
    "date": 2008,
    "abstract": "Software in embedded (e.g. automotive) systems requires a high level of reliability. Model-based development techniques are increasingly used to reach this goal, but so far there is relatively little published knowledge on the compar- ative beneﬁts in using different assurance techniques. We investigate different and potentially complementary model-based software quality assurance methods (namely simulation and white-box testing vs. model-checking) at the hand of an application to the software component of a door control unit. We draw conclu- sions with regards to suitable application use cases.",
    "keywords": []
  },
  {
    "title": "Ontology Guided Evolution of Complex Embedded Systems Projects in the Direction of  MDA",
    "date": 2008,
    "abstract": "Implementation of MDA in large, product developing organizations involves changing processes, practices, tools, and communication infrastruc- tures. The paper presents a case study, in which modeling related needs of a unit within Ericsson were compared to features of current and envisioned MDA tools, using qualitative methods. The paper’s main contribution is an ontology defining areas and sub-areas of improvement associated with the introduction of MDA in complex embedded systems projects. The ontology is grounded in in- terviews with senior modellers at Ericsson and in survey publications from within the field of MDA. It identifies 26 improvement areas concerned with model content, modeling activities, and the management of modeling projects. The ontology has been presented to stakeholders within the unit studied, with positive feedback: appreciated were its groundedness, traceability, holistic scope, and potential as platform and checklist for several recurrent analysis and communication tasks related to software process improvement within Ericsson.",
    "keywords": []
  },
  {
    "title": "General Mode Controller for Software on Artificial Satellite with Model-Based Validation Tool",
    "date": 2008,
    "abstract": "High quality and flexibility are strongly required for embedded soft- ware on artificial satellites. High quality is very important because any single halt is not allowed over 15 years operation period without any significant main- tenance. Flexibility is also important to adapt customer requirements which may vary after operation experiences. A quick and reliable way to modify the soft- ware functions is required. The model-based approach will contribute to solve this problem. Mitsubishi Electric Corporation, one of the representing artificial satellite suppliers in Japan, is now implementing a General Mode Controller on on-board software of satellites. We noticed functions related to modes and se- quences are often required to modify from previous projects. The General Mode Controller can modify them in a reliable way by changing control parameters without modifying source code. The control parameters are verified by using a model-based tool, Matlab Simulink and Stateflow, to enable quick and low risk modifications.",
    "keywords": [
      "Mode controller",
      "embedded system",
      "high quality",
      "flexibility",
      "Simu- link",
      "Stateflow."
    ]
  },
  {
    "title": "Educators Symposium at MODELS 2008",
    "date": 2008,
    "abstract": "Model-driven engineering is becoming increasingly popular in software development projects as it raises level of abstraction, thus improving our ability to handle complex systems. In many academic and industrial centers, software modeling has already been introduced into their curricula. Despite this, it seems that education does not yet support the modeling paradigm well enough thus limiting its acceptance as a mature method of developing software systems. The goal of this symposium was to ﬁnd ways to change this situation. Speciﬁcally, the symposium sought ways of showing beneﬁts of modeling in a way that is pedagogically eﬀective and attractive to the students. It also tried to make recommendations for placing the modeling courses in the overall software development educational path, which should include not only UML fundamentals but also a demonstration of the importance and place of modeling in the overall path from business (environment) to software products.",
    "keywords": []
  },
  {
    "title": "Models. Models. Models. So What?",
    "date": 2009,
    "abstract": "In 1985, in an interview for some then-popular magazine, I was asked when models and model-driven development would become commonplace. ”In three years time,” I replied conﬁdently. In 1987, I was asked the same question, and my answer remained the same. And 1989. And ’91. Were you to ask me the same question today, I would answer it in the same way. Perhaps I should have gone surﬁng instead.",
    "keywords": []
  },
  {
    "title": "Modeling Modeling",
    "date": 2009,
    "abstract": "Model-driven engineering and model-based approaches have perme- ated all branches of software engineering; to the point that it seems that we are using models, as Molière’s Monsieur Jourdain was using prose, without know- ing it. At the heart of modeling, there is a relation that we establish to represent something by something else. In this paper we review various definitions of models and relations between them. Then, we define a canonical set of relations that can be used to express various kinds of representation relations and we propose a graphical concrete syntax to represent these relations. Hence, this pa- per is a contribution towards a theory of modeling.",
    "keywords": []
  },
  {
    "title": "Representation and Traversal of Large Clabject Models",
    "date": 2009,
    "abstract": "Multi-level modeling using so-called clabjects has been proposed as an alternative to UML for modeling domains that feature more than one classi- fication level. In real-world applications, however, this modeling formalism has not yet become popular, because it is a challenge to efficiently represent large models, and providing fast access to all information spread across the meta- levels at the same time. In this paper we present the model representation con- cept that relies on a permanent condensed view of the model, the corresponding traversal algorithms, and their implementations that proved adequate for model- driven engineering of industrial automation systems consisting of hundreds of thousands of model elements.",
    "keywords": [
      "Clabject",
      "Multi-Level Modeling",
      "Efficient Representation."
    ]
  },
  {
    "title": "Meta-model Pruning⋆",
    "date": 2009,
    "abstract": "Large and complex meta-models such as those of Uml and its proﬁles are growing due to modelling and inter-operability needs of numerous stakeholders. The complexity of such meta-models has led to coining of the term meta-muddle. Individual users often exercise only a small view of a meta-muddle for tasks ranging from model creation to construction of model transformations. What is the eﬀective meta-model that represents this view? We present a ﬂexible meta-model pruning al- gorithm and tool to extract eﬀective meta-models from a meta-muddle. We use the notion of model typing for meta-models to verify that the al- gorithm generates a super-type of the large meta-model representing the meta-muddle. This implies that all programs written using the eﬀective meta-model will work for the meta-muddle hence preserving backward compatibility. All instances of the eﬀective meta-model are also instances of the meta-muddle. We illustrate how pruning the original Uml meta- model produces diﬀerent eﬀective meta-models.",
    "keywords": [
      "Meta-model pruning",
      "GPML",
      "DSML",
      "UML",
      "Kermeta",
      "eﬀec- tive modelling domain",
      "test input domain."
    ]
  },
  {
    "title": "A UML/MARTE Model Analysis Method for Detection of Data Races in Concurrent Systems",
    "date": 2009,
    "abstract": "The earlier concurrency problems are identified, the less costly they are to fix. As larger, more complex concurrent systems are developed, early detection of problems is made increasingly difficult. We have developed a gen- eral approach meant to be used in the context of Model Driven Development. Our approach is based on the analysis of design models expressed in the Uni- fied Modeling Language (UML) and uses specifically designed genetic algorithms to detect concurrency problems. Our main motivation is to devise practical solutions that are applicable in the context of UML design of concur- rent systems without requiring additional modeling. All relevant concurrency information is extracted from UML models that comply with the UML Model- ing and Analysis of Real-Time and Embedded Systems (MARTE) profile. Our approach was shown to work for both deadlocks and starvation. The current pa- per addresses data race detection, further illustrating how our approach can be tailored to other concurrency issues. Results on a case study inspired from the Therac-25 radiation machine show that our approach is effective in the detec- tion of data races.",
    "keywords": [
      "MDD",
      "data races",
      "model analysis",
      "concurrent systems",
      "UML",
      "MARTE",
      "genetic algorithms."
    ]
  },
  {
    "title": "Model Driven Performance Measurement and Assessment with MoDePeMART⋆",
    "date": 2009,
    "abstract": "Software performance is one of important software Quality of Service attributes. For this reason, several approaches integrate perfor- mance prediction in Model Driven Engineering(MDE). However, MDE still lacks a systematic approach for performance measurement and met- rics assessment. This paper presents MoDePeMART, an approach for Model Driven Performance Measurement and Assessment with Rela- tional Traces. The approach suggests declarative speciﬁcation of per- formance metrics in a domain speciﬁc language and usage of relational databases for storage and metric computation. The approach is eval- uated with the implementation of a UML Proﬁle for UML Class and State diagrams and transformations from proﬁle to a commercial rela- tional database management system.",
    "keywords": [
      "Software Performance Measurement and Assessment",
      "Model Driven Engineering",
      "Transformational and Reactive Systems."
    ]
  },
  {
    "title": "Security Analysis of a Biometric Authentication System Using UMLsec and JML*",
    "date": 2009,
    "abstract": "Quality assurance for security-critical systems is particularly chal- lenging: many systems are developed, deployed, and used that do not satisfy their security requirements. A number of software engineering approaches have been developed over the last few years to address this challenge, both in the context of model-level and code-level security assurance. However, there is lit- tle experience so far in using these approaches in an industrial context, the chal- lenges and benefits involved and the relative advantages and disadvantages of different approaches. This paper reports on experiences from a practical appli- cation of two of these security assurance approaches. As a representative of model-based security analysis, we considered the UMLsec approach and we in- vestigated the JML annotation language as a representative of a code-level as- surance approach. We applied both approaches to the development and security analysis of a biometric authentication system and performed a comparative evaluation based on our experiences.",
    "keywords": [
      "Security analysis",
      "JML",
      "UMLsec",
      "biometric authentication."
    ]
  },
  {
    "title": "Automatically Discovering Hidden\nTransformation Chaining Constraints",
    "date": 2009,
    "abstract": "Model transformations operate on models conforming to pre- cisely deﬁned metamodels. Consequently, it often seems relatively easy to chain them: the output of a transformation may be given as input to a second one if metamodels match. However, this simple rule has some obvious limitations. For instance, a transformation may only use a sub- set of a metamodel. Therefore, chaining transformations appropriately requires more information.",
    "keywords": []
  },
  {
    "title": "CSP(M): Constraint Satisfaction Problem over Models⋆",
    "date": 2009,
    "abstract": "Constraint satisfaction programming (CSP)has been successfully used in model-driven development (MDD) for solving a wide range of (combinatorial) problems. In CSP, declarative constraints capture restrictions over variables with ﬁnite domains where both the number of variables and their domains are required to be a priori ﬁnite. However, the existing formulation of constraint satisfaction problems can be too restrictive to support dynamically evolving domains and con- straints necessitated in many MDD applications as the graph nature of the under- lying models needs to be encoded with variables of ﬁnite domain. In the paper, we reformulate the constraint satisfaction problem directly on the model-level by using graph patterns as constraints and graph transformation rules as labeling op- erations. This allows expressing problems composed of dynamic model manipu- lation and complex graph structural constraints in an intuitive way. Furthermore, we present a prototype constraint solver for the domain of graph models built upon the VIATRA2 model transformation framework, and provide an initial evaluation of its performance.",
    "keywords": [
      "Constraint satisfaction programming",
      "graph transformation."
    ]
  },
  {
    "title": "Parsing SBVR-Based Controlled Languages⋆,⋆⋆",
    "date": 2009,
    "abstract": "Conceptual schemas (CS) are core elements of information systems knowledge. A challenging issue in the management processes is to allow decision makers, such as business people, to directly deﬁne and reﬁne their schemas using a pseudo-natural language. The recently pub- lished Semantics for Business Vocabulary and Rules (SBVR) is a good candidate for an intermediate layer: it oﬀers an abstract syntax able to express a CS, as well as a concrete syntax based on structured English. In this article, we propose an original method for extracting a SBVR ter- minal model out of a controlled English text and then transform it into a UML class diagram. We describe a model-driven engineering approach in which constraint-programming based search is combined with model transformation. The use of an advanced resolution technique (conﬁgura- tion) as an operation on models allows for non-deterministic parsing and language ﬂexibility. In addition to the theoretical results, preliminary experiments on a running example are provided.",
    "keywords": [
      "Controlled languages",
      "parsing",
      "SBVR",
      "model-driven engi- neering",
      "constraints",
      "conﬁguration",
      "model search."
    ]
  },
  {
    "title": "SLIM—A Lightweight Environment for Synchronous Collaborative Modeling",
    "date": 2009,
    "abstract": "UML diagrams have become the de-facto standard for the vi- sual modeling of software systems. The creation and discussion of these diagrams is a critical factor impacting the quality of the artifacts un- der development. Traditionally, facilitating the collaboration of globally distributed team members with heterogeneous system environments has been a costly and time-consuming endeavor. This paper aims to advance the state-of-the-art of model-based development by providing a collabo- ration environment, which supports the synchronous distributed creation and manipulation of UML diagrams and also lowers the technical entry barriers for participating in the modeling process. We present a prototyp- ical implementation of a collaborative editor for synchronous lightweight modeling (SLIM). Applying innovative techniques, which only rely on functionality natively supported by modern web browsers, technical is- sues impeding clients to be integrated into the collaborative environment are avoided and ad hoc collaboration is facilitated.",
    "keywords": [
      "Collaborative Modeling",
      "Web 2.0",
      "Real-Time Editor."
    ]
  },
  {
    "title": "Language-Independent Change Management of Process Models",
    "date": 2009,
    "abstract": "In model-driven development approaches, process models are used at different levels of abstraction and are described by different languages. Similar to other software artifacts, process models are developed in team environments and underlie constant change. This requires reusable techniques for the detection of changes between different process models and the computation of dependen- cies and conﬂicts between changes. In this paper, we propose a framework for the construction of process model change management solutions that provides generic techniques for the detection of differences and the computation of de- pendencies and conﬂicts between changes. The framework contains an abstract representation for process models that serves as a common denominator for dif- ferent process models. In addition, we show how the framework is instantiated exemplarily for BPMN.",
    "keywords": [
      "Process model change management",
      "process model differences."
    ]
  },
  {
    "title": "Requirements for Practical Model Merge – An Industrial Perspective*",
    "date": 2009,
    "abstract": "All the support tools that developers are used to must be in place, if the use of model-centric development in companies has to take off. Industry deals with big models and many people working on the same model. Collabora- tion in a team inevitably leads to parallel work creating different versions that eventually will have to be merged together. However, our experience is that at present the support for model merge is far from optimal. In this paper, we put forward a number of requirements for practical merge tools, based on our analysis of literature, merge tool evaluations, interviews with developers, and a number of use cases for concurrent development of models. We found future work to do for both tool vendors and academic research. Fortunately we also uncovered a few tips and tricks that companies using model-centric develop- ment can implement on the short term while waiting for better times.",
    "keywords": [
      "Model merge",
      "diff",
      "version control",
      "parallel work",
      "team co- ordination",
      "industrial experience."
    ]
  },
  {
    "title": "Evaluating the Impact of UML Modeling on\nSoftware Quality: An Industrial Case Study⋆",
    "date": 2009,
    "abstract": "The contribution of formal modeling approaches in software development has always been a subject of debates. The proponents of model-driven development argue that big upfront designs although re- quire substantial investment will payoﬀlater in the implementation phase in terms of increased productivity and quality. On the other hand, soft- ware engineers who are not very keen on modeling perceive the activity as simply a waste of time and money without any real contribution to the ﬁnal software product. Considering present advancement of model- based software development in software industry, we are challenged to investigate the real contribution of modeling in software development. Therefore, in this paper we report on an empirical investigation on the impact of UML modeling on the quality of software system. In particu- lar, we focus on defect density as a measure of software quality. Based on a signiﬁcant industrial case study, we have found that the use of UML modeling potentially reduces defect density in software system.",
    "keywords": [
      "UML",
      "Complexity",
      "Coupling",
      "Defect Density",
      "Case Study."
    ]
  },
  {
    "title": "Concern Visibility in Base Station Development – An Empirical Investigation*",
    "date": 2009,
    "abstract": "Contemporary model driven development tools only partially support the abstractions occurring in complex embedded systems development. The pa- per presents an interpretive case study in which the concerns held by 7 engi- neers in a large product developing organization were compared to the concerns supported by the modeling tool in use. The paper’s main finding is an empiri- cally grounded catalogue of concerns, categorized with respect to visibility in models and other artefacts in use. In the studied case, 26% of the concerns were visible in the models, whereas 38% were visible elsewhere and 36% not visible at all. The catalogue has been presented to several stakeholders in the unit stud- ied, with positive feedback: particularly appreciated were the notion of concern visibility as indicator of degree of implementation of model driven develop- ment, and that concerns have traceable connections to experiences of the unit’s engineers.",
    "keywords": [
      "Model driven development (MDD)",
      "aspect oriented modeling  (AOM)",
      "software architecture",
      "viewpoints",
      "concerns",
      "base stations",
      "telecommu- nication systems",
      "embedded systems."
    ]
  },
  {
    "title": "Inﬂuencing Factors in Model-Based Testing with UML State Machines: Report on an Industrial Cooperation⋆",
    "date": 2009,
    "abstract": "Automatic model-based test generation is inﬂuenced by many factors such as the test generation algorithm, the structure of the used test model, and the applied coverage criteria. In this paper, we report on an industrial cooperation for model-based testing: We used a UML state machine to generate test suites, the original system under test was not pro- vided, and we conducted mutation analysis on artiﬁcial implementations. The focus of this report is on tuning the inﬂuencing factors of the test gen- eration and showing their impact on the generated test suites. This report raises further questions, e.g. about the role of test model transformations for coverage criteria satisfaction.",
    "keywords": [
      "Model-Based Testing",
      "State Machines",
      "Coverage Criteria",
      "Mutation Analysis",
      "Industrial Cooperation."
    ]
  },
  {
    "title": "Towards Composite Model Transformations Using Distributed Graph Transformation Concepts",
    "date": 2009,
    "abstract": "Model-based development of highly complex software systems leads to large models. Storing them in repositories offers the possibility to work with these models in a distributed environment. However, they are not modularized and thus, do not especially support distributed development. An alternative is to con- sider composite models such that several teams can work largely independently. In this paper, we consider a general approach to composite models and their trans- formation based on graph transformation concepts. To illustrate this approach, we present a concrete setting for composite models based on the Eclipse Modeling Framework (EMF). EMF models can be distributed over several sites. While re- mote references can express import relations, export and import interfaces are not explicitly deﬁned. In our approach, we sketch composite models with explicit and implicit interfaces using concepts of distributed graph transformation and outline different kinds of composite model transformations.",
    "keywords": [
      "Distributed modeling",
      "graph transformation",
      "Eclipse."
    ]
  },
  {
    "title": "On-the-Fly Construction, Correctness and Completeness of Model Transformations Based on Triple Graph Grammars",
    "date": 2009,
    "abstract": "Triple graph grammars (TGGs) are a formal and intuitive concept for the speciﬁcation of model transformations. Their main ad- vantage is an automatic derivation of operational rules for bidirectional model transformations, which simpliﬁes speciﬁcation and enhances us- ability as well as consistency.",
    "keywords": []
  },
  {
    "title": "Formal Support for QVT-Relations with Coloured Petri Nets",
    "date": 2009,
    "abstract": "QVT is the OMG standard language for specifying model- to-model transformations in MDA. Even though it plays a crucial role in model driven development, there are scarce tools supporting the ex- ecution of its sublanguage QVT-Relations, and none for its analysis or veriﬁcation. In order to alleviate this situation, this paper provides a for- mal semantics for QVT-Relations through its compilation into Coloured Petri nets, enabling the execution and validation of QVT speciﬁcations. The theory of Petri nets provides useful techniques to analyse trans- formations (e.g. reachability, model-checking, boundedness and invari- ants) and to determine their conﬂuence and termination given a starting model. We also report on using CPNTools for the execution, debugging, and analysis of transformations, and on a tool chain to transform QVT- Relations speciﬁcations into the input format of CPNTools.",
    "keywords": []
  },
  {
    "title": "An Example Is Worth a Thousand Words:\nComposite Operation Modeling By-Example⋆",
    "date": 2009,
    "abstract": "Predeﬁned composite operations are handy for eﬃcient mod- eling, e.g., for the automatic execution of refactorings, and for the in- troduction of patterns in existing models. Some modeling environments provide an initial set of basic refactoring operations, but hardly oﬀer any extension points for the user. Even if extension points exist, the intro- duction of new composite operations requires programming skills and deep knowledge of the respective metamodel.",
    "keywords": []
  },
  {
    "title": "Refactoring-Safe Modeling of Aspect-Oriented Scenarios",
    "date": 2009,
    "abstract": "Aspects use pointcut expressions to specify patterns that are matched against a base model, hence defining the base locations to which aspects are ap- plied. The fragile pointcut problem is well-known in aspect-oriented modeling, as small changes in the base may lead to non-matching patterns. Consequently, aspects are not applied as desired. This is especially problematic for refactoring. Even though the meaning of the model has not changed, pointcut expressions may no longer match. We present an aspect-oriented modeling technique for scenarios that is refactoring-safe. The scenarios are modeled with Aspect- oriented Use Case Maps (AoUCM), an extension of the recent ITU standard User Requirements Notation. AoUCM takes the semantics of the modeling no- tation into account, thus ensuring pointcut expressions still match even after, for example, refactoring a single use case map into several hierarchical maps. Fur- thermore, AoUCM allows the composed model to be viewed without having to resolve complex layout issues. The general principles of our approach are also applicable to other aspect-oriented modeling notations.",
    "keywords": [
      "Aspects-oriented Modeling",
      "User Requirements Notation",
      "Aspect- oriented Use Case Maps."
    ]
  },
  {
    "title": "Model-Based Testing Using LSCs and S2A⋆,⋆⋆",
    "date": 2009,
    "abstract": "We report on our preliminary experience in using high-level visual scenario-based models for tests speciﬁcation, test generation, and aspect-based test execution, in the context of an industrial application. To specify scenario- based tests, we used a UML2-compliant variant of live sequence charts (LSC). To automatically generate testing code from the models, we used a modiﬁed ver- sion of the S2A Compiler, outputting AspectC++ code. Finally, to examine the results of the tests, we used the Tracer, a prototype tool for model-based trace visualization and exploration. Our experience reveals the advantages of integrat- ing models into industrial settings, speciﬁcally for model-based test speciﬁcation and aspect-based execution: generating aspect code from visual models enables exploiting the expressive power of aspects for testing without manual coding and without knowledge of their rather complex syntax and semantics. We further dis- cuss technological and other barriers for the future successful integration of our initial work in industrial context.",
    "keywords": []
  },
  {
    "title": "Model Driven Development of Graphical User  \nInterfaces for Enterprise Business Applications – \nExperience, Lessons Learnt and a Way Forward*",
    "date": 2009,
    "abstract": "We discuss our experience in applying model-driven techniques to build Graphical User Interfaces (GUI) of large enterprise business applications. Our approach involves capturing various user interface patterns in the form of platform independent parameterized templates and instantiating them with rele- vant application data, serving as the template arguments. Models thus instantiated are translated to platform specific GUI implementation artifacts by a set of tem- plate-specific code generators. We describe this approach in detail and share our experiences and the lessons learnt from using the approach in developing large da- tabase-centric business applications for the past fourteen years. Our ongoing work to address some of the limitations of this approach, especially on variability man- agement of GUI in software product lines, is also presented in brief.",
    "keywords": [
      "Modeling",
      "Graphical User Interfaces",
      "Meta Modeling",
      "Code   Generation."
    ]
  },
  {
    "title": "Business Process Models as a Showcase for\nSyntax-Based Assistance in Diagram Editors",
    "date": 2009,
    "abstract": "Recently, a generic approach for syntax-based user assistance in diagram editors has been proposed that requires the syntax of the vi- sual language to be deﬁned by a graph grammar. The present paper describes how this approach can be applied to the language of business process models (BPMs), which is widely used nowadays. The resulting BPM editor provides the following assistance features: combination or completion of BPM fragments, generation of BPM examples, an exten- sive set of correctness-preserving editing operations for BPMs, and auto- link, i.e., the automatic connection of activities by sequence ﬂow.",
    "keywords": []
  },
  {
    "title": "Rule-Enhanced Business Process Modeling Language for Service Choreographies",
    "date": 2009,
    "abstract": "To address problem of modeling service choreographies, the paper tackles the following challenges of the state of the art in choreography model- ing: i) choreography models are not well-connected with the underlying busi- ness vocabulary models. ii) there is limited support for decoupling parts of business logic from complete choreography models. This reduces dynamic changes of choreographies; iii) choreography models contain redundant ele- ments of shared business logic, which might lead to an inconsistent implemen- tation and incompatible behavior. Our proposal – rBPMN – is an extension of a business process modeling language with rule and choreography modeling sup- port. rBPMN is defined by weaving the metamodels of the Business Process Modeling Notation (BPMN) and REWERSE Rule Markup Language (R2ML).",
    "keywords": [
      "BPMN",
      "R2ML",
      "rules",
      "processes",
      "metamodels",
      "MDE."
    ]
  },
  {
    "title": "Change-Driven Model Transformations⋆ Derivation and Processing of Change Histories",
    "date": 2009,
    "abstract": "Nowadays, evolving models are prime artefacts of model-driven soft- ware engineering. In tool integration scenarios, a multitude of tools and modeling languages are used where complex model transformations need to incrementally synchronize various models residing within different external tools. In the pa- per, we investigate a novel class of transformations, that are directly triggered by model changes. First, model changes in the source model are recorded incremen- tally by a change history model. Then a model-to-model transformation is carried out to generate a change model for the target language. Finally, the target change history model is processed (at any time) to incrementally update the target model itself. Moreover, our technique also allows incremental updates in an external model where only the model manipulation interface is under our control (but not the model itself). Our approach is implemented within the VIATRA2 framework, and it builds on live transformations and incremental pattern matching.",
    "keywords": [
      "Incremental model transformation",
      "change models",
      "change-driven transformations."
    ]
  },
  {
    "title": "An Incremental Algorithm for\nHigh-Performance Runtime Model Consistency⋆",
    "date": 2009,
    "abstract": "We present a novel technique for applying two-level runtime models to distributed systems. Our approach uses graph rewriting rules to transform a high-level source model into one of many possible target models. When either model is changed at runtime, the transformation is incrementally updated. We describe the theory underlying our approach, and show restrictions suﬃcient for a simple and eﬃcient implementation.",
    "keywords": []
  },
  {
    "title": "Traceability-Based Change Awareness",
    "date": 2009,
    "abstract": "Many tools in software engineering projects support the visualization and collaborative modification of custom sets of artifacts. This includes tools for requirements engineering, UML tools for design, project management tools, developer tools and many more. A key factor for success in software engineer- ing projects is the collective understanding of changes applied to these artifacts. To support this, there are several strategies to automatically notify project par- ticipants about relevant changes. Known strategies are limited to a fixed set of artifacts and/or make no use of traceability information to supply change notifi- cations. This paper proposes a change notification approach based on traceabil- ity in a unified model and building upon operation-based change tracking. The unified model explicitly combines system specification models and project management models into one fully traceable model. To show the benefit of our approach we compare it to related approaches in a case study.",
    "keywords": [
      "Change awareness",
      "traceability",
      "unified model",
      "operation-based",
      "notification."
    ]
  },
  {
    "title": "Interaction Design and Model-Driven Development",
    "date": 2009,
    "abstract": "Throughout the evolution of software development and soft- ware engineering methods, human interaction and the interfaces that support it have been too often ignored or treated as secondary con- cerns. Most modern modeling languages and methods - UML and the uniﬁed process most deﬁnitely among them - have been devised with a highly focused concern for representing procedures, information, and software structures. The needs of interaction design and designers have been addressed, if at all, in afterthought. Instead of well-conceived no- tations and techniques, interaction designers have been given awkward adaptations of models conceived for completely diﬀerent and largely in- compatible purposes. Instead of placing users and use at the center of developmental and methodological focus, the dominant modeling lan- guages and methods have relegated them to the periphery. Despite noble calls for rapprochement and valiant attempts to build bridges, the gap between software engineering on the one side and human-computer in- teraction on the other remains stubbornly deep and wide, ﬁlled with misunderstanding and devoid of meaningful integration.",
    "keywords": []
  },
  {
    "title": "Towards Test-Driven Semantics Speciﬁcation",
    "date": 2009,
    "abstract": "Behavioral models are getting more and more important within the software development cycle. To get the most use out of them, their behavior should be deﬁned formally. As a result, many approaches exist which aim at specifying formal semantics for behavioral languages (e.g., Dynamic Meta Modeling (DMM), Semantic Anchoring). Most of these approaches give rise to a formal semantics which can e.g. be used to check the quality of a particular language instance, for instance using model checking techniques.",
    "keywords": []
  },
  {
    "title": "Scalable Semantic Annotation Using Lattice-Based Ontologies⋆",
    "date": 2009,
    "abstract": "Including semantic information in models helps to expose modeling errors early in the design process, engage a designer in a deeper understanding of the model, and standardize concepts and terminology across a development team. It is impractical, however, for model builders to manually annotate every modeling element with semantic properties. This paper demonstrates a correct, scalable and automated method to infer semantic properties using lattice-based ontologies, given relatively few manual annotations. Semantic concepts and their relationships are formalized as a lattice, and relationships within and between components are expressed as a set of constraints and acceptance criteria relative to the lattice. Our inference engine automatically infers properties wher- ever they are not explicitly speciﬁed. Our implementation leverages the infrastructure in the Ptolemy II type system to get eﬃcient and scalable inference and consistency checking. We demonstrate the approach on a non-trivial Ptolemy II model of an adaptive cruise control system.",
    "keywords": []
  },
  {
    "title": "OntoDSL: An Ontology-Based Framework for Domain-Speciﬁc Languages",
    "date": 2009,
    "abstract": "Domain-speciﬁc languages (DSLs) are high-level and should provide abstractions and notations for better understanding and easier modeling of applications of a special domain. Current shortcomings of DSLs include learning curve and formal semantics. This paper reports on a novel approach that allows the use of ontologies to describe DSLs. The formal semantics of OWL together with reasoning services allow for addressing constraint deﬁnition, progressive evaluation, suggestions, and debugging. The approach integrates existing metamodels, concrete syntaxes and a query language. A scenario in which domain models for network devices are created illustrates the development environment.",
    "keywords": [
      "Domain-Speciﬁc Languages",
      "Technical Space",
      "Ontologies",
      "Reasoning Services."
    ]
  },
  {
    "title": "Domain-Speciﬁc Languages in Practice: A User Study on the Success Factors⋆",
    "date": 2009,
    "abstract": "In this paper we present an empirical study on the use of a domain- speciﬁc language(DSL) in industry. This DSL encapsulates the details of services that communicate using Windows Communication Foundation (WCF). From def- initions of the data contracts between clients and servers, WCF/C# code for ser- vice plumbing is generated. We conducted a survey amongst developers that use this DSL while developing applications for customers. The DSL has been used in about 30 projects all around the world.",
    "keywords": []
  },
  {
    "title": "Evaluating Context Descriptions and Property  \nDefinition Patterns for Software Formal Validation*",
    "date": 2009,
    "abstract": "A well known challenge in the formal methods domain is to improve their integration with practical engineering methods. In the context of embed- ded systems, model checking requires first to model the system to be validated, then to formalize the properties to be satisfied, and finally to describe the be- havior of the environment. This last point which we name as the proof context is often neglected. It could, however, be of great importance in order to reduce the complexity of the proof. The question is then how to formalize such a proof context. We experiment a language, named CDL (Context Description Lan- guage), for describing a system environment using actors and sequence dia- grams, together with the properties to be checked. The properties are specified with textual patterns and attached to specific regions in the context. Our contri- bution is a report on several industrial embedded system applications.",
    "keywords": [
      "Formal methods",
      "context description",
      "property patterns",
      "observers",
      "timed automata",
      "model checking."
    ]
  },
  {
    "title": "Anatomy of a Visual Domain-Specific Language Project in an Industrial Context*",
    "date": 2009,
    "abstract": "Domain-specific languages (DSL) are specialized modeling lan- guages targeting a narrow domain. In this paper, we present the results of a re- search project on visual DSLs set in an industrial context, using the domain of elevator controllers. After domain analysis and inception of new, abstract mod- eling concepts a language prototype was developed, considering aspects such as usability, combination of visual and textual DSLs, and performance of gener- ated code. We describe the challenges encountered during the project, such as defining a user-friendly concrete syntax or tool limitations, and analyze them in retrospective. The paper concludes with several metrics to support the findings.",
    "keywords": [
      "Domain-specific language",
      "visual",
      "textual",
      "code generation."
    ]
  },
  {
    "title": "A Goal-Based Modeling Approach to Develop Requirements of an Adaptive System with Environmental Uncertainty⋆",
    "date": 2009,
    "abstract": "Dynamically adaptive systems (DASs) are intended to mon- itor the execution environment and then dynamically adapt their behav- ior in response to changing environmental conditions. The uncertainty of the execution environment is a major motivation for dynamic adap- tation; it is impossible to know at development time all of the possible combinations of environmental conditions that will be encountered. To date, the work performed in requirements engineering for a DAS includes requirements monitoring and reasoning about the correctness of adap- tations, where the DAS requirements are assumed to exist. This paper introduces a goal-based modeling approach to develop the requirements for a DAS, while explicitly factoring uncertainty into the process and resulting requirements. We introduce a variation of threat modeling to identify sources of uncertainty and demonstrate how the RELAX speciﬁ- cation language can be used to specify more ﬂexible requirements within a goal model to handle the uncertainty.",
    "keywords": [
      "Requirements engineering",
      "goal models",
      "uncertainty",
      "dynam- ically adaptive systems."
    ]
  },
  {
    "title": "A Use Case Modeling Approach to Facilitate the Transition towards Analysis Models: Concepts and Empirical Evaluation",
    "date": 2009,
    "abstract": "Use case modeling (UCM) is commonly applied to document re- quirements. Use case specifications (UCSs) are usually structured, unrestricted textual documents complying with a certain template. However, because they remain essentially textual, ambiguities are inevitable. In this paper, we propose a new UCM approach, which is composed of a set of well-defined restriction rules and a new template. The goal is to reduce ambiguity and facilitate auto- mated analysis, though the later point is not addressed in this paper. We also re- port on a controlled experiment which evaluates our approach in terms of its ease of application and the quality of the analysis models derived by trained in- dividuals. Results show that the restriction rules are overall easy to apply and that our approach results in significant improvements over UCM using a stan- dard template and no restrictions in UCSs, in terms of the correctness of derived class diagrams and the understandability of UCSs.",
    "keywords": [
      "Use Case",
      "Use Case Modeling",
      "Use Case Template",
      "Restriction  Rules",
      "Analysis Model",
      "Controlled Experiment."
    ]
  },
  {
    "title": "Polymorphic Scenario-Based Speciﬁcation Models: Semantics and Applications⋆",
    "date": 2009,
    "abstract": "We present polymorphic scenarios, a generalization of a UML2-compliant variant of Damm and Harel’s live sequence charts (LSC) in the context of object-orientation. Polymorphic scenarios are visualized using (modal) sequence diagrams where lifelines may represent classes and interfaces rather than concrete objects. Their semantics takes ad- vantage of inheritance and interface realization to allow the speciﬁcation of most expressive, succinct, and reusable universal and existential inter- object scenarios for object-oriented system models. We motivate the use of polymorphic scenarios, formally deﬁne their trace-based semantics, and present their application for scenario-based testing and execution, as implemented in the S2A compiler developed in our group.",
    "keywords": []
  },
  {
    "title": "Aspect Model Unweaving⋆",
    "date": 2009,
    "abstract": "Since software systems need to be continuously available, their ability to evolve at runtime is a key issue. The emergence of mod- els@runtime, combined with Aspect-Oriented Modeling techniques, is a promising approach to tame the complexity of adaptive systems. How- ever, with no support for aspect unweaving, these approaches are not ag- ile enough in an adaptive system context. In case of small modiﬁcations, the adapted model has to be generated by again weaving all the aspects, even those unchanged. This paper shows how aspects can be unwoven, based on a precise traceability metamodel dedicated to aspect model weaving. We analyze traceability models, which describe how aspects were woven into a base, to determine the extent to which an aspect has aﬀected the woven model in order to determine how it can be unwoven. Aspect unweaving is ﬁnally performed by applying inverse operations of a sub-sequence of the weaving operations in opposite order.",
    "keywords": []
  },
  {
    "title": "Model Composition Contracts",
    "date": 2009,
    "abstract": "The state-of-the-art in aspect-oriented programming and modeling provides ﬂexible querying and composition mechanisms that allow virtually un- restricted modiﬁcations to base code or models using static or dynamic weaving. There is, however, a lack of support for specifying and controlling the permit- ted effects of compositions with respect to the base models involved. We present model composition contracts, which govern access to the base models via aspects; in essence, the contracts control how aspect compositions may or may not access and change the models, or the underlying code reﬂected by models. The compo- sition contracts deﬁne constraints in terms of pre- and post-conditions restricting the eligibility for composition. We argue that composition contracts improve re- liability of model composition in software engineering, and evaluate their effects on model designs and implementations using a case study. We support the app- roach with a prototype tool for specifying and checking contracts.",
    "keywords": [
      "Model composition",
      "designbycontract",
      "aspect-oriented development."
    ]
  },
  {
    "title": "Abstracting Complex Languages through Transformation and Composition⋆",
    "date": 2009,
    "abstract": "Domain-speciﬁc languages (DSLs) can simplify the develop- ment of complex software systems by providing domain-speciﬁc abstrac- tions. However, the complexity of some domains has led to a number of DSLs that are themselves complex, limiting the original beneﬁts of using DSLs. We show how to develop DSLs as abstractions of other DSLs by transfering translational approaches for textual DSLs into the domain of modelling languages. We argue that existing model transformation languages are at too low a level of abstraction for succinctly expressing transformations between abstract and concrete DSLs. Patterns identi- ﬁed in such model transformations can be used to raise the level of ab- straction. We show how we can allow part of the transformation to be expressed using the concrete syntax of the concrete DSL.",
    "keywords": []
  },
  {
    "title": "An Approach for Evolving Transformation Chains⋆",
    "date": 2009,
    "abstract": "A transformation chain (TC) generates applications from high-level models that are deﬁned in terms of problem domain concepts. The result is a low-level model that is rooted in the solution domain. The evolution of a TC is a complex and expensive endeavor since there are intricate dependencies between all its constituent parts. More speciﬁc, an evolution problem arises when we need to add an unanticipated con- cern (e.g., security) that does not ﬁt the expressiveness of the high-level metamodel, because such an addition forces us to adapt existing assets (i.e., metamodels, models, and transformations). We present a solution that adds a new concern model to the TC, in an independent way.",
    "keywords": [
      "Model Driven Engineering",
      "Model transformation",
      "Model composition."
    ]
  },
  {
    "title": "Deterministic UML Models for Interconnected Activities and State Machines",
    "date": 2009,
    "abstract": "The interconnection between UML activities and state ma- chines enables the comprehensible modeling of systems based on data ﬂows and events. In this paper, we propose a novel approach to guarantee a deterministic behavior for models in which activity and state diagrams work together. At ﬁrst, deterministic models are ensured independently within both diagrams by using our UML proﬁle for Deterministic Mod- els for signal processing embedded systems (DMOSES). The relationship between executions of the model elements is analyzed according to in- terconnections of the activity and state diagrams described in the UML standard. To avoid nondeterministic models, we deﬁne the execution be- havior of cooperating activities and state machines. The interconnection of both diagrams and their corresponding behavior are illustrated in an embedded system example that uses parallel processing for data as well as for events. Our approach simpliﬁes the development of deterministic embedded systems by code generation from UML models.",
    "keywords": [
      "Activity",
      "state machine",
      "deterministic behavior."
    ]
  },
  {
    "title": "Automated Encapsulation of UML Activities for Incremental Development and Veriﬁcation",
    "date": 2009,
    "abstract": "With their revision in the UML 2.x standard, activities have been extended with streaming parameters. This facilitates a reuse-orien- ted speciﬁcation style, in which dedicated functions can be contributed by self-contained activities as building blocks: Using streaming param- eters, activities can be composed together in a quite powerful manner, since streaming parameters may also pass information while activities are executing. However, to compose them correctly, we must know in which sequence an activity may emit or accept these streaming parame- ters. Therefore, we propose special UML state machines that specify the externally visible behavior of activities. Further, we develop an algorithm to construct these state machines automatically for an activity based on model checking. Using these behavioral contracts, activities can then be composed without looking at their internal details. Moreover, the con- tracts can be used during system veriﬁcation to reduce the complexity of the analysis.",
    "keywords": [
      "System Composition",
      "UML Activities",
      "UML State Machines",
      "UML Streaming Parameters",
      "Model Reuse",
      "Veriﬁcation."
    ]
  },
  {
    "title": "Using UML Statecharts with Knowledge Logic Guards⋆",
    "date": 2009,
    "abstract": "This paper describes an extension of UML statecharts, called K-statechart, suitable for the formal speciﬁcation, modeling, and runtime veriﬁcation of system behavior that depends on knowledge and belief in distributed multi-agent systems. With K-statecharts, statechart transi- tion guards allow the use of knowledge-logic formulae, a form of modal logic used for reasoning about multi-agent systems. We demonstrate the proposed formalism using an example of a multi-agent system that con- sists of three traﬃc-light controllers. We also describe a newly developed K-statechart code generator that is part of the StateRover Eclipse-IDE plug-in for statechart-based modeling and formal speciﬁcation.",
    "keywords": [
      "K-statechart",
      "knowledge-logic",
      "adaptive behavior",
      "formal speciﬁcation",
      "runtime veriﬁcation."
    ]
  },
  {
    "title": "A Modeling Language for Activity-Oriented Composition of Service-Oriented Software Systems",
    "date": 2009,
    "abstract": "The proliferation of smart spaces and emergence of new standards, such as Web Services, have paved the way for a new breed of software systems. Often the complete functional and QoS requirements of such software systems are not known a priori at design-time, and even if they are, they may change at run-time. Unfortunately, the majority of existing software engineering tech- niques rely heavily on human reasoning and manual intervention, making them inapplicable for automatic composition of such software systems at run-time. Moreover, these approaches are primarily intended to be used by technically knowledgeable software engineers, as opposed to domain users. In this paper, we present Service Activity Schemas (SAS), an activity-oriented language for modeling software system’s functional and QoS requirements. SAS targets ser- vice-oriented software systems, and relies on an ontology to provide domain experts with modeling constructs that are intuitively understood. SAS forms the centerpiece of a framework intended for user-driven composition and adapta- tion of service-oriented software systems in a pervasive setting. We provide a detailed description of SAS in the context of a case study and formally specify its structural and dynamic properties.",
    "keywords": [
      "Requirements Modeling",
      "Domain Specific Modeling Languages",
      "Model Driven Development",
      "Autonomic Computing",
      "Pervasive Systems."
    ]
  },
  {
    "title": "A Domain Specific Modeling Language Supporting Specification, Simulation and Execution of Dynamic Adaptive Systems*",
    "date": 2009,
    "abstract": "Constructing and executing distributed systems that can automati- cally adapt to the dynamic changes of the environment are highly complex tasks. Non-trivial challenges include provisioning of efficient design time and run time representations, system validation to ensure safe adaptation of interde- pendent components, and scalable solutions to cope with the possible combina- torial explosions of adaptive system artifacts such as configurations, variant dependencies and adaptation rules. These are all challenges where current ap- proaches offer only partial solutions. Furthermore, in current approaches the adaptation logic is typically specified at the code level, tightly coupled with the main system functionality, making it hard to control and maintain. This paper presents a domain specific modeling language (DSML) allowing specification of the adaptation logic at the model level, and separation of the adaptation logic from the main system functionality. It supports model-checking and design- time simulation for early validation of adaptation policies. The model level specifications are used to generate the adaptation logic. The DSML also pro- vides indirection mechanisms to cope with combinatorial explosions of adaptive system artifacts. The proposed approach has been implemented and validated through case studies.",
    "keywords": []
  },
  {
    "title": "Executable Domain Speciﬁc Language for Message-Based System Integration",
    "date": 2009,
    "abstract": "Heterogeneous IT-systems rarely rely on a common data for- mat and structure, so in order to integrate them, the corresponding data/message transformations must be developed. Transformations may also be required by the business logic. We present a platform-independent approach for message transformation speciﬁcation, in form of a system integration DSL, and discuss approaches for making it executable.",
    "keywords": [
      "System integration",
      "domain speciﬁc language",
      "model execu- tion."
    ]
  },
  {
    "title": "Architectural Mining: The Other Side of the MDD",
    "date": 2009,
    "abstract": "A back-of-the-envelope calculation suggests that - very, very conservatively - the world produces well over 33 billion lines of new or modiﬁed code every year. Curiously, the moment that code springs into being and is made manifest in a running system, it become legacy. The re- lentless accretion of code over months, years, even decades quickly turns every successful new project into a brownﬁeld one. Although software has no mass, it does have weight, weight that can ossify any system by creating intertia to change and deadly creeping complexity. It requires energy to make such a system simple, and to intentionally apply that en- ergy requires that one be able to reason about, understand, and visualize the system as built.",
    "keywords": []
  },
  {
    "title": "Generic Model Refactorings⋆",
    "date": 2009,
    "abstract": "Many modeling languages share some common concepts and principles. For example, Java, MOF, and UML share some aspects of the concepts of classes, methods, attributes, and inheritance. However, model transformations such as refactorings speciﬁed for a given language cannot be readily reused for another language because their related meta- models may be structurally diﬀerent. Our aim is to enable a ﬂexible reuse of model transformations across various metamodels. Thus, in this pa- per, we present an approach allowing the speciﬁcation of generic model transformations, in particular refactorings, so that they can be applied to diﬀerent metamodels. Our approach relies on two mechanisms: (1) an adaptation based mainly on the weaving of aspects; (2) the notion of model typing, an extension of object typing in the model-oriented con- text. We validated our approach by performing some experiments that consisted of specifying three well known refactorings (Encapsulate Field, Move Method, and Pull Up Method) and applying each of them onto three diﬀerent metamodels (Java, MOF, and UML).",
    "keywords": [
      "Adaptation",
      "Aspect Weaving",
      "Genericity",
      "Model Typing",
      "Refactoring."
    ]
  },
  {
    "title": "Constraining Type Parameters of UML 2 Templates with Substitutable Classiﬁers",
    "date": 2009,
    "abstract": "Generic programming is a ﬁeld of computer science which consists in deﬁning abstract and reusable representations of eﬃcient data structures and algorithms. In popular imperative languages, it is usually supported by a template-like notation, where generic elements are represented by templates exposing formal parameters. Deﬁning such generic artifacts may require deﬁning constraints on the actual types that can be provided in a particular substitution. UML 2 templates support two mechanisms for expressing such constraints. Unfortunately, the UML speciﬁcation provides very few details on their usage. The purpose of our article is to provide such details with regard to one of these constraining mechanisms (namely, \"substitutable constraining classiﬁers\") as well as modeling patterns inspired by practices from generic programming.",
    "keywords": []
  },
  {
    "title": "Generating Assertion Code from OCL:\nA Transformational Approach Based on\nSimilarities of Implementation Languages",
    "date": 2009,
    "abstract": "The Object Constraint Language (OCL) carries a platform independent characteristic allowing it to be decoupled from implementa- tion details, and therefore it is widely applied in model transformations used by model-driven development techniques. However, OCL can be found tremendously useful in the implementation phase aiding assertion code generation and allowing system veriﬁcation. Yet, taking full advan- tage of OCL without destroying its platform independence is a diﬃcult task. This paper proposes an approach for generating assertion code from OCL constraints by using a model transformation technique to abstract language speciﬁc details away from OCL high-level concepts, showing wide applicability of model transformation techniques. We take advan- tage of structural similarities of implementation languages to describe a rewriting framework, which is used to easily and ﬂexibly reformulate OCL constraints into any target language, making them executable on any platform. A tool is implemented to demonstrate the eﬀectiveness of this approach.",
    "keywords": [
      "OCL",
      "constraints",
      "assertion code",
      "programming languages."
    ]
  },
  {
    "title": "OCLLib, OCLUnit, OCLDoc: Pragmatic\nExtensions for the Object Constraint Language⋆",
    "date": 2009,
    "abstract": "The usage of the Uniﬁed Modeling Language in the indus- trial context becomes increasingly popular. There is an agreement in academia that the Object Constraint Language (OCL) is suitable for deﬁning model constraints and queries. However, it has not yet been broadly adopted by practitioners because they ﬁnd it diﬃcult to deﬁne OCL expressions. Thus, simpliﬁcation is desirable to increase the use of OCL in practice. We propose OCL libraries (OCLLib), which simplify the development of OCL expressions and enable a high reuse factor, are conﬁgurable, testable (OCLUnit) and documented (OCLDoc). In this paper we present the underlying concepts related to OCL library devel- opment we used in UML speciﬁc and domain speciﬁc projects conducted in academic and industrial contexts, respectively.",
    "keywords": [
      "Systematic development of OCL",
      "OCL libraries",
      "OCL test- ing",
      "OCL documentation."
    ]
  },
  {
    "title": "Variability within\nModeling Language Deﬁnitions",
    "date": 2009,
    "abstract": "We present a taxonomy of the variability mechanisms of- fered by modeling languages. The deﬁnition of a formal language en- compasses a syntax and a semantic domain as well as the mapping that relates them, thus language variabilities are classiﬁed according to which of those three pillars they address. This work furthermore proposes a framework to explicitly document and manage the variation points and their corresponding variants of a variable modeling language. The frame- work enables the systematic study of various kinds of variabilities and their interdependencies. Moreover, it allows a methodical customization of a language, for example, to a given application domain. The taxon- omy of variability is explicitly of interest for the UML to provide a more precise understanding of its variation points.",
    "keywords": [
      "Modeling languages",
      "variability",
      "formal semantics",
      "UML."
    ]
  },
  {
    "title": "Variability Modelling throughout the Product Line Lifecycle*",
    "date": 2009,
    "abstract": "This paper summarizes our experience with introducing feature mod- elling into several product lines within Siemens. Feature models are used for solving various tasks in the product line lifecycle, starting with scoping the re- usable asset base up to support for actual product configuration. Using feature models as primary artefacts for managing variability early in the lifecycle, we could improve the efficiency and transparency of scoping activities considera- bly and made the development efforts way easier to schedule. On the other end of the lifecycle, feature models lowered the engineering efforts in solution busi- ness in supporting product configuration and instantiation.",
    "keywords": []
  },
  {
    "title": "Weaving Variability into Domain Metamodels⋆",
    "date": 2009,
    "abstract": "Domain-Speciﬁc Modeling Languages (DSMLs) describe the concepts of a particular domain and their relationships, in a metamodel. From a given DSML, it is possible to describe a wide range of diﬀer- ent models. These models often share a common base and vary on some parts. Current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a signiﬁcant overhead in product line engineering of DSMLs. We propose to consider variability as an independent aspect to be woven into the DSML to introduce variability capabilities. In partic- ular we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variabil- ity into two very diﬀerent metamodels: Ecore and SmartAdapter, our Aspect-Oriented modeling weaver, thus adding ﬂexibility in the weaving process itself. These results emphasize how new abilities of the language can be provided by this means.",
    "keywords": []
  },
  {
    "title": "Automatic Domain Model Migration to Manage Metamodel Evolution",
    "date": 2009,
    "abstract": "Metamodel evolution is a signiﬁcant problem in domain spe- ciﬁc software development for several reasons. Domain-speciﬁc modeling languages (DSMLs) are likely to evolve much more frequently than pro- gramming languages and commonly used software formalisms, often re- sulting in a large number of valuable instance models that are no longer compliant with the metamodel. In this paper, we present the Model Change Language (MCL), aimed at satisfying these requirements.",
    "keywords": []
  },
  {
    "title": "Model Transformation by Demonstration",
    "date": 2009,
    "abstract": "Model transformations provide a powerful capability to automate model refinements. However, the use of model transformation languages may present challenges to those who are unfamiliar with a specific transformation language. This paper presents an approach called model transformation by demonstration (MTBD), which allows an end-user to demonstrate the exact transformation desired by actually editing a source model and demonstrating the changes that evolve to a target model. An inference engine built into the un- derlying modeling tool records all editing operations and infers a transformation pattern, which can be reused in other models. The paper motivates the need for the approach and discusses the technical contributions of MTBD. A case study with several sample inferred transformations serves as a concrete example of the benefits of MTBD.",
    "keywords": [
      "Model transformation",
      "Program inference",
      "Refactoring."
    ]
  },
  {
    "title": "Reviving QVT Relations: Model-Based Debugging Using Colored Petri Nets⋆",
    "date": 2009,
    "abstract": "The standardized QVT Relations language, one cornerstone of Model-Driven Architecture (MDA), has not yet gained widespread use in practice, not least due to missing tool support in general and inadequate debugging support in particular. Transformation engines in- terpreting QVT Relations operate on a low level of abstraction, hide the operational semantics of a transformation and scatter metamodels, models, QVT code, and traces across diﬀerent artifacts. We propose a model-based debugger representing QVT Relations on bases of TROPIC, a model transformation framework which utilizes a variant of Colored Petri Nets (CPNs) providing an explicit runtime model and a homoge- nous view on all artifacts of a transformation.",
    "keywords": [
      "QVT Relations",
      "Debugging",
      "Model Transformations",
      "CPN."
    ]
  },
  {
    "title": "Incremental Development of Model Transformation Chains Using Automated Testing⋆",
    "date": 2009,
    "abstract": "Model transformations are a key technique in model-driven engi- neering. If several transformations are composed into a model transformation chain, an approach is needed that allows software engineers to incrementally improve the quality of the model transformation chain. In this paper, we propose incremental development of model transformation chains based on automated testing. We present four test design techniques and a test framework architecture for testing transformation chains and report on the validation of our approach when developing a transformation chain for model version management.",
    "keywords": [
      "Model transformation",
      "automated testing."
    ]
  },
  {
    "title": "Test-Driven Development of Model Transformations⋆",
    "date": 2009,
    "abstract": "Model transformations enable the automated development paradigm proposed by Model Driven Engineering. However, since the requirements for building a model transformation are usually expressed informally, requirements descriptions are diﬃcult to keep updated and synchronized with their corresponding implementations. Therefore, hu- man eﬀort is usually required for validating model transformations. The present work deﬁnes a test-driven method for the development process of model-to-model transformations. This method is focused on the capture of requirements for transformations in such a way that guides the devel- opment and the documentation of model transformations. Requirements are expressed by means of test cases that can be automatically validated. The proposal has been applied to the MOSKitt open source CASE tool in an industrial scenario.",
    "keywords": [
      "Model-to-model transformations",
      "test-driven development."
    ]
  },
  {
    "title": "A Uniﬁed Approach to Modeling and Programming",
    "date": 2010,
    "abstract": "SIMULA was a language for modeling and programming and provided a uniﬁed approach to modeling and programming in contrast to methodologies based on structured analysis and design. The current development seems to be going in the direction of separation of modeling and programming. The goal of this paper is to go back to the future and get inspiration from SIMULA and propose a uniﬁed approach. In addi- tion to reintroducing the contributions of SIMULA and the Scandina- vian approach to object-oriented programming, we do this by discussing a number of issues in modeling and programming and argue1 why we consider a uniﬁed approach to be an advantage.",
    "keywords": []
  },
  {
    "title": "Generic Meta-modelling with Concepts,\nTemplates and Mixin Layers",
    "date": 2010,
    "abstract": "Meta-modelling is a key technique in Model Driven Engi- neering, where it is used for language engineering and domain modelling. However, mainstream approaches like the OMG’s Meta-Object Facility provide little support for abstraction, modularity, reusability and ex- tendibility of (meta-)models, behaviours and transformations. In order to alleviate this weakness, we bring three elements of generic programming into meta-modelling: concepts, templates and mixin layers. Concepts permit an additional typing for models, enabling the deﬁni- tion of behaviours and transformations independently of meta-models, making speciﬁcations reusable. Templates use concepts to express re- quirements on their generic parameters, and are applicable to models and meta-models. Finally, we deﬁne functional layers by means of meta- model mixins which can extend other meta-models. As a proof of concept we also report on MetaDepth, a multi-level meta-modelling framework that implements these ideas.",
    "keywords": []
  },
  {
    "title": "An Observer-Based Notion of Model Inheritance",
    "date": 2010,
    "abstract": "A model-based engineering discipline presupposes that models are or- ganised by creating relationships between them. While there has been consider- able work on understanding what it means to instantiate one model from another, little is known about when a model should be considered to be a specialisation of another one. This paper motivates and discusses ways of deﬁning specialisa- tion relationships between models, languages, and transformations respectively. Several alternatives of deﬁning a specialisation relationship are considered and discussed. The paper’s main contribution is the introduction of the notions of an observer and a context in order to deﬁne and validate specialisation relationships. The ideas and discussions presented in this paper are meant to provide a stepping stone towards a systematic basis for organising models.",
    "keywords": [
      "model inheritance",
      "model compatibility",
      "language engineering",
      "model evolution."
    ]
  },
  {
    "title": "MDE-Based Approach for Generalizing Design Space Exploration",
    "date": 2010,
    "abstract": "Design Space Exploration (DSE) is the exploration of de- sign alternatives before the implementation. Existing DSE frameworks are domain-speciﬁc where the representation, evaluation method as well as exploration algorithm are tightly coupled with domain-dependent as- sumptions. Although the tasks involved in DSE are similar, the inﬂex- ibility of the existing frameworks restricts their reuse for solving DSE problems from other domains.",
    "keywords": []
  },
  {
    "title": "A Comparison of Model Migration Tools",
    "date": 2010,
    "abstract": "Modelling languages and thus their metamodels are sub- ject to change. When a metamodel evolves, existing models may no longer conform to the evolved metamodel. To avoid rebuilding them from scratch, existing models must be migrated to conform to the evolved metamodel. Manually migrating existing models is tedious and error- prone. To alleviate this, several tools have been proposed to build a mi- gration strategy that automates the migration of existing models. Little is known about the advantages and disadvantages of the tools in diﬀer- ent situations. In this paper, we thus compare a representative sample of migration tools – AML, COPE, Ecore2Ecore and Epsilon Flock – using common migration examples. The criteria used in the comparison aim to support users in selecting the most appropriate tool for their situation.",
    "keywords": []
  },
  {
    "title": "Incremental Evaluation of Model Queries over EMF Models⋆",
    "date": 2010,
    "abstract": "Model-driven development tools built on industry standard platforms, such as the Eclipse Modeling Framework (EMF), heavily utilize model queries in model transformation, well-formedness constraint validation and domain-speciﬁc model execution. As these queries are executed rather frequently in interactive modeling applications, they have a signiﬁcant impact on runtime performance and end user experience. However, due to their complexity, these queries can be time consuming to implement and optimize on a case-by-case basis. Conse- quently, there is a need for a model query framework that combines an easy-to-use and concise declarative query formalism with high runtime performance.",
    "keywords": []
  },
  {
    "title": "Active Operations on Collections",
    "date": 2010,
    "abstract": "Collections are omnipresent within models: collections of ref- erences can represent relations between objects, and collections of values can represent object attributes. Consequently, manipulating models often consists of performing operations on collections. For example, transfor- mations create target collections from given source collections. Similarly, constraint evaluations perform computation on collections. Recent re- search works focus on making such transformations or constraint evalu- ations active (i.e. incremental, or live). However, they propose their own solutions to the issue by the introduction of speciﬁc languages and/or systems. This paper proposes a mathematical formalism, centered on collections and independent of languages and systems, that describes how the implementation of standard operations on collections can be made active. The formalism also introduces a reversed active assignment dedicated to bidirectional operations. A case study illustrates how to use the formalism and its Active Kermeta implementation for creating an active transformation.",
    "keywords": []
  },
  {
    "title": "transML: A Family of Languages to Model\nModel Transformations",
    "date": 2010,
    "abstract": "Model transformation is one of the pillars of Model-Driven Engineering (MDE). The increasing complexity of systems and modelling languages has dramatically raised the complexity and size of model trans- formations. Even though many transformation languages and tools have been proposed in the last few years, most of them are directed to the implementation phase of transformation development. However, there is a lack of cohesive support for the other phases of the transformation development, like requirements, analysis, design and testing. In this paper, we propose a uniﬁed family of languages to cover the life-cycle of transformation development. Moreover, following an MDE approach, we provide tools to partially automate the progressive reﬁne- ment of models between the diﬀerent phases and the generation of code for speciﬁc transformation implementation languages.",
    "keywords": []
  },
  {
    "title": "Henshin: Advanced Concepts and Tools for In-Place EMF Model Transformations",
    "date": 2010,
    "abstract": "The Eclipse Modeling Framework (EMF) provides model- ing and code generation facilities for Java applications based on struc- tured data models. Henshin is a new language and associated tool set for in-place transformations of EMF models. The Henshin transforma- tion language uses pattern-based rules on the lowest level, which can be structured into nested transformation units with well-deﬁned operational semantics. So-called amalgamation units are a special type of transfor- mation units that provide a forall-operator for pattern replacement. For all of these concepts, Henshin oﬀers a visual syntax, sophisticated editing functionalities, execution and analysis tools. The Henshin transformation language has its roots in attributed graph transformations, which oﬀer a formal foundation for validation of EMF model transformations. The transformation concepts are demonstrated using two case studies: EMF model refactoring and meta-model evolution.",
    "keywords": []
  },
  {
    "title": "A Technique for Automatic Validation of Model Transformations",
    "date": 2010,
    "abstract": "We present in this paper a technique for proving properties about model transformations. The properties we are concerned about relate the structure of an input model with the structure of the trans- formed model. The main highlight of our approach is that we are able to prove the properties for all models, i.e. the transformation designer may be certain about the structural soundness of the results of his/her transformations. In order to achieve this we have designed and experi- mented with a transformation model checker, which builds what we call a state space for a transformation. That state space is then used as in classical model checking to prove the property or, in case the property does not hold to produce a counterexample. If the property holds this information can be used as a certiﬁcation for the transformation, other- wise the counterexample can be used as debug information during the transformation design process.",
    "keywords": []
  },
  {
    "title": "Static- and Dynamic Consistency Analysis of\nUML State Chart Models",
    "date": 2010,
    "abstract": "UML state chart models describing the behavior of a system can be used as a formal speciﬁcation thereof. The existence of advanced modeling tools allows for model simulation and enables the execution of manually created tests on the models. In this work the usage of static and dynamic model analysis techniques is proposed to reveal errors in these models. The static analysis focuses on the syntax, communication structure and non-determinism. The dynamic analysis is based on a ran- dom test approach and can reveal bugs like deadlocks and inter-model loops. Further the data generated during the dynamic analysis allows for additional correctness checks such as e.g. the number or lengths of paths. The presented approach is implemented in a prototype and revealed sev- eral bugs in an industrial case study not found during simulation and manual model testing.",
    "keywords": []
  },
  {
    "title": "Verifying Semantic Conformance of State Machine-to-Java Code Generators",
    "date": 2010,
    "abstract": "When applying model-driven engineering to safety-critical systems, the correctness of model transformations is crucial. In this pa- per, we investigate a novel approach to verifying the conformance to source language semantics of model-to-code transformations that uses annotations in the generated code. These annotations are inserted by the transformation and are used to guide a model checker to verify that the generated code satisﬁes the semantics of the source language – UML state machines in this paper. Verifying the generated output in this way is more eﬃcient than formally verifying the transformation’s deﬁnition. The veriﬁcation is performed using Java Pathﬁnder (JPF) [1], a model checker for Java source code. The approach has been applied to verify three UML state machine to Java code generators: one developed by us and two commercial generators (Rhapsody and Visual Paradigm). We were able to detect non-conformance in both commercial tools, which failed some semantic properties extracted from the UML speciﬁcation.",
    "keywords": []
  },
  {
    "title": "A Dynamic-Priority Based Approach to Fixing Inconsistent Feature Models",
    "date": 2010,
    "abstract": "In feature models’ construction, one basic task is to ensure the consistency of feature models, which often involves detecting and ﬁxing of inconsistencies in feature models. Several approaches have been proposed to detect inconsistencies, but few focus on the problem of ﬁxing inconsistent feature models. In this paper, we propose a dynamic-priority based approach to ﬁxing inconsistent feature models, with the purpose of helping domain analysts ﬁnd solutions to inconsistencies eﬃciently. The basic idea of our approach is to ﬁrst recommend a solution auto- matically, then gradually reach the desirable solution by dynamically adjusting priorities of constraints. To this end, we adopt the constraint hierarchy theory to express the degree of domain analysts’ conﬁdence on constraints (i.e. the priorities of constraints) and resolve inconsistencies among constraints. Two case studies have been conducted to demon- strate the usability and scalability of our approach.",
    "keywords": [
      "Feature Model",
      "Priority",
      "Inconsistency Fixing."
    ]
  },
  {
    "title": "Taming Graphical Modeling",
    "date": 2010,
    "abstract": "Visual models help to understand complex systems. How- ever, with the user interaction paradigms established today, activities such as creating, maintaining or browsing visual models can be very te- dious. Valuable engineering time is wasted with archaic activities such as manual placement and routing of nodes and edges. This paper presents an approach to enhance productivity by focusing on the pragmatics of model-based design. Our contribution is twofold: First, the concept of meta layout enables the synthesis of diﬀerent diagrammatic views on graphical models. This modularly employs sophisticated layout algorithms, closing the gap be- tween MDE and graph drawing theory. Second, a view management logic harnesses this auto-layout to present customized views on models. These concepts have been implemented in the open source Kiel In- tegrated Environment for Layout Eclipse Rich Client (KIELER). Two applications—editing and simulation—illustrate how view management helps to increase developer productivity and tame model complexity.",
    "keywords": []
  },
  {
    "title": "Taming EMF and GMF\nUsing Model Transformation",
    "date": 2010,
    "abstract": "EMF and GMF are powerful frameworks for implementing tool support for modelling languages in Eclipse. However, with power comes complexity; implementing a graphical editor for a modelling lan- guage using EMF and GMF requires developers to hand craft and main- tain several low-level interconnected models through a loosely-guided, labour-intensive and error-prone process. In this paper we demonstrate how the application of model transformation techniques can help with taming the complexity of GMF and EMF and deliver signiﬁcant produc- tivity, quality, and maintainability beneﬁts. We also present EuGENia, an open-source tool that implements the proposed approach, illustrate its functionality through an example, and report on the community’s response to the tool.",
    "keywords": []
  },
  {
    "title": "A Visual Traceability Modeling Language",
    "date": 2010,
    "abstract": "Software traceability is eﬀort intensive and must be applied strategically in order to maximize its beneﬁts and justify its costs. Unfor- tunately, development tools provide only limited support for traceability, and as a result users often construct trace queries using generic query languages which require intensive knowledge of the data-structures in which artifacts are stored. In this paper, we propose a usage-centered traceability process that utilizes UML class diagrams to deﬁne trace- ability strategies for a project and then visually represents trace queries as constraints upon subsets of the model. The Visual Trace Modeling Language (VTML) allows users to model queries while hiding the un- derlying technical details and data structures. The approach has been demonstrated through a prototype system and and evaluated through a preliminary experiment to evaluate the expressiveness and readability of VTML in comparison to generic SQL queries.",
    "keywords": []
  },
  {
    "title": "Application Logic Patterns – Reusable Elements\nof User-System Interaction",
    "date": 2010,
    "abstract": "Patterns of various kind are commonly used to reduce costs and improve quality in software development. This paper introduces the concept of patterns at the level of detailed descriptions of the user-system dialogue. Application Logic Patterns deﬁne generalised sequences of in- teractions performed by the system and its users in the context of an ab- stract problem domain. The patterns are organised into a library. They are precisely described by a language which is deﬁned through a strict meta-model. It extends the notation and semantics of the UML activ- ities and use cases. Each of the patterns describing the visible system dynamics is linked to an abstract domain model central to all the pat- terns. The patterns can be easily instantiated by substituting abstract domain notions with the notions speciﬁc to a given domain. This ease of use and reduction in eﬀort is validated in a controlled experiment using an open-source tool.",
    "keywords": []
  },
  {
    "title": "A Metamodel-Based Approach for Automatic User \nInterface Generation",
    "date": 2010,
    "abstract": "One of the advantages of following a MDA-based approach in the development of interactive applications is the possibility of generating multiple platform-specific user interfaces (UI) from the same platform independent UI model. However, the effort required to create the UI model may be significant. In the case of data-intensive applications, a large part of the UI structure and functionality is closely related with the structure and functionality of the do- main entities described in the domain model, and the access rules specified in the use case model. This paper presents an approach to reduce the effort re- quired to create platform independent UI models for data intensive applications, by automatically generating an initial UI model from domain and use case models. For that purpose, UML-aligned metamodels for domain and use case models are defined, together with a MOF-based metamodel for user interface models. The transformation rules that drive the UI model generation are intro- duced. It is also proposed a MDA-based process for the development of data in- tensive interactive applications based on the proposed model architecture and transformations.",
    "keywords": [
      "MDD",
      "MDA",
      "Metamodel",
      "User Interface Automatic Generation",
      "Model Transformation."
    ]
  },
  {
    "title": "Rapid UI Development for Enterprise\nApplications: Combining Manual and\nModel-Driven Techniques",
    "date": 2010,
    "abstract": "UI development for enterprise applications is a time-consum- ing and error-prone task. In fact, approximately 50% of development resources are devoted to UI implementation tasks [1]. Model-driven UI development aims to reduce this eﬀort. However, the quality of the ﬁnal layout is a problem of this approach, especially when dealing with large and complex domain models. We share our experience in successfully using model-driven UI development in a large-scale enterprise project. Our approach mitigates the problems of model-driven UI development by combining manual layout with automatic inference of UI elements from a given domain model. Furthermore, we provide means to inﬂuence the UI generation at design time and to customize the UI at runtime. Thus, our approach signiﬁcantly reduces the UI implementation eﬀort while retaining control of the resulting UI.",
    "keywords": [
      "Model-Driven UI Development",
      "UI Generation",
      "UI Cus- tomisation."
    ]
  },
  {
    "title": "Environment Modeling with UML/MARTE to Support \nBlack-Box System Testing for Real-Time Embedded \nSystems: Methodology and Industrial Case Studies",
    "date": 2010,
    "abstract": "The behavior of real-time embedded systems (RTES) is driven by their environment. Independent system test teams normally focus on black-box testing as they have typically no easy access to precise design information. Black-box testing in this context is mostly about selecting test scenarios that are more likely to lead to unsafe situations in the environment. Our Model-Based Testing (MBT) methodology explicitly models key properties of the environ- ment, its interactions with the RTES, and potentially unsafe situations triggered by failures of the RTES under test. Though environment modeling is not new, we propose a precise methodology fitting our specific purpose, based on a lan- guage that is familiar to software testers, that is the UML and its extensions, as opposed to technologies geared towards simulating natural phenomena. Fur- thermore, in our context, simulation should only be concerned with what is visible to the RTES under test. Our methodology, focused on black-box MBT, was assessed on two industrial case studies. We show how the models are used to fully automate black-box testing using search-based test case generation techniques and the generation of code simulating the environment.",
    "keywords": []
  },
  {
    "title": "Improving Test Models for Large Scale Industrial \nSystems: An Inquisitive Study",
    "date": 2010,
    "abstract": "Although documentation of software tests is becoming increasingly important, there is little knowledge on whether modeling languages and tools are effective in industrial projects. Recent reports have pointed out that test modeling techniques might be barely used by software developers due to their inability to cover test concepts relevant in real-life large applications. This pa- per reports an inquisitive multi-phase study aimed at revealing test-relevant concepts not supported by modeling languages. The study encompassed several questionnaire responses and interviews with developers, and observational analyses run over two years in large-scale software projects. Various test con- cepts were brought forth and they fall in three categories: (i) test cases and software evolution, (ii) interdependencies between test cases, and (iii) categori- zation and grouping of test cases. Finally, the relevance of the identified test concepts is discussed in terms of an industrial system for inventory and supply control of petroleum products.",
    "keywords": [
      "Modeling",
      "Software Testing",
      "Industrial Applications."
    ]
  },
  {
    "title": "Automatically Discovering Properties That\nSpecify the Latent Behavior of UML Models⋆,⋆⋆",
    "date": 2010,
    "abstract": "Formal analysis can be used to verify that a model of the system adheres to its requirements. As such, traditional formal analysis focuses on whether known (desired) system properties are satisﬁed. In contrast, this paper proposes an automated approach to generating tem- poral logic properties that specify the latent behavior of existing UML models; these are unknown properties exhibited by the system that may or may not be desirable. A key component of our approach is Marple, a evolutionary-computation tool that leverages natural selection to dis- cover a set of properties that cover diﬀerent regions of the model state space. The Marple-discovered properties can be used to reﬁne the mod- els to either remove unwanted behavior or to explicitly document a desir- able property as required system behavior. We use Marple to discover unwanted latent behavior in two applications: an autonomous robot nav- igation system and an automotive door locking control system obtained from one of our industrial collaborators.",
    "keywords": []
  },
  {
    "title": "Towards a Semantics of Activity Diagrams with\nSemantic Variation Points",
    "date": 2010,
    "abstract": "UML activity diagrams have become an established nota- tion to model control and data ﬂow on various levels of abstraction, ranging from ﬁne-grained descriptions of algorithms to high-level work- ﬂow models in business applications. A formal semantics has to capture the ﬂexibility of the interpretation of activity diagrams in real systems, which makes it inappropriate to deﬁne a ﬁxed formal semantics. In this paper, we deﬁne a semantics with semantic variation points that allow for a customizable, application-speciﬁc interpretation of activity diagrams. We examine concrete variants of the activity diagram semantics which may also entail variants of the syntax reﬂecting the intended use at hand.",
    "keywords": []
  },
  {
    "title": "An AADL-Based Approach to Variability Modeling of\nAutomotive Control Systems",
    "date": 2010,
    "abstract": "While the complexity of automotive systems is increasing, nowadays, most of the newly developed functionalities are implemented by software. This implies that software plays an important role in the development of automotive systems. However, several ineﬃciency problems related to software remain un- resolved. One problem is to ﬁnd an eﬀective way to handle a large-scale varia- tion of automotive systems. Hence, this paper presents an AADL (Architecture Analysis & Design Language)-based approach to the variation-related problem. The proposed approach captures the variation of automotive systems and yields their variability models. The obtained models promote an eﬃcient development that exploits system variation. In this paper, we explain the detailed procedure of AADL-based development with the help of an example of development of cruise control systems.",
    "keywords": [
      "ADL",
      "architecture description language",
      "AADL",
      "architecture analy- sis & design language",
      "variability modeling",
      "automotive electronics systems."
    ]
  },
  {
    "title": "Extending Variability for OCL Interpretation",
    "date": 2010,
    "abstract": "In recent years, OCL advanced from a language used to con- strain UML models to a constraint language that is applied to various modelling languages. This includes Domain Speciﬁc Languages (DSLs) and meta-modelling languages like MOF or Ecore. Consequently, it is rather common to provide variability for OCL parsers to work with dif- ferent modelling languages. A second variability dimension relates to the technical space that models are realised in. Current OCL interpreters do not support such variability as their implementation is typically bound to a speciﬁc technical space like Java, Ecore, or a speciﬁc model reposi- tory. In this paper we propose a generic adaptation architecture for OCL that hides models and model instances behind well-deﬁned interfaces. We present how the implementation of such an architecture for DresdenOCL enables reuse of the same OCL interpreter for various technical spaces and evaluate our approach in three case studies.",
    "keywords": [
      "OCL",
      "OCL Infrastructure",
      "OCL Tool",
      "MDSD",
      "Modelling",
      "Constraint Interpretation",
      "Technological Spaces",
      "Variability",
      "Adaptation."
    ]
  },
  {
    "title": "Inter-modelling: From Theory to Practice",
    "date": 2010,
    "abstract": "We deﬁne inter-modelling as the activity of building models that describe how modelling languages should be related. This includes many common activities in Model Driven Engineering, like the speciﬁca- tion of model-to-model transformations, the deﬁnition of model match- ing and model traceability constraints, the development of inter-model consistency maintainers and exogenous model management operators. Recently, we proposed a formal approach to specify the allowed and forbidden relations between two modelling languages by means of bidi- rectional declarative patterns. Such speciﬁcations were used to generate graph rewriting rules able to enforce the relations in (forward and back- ward) model-to-model transformation scenarios. In this paper we extend the usage of patterns for two further inter-modelling scenarios – model matching and model traceability – and report on an EMF-based tool im- plementing them. The tool allows a high-level analysis of speciﬁcations based on the theory developed so far, as well as manipulation of traces by compilation of patterns into the Epsilon Object Language.",
    "keywords": []
  },
  {
    "title": "Consistent Modeling Using Multiple UML Profiles",
    "date": 2010,
    "abstract": "The design of complex technical system invariably involves multiple domain-specific languages to cover the many different facets of such systems. However, unless the languages are designed to be used in combination, this typically leads to conflicting specifications that are difficult to reconcile due to the ontological and other differences between the languages used. In this paper, we describe a pragmatic but systematic approach to resolving this problem for the special but common case in which the domain-specific languages are all defined as UML profiles.",
    "keywords": []
  },
  {
    "title": "A Systematic Review on the Deﬁnition of UML Proﬁles⋆",
    "date": 2010,
    "abstract": "This article reports a systematic review on the deﬁnition of UML proﬁles in the research literature. Several exploratory statis- tical analyses have been performed in order to characterise both the idiosyncrasy of UML proﬁles and how they are reported in the litera- ture. This study uncovers the diﬀerences between presentation styles for behavioural and structural domains, and shows how UML proﬁles based on Class, Association, and Property structural metaclasses clearly out- number any other kind. Also, this review reveals how half of the examined UML proﬁles merely extend the abstract syntax, without adding neither icons nor constraints. The main contribution of this study is therefore a clear picture of the state-of-the-art in UML proﬁling, together with a set of open questions regarding its future.",
    "keywords": [
      "UML",
      "modelling",
      "proﬁles",
      "review."
    ]
  },
  {
    "title": "The Value in Muddling Around Modelling",
    "date": 2011,
    "abstract": "Software is a designed artifact. In other design disciplines, such as building architecture, there is a well-established tradition of design studies which inform not only the discipline itself but also tool design, processes, and collaborative work. This talk considers software from such a 'design studies' perspective. The talk will present a series of observations from empirical studies of expert software designers, and will draw on examples from actual professional practice. It will consider what experts’ mental imagery, software visualisations, and sketches suggest about software design thinking. It will discuss which representations designers use when allowed to choose freely, how designers’ informal representations relate to the formal representations from their discipline, how the character of their informal representations facilitates design discussions, and why many of the functions afforded by their sketching are not well supported by existing CAD systems. It will consider what the observations and sketches reveal about requirements for an idea-capture tool that supports collaborative design. The talk will also discuss some of the deliberate practices experts use to promote innovation. Finally, it will open discussion on the tensions between observed software design practices and received methodology in software engineering.",
    "keywords": [
      "empirical studies",
      "expert design",
      "software design",
      "flexible modeling",
      "software engineering practice."
    ]
  },
  {
    "title": "Towards Quality Driven Exploration of Model Transformation Spaces⋆",
    "date": 2011,
    "abstract": "Verifying that a software system has certain non-functional properties is a primary concern in many engineering ﬁelds. Although several model-driven approaches exist to predict quality attributes from system models, they still lack the proper level of automation envisioned by Model Driven Software Development. When a potential issue con- cerning non-functional properties is discovered, the identiﬁcation of a solution is still entirely up to the engineer and to his/her experience. This paper presents QVT-Rational, our multi-modeling solution to auto- mate the detection-solution loop. We leverage and extend existing model transformation techniques with constructs to elicit the space of the al- ternative solutions and to bind quality properties to them. Our frame- work is highly customizable, it supports the deﬁnition of non-functional requirements and provides an engine to automatically explore the solu- tion space. We evaluate our approach by applying it to two well-known software engineering problems — Object-Relational Mapping and com- ponents allocation — and by showing how several solutions that satisfy given performance requirements can be automatically identiﬁed.",
    "keywords": [
      "Feedback Provisioning",
      "Model Transformations."
    ]
  },
  {
    "title": "Automated Model-to-Metamodel Transformations Based on the Concepts of Deep Instantiation",
    "date": 2011,
    "abstract": "Numerous systems, especially component-based systems, are based on a multi-phase development process where an ontological hierar- chy is established. Solutions based on modeling / metamodeling can be used for such systems, but all of them are aﬄicted with diﬀerent draw- backs. The main problem is that elements representing both CLAsses and oBJECTs (clabjects), which are needed to specify an ontological hi- erarchy, are not supported by standard metamodeling frameworks. This paper presents the combination of two approaches, namely deep instanti- ation and model-to-metamodel transformations. The resulting approach combines the clean and compact speciﬁcation of deep instantiation with the easy applicability of model-to-metamodel transformations in an au- tomated way. Along with this a set of generic operators to specify these transformations is identiﬁed.",
    "keywords": [
      "Model-to-Metamodel (M2MM)",
      "Model-to-Model (M2M)",
      "Model Transformation",
      "Deep Instantiation",
      "Transformation Operator",
      "Clabject",
      "Model-Driven Software Development (MDSD)."
    ]
  },
  {
    "title": "Lazy Execution of Model-to-Model Transformations",
    "date": 2011,
    "abstract": "The increasing adoption of Model-Driven Engineering in in- dustrial contexts highlights scalability as a critical limitation of several MDE tools. Most of the current model-to-model transformation engines have been designed for one-shot translation of input models to output models, and present eﬃciency issues when applied to very large models. In this paper, we study the application of a lazy-evaluation approach to model transformations. We present a lazy execution algorithm for ATL, and we empirically evaluate a prototype implementation. With it, the elements of the target model are generated only when (and if) they are accessed, enabling also transformations that generate inﬁnite target models. We achieve our goal on a signiﬁcant subset of ATL by extending the ATL compiler.",
    "keywords": []
  },
  {
    "title": "Measuring UML Models Using Metrics\nDeﬁned in OCL within the SQUAM Framework",
    "date": 2011,
    "abstract": "In software engineering practice, measurements may reduce development costs by improving processes and products at early stages. In model driven approaches, measurements can be conducted right from the start of a project. For UML models, a collection of metrics has been empirically validated, however, these need to be precisely deﬁned in or- der to be useful. Deﬁnition of UML metrics in OCL oﬀers a high degree of precision and portability, but due to shortcomings of this language this approach is not widespread. We propose the SQUAM framework, a tool– supported methodology to develop OCL speciﬁcations, which incorpo- rates best practices in software development, such as libraries, testing and documentation. As a proof of concept we have developed 26 metrics for UML class diagrams in the academic context. This demonstrated the high eﬀectiveness of our approach: quick learning, high satisfaction of develop- ers, low imposed complexity and potential time reduction through reuse.",
    "keywords": [
      "model analysis",
      "UML metrics",
      "OCL speciﬁcation",
      "OCL pragmatic extensions",
      "OCL development process."
    ]
  },
  {
    "title": "Modeling Model Slicers⋆",
    "date": 2011,
    "abstract": "Among model comprehension tools, model slicers are tools that ex- tract a subset from a model, for a speciﬁc purpose. Model slicers are tools that let modelers rapidly gather relevant knowledge from large models. However, exist- ing slicers are dedicated to one modeling language. This is an issue when we ob- serve that new domain speciﬁc modeling languages (DSMLs), for which we want slicing abilities, are created almost on a daily basis. This paper proposes the Kom- pren language to model and generate model slicers for any DSL (e.g. software de- velopment and building architecture) and for different purposes (e.g. monitoring and model comprehension). Kompren’s abilities for model slicers construction is based on case studies from various domains.",
    "keywords": []
  },
  {
    "title": "Morsa: A Scalable Approach for Persisting and Accessing Large Models⋆",
    "date": 2011,
    "abstract": "Applying Model-Driven Engineering (MDE) in industrial- scale systems requires managing complex models which may be very large. These models must be persisted in a scalable way that allows their manipulation by client applications without fully loading them.",
    "keywords": []
  },
  {
    "title": "Expressing Aspectual Interactions in Design: Experiences in the Slot Machine Domain",
    "date": 2011,
    "abstract": "In the context of an industrial project we are implementing the software of a casino slot machine. This software has a signiﬁcant amount of cross-cutting concerns that depend on, and interact with each other, as well as with the modular concerns. We therefore wish to express our design using an appropriate Aspect-Oriented Modeling methodol- ogy and notation. We evaluated two of the most mature methodologies: Theme/UML and WEAVR, to establish their suitability. Remarkably, neither of these allow us to express any of the dependencies and inter- actions to our satisfaction. In both cases, half of the interaction types cannot be expressed at all while the other half need to be expressed using a workaround that hides the intention of the design. As a result, we consider both methodologies and notations unsuitable for expressing the dependencies and interactions present in the slot machine domain. In this paper we describe our evaluation experience.",
    "keywords": []
  },
  {
    "title": "An Industrial Application of Robustness Testing Using \nAspect-Oriented Modeling, UML/MARTE, and Search \nAlgorithms",
    "date": 2011,
    "abstract": "Systematic and rigorous robustness testing is very critical for embedded systems, as for example communication and control systems. Robustness testing aims at testing the behavior of a system in the presence of faulty situations in its operating environment (e.g., sensors and actuators). In such situations, the system should gracefully degrade its performance instead of abruptly stopping execution. To systematically perform robustness testing, one option is to resort to model-based robustness testing (MBRT), based for example on UML/MARTE models. However, to successfully apply MBRT in industrial contexts, new technology needs to be developed to scale to the complexity of real industrial systems. In this paper, we report on our experience of performing MBRT on video conferencing systems developed by Cisco Systems, Norway. We discuss how we developed and integrated various techniques and tools to achieve a fully automated MBRT that is able to detect previously uncaught software faults in those systems. We provide an overview of how we achieved scalable modeling of robustness behavior using aspect-oriented modeling, test case generation using search algorithms, and environment emulation for test case execution. Our experience and lessons learned identify challenges and open research questions for the industrial application of MBRT.",
    "keywords": [
      "Model-based testing",
      "aspect-oriented modeling",
      "search algorithms",
      "MARTE",
      "UML",
      "robustness."
    ]
  },
  {
    "title": "Aspect-Oriented Modelling\nfor Distributed Systems",
    "date": 2011,
    "abstract": "Aspect-Oriented Modelling techniques allow a modeller to describe within a single aspect model all model elements that deﬁne the structural and/or behavioural properties of a concern. When applied to a base model, the model weaver ensures that the entire aspect is reﬂected in the woven model. While this is essential for centralized systems, it is not the case when model elements of a concern are scattered over nodes in a distributed system. We propose an extension to our Reusable Aspect Models that allows the modeller to augment an aspect model of a concern that can crosscut the nodes of a distributed system with distribution role deﬁnitions. A distributed system conﬁguration ﬁle speciﬁes the diﬀerent node types of the distributed system, and which roles of a distributed as- pect are assigned to which nodes. The weaver makes sure that every role of a distributed aspect is assigned to at least one node in the system to ensure consistent aspect use. The weaver then generates for each node a ﬁnal application model that only contains the model elements pertaining to the distribution roles the node plays.",
    "keywords": []
  },
  {
    "title": "A Precise Style for Business Process Modelling:\nResults from Two Controlled Experiments",
    "date": 2011,
    "abstract": "We present a precise style for the modelling of business pro- cesses based on the UML activity diagrams and two controlled exper- iments to compare this style with a lighter variant. The comparison has been performed with respect to the comprehensibility of business processes and the eﬀort to comprehend them. The ﬁrst experiment has been conducted at the Free University of Bolzano-Bozen, while the sec- ond experiment (i.e., a diﬀerentiated replication) at the University of Genova. The participants to the ﬁrst experiment were Master students and so more experienced than the participants to the replication, who were Bachelor students. The results indicate that: (a) all the participants achieved a signiﬁcantly better comprehension level with the precise style; (b) the used style did not have any signiﬁcant impact on the eﬀort; and (c) more experienced participants beneﬁted more from the precise style.",
    "keywords": [
      "Business Process Modelling",
      "UML activity diagrams",
      "Con- trolled experiment",
      "Precise and Ultra-light styles."
    ]
  },
  {
    "title": "Semantically Conﬁgurable Consistency Analysis for Class and Object Diagrams",
    "date": 2011,
    "abstract": "Checking consistency between an object diagram (OD) and a class diagram (CD) is an important analysis problem. However, several variations in the semantics of CDs and ODs, as used in diﬀerent contexts and for diﬀerent purposes, create a challenge for analysis tools. To ad- dress this challenge in this paper we investigate semantically conﬁgurable model analysis. We formalize the variability in the languages semantics using a feature model: each conﬁguration that the model permits induces a diﬀerent semantics. Moreover, we develop a parametrized analysis that can be instantiated to comply with every legal conﬁguration of the fea- ture model. Thus, the analysis is semantically conﬁgured and its results change according to the semantics induced by the selected feature conﬁg- uration. The ideas are implemented using a parametrized transformation to Alloy. The work can be viewed as a case study example for a formal and automated approach to handling semantic variability in modeling languages.",
    "keywords": []
  },
  {
    "title": "Identifying the Weaknesses of UML Class\nDiagrams during Data Model Comprehension",
    "date": 2011,
    "abstract": "In this paper we present an experiment and two replications aimed at comparing the support provided by ER and UML class dia- grams during comprehension activities by focusing on the single build- ing blocks of the two notations. This kind of analysis can be used to identify weakness in a notation and/or justify the need of preferring ER or UML for data modeling. The results reveal that UML class diagrams are generally more comprehensible than ER diagrams, even if the former has some weaknesses related to three building blocks, i.e., multi-value attribute, composite attribute, and weak entity. These ﬁndings suggest that a UML class diagram extension should be considered to overcome these weaknesses and improve the comprehensibility of the notation.",
    "keywords": []
  },
  {
    "title": "Engineering Android Applications\nBased on UML Activities",
    "date": 2011,
    "abstract": "With the evolving capabilities of devices, mobile applications are emerging towards complex reactive systems. To handle this complex- ity and shorten development time by increased reuse, we propose an en- gineering approach based on UML activities, which are used like building blocks to construct applications. Libraries of such building blocks make Android-speciﬁc features available. Tool support provides automatic for- mal analysis for soundness and automatic implementation. Furthermore, the approach is easily extensible, since new features can be provided by new building blocks, without changing the tools or notation. We demon- strate the method by a voice messaging application.",
    "keywords": [
      "Mobile Applications",
      "Android",
      "UML Activities",
      "Model-Driven Engineering."
    ]
  },
  {
    "title": "Domain-Speciﬁc Model Transformation in\nBuilding Quantity Take-Oﬀ",
    "date": 2011,
    "abstract": "The two core concepts of model-driven engineering are mod- els and model transformations. Domain-Speciﬁc Modelling has become accepted as a powerful means of providing domain experts and end users with the ability to create and manipulate models within the systems that they use. In this paper we argue that there are domains for which it is appropriate to also provide domain experts with the ability to modify and develop model transformations. One such domain is that of quantity surveying, and speciﬁcally the taking-oﬀof quantities from a building design. We describe a language for expressing transformations between building models and bills of quantities, and its implementation within an automated quantity take-oﬀtool, reﬂecting on the commonalities and diﬀerences between this language and a general-purpose model transfor- mation language/tool.",
    "keywords": []
  },
  {
    "title": "Improving Scalability and Maintenance of\nSoftware for High-Performance Scientiﬁc\nComputing by Combining MDE and Frameworks",
    "date": 2011,
    "abstract": "In recent years, numerical simulation has attracted increas- ing interest within industry and among academics. Paradoxically, the development and maintenance of high performance scientiﬁc computing software has become more complex due to the diversiﬁcation of hardware architectures and their related programming languages and libraries. In this paper, we share our experience in using model-driven develop- ment for numerical simulation software. Our approach called MDE4HPC proposes to tackle development complexity by using a domain speciﬁc modeling language to describe abstract views of the software. We present and analyse the results obtained with its implementation when deriving this abstract model to target Arcane, a development framework for 2D and 3D numerical simulation software.",
    "keywords": []
  },
  {
    "title": "A Critical Review of Applied MDA for\nEmbedded Devices: Identiﬁcation of Problem\nClasses and Discussing Porting Eﬀorts in\nPractice",
    "date": 2011,
    "abstract": "Model-driven development (MDD) has seen wide application in research, but still has limitations in real world industrial projects. One project which applies such MDD principles is about developing the software of a feature phone. While advantages seem to outweigh any dis- advantages in theory, several problems arise when applying the model- driven methodology in practice. Problems when adopting this approach are shown as well as a practical solution to utilize one of the main ad- vantages of MDD—portability. Issues that originate from using a tool which supports a model-driven approach are presented. A conclusion sums up the personal experiences made when applying MDD in a real world project.",
    "keywords": []
  },
  {
    "title": "Designing Heterogeneous Component Based\nSystems: Evaluation of MARTE Standard and\nEnhancement Proposal",
    "date": 2011,
    "abstract": "Building complex real-time embedded systems requires as- sembly of heterogeneous components, possibly using various computation and communication models. A great challenge is to be able to design such systems using models where these heterogeneity characteristics are de- scribed precisely to assist the next step of the development including im- plementation or analysis. Although the new MARTE standard provides the core concepts to model real-time components using various commu- nication paradigms, we state in this paper that MARTE extensions have still to be made and we propose to extract common features from several component based approaches in order to support ﬁner compositions of heterogeneous sub-systems.",
    "keywords": []
  },
  {
    "title": "Semantic Clone Detection for Model-Based\nDevelopment of Embedded Systems",
    "date": 2011,
    "abstract": "With model-based development becoming an increasingly common development methodology in embedded systems engineering, models have become an important asset of the the software development process. Therefore, techniques for the automatic detection of clones in those models have been developed to improve their maintainability. As these approaches currently only consider syntactic clones, the detection of clones is limited to syntactically equivalent copies. Using the concept of normal forms, these approaches can be extended to also cover seman- tic clones with identical behavior but diﬀerent structure. The submission presents a generalized concept of clones for Simulink models, describes a pattern-based normal-form approach, and discusses results of the appli- cation of an implementation of this approach.",
    "keywords": []
  },
  {
    "title": "Instant and Incremental QVT Transformation for Runtime Models",
    "date": 2011,
    "abstract": "As a dynamic representation of the running system, a run- time model provides a model-based interface to monitor and control the system. A key issue for runtime models is to maintain their causal connec- tions with the running system. That means when the systems change, the models should change accordingly, and vice versa. However, for the ab- stract runtime models that are heterogeneous to their target systems, it is challenging to maintain such causal connections. This paper presents a model-transformation-based approach to maintaining causal connections for abstract runtime models. We deﬁne a new instant and incremental transformation semantics for the QVT-Relational language, according to the requirements of runtime models, and develop the transformation algorithm following this semantics. We implement this approach on the mediniQVT transformation engine, and apply it to provide the runtime model for an intelligent oﬃce system named SmartLab.",
    "keywords": []
  },
  {
    "title": "Service–Oriented Architecture Modeling:\nBridging the Gap between Structure and Behavior",
    "date": 2011,
    "abstract": "Model–driven development of large-scale software systems is highly likely to produce models that describe the systems from many diverse perspec- tives using a variety of modeling languages. Checking and maintaining consis- tency of information captured in such multi-modeling environments is known to be challenging. In this paper we describe an approach to systematically synchro- nize multi–models. The approach speciﬁcally addresses the problem of synchronizing business processes and domain models in a Service-oriented Ar- chitecture development environment. In the approach, the human effort required to synchronize independently developed models is supplemented with signiﬁcant automated support. This process is used to identify concept divergences, that is, a concept in one model which cannot be matched with concepts in the other model. We automate the propagation of divergence resolution decisions across the conﬂicting models. We illustrate the approach using models developed for a Car Crash Crisis Management System (CCCMS), a case study problem used to assess Aspect–oriented Modeling approaches.",
    "keywords": []
  },
  {
    "title": "From State- to Delta-Based Bidirectional Model\nTransformations: The Symmetric Case",
    "date": 2011,
    "abstract": "A bidirectional transformation (BX) keeps a pair of interre- lated models synchronized. Symmetric BXs are those for which neither model in the pair fully determines the other. We build two algebraic frameworks for symmetric BXs, with one correctly implementing the other, and both being delta-based generalizations of known state-based frameworks. We identify two new algebraic laws—weak undoability and weak invertibility, which capture important semantics of BX and are use- ful for both state- and delta-based settings. Our approach also provides a ﬂexible tool architecture adaptable to diﬀerent user’s needs.",
    "keywords": []
  },
  {
    "title": "Enforcing S&D Pattern Design in RCES with Modeling\nand Formal Approaches",
    "date": 2011,
    "abstract": "The requirement for higher security and dependability of systems is continuously increasing even in domains not traditionally deeply involved in such issues. Yet, evolution of embedded systems towards devices connected via In- ternet, wireless communication or other interfaces requires a reconsideration of secure and trusted embedded systems engineering processes. In this paper, we propose an approach that associates model driven engineering (MDE) and formal validation to build security and dependability (S&D) patterns for trusted RCES applications. The contribution of this work is twofold. On the one hand, we use model-based techniques to capture a set of artifacts to encode S&D patterns. On the other hand, we introduce a set of artifacts for the formal validation of these patterns in order to guarantee their correctness. The formal validation in turn fol- lows the the MDE process and thus links concrete validation results to the S&D requirements identiﬁed at higher levels of abstraction.",
    "keywords": [
      "Resource Constrained Embedded Systems",
      "Trust",
      "Security",
      "Depend- ability",
      "Pattern",
      "Meta-model",
      "Model Driven Engineering",
      "Formal Modeling."
    ]
  },
  {
    "title": "A Model-Based and Automated Approach to Size \nEstimation of Embedded Software Components",
    "date": 2011,
    "abstract": "Accurate estimation of Software Code Size is important for developing cost-efficient embedded systems. The Code Size affects the amount of system resources needed, like ROM and RAM memory, and processing capacity. In our previous work, we have estimated the Code Size based on CFP (COSMIC Function Points) within 15% accuracy, with the purpose of deciding how much ROM memory to fit into products with high cost pressure. Our manual CFP measurement process would require 2,5 man years to estimate the ROM size required in a typical car. In this paper, we want to investigate how the manual effort involved in estimation of Code Size can be minimized. We define a UML Profile capturing all information needed for estimation of Code Size, and develop a tool for automated estimation of Code Size based on CFP. A case study will show how UML models save manual effort in a realistic case.",
    "keywords": [
      "UML Profile",
      "UML components",
      "software components",
      "functional  size measurement",
      "code size estimation."
    ]
  },
  {
    "title": "MDE to Manage Communications with and\nbetween Resource-Constrained Systems",
    "date": 2011,
    "abstract": "With the emergence of Internet of Things (IoT), many things which typically used to be isolated or operated in small local networks, will be interconnected through the Internet. One main challenge to tackle in IoT is eﬃcient management of communication between things, since things can be very diﬀerent in terms of available resources, size and communication protocols. Current Internet-enabled devices are typically powerful enough to rely on common operating systems, standard net- work protocols and middlewares. In IoT many devices will be too con- strained to rely on such resource-consuming infrastructures; they run ad-hoc proprietary protocols. The contribution of this paper is a model- based approach for the eﬃcient provisioning and management of the communication between heterogeneous resource-constrained devices. It includes a DSML which compiles to a set of interoperable communication libraries providing an abstract communication layer that can integrate both powerful and resource-constrained devices. The approach is imple- mented in an IDE for the development resource-constrained Things.",
    "keywords": []
  },
  {
    "title": "Diagram Definition: A Case Study with the UML Class \nDiagram",
    "date": 2011,
    "abstract": "The abstract syntax of a graphical modeling language is typically defined with a metamodel while its concrete syntax (diagram) is informally defined with text and figures. Recently, the Object Management Group (OMG) released a beta specification, called Diagram Definition (DD), to formally define both the interchange syntax and the graphical syntax of diagrams. In this paper, we validate DD by using it to define a subset of the UML class diagram. Specifically, we define the interchange syntax with a MOF-based metamodel and the graphical syntax with a QVT mapping to a graphics metamodel. We then run an experiment where we interchange and render an example diagram. We highlight various design decisions and discuss challenges of using DD in practice. Finally, we conclude that DD is a sound approach for formally defining diagrams that is expected to facilitate the interchange and the consistent rendering of diagrams between tools.",
    "keywords": [
      "Diagram",
      "Definition",
      "Model",
      "MOF",
      "UML",
      "QVT",
      "DD",
      "SVG."
    ]
  },
  {
    "title": "Reducing Multiplicities in Class Diagrams",
    "date": 2011,
    "abstract": "In class diagrams, so-called multiplicities are integer ranges attached to association ends. They constrain the number of instances of the associated class that an instance may be linked to, or in an alterna- tive reading, the number of links to instances of the associated class. In complex diagrams with several chains of associations between two classes (arising e.g. in conﬁguration management) it may happen that the lower or upper bound of a range can never be attained because of restrictions imposed by a parallel chain. In this paper we investigate how multiplicities behave when chain- ing associations together, and we characterise situations where intervals can be tightened due to information from other chains. Detecting and eliminating such redundancies provides valuable feedback to the user, as redundancies may hint at some underlying misconception.",
    "keywords": []
  },
  {
    "title": "Creating Models for Simulating the Face",
    "date": 2011,
    "abstract": "Creating animated computer generated faces which can withstand scrutiny on the large screen is a daunting task. How does the face move? How does it reflect light? What information is relevant? How can it be captured and then transformed to convincingly breathe life into a digital human or fantastic creature? The talk will give examples of new technologies and methodologies developed to achieve this in blockbuster films including “Avatar” and will point the way to the next generation of computer generated characters by showing the increasing importance of computational simulation and discovering and modeling what is really going on underneath the skin.",
    "keywords": [
      "computer animation",
      "computer generated characters",
      "computational  simulation."
    ]
  },
  {
    "title": "EUnit: A Unit Testing Framework for Model\nManagement Tasks",
    "date": 2011,
    "abstract": "Validating and transforming models are essential steps in model-driven engineering. These tasks are often implemented as opera- tions in general purpose programming languages or task-speciﬁc model management languages. Just like other software artefacts, these tasks must be tested to reduce the risk of defects. Testing model management tasks requires testers to select and manage the relevant combinations of input models, tasks and expected outputs. This is complicated by the fact that many technologies may be used in the same system, each with their own integration challenges. In addition, advanced test oracles are required: tests may need to compare entire models or directory trees. To tackle these issues, we propose creating an integrated unit test- ing framework for model management operations. We have developed the EUnit unit testing framework to validate our approach. EUnit tests specify how models and tasks are to be combined, while staying decou- pled from the speciﬁc technologies used.",
    "keywords": [
      "Software testing",
      "unit testing",
      "model management",
      "test frameworks",
      "model validation",
      "model transformation."
    ]
  },
  {
    "title": "Verifying UML-RT Protocol Conformance Using Model Checking⋆",
    "date": 2011,
    "abstract": "In UML-RT, capsules communicate via protocols which con- nect capsule ports. Protocol State Machines (PSMs) allow the description of the legal message sequences of a port and are potentially very useful for the modular development and veriﬁcation of systems. However, it is unclear how exactly conformance of a capsule to its PSMs should be deﬁned and how this can be checked automatically. In this paper, we pro- vide a deﬁnition of protocol conformance and show how software model checking can be used to check protocol conformance automatically. We describe the design and implementation of a tool that checks the confor- mance of a capsule with Java action code with respect to the PSMs of all its ports. The results of the validation of the tool on three case studies are summarized.",
    "keywords": []
  },
  {
    "title": "Model-Based Coverage-Driven Test Suite\nGeneration for Software Product Lines",
    "date": 2011,
    "abstract": "Software Product Line (SPL) engineering is a popular ap- proach for the systematic reuse of software artifacts across a large num- ber of similar products. Unfortunately, testing each product of an SPL separately is often unfeasible. Consequently, SPL engineering is in con- ﬂict with standards like ISO 26262, which require each installed software conﬁguration of safety-critical SPLs to be tested using a model-based approach with well-deﬁned coverage criteria. In this paper we address this dilemma and present a new SPL test suite generation algorithm that uses model-based testing techniques to derive a small test suite from one variable 150% test model of the SPL such that a given coverage criterion is satisﬁed for the test model of every product. Furthermore, our algorithm simpliﬁes the subsequent selection of a small, representative set of products (w.r.t. the given coverage criterion) on which the generated test suite can be executed.",
    "keywords": []
  },
  {
    "title": "Constraint-Based Model Refactoring",
    "date": 2011,
    "abstract": "The UML standard specifies well-formedness rules as constraints on UML models. To be correct, refactoring of a model must take these constraints into account and check that they are still satisfied after a refactoring has been performed — if not, the refactoring must be refused. With constraint-based re- factoring, constraint checking is replaced by constraint solving, lifting the role of constraints from permitting or denying a tentative refactoring to computing additional model changes required for the refactoring to be executable. Thus, to the degree that the semantics of a modelling language is specified using con- straints, refactorings based on these constraints are guaranteed to be meaning preserving. To enable the reuse of pre-existing constraints for refactoring, we present a mapping from well-formedness rules as provided by the UML stan- dard to constraint rules as required by constraint-based refactoring. Using these mappings, models can be refactored at no extra cost; if refactorings fail, the lack of meaning preservation points us to how the constraint-based semantic specifi- cations of the modelling language can be improved.",
    "keywords": []
  },
  {
    "title": "Supporting Design Model Refactoring\nfor Improving Class Responsibility Assignment",
    "date": 2011,
    "abstract": "Although a responsibility driven approach in object oriented analysis and design methodologies is promising, the assignment of the identiﬁed respon- sibilities to classes (simply, class responsibility assignment: CRA) is a crucial issue to achieve design of higher quality. The GRASP by Larman is a guideline for CRA and is being put into practice. However, since it is described in an infor- mal way using a natural language, its successful usage greatly relies on designers’ skills. This paper proposes a technique to represent GRASP formally and to au- tomate appropriate CRA based on them. Our computerized tool automatically detects inappropriate CRA and suggests alternatives of appropriate CRAs to de- signers so that they can improve a CRA based on the suggested alternatives. We made preliminary experiments to show the usefulness of our tool.",
    "keywords": [
      "object-oriented design",
      "class responsibility assignment",
      "GRASP."
    ]
  },
  {
    "title": "Vision Paper: The Essence of Structural Models",
    "date": 2011,
    "abstract": "Models should represent the essential aspects of a system and leave out the inessential details. In this paper we propose an automatic approach to determine whether a model indeed focuses on the essential aspects. We deﬁne a new metric, structural essence, that quantiﬁes the fraction of essential elements in a model. Our approach targets structural models, such as the prevalent UML class diagrams. It is inspired by the idea of algorithmic essence – the amount of repetitive constructs in a program – and the duality between behavior and structure. We present a framework for computing the essence of a structural model based on a transformation of that model into a “distilled model” and on an existing graph algorithm operating on that distilled model. We discuss the meaning of our concept of structural essence based on a set of example models. We hope that our notion of structural essence will spark discussions on the purpose and the essence of models.",
    "keywords": []
  },
  {
    "title": "Vision Paper:\nTowards Model-Based Energy Testing",
    "date": 2011,
    "abstract": "Today, energy consumption is one of the major challenges for optimisation of future software applications and ICT infrastructures. To develop software w.r.t. its energy consumption, testing is an essen- tial activity, since testing allows quality assurance and thus, energy con- sumption reduction during the software’s development. Although ﬁrst approaches measuring and predicting software’s energy consumption for its execution on a speciﬁc hardware platform exist, no model-based test- ing approach has been developed, yet. In this paper we present our vi- sion of a model-based energy testing approach that uses a combination of abstract interpretation and run-time proﬁling to predict the energy consumption of software applications and to derive energy consumption test cases.",
    "keywords": [
      "Energy consumption testing",
      "abstract interpretation",
      "pro- ﬁling",
      "unit testing",
      "model-based testing."
    ]
  },
  {
    "title": "Vision Paper: Make a Difference! (Semantically)⋆",
    "date": 2011,
    "abstract": "Syntactic difference between models is a wide research area with applications in tools for model evolution, model synchronization and version con- trol. On the other hand, semantic difference between models is rarely discussed. We point out to main use cases of semantic difference between models, and then propose a framework for deﬁning well-formed difference operators on model semantics as adjoints of model combinators such as conjunction, disjunction and structural composition. The framework is deﬁned by properties other then con- structively. We instantiate the framework for two rather different modeling lan- guages: feature models and automata speciﬁcations. We believe that the algebraic theory of semantic difference will allow to deﬁne practical model differencing tools in the future.",
    "keywords": []
  },
  {
    "title": "Automatic Derivation of Utility Functions for Monitoring Software Requirements⋆",
    "date": 2011,
    "abstract": "Utility functions can be used to monitor requirements of a dynamically adaptive system (DAS). More speciﬁcally, a utility function maps monitoring information to a scalar value proportional to how well a requirement is satisﬁed. Utility functions may be manually elicited by requirements engineers, or indirectly inferred through statistical regres- sion techniques. This paper presents a goal-based requirements model- driven approach for automatically deriving state-, metric-, and fuzzy logic-based utility functions for RELAXed goal models. State- and fuzzy logic-based utility functions are responsible for detecting requirements vi- olations, and metric-based utility functions are used to detect conditions conducive to a requirements violation. We demonstrate the proposed ap- proach by applying it to the goal model of an intelligent vehicle system (IVS) and use the derived utility functions to monitor the IVS under diﬀerent environmental conditions at run time.",
    "keywords": []
  },
  {
    "title": "Logic-Based Model-Level Software Development with F-OML",
    "date": 2011,
    "abstract": "Models are at the heart of the emerging Model-driven En- gineering (MDE) approach in which software is developed by repeated transformations of models. Intensive eﬀorts in the modeling community in the past two decades have produced an impressive variety of tool sup- port for models. Nonetheless, models are still not widely used throughout the software evolution life cycle and, in many cases, they are neglected in later stages of software development. To make models more useful, one needs a powerful model-level IDE that supports a wide range of object modeling tasks. Such IDEs must have a consistent formal foundation.",
    "keywords": []
  },
  {
    "title": "Formal Veriﬁcation of QVT Transformations for\nCode Generation",
    "date": 2011,
    "abstract": "We present a formal calculus for operational QVT. The cal- culus is implemented in the interactive theorem prover KIV and allows to prove properties of QVT transformations for arbitrary meta models. Additionally we present a framework for provably correct Java code generation. The framework uses a meta model for a Java abstract syntax tree as the target of QVT transformations. This meta model is mapped to a formal Java semantics in KIV. This makes it possible to formally prove with the QVT calculus that a transformation always generates a Java model (i.e. a program) that is type correct and has certain semantical properties. The Java model can be used to generate source code by a model-to-text transformation or byte code directly.",
    "keywords": []
  },
  {
    "title": "Model-Based (Mechanical) Product Design",
    "date": 2011,
    "abstract": "Mechanical product engineering is a research and industrial activity which studies the design of complex mechanical systems. The process, which involves the collaboration of various experts using domain- speciﬁc software, raises syntactic and semantic interoperability issues which are not addressed by existing software solutions or their underly- ing concepts. This article proposes a ﬂexible model-based software archi- tecture that allows for a federation of experts to deﬁne and collaborate in innovative design processes. The presented generic approach is backed and validated by its implementation on an academic usecase.",
    "keywords": []
  },
  {
    "title": "Applying a Model-Based Approach to IT Systems \nDevelopment Using SysML Extension",
    "date": 2011,
    "abstract": "Model-based system engineering (MBSE) is regarded as an effective way of developing systems. We are now applying the model-based approach to IT system development/integration (SI) because we urgently need to reduce the cost of SI. However, there are various challenges imposed when applying MBSE to SI. One of these is that reducing the cost to update models is more significant than that in other MBSE domains such as embedded systems. We adopted SysML to handle these issues and extended it to modeling IT systems. We present the details on this SysML extension and how it overcame these issues. We are developing an in-house SI-support tool called \"CASSI\", which evaluates the non-functional requirements; performance and availability of the IT system's models written in that extended manner and helps these models to be reused. This paper also includes industrial case studies of CASSI, and its effectiveness is discussed.",
    "keywords": [
      "Model-based",
      "IT systems development",
      "system modeling."
    ]
  },
  {
    "title": "Early Experience with Agile Methodology in a  \nModel-Driven Approach",
    "date": 2011,
    "abstract": "We are in the business of delivering software intensive business systems using model-driven techniques. Developing suitable code generators is an important step in model-based development of purpose-specific business applications. Hence, it becomes critical to ensure that code generator development doesn’t become a bottleneck for the project delivery. After establishing a sophisticated technology infrastructure to facilitate quick and easy adaptation of model-based code generators, we experimented with agile methodology. In this paper, we discuss why pure agile methodology does not work for model-driven software development. We propose a modification to the agile methodology in the form of meta-sprints as a golden mean between agile method and traditional plan-driven method. Early experience with the proposed development method is shared along with the lessons learnt.",
    "keywords": [
      "model-driven development",
      "agile method",
      "software intensive  business systems."
    ]
  },
  {
    "title": "CD2Alloy: Class Diagrams Analysis Using Alloy Revisited",
    "date": 2011,
    "abstract": "We present CD2Alloy, a novel, powerful translation of UML class diagrams (CDs) to Alloy. Unlike existing translations, which are based on a shallow embedding strategy, and are thus limited to check- ing consistency and generating conforming object models of a single CD, and support a limited set of CD language features, CD2Alloy uses a deeper embedding strategy. Rather than mapping each CD construct to a semantically equivalent Alloy construct, CD2Alloy deﬁnes (some) CD constructs as new concepts within Alloy. This enables solving sev- eral analysis problems that involve more than one CD and could not be solved by earlier works, and supporting an extended list of CD language features. The ideas are implemented in a prototype Eclipse plug-in. The work advances the state-of-the-art in CD analysis, and can also be viewed as an interesting case study for the diﬀerent possible translations of one modeling language to another, their strengths and weaknesses.",
    "keywords": []
  },
  {
    "title": "Model-Driven Engineering and Optimizing Compilers:\nA Bridge Too Far?",
    "date": 2011,
    "abstract": "A primary goal of Model Driven Engineering (MDE) is to reduce the cost and effort of developing complex software systems using techniques for transforming abstract views of software to concrete implementations. The rich set of tools that have been developed, especially the growing maturity of model transformation technologies, opens the possibility of applying MDE technologies to transformation-based problems in other domains. In this paper, we present our experience with using MDE technologies to build and evolve compiler infrastructures in the optimizing compiler domain. We illus- trate, through our two ongoing research compiler projects for C and a functional language, the challenging aspects of optimizing compiler research and show how mature MDE technologies can be used to address them. We also identify some of the pitfalls that arise from unrealistic expectations of what can be accomplished using MDE and discuss how they can lead to unsuccessful and frustrating appli- cation of MDE technologies.",
    "keywords": []
  },
  {
    "title": "Towards a General Composition Semantics for Rule-Based Model Transformation",
    "date": 2011,
    "abstract": "As model transformations have become an integral part of the automated software engineering lifecycle, reuse, modularisation, and composition of model transformations becomes important. One way to compose model transformations is to compose modules of transformation rules, and execute the composition as one transformation (internal com- position). This kind of composition can provide ﬁne-grained semantics, as it is part of the transformation language. This paper aims to gener- alise two internal composition mechanisms for rule-based transformation languages, module import and rule inheritance, by providing executable semantics for the composition mechanisms within a virtual machine. The generality of the virtual machine is demonstrated for diﬀerent rule-based transformation languages by compiling those languages to, and execut- ing them on this virtual machine. We will discuss how ATL and graph transformations can be mapped to modules and rules inside the virtual machine.",
    "keywords": [
      "Model transformation",
      "Model transformation composition",
      "ATL",
      "Graph transformation."
    ]
  },
  {
    "title": "Properties of Realistic Feature Models Make\nCombinatorial Testing of Product Lines Feasible",
    "date": 2011,
    "abstract": "Feature models and associated feature diagrams allow mod- eling and visualizing the constraints leading to the valid products of a product line. In terms of their expressiveness, feature diagrams are equiv- alent to propositional formulas which makes them theoretically expensive to process and analyze. For example, satisfying propositional formulas, which translates into ﬁnding a valid product for a given feature model, is an NP-hard problem, which has no fast, optimal solution. This theo- retical complexity could prevent the use of powerful analysis techniques to assist in the development and testing of product lines. However, we have found that satisfying realistic feature models is quick. Thus, we show that combinatorial interaction testing of product lines is feasible in practice. Based on this, we investigate covering array generation time and results for realistic feature models and ﬁnd where the algorithms can be improved.",
    "keywords": [
      "Software Product Lines",
      "Testing",
      "Feature Models",
      "Practical",
      "Realistic",
      "Combinatorial Interaction Testing."
    ]
  },
  {
    "title": "Reasoning about Metamodeling with Formal\nSpeciﬁcations and Automatic Proofs",
    "date": 2011,
    "abstract": "Metamodeling is foundational to many modeling frameworks, and so it is important to formalize and reason about it. Ideally, correct- ness proofs and test-case generation on the metamodeling framework should be automatic. However, it has yet to be shown that extensive au- tomated reasoning on metamodeling frameworks can be achieved. In this paper we present one approach to this problem: Metamodeling frame- works are speciﬁed modularly using algebraic data types and constraint logic programming (CLP). Proofs and test-case generation are encoded as CLP satisﬁability problems and automatically solved.",
    "keywords": []
  },
  {
    "title": "Correctness of Model Synchronization Based on Triple Graph Grammars",
    "date": 2011,
    "abstract": "Triple graph grammars (TGGs) have been used successfully to ana- lyze correctness and completeness of bidirectional model transformations, but a corresponding formal approach to model synchronization has been missing. This paper closes this gap by providing a formal synchronization framework with bidi- rectional update propagation operations. They are generated from a TGG, which speciﬁes the language of all consistently integrated source and target models.",
    "keywords": []
  },
  {
    "title": "A Toolchain for the Detection of Structural and Behavioral Latent System Properties⋆",
    "date": 2011,
    "abstract": "The cost to repair a requirements-based defect in software- based systems increases substantially with each successive phase of the software lifecycle in which the error is allowed to propagate. While tools exist to facilitate early detection of design ﬂaws, such tools do not detect ﬂaws in system requirements, thus allowing such ﬂaws to propagate into system design and implementation. This paper describes an experience report using a toolchain that supports a novel combination of structural and behavioral analysis of UML state diagrams that is not currently available in commercial UML modeling tools. With the toolchain, mod- els can be incrementally and systematically improved through syntax- based analysis, type checking, and detection of latent behavioral system properties, including feature interactions. This paper demonstrates use of the toolchain on an industry-provided model of onboard electronics for an automotive application.",
    "keywords": [
      "requirements engineering",
      "UML",
      "latent properties",
      "model checking."
    ]
  },
  {
    "title": "Deﬁning MARTE’s VSL as an Extension of Alf",
    "date": 2011,
    "abstract": "VSL and Alf are two OMG standards providing a textual notation for complex mathematical expressions and detailed activities respectively. Since these two notations have been designed by separate communities (real-time embedded for VSL and software engineering for Alf), they diﬀer in syntax and semantics. Nevertheless, they clearly exhibit intersections in their form and use cases. The purpose of this article is to demonstrate that an alignment eﬀort between the two lan- guages would be beneﬁcial for both users and tool providers. We show that most of the syntactic constructs introduced in VSL are related to general-purpose concerns (i.e., they are not speciﬁc to the real-time do- main), most of them being covered by Alf. In this paper, we ﬁrst identify the subset of VSL which is valuable for the real-time domain, and then propose a way of extending Alf with this subset1.",
    "keywords": []
  },
  {
    "title": "Using Delta Model for Collaborative Work of Industrial \nLarge-Scaled E/E Architecture Models",
    "date": 2011,
    "abstract": "Development of model-based Electric/Electronic (E/E) architecture in the automotive industry poses a high demand on the data management of models. The collaborative modeling work involves stakeholders dispersed across various locations and departments, while the models themselves are of- ten extremely large-scaled. In this paper, we present our approach addressing the model data management issue for both asynchronous and synchronous modeling. Compared to asynchronous modeling, which is based on the lock/commit mechanism for cross-department collaboration, synchronous mod- eling is targeted to assist quick and efficient interaction among small groups of members. We use the delta model for versioning in the database as well as for the synchronous modeling functionality. Furthermore, other versatile uses of the delta model such as the cumulative delta model and the reverse delta model are also introduced.",
    "keywords": [
      "Delta Model",
      "Collaborative Modeling",
      "Real-time Collaboration",
      "Versioning",
      "Groupware",
      "Computer Supported Cooperative Work (CSCW)."
    ]
  },
  {
    "title": "Bottom-Up Meta-Modelling:\nAn Interactive Approach",
    "date": 2012,
    "abstract": "The intensive use of models in Model-Driven Engineering (MDE) raises the need to develop meta-models with diﬀerent aims, like the construction of textual and visual modelling languages and the spec- iﬁcation of source and target ends of model-to-model transformations. While domain experts have the knowledge about the concepts of the do- main, they usually lack the skills to build meta-models. These should be tailored according to their future usage and speciﬁc implementation plat- form, which demands knowledge available only to engineers with great expertise in MDE platforms. These issues hinder a wider adoption of MDE both by domain experts and software engineers. In order to alleviate this situation we propose an interactive, iterative approach to meta-model construction enabling the speciﬁcation of model fragments by domain experts, with the possibility of using informal draw- ing tools like Dia. These fragments can be annotated with hints about the intention or needs for certain elements. A meta-model is automati- cally induced, which can be refactored in an interactive way, and then compiled into an implementation meta-model using proﬁles and patterns for diﬀerent platforms and purposes.",
    "keywords": [
      "Meta-Modelling",
      "Domain-Speciﬁc Modelling Languages",
      "Interactive Meta-Modelling",
      "Meta-Model Design Exploration."
    ]
  },
  {
    "title": "FacadeMetamodel: Masking UML",
    "date": 2012,
    "abstract": "UML profiling is pragmatic choice that lets language designers define a Domain-Specific Modeling Language (DSML) by tuning UML to meet specific domain. An alternative approach is to define a pure-DSML. Each approach has its own benefits and drawbacks. We propose an approach and a tool that helps get the best from both approaches; maximizing reuse while retaining a focused and adapted DSML. We guide the language designer in the definition of a metamodel based on one or more UML profiles. Language designers then recast UML so that only what they need will appear in this metamodel. From that, the tool automatically generates the pure-DSML and the transformations between it and UML. However, the new pure-DSML is only a facade; models can be manipulated using the pure-DSML abstract syntax but they are actually stored in fully-compliant UML abstract syntax and therefore remain compatible with UML tools.",
    "keywords": []
  },
  {
    "title": "T□: A Domain Speciﬁc Language for Rapid\nWorkﬂow Development",
    "date": 2012,
    "abstract": "In MDE, software systems are always synchronized with their models since changes are made ﬁrst to the model whenever there are changes in the requirement speciﬁcations. While MDE has a lot of po- tential, it requires maturity and tool support. In this research we present a framework for a workﬂow management system based on the MDE approach. We propose a domain speciﬁc language, T□(T-Square) for rapidly specifying details of (workﬂow) tasks and their associated user interfaces which may be used with the NOVA Workﬂow, an executable workﬂow management system. T□includes syntax for writing procedu- ral statements, for querying an ontology, for declaring user interfaces, for applying access control policy, and for scheduling tasks, using Xtext to write the grammar. We apply transformation methods, based on Xtend, to generate executable software from the abstract task speciﬁcations. A running example from health services delivery illustrates the usefulness of this approach.",
    "keywords": [
      "Workﬂow Management System",
      "Model Driven Engineering",
      "Ontology",
      "Domain Speciﬁc Language."
    ]
  },
  {
    "title": "Relaxing Claims: Coping with Uncertainty\nWhile Evaluating Assumptions at Run Time",
    "date": 2012,
    "abstract": "Self-adaptation enables software systems to respond to chang- ing environmental contexts that may not be fully understood at design time. Designing a dynamically adaptive system (DAS) to cope with this uncertainty is challenging, as it is impractical during requirements anal- ysis and design time to anticipate every environmental condition that the DAS may encounter. Previously, the RELAX language was proposed to make requirements more tolerant to environmental uncertainty, and Claims were applied as markers of uncertainty that document how design assumptions aﬀect goals. This paper integrates these two techniques in order to assess the validity of Claims at run time while tolerating mi- nor and unanticipated environmental conditions that can trigger adap- tations. We apply the proposed approach to the dynamic reconﬁguration of a remote data mirroring network that must diﬀuse data while mini- mizing costs and exposure to data loss. Results show RELAXing Claims enables a DAS to reduce adaptation costs.",
    "keywords": []
  },
  {
    "title": "Dynamic Evolution of Context-Aware Systems with Models at Runtime⋆",
    "date": 2012,
    "abstract": "Model-driven techniques have proven to yield signiﬁcant beneﬁts for context-aware systems. Speciﬁcally, semantically-rich models are used at runtime to monitor the system context and guide necessary changes. Under the closed- world assumption, adaptations are fully known at design time. Nevertheless, it is difﬁcult to foresee all the possible situations that may arise in uncertain and complex contexts. In this paper, we present a model-based framework to support the dynamic evolution of context-aware systems to deal with unexpected context events in the open world. If model adaptations are not enough to solve uncertainty, our model-based evolution planner guides the evolution of the supporting models to preserve high-level requirements. A case study about a context-aware Web service composition, which is executed in a distributed computing infrastructure, illustrates the applicability of our framework. A realization methodology and a prototype system support our approach.",
    "keywords": []
  },
  {
    "title": "An Eclipse Modelling Framework Alternative\nto Meet the Models@Runtime Requirements",
    "date": 2012,
    "abstract": "Models@Runtime aims at taming the complexity of software dynamic adaptation by pushing further the idea of reﬂection and con- sidering the reﬂection layer as a ﬁrst-class modeling space. A natural approach to Models@Runtime is to use MDE techniques, in particular those based on the Eclipse Modeling Framework. EMF provides facilities for building DSLs and tools based on a structured data model, with tight integration with the Eclipse IDE. EMF has rapidly become the defacto standard in the MDE community and has also been adopted for building Models@Runtime platforms. For example, Frascati (implementing the Service Component Architecture standard) uses EMF for the design and runtime tooling of its architecture description language. However, EMF has primarily been thought to support design-time activities. This paper highlights speciﬁc Models@Runtime requirements, discusses the bene- ﬁts and limitations of EMF in this context, and presents an alternative implementation to meet these requirements.",
    "keywords": [
      "Model@Runtime",
      "EMF",
      "adaptation."
    ]
  },
  {
    "title": "Automated and Transparent Model\nFragmentation for Persisting Large Models",
    "date": 2012,
    "abstract": "Existing model persistence frameworks either store models as a whole or object by object. Since most modeling tasks work with larger aggregates of a model, existing persistence frameworks either load too many objects or access many objects individually. We propose to persist a model broken into larger fragments. First, we assess the size of large models and describe typical usage patterns to show that most applications work with aggregates of model objects. Secondly, we provide an analytical framework to assess execution time gains for partially loading models fragmented with diﬀerent gran- ularity. Thirdly, we propose meta-model-based fragmentation that we implemented in an EMF based framework. Fourthly, we analyze our ap- proach in comparison to other persistence frameworks based on four com- mon modeling tasks: create/modify, traverse, query, and partial loads. We show that there is no generally optimal fragmentation, that frag- mentation can be achieved automatically and transparently, and that fragmentation provides considerable performance gains.",
    "keywords": []
  },
  {
    "title": "Formally Deﬁning and Iterating Inﬁnite Models ⋆",
    "date": 2012,
    "abstract": "The wide adoption of MDE raises new situations where we need to manipulate very large models or even inﬁnite model streams gathered at runtime (e.g., monitoring). These new uses cases for MDE raise challenges that had been unforeseen by the time standard modeling framework were designed. This paper proposes a formal deﬁnition of an inﬁnite model, as well as a formal framework to reason on queries over inﬁnite models. This formal query deﬁnition aims at supporting the design and veriﬁcation of operations that manipulate inﬁnite mod- els. First, we precisely identify the MOF parts which must be reﬁned to support inﬁnite structure. Then, we provide a formal coinductive deﬁnition dealing with unbounded and potentially inﬁnite graph-based structure.",
    "keywords": []
  },
  {
    "title": "Query-Driven Soft Interconnection of EMF Models⋆",
    "date": 2012,
    "abstract": "Model repositories based on the Eclipse Modeling Framework (EMF) play a central role in the model-driven development of complex software-intensive systems by oﬀering means to persist and manipulate models obtained from heterogeneous languages and tools. Complex EMF models can be assembled by interconnecting model fragments by hard links, i.e. regular references, where the target end points to external re- sources using storage-speciﬁc URIs. This approach, in certain application scenarios, may prove to be a too rigid and error prone way of interlinking models. As a ﬂexible alternative, we propose to combine derived features of EMF models with advanced incremental model queries as means for soft interlinking of model elements residing in diﬀerent model resources. These soft links can be calculated on-demand with graceful handling for temporarily unresolved references. In the background, the interlinks are maintained eﬃciently and ﬂexibly by using incremental model queries as provided by the EMF-IncQuery framework.",
    "keywords": []
  },
  {
    "title": "Modeling the Linguistic Architecture\nof Software Products",
    "date": 2012,
    "abstract": "Understanding modern software products is challenging along several dimensions. In the past, much attention has been focused on the logical and physical architecture of the products in terms of the rele- vant components, features, ﬁles, and tools. In contrast, in this paper, we focus on the linguistic architecture of software products in terms of the involved software languages and related technologies, and technolog- ical spaces with linguistic relationships such as membership, subset, or conformance. We develop a designated form of megamodeling with cor- responding language and tool support. An important capability of the megamodeling approach is that entities and relationships of the meg- amodel are linked to illustrative software artifacts. This is particularly important during the understanding process for validation purposes. We demonstrate such megamodeling for a technology for Object/XML map- ping. This work contributes to the 101companies community project.",
    "keywords": [
      "Megamodel",
      "Linguistic architecture",
      "Software language",
      "Soft- ware technology",
      "Technological space",
      "Object/XML mapping",
      "MegaL."
    ]
  },
  {
    "title": "Cross-Language Support Mechanisms\nSigniﬁcantly Aid Software Development",
    "date": 2012,
    "abstract": "Contemporary software systems combine many artifacts speciﬁed in various modeling and programming languages, domain- speciﬁc and general purpose as well. Since multi-language systems are so widespread, working on them calls for tools with cross-language support mechanisms such as (1) visualization, (2) static checking, (3) navigation, and (4) refactoring of cross-language relations. We investigate whether these four mechanisms indeed improve eﬃciency and quality of devel- opment of multi-language systems. We run a controlled experiment in which 22 participants perform typical software evolution tasks on the JTrac web application using a prototype tool implementing these mecha- nisms. The results speak clearly for integration of cross-language support mechanisms into software development tools, and justify research on au- tomatic inference, manipulation and handling of cross-language relations.",
    "keywords": []
  },
  {
    "title": "Do Professional Developers Beneﬁt from Design\nPattern Documentation? A Replication in the\nContext of Source Code Comprehension",
    "date": 2012,
    "abstract": "We present the results of a diﬀerentiated replication conducted with professional developers to assess whether the presence and the kind of documentation for the solutions or instances of design patterns aﬀect source code comprehension. The participants were di- vided into three groups and asked to comprehend a chunk of the JHot- Draw source code. Depending on the group, each participant was or not provided with the graphical and textual representations of the design pattern instances implemented within that source code. In the case of graphically documented instances, we used UML class diagrams, while textually documented instances are reported as comment in the source code. The results revealed that participants provided with the docu- mentation of the instances achieved a signiﬁcantly better comprehension than the participants with source code alone. The eﬀect of the kind of documentation is not statistically signiﬁcant.",
    "keywords": [
      "Design Patterns",
      "Controlled Experiment",
      "Maintenance",
      "Replications",
      "Software Models",
      "Source Code Comprehension."
    ]
  },
  {
    "title": "Incremental Consistency Checking for Complex Design\nRules and Larger Model Changes",
    "date": 2012,
    "abstract": "Advances in consistency checking in model-based software develop- ment made it possible to detect errors in real-time. However, existing approaches assume that changes come in small quantities and design rules are generally small in scope. Yet activities such as model transformation, re-factoring, model merg- ing, or repairs may cause larger model changes and hence cause performance problems during consistency checking. The goal of this work is to increase the performance of re-validating design rules. This work proposes an automated and tool supported approach that re-validates the affected parts of a design rule only. It was empirical evaluated on 19 design rules and 30 small to large design models and the evaluation shows that the approach improves the computational cost of consistency checking with the gains increasing with the size and complexity of design rules.",
    "keywords": [
      "consistency checking",
      "performance",
      "incremental checking."
    ]
  },
  {
    "title": "Evaluating the Impact of Aspects on Inconsistency \nDetection Effort: A Controlled Experiment",
    "date": 2012,
    "abstract": "Design models represent modular realizations of stakeholders’ con- cerns and communicate the design decisions to be implemented by developers. Unfortunately, they often suffer from inconsistency problems. Aspect-oriented modeling (AOM) aims at promoting better modularity. However, there is no empirical knowledge about its impact on the inconsistency detection effort. To address this gap, this work investigates the effects of AOM on: (1) the develop- ers’ effort to detect inconsistencies; (2) the inconsistency detection rate; and (3) the interpretation of design models in the presence of inconsistencies. A con- trolled experiment was conducted with 26 subjects and involved the analysis of 520 models. The results, supported by statistical tests, show that the effort of detecting inconsistencies is 20 percent lower in AO models than in their OO counterparts. On the other hand, the inconsistency detection rate and the num- ber of misinterpretations are 43 and 37 percent higher in AO models than in OO models, respectively.",
    "keywords": [
      "Aspect-Oriented Modeling",
      "Model Composition",
      "Inconsistency",
      "Developer Effort",
      "Empirical Studies."
    ]
  },
  {
    "title": "On Integrating\nStructure and Behavior Modeling with OCL",
    "date": 2012,
    "abstract": "Precise modeling with UML and OCL traditionally focuses on structural model features like class invariants. OCL also allows the developer to handle behavioral aspects in form of operation pre- and postconditions. However, behavioral UML models like statecharts have rarely been integrated into UML and OCL modeling tools. This pa- per discusses an approach that combines precise structure and behav- ior modeling: Class diagrams together with class invariants restrict the model structure and protocol state machines constrain the model behav- ior. Protocol state machines can take advantage of OCL in form of OCL state invariants and OCL guards and postconditions for state transitions. Protocol state machines can cover complete object lifecycles in contrast to operation pre- and postconditions which only aﬀect single operation calls. The paper reports on the chosen UML language features and their implementation in a UML and OCL validation and veriﬁcation tool.",
    "keywords": [
      "Structure modeling",
      "Behavior modeling",
      "UML",
      "OCL",
      "Pro- tocol state machine",
      "State invariant",
      "Guard",
      "Transition postcondition."
    ]
  },
  {
    "title": "Multi-perspectives on Feature Models",
    "date": 2012,
    "abstract": "Domain feature models concisely express commonality and variability among variants of a software product line. For supporting separation of concerns, e.g., due to legal restrictions, technical consid- erations and business requirements, multi-view approaches restrict the conﬁguration choices on feature models for diﬀerent stakeholders. How- ever, recent approaches lack a formalization for precise, yet ﬂexible spec- iﬁcations of views that ensure every derivable conﬁguration perspective to obey feature model semantics. Here, we introduce a novel approach for preconﬁguring feature models to create multi-perspectives. Such cus- tomized perspectives result from composition of various concern-relevant views. A structured view model is used to organize features in view groups, wherein a feature may be contained in multiple views. We pro- vide formalizations for view composition and guaranteed consistency of perspectives w.r.t. feature model semantics. Thereupon, an eﬃcient algo- rithm to verify consistency for entire multi-perspectives is provided. We present an implementation and evaluate our concepts by means of various experiments.",
    "keywords": [
      "Software Product Lines",
      "Feature Models",
      "Preconﬁguration",
      "Customization",
      "Automated View Composition."
    ]
  },
  {
    "title": "Generating Better Partial Covering Arrays\nby Modeling Weights on Sub-product Lines",
    "date": 2012,
    "abstract": "Combinatorial interaction testing is an approach for testing product lines. A set of products to test can be set up from the cover- ing array generated from a feature model. The products occurring in a partial covering array, however, may not focus on the important feature interactions nor resemble any actual product in the market. Knowledge about which interactions are prevalent in the market can be modeled by assigning weights to sub-product lines. Such models enable a covering array generator to select important interactions to cover ﬁrst for a par- tial covering array, enable it to construct products resembling those in the market and enable it to suggest simple changes to an existing set of products to test for incremental adaption to market changes. We report experiences from the application of weighted combinatorial interaction testing for test product selection on an industrial product line, TOMRA’s Reverse Vending Machines.",
    "keywords": [
      "Product Lines",
      "Software",
      "Hardware",
      "Testing",
      "Combinatorial Interaction Testing",
      "Evolution."
    ]
  },
  {
    "title": "Towards Business Application Product Lines",
    "date": 2012,
    "abstract": "With continued increase in business dynamics, it is becoming increa- singly harder to deliver purpose-specific business systems in the ever-shrinking window of opportunity. Code-centric software product line engineering (SPLE) techniques show unacceptable responsiveness as business applications are sub- jected to changes along multiple dimensions that continue to evolve simulta- neously. Through clear separation of functional concerns from technology, model-driven approaches enable easy delivery of the same functionality into multiple technology platforms. However, business systems for same functional intent tend to have similar but non-identical functionality. This makes a strong case for bringing in SPLE ideas i.e., what can change where and when, to mod- els. We propose an abstraction that aims to address composition, variability and resolution in a unified manner; describe its model-based realization; and outline the key enablers necessary for raising business application product lines. Early experience of our approach and issues that remain to be addressed for industry acceptance are highlighted.",
    "keywords": [
      "software product lines",
      "model driven engineering."
    ]
  },
  {
    "title": "Inter-association Constraints in UML2: Comparative Analysis, Usage Recommendations, and Modeling Guidelines",
    "date": 2012,
    "abstract": "UML speciﬁcation is verbal and imprecise, the exact mean- ing of many class diagram constructs and their interaction is still obscure. There are major problems with the inter-association constraints subsets, union, redeﬁnition, association specialization, association-class special- ization. Although their standard semantics is ambiguous and their inter- action unclear, the UML meta-model intensively uses these constraints.",
    "keywords": []
  },
  {
    "title": "The Coroutine Model of Computation",
    "date": 2012,
    "abstract": "This paper presents a general denotational formalism called the Coroutine Model of Computation for control-oriented computational models. This formalism characterizes atomic elements with control be- havior as Continuation Actors, giving them a static semantics with a functional interface. Coroutine Models are then deﬁned as networks of Continuation Actors, representing a set of control locations between which control traverses during execution. This paper gives both a strict and non-strict denotational semantics for Coroutine Models in terms of compositions of Continuation Actors and their interfaces. In the strict form, the traversal of control locations forms a control path producing output values, whereas in the non-strict form, execution traverses a tree of potential control locations producing partial information about out- put values. Furthermore, the given non-strict form of these semantics is claimed to have useful monotonicity properties.",
    "keywords": []
  },
  {
    "title": "Assume-Guarantee Scenarios: Semantics and Synthesis⋆",
    "date": 2012,
    "abstract": "The behavior of open reactive systems is best described in an assume-guarantee style speciﬁcation: a system guarantees certain prescribed behavior provided that its environment follows certain given assumptions. Scenario-based modeling languages, such as variants of message sequence charts, have been used to specify reactive systems behavior in a visual, modular, intuitive way. However, none have yet provided full support for assume-guarantee style speciﬁcations.",
    "keywords": []
  },
  {
    "title": "An Exploratory Study of Forces and Frictions\nAﬀecting Large-Scale Model-Driven\nDevelopment",
    "date": 2012,
    "abstract": "In this paper, we investigate model-driven engineering, re- porting on an exploratory case-study conducted at a large automotive company. The study consisted of interviews with 20 engineers and man- agers working in diﬀerent roles. We found that, in the context of a large organization, contextual forces dominate the cognitive issues of using model-driven technology. The four forces we identiﬁed that are likely in- dependent of the particular abstractions chosen as the basis of software development are the need for diﬃng in software product lines, the needs for problem-speciﬁc languages and types, the need for live modeling in ex- ploratory activities, and the need for point-to-point traceability between artifacts. We also identiﬁed triggers of accidental complexity, which we refer to as points of friction introduced by languages and tools. Examples of the friction points identiﬁed are insuﬃcient support for model diﬃng, point-to-point traceability, and model changes at runtime.",
    "keywords": []
  },
  {
    "title": "A Model-Driven Approach to Support \nEngineering Changes in Industrial Robotics Software",
    "date": 2012,
    "abstract": "Software development has improved greatly over the past decades with the introduction of new programming languages and tools. However, software development in the context of industrial robotics is dominated by practices that require attention to low-level accidental complexities related to the solution space of a particular domain. Most vendor-specific robotics platforms force the developer to be concerned with many low-level implementation details, which presents a maintenance challenge in the context of making engineering changes to the robotics solution. Additionally, satisfying the timing requirements across the platforms of multiple robot vendors represents an additional challenge. We introduce our work using Domain- Specific Modeling to support the control of industrial robots using models that are at a higher level of abstraction than traditional robot programming languages. Our modeling approach assists robotics developers to plan the schedule, validate timing requirements, optimize robot control, handle engineering changes, and support multiple platforms.",
    "keywords": [
      "Domain-Specific Modeling",
      "Robotics",
      "Software Maintenance",
      "Digital Factory",
      "Digital Master."
    ]
  },
  {
    "title": "Managing Related Models in Vehicle Control\nSoftware Development",
    "date": 2012,
    "abstract": "Model management is critical for large software-intensive system development as it ensures the consistency and correctness of the models that are separately developed but interrelated. It is especially crucial when the models are acquired from diﬀerent sources and evolve frequently. Traditional approaches to model management in vehicle con- trol software development rely on information examination guarded by a rigorous development process, which requires a high-level of knowledge and may be less eﬀective than is desirable. To address this issue, we in- vestigate the applicability of the macromodel concept – a formal method for the speciﬁcation of model relationships – to model management of vehicle control system development. Through studying some represen- tative relationships, we build a macromodel based management method and demonstrate its eﬀectiveness using the ﬂow diagrams in a functional architecture model from industry.",
    "keywords": []
  },
  {
    "title": "Detecting Speciﬁcation Errors in Declarative\nLanguages with Constraints",
    "date": 2012,
    "abstract": "Declarative speciﬁcation languages with constraints are used in model-driven engineering to specify formal semantics, deﬁne model transformations, and describe domain constraints. While these languages support concise speciﬁcations, they are nevertheless prone to diﬃcult se- mantic errors. In this paper we present a type-theoretic approach to the static detection of speciﬁcation errors. Our approach infers approx- imations of satisfying assignments and represents them via a canonical regular type system. Type inference is experimentally eﬃcient and type judgments are comprehensible by the user.",
    "keywords": []
  },
  {
    "title": "From UML and OCL\nto Relational Logic and Back",
    "date": 2012,
    "abstract": "Languages like UML and OCL are used to precisely model systems. Complex UML and OCL models therefore represent a crucial part of model-driven development, as they formally specify the main sys- tem properties. Consequently, creating complete and correct models is a critical concern. For this purpose, we provide a lightweight model valida- tion method based on eﬃcient SAT solving techniques. In this paper, we present a transformation from UML class diagram and OCL concepts into relational logic. Relational logic in turn represents the source for advanced SAT-based model instance ﬁnders like Kodkod. This paper fo- cuses on a natural transformation approach which aims to exploit the features of relational logic as directly as possible through straitening the handling of main UML and OCL features. This approach allows us to explicitly beneﬁt from the eﬃcient handling of relational logic in Kodkod and to interpret found results backwards in terms of UML and OCL.",
    "keywords": []
  },
  {
    "title": "On Verifying ATL Transformations\nUsing ‘off-the-shelf’ SMT Solvers",
    "date": 2012,
    "abstract": "MDE is a software development process where models constitute pivotal elements of the software to be built. If models are well-speciﬁed, trans- formations can be employed for various purposes, e.g., to produce ﬁnal code. However, transformations are only meaningful when they are ‘correct’: they must produce valid models from valid input models. A valid model has conformance to its meta-model and fulﬁls its constraints, usually written in OCL. In this paper, we propose a novel methodology to perform automatic, unbounded veriﬁcation of ATL transformations. Its main component is a novel ﬁrst-order semantics for ATL transformations, based on the interpretation of the corresponding rules and their execution semantics as ﬁrst-order predicates. Although, our semantics is not complete, it does cover a signiﬁcant subset of the ATL language. Using this se- mantics, transformation correctness can be automatically veriﬁed with respect to non-trivial OCL pre- and postconditions by using SMT solvers, e.g. Z3 and Yices.",
    "keywords": []
  },
  {
    "title": "ATLTest: A White-Box Test Generation\nApproach for ATL Transformations",
    "date": 2012,
    "abstract": "MDE is being applied to the development of increasingly complex systems that require larger model transformations. Given that the speciﬁcation of such transformations is an error-prone task, techniques to guarantee their quality must be provided. Testing is a well-known technique for ﬁnding errors in programs. In this sense, adop- tion of testing techniques in the model transformation domain would be helpful to improve their quality. So far, testing of model transforma- tions has focused on black-box testing techniques. Instead, in this paper we provide a white-box test model generation approach for ATL model transformations.",
    "keywords": []
  },
  {
    "title": "Empirical Evaluation on FBD Model-Based Test\nCoverage Criteria Using Mutation Analysis",
    "date": 2012,
    "abstract": "Function Block Diagram (FBD), one of the PLC program- ming languages, is a graphical modeling language which has been increas- ingly used to implement safety-critical software such as nuclear reactor protection software. With increased importance of structural testing for FBD models, FBD model-based test coverage criteria have been intro- duced. In this paper, we empirically evaluate the fault detection eﬀective- ness of the FBD coverage criteria using mutation analysis. We produce 1800 test suites satisfying the FBD criteria and generate more than 600 mutants automatically for the target industrial FBD models. Then we evaluate mutant detection of the test suites to assess the fault detection eﬀectiveness of the coverage criteria. Based on the experimental results, we analyze strengths and weaknesses of the FBD coverage criteria, and suggest possible improvements for the test coverage criteria.",
    "keywords": [
      "Function block diagram",
      "mutation analysis",
      "test coverage criteria."
    ]
  },
  {
    "title": "Seeing Errors:\nModel Driven Simulation Trace Visualization",
    "date": 2012,
    "abstract": "Powerful theoretical frameworks exist for model validation and veriﬁcation, yet their use in concrete projects is limited. This is partially due to the fact that the results of model veriﬁcation and sim- ulation are diﬃcult to exploit. This paper reports on a model driven approach that supports the user during the error diagnosis phases, by allowing customizable simulation trace visualization. Our thesis is that we can use models to signiﬁcantly improve the information visualiza- tion during the diagnosis phase. This thesis is supported by Metaviz - a model-driven framework for simulation trace visualization. Metaviz uses the IFx-OMEGA model validation platform and a state-of-the-art information visualization reference model together with a well-deﬁned development process guiding the user into building custom visualiza- tions,essentially by deﬁning model transformations. This approach has the potential to improve the practical usage of modeling techniques and to increase the usability and attractiveness of model validation tools.",
    "keywords": [
      "Software visualization",
      "trace exploration",
      "embedded sys- tems",
      "model based validation",
      "model dynamic analysis."
    ]
  },
  {
    "title": "A Modeling Approach to Support\nthe Similarity-Based Reuse of Conﬁguration Data",
    "date": 2012,
    "abstract": "Product conﬁguration in families of Integrated Control Sys- tems (ICSs) involves resolving thousands of conﬁgurable parameters and is, therefore, time-consuming and error-prone. Typically, these systems consist of highly similar components that need to be conﬁgured similarly. For large-scale systems, a considerable portion of the conﬁguration data can be reused, based on such similarities, during the conﬁguration of each individual product. In this paper, we propose a model-based approach to automate the reuse of conﬁguration data based on the similarities within an ICS product. Our approach enables conﬁguration engineers to manip- ulate the reuse of conﬁguration data, and ensures the consistency of the reused data. Evaluation of the approach, using a number of conﬁgured products from an industry partner, shows that more than 60% of con- ﬁguration data can be automatically reused using our similarity-based approach, thereby reducing conﬁguration eﬀort.",
    "keywords": [
      "Product conﬁguration",
      "Internal similarities",
      "Model-based software engineering",
      "UML/OCL",
      "Feature Modeling."
    ]
  },
  {
    "title": "Model Driven Configuration of Fault Tolerance Solutions \nfor Component-Based Software System",
    "date": 2012,
    "abstract": "Fault tolerance is very important for complex component-based software systems, but its configuration is complicated and challenging. In this paper, we propose a model driven approach to semi-automatic configuration of fault tolerance solutions. At design time, a set of reusable fault tolerance solu- tions are modeled as architecture styles, with the key properties verified by model checking. At runtime, the runtime software architecture of the target sys- tem is automatically constructed by the code generated from the given architec- tural meta-model. Then, the impact of each component on the system reliability is automatically analyzed to recommend which components should be consi- dered in the fault tolerance configuration. Finally, after which components are guaranteed by what fault tolerance solution is decided by the system administra- tion, the architecture model is automatically changed by merging with the selected fault tolerance styles and finally, these changes are automatically propagated to the target system. This approach is evaluated on Java enterprise systems.",
    "keywords": [
      "fault tolerance",
      "component-based system",
      "dynamic configuration",
      "mode driven approach",
      "software architecture."
    ]
  },
  {
    "title": "Applying a Consistency Checking Framework\nfor Heterogeneous Models and Artifacts\nin Industrial Product Lines",
    "date": 2012,
    "abstract": "Product line engineering relies on heterogeneous models and artifacts to deﬁne and implement the product line’s reusable assets. The complexity and heterogeneity of product line artifacts as well as their interdependencies make it hard to maintain consistency during develop- ment and evolution, regardless of the modeling approaches used. Engi- neers thus need support for detecting and resolving inconsistencies within and between the various artifacts. In this paper we present a framework for checking and maintaining consistency of arbitrary product line arti- facts. Our approach is ﬂexible and extensible regarding the supported artifact types and the deﬁnition of constraints. We discuss tool support developed for the DOPLER product line tool suite. We report the re- sults of applying the approach to sales support applications of industrial product lines.",
    "keywords": [
      "Model-based product lines",
      "consistency checking",
      "sales support."
    ]
  },
  {
    "title": "Generation of Operational Transformation Rules\nfrom Examples of Model Transformations",
    "date": 2012,
    "abstract": "Model transformation by example (MTBE) aims at deﬁning a model transformation according to a set of examples of this transforma- tion. Examples are given in the form of pairs, each having an input model and its corresponding output transformed model, with the transforma- tion traces. The transformation rules are then automatically extracted from the examples. In this paper, we propose a two-step approach to gen- erate the transformation rules. In a ﬁrst step, transformation patterns are learned from the examples through a classiﬁcation of the model el- ements of the examples, and a classiﬁcation of the transformation links using Formal Concept Analysis. In a second step, those transformation patterns are analyzed in order to select the more pertinent ones and to transform them into operational transformation rules written for the Jess rule engine. The generated rules are then executed on examples to evaluate their relevance through classical precision/recall measures.",
    "keywords": []
  },
  {
    "title": "Using Feature Model to Build Model\nTransformation Chains",
    "date": 2012,
    "abstract": "Model transformations are intrinsically related to model- driven engineering. According to the increasing size of standardised meta- model, large transformations need to be developed to cover them. Several approaches promote separation of concerns in this context, that is, the deﬁnition of small transformations in order to master the overall com- plexity. Unfortunately, the decomposition of transformations into smaller ones raises new issues: organising the increasing number of transforma- tions and ensuring their composition (i.e. the chaining). In this paper, we propose to use feature models to classify model transformations ded- icated to a given business domain. Based on this feature models, au- tomated techniques are used to support the designer, according to two axis: (i) the deﬁnition of a valid set of model transformations and (ii) the generation of an executable chain of model transformation that ac- curately implement designer’s intention. This approach is validated on Gaspard2, a tool dedicated to the design of embedded system.",
    "keywords": []
  },
  {
    "title": "A Generic Approach Simplifying\nModel-to-Model Transformation Chains",
    "date": 2012,
    "abstract": "The model-driven architecture proposes stepwise model re- ﬁnement. The resulting model-to-model (M2M) transformation chains can consist of many steps. For realizing the transformations two ap- proaches exist: Exogenous transformations, where input and output use diﬀerent metamodels, and endogenous transformations, that use the same metamodel for input and output. Due to the particularities of embedded systems, using only endogenous transformations is not ap- propriate. For exogenous transformations, problems arise with respect to creation and maintenance of the subsequent metamodels. Another problem of these M2M transformation chains is that for one transforma- tion step typically large parts of the model data remain unchanged. The resulting M2M transformation does often include many copy operations that distract the developers from the “real” transformations and increase implementation overhead. This paper introduces a generic approach that solves these issues by a (semi-) automatic metamodel construction and copy operation of unchanged model data between subsequent steps.",
    "keywords": [
      "Transformation Chain",
      "Model-to-Model Transformation",
      "Metamodel-to-Metamodel Transformation",
      "Model-driven Software Development",
      "Model-driven Architecture."
    ]
  },
  {
    "title": "An Approach for Synchronizing UML Models\nand Narrative Text in Literate Modeling",
    "date": 2012,
    "abstract": "A major challenge in adopting UML in industrial environ- ments is the lack of accessibility and comprehensibility of some diagram types by non-technical stakeholders. Literate Modeling improves compre- hension of these diagrams by adding narrative text, but lacks good tool support for synchronizing model and text. This paper presents an ap- proach for keeping model and text synchronized by eﬀectively combining state-of-the-art natural language processing technology with OCL model querying. Thereby, consistency of element names in the UML model with their counterparts in the text is achieved by using text annotations to provide the semantic link. At a structural level, we propose an algorithm that checks element relationships in the UML model using a set of vali- dation constraints when particular sentence characteristics are detected. An analysis of the runtime complexity shows the feasibility of including the proposed solution in one of today’s CASE tools.",
    "keywords": []
  },
  {
    "title": "Model Matching for Trace Link Generation in Model-Driven Software Development",
    "date": 2012,
    "abstract": "With the advent of Model-driven Software Engineering, the advantage of generating trace links between source and target model elements automatically, eases the problem of creating and maintaining traceability data. Yet, an existing transformation engine as in the above case is not always given in model-based development, (i.e. when transfor- mations are implemented manually) and can not be leveraged for the sake of trace link generation through the transformation mapping. We tackle this problem by using model matching techniques to generate trace links for arbitrary source and target models. Thereby, our approach is based on a novel, language-agnostic concept deﬁning three similarity measures for matching. To achieve this, we exploit metamodel matching techniques for graph-based model matching. Furthermore, we evaluate our approach according to large-scale SAP business transformations and the ATL Zoo.",
    "keywords": [
      "Traceability",
      "Model Matching",
      "Software Quality."
    ]
  },
  {
    "title": "Matching Business Process Workﬂows\nacross Abstraction Levels",
    "date": 2012,
    "abstract": "In Business Process Modeling, several models are deﬁned for the same system, supporting the transition from business require- ments to IT implementations. Each of these models targets a diﬀerent abstraction level and stakeholder perspective. In order to maintain con- sistency among these models, which has become a major challenge not only in this ﬁeld, the correspondence between them has to be identiﬁed. A correspondence between process models establishes which activities in one model correspond to which activities in another model. This pa- per presents an algorithm for determining such correspondences. The algorithm is based on an empirical study of process models at a large company in the banking sector, which revealed frequent correspondence patterns between models spanning multiple abstraction levels. The algo- rithm has two phases, ﬁrst establishing correspondences based on similar- ity of model element attributes such as types and names and then reﬁning the result based on the structure of the models. Compared to previous work, our algorithm can recover complex correspondences relating whole process fragments rather than just individual activities. We evaluate the algorithm on 26 pairs of business-technical and technical-IT level mod- els from four real-world projects, achieving overall precision of 93% and recall of 70%. Given the substantial recall and the high precision, the al- gorithm helps automating signiﬁcant part of the correspondence recovery for such models.",
    "keywords": [
      "BPMN Matching",
      "Consistency Management",
      "Change Extraction."
    ]
  },
  {
    "title": "Experiences of Applying UML/MARTE  \non Three Industrial Projects",
    "date": 2012,
    "abstract": "MARTE (Modeling and Analysis of Real-Time and Embedded Sys- tems) is a UML profile, which has been developed to model concepts specific to Real-Time and Embedded Systems (RTES). In previous years, we have applied UML/MARTE to three distinct industrial problems in various industry sectors: architecture modeling and configuration of large-scale and highly configurable integrated control systems, model-based robustness testing of communication- intensive systems, and model-based environment simulator generation of large- scale RTES for testing. In this paper, we report on our experiences of solving these problems by applying UML/MARTE on four industrial case studies. Based on our common experiences, we derive a framework to help practitioners for fu- ture applications of UML/MARTE. The framework provides a set of detailed guidelines on how to apply MARTE in industrial contexts and will help reduce the gap between the modeling standards and industrial needs.",
    "keywords": [
      "UML",
      "MARTE",
      "Real-time Embedded Systems",
      "Architecture  Modeling",
      "Model-based Testing."
    ]
  },
  {
    "title": "Cost Estimation for Model-Driven Engineering",
    "date": 2012,
    "abstract": "Cost estimation studies in model-driven engineering (MDE) are scarce; ﬁrst, due to diﬃculty in quantifying qualitative characteris- tics of MDE that supposedly inﬂuence software development eﬀort and second, due to the complexity of measuring varied artifacts that are gen- erated and used in an end-to-end MDE toolset. A cost estimation ap- proach is therefore needed that can incorporate characteristics of MDE that aﬀect economies of scale and eﬀort in application development with the size computation of various artifacts in MDE. We plan to use the con- structive cost model (COCOMO) II to obtain baseline cost estimation of MDE applications. Our main contributions are a method to capture the qualitative characteristics of MDE in terms of cost drivers in COCOMO II and a method for computation of various artifacts generated by an MDE toolset. Our initial exploration of these ideas suggests that it is possible to automate cost estimation for MDE.",
    "keywords": [
      "Model-driven Engineering",
      "Cost Estimation",
      "COCOMO II."
    ]
  },
  {
    "title": "Evaluating the Effort of Composing Design Models:  \nA Controlled Experiment",
    "date": 2012,
    "abstract": "The lack of empirical knowledge about the effects of model composi- tion techniques on developers’ effort is the key impairment for their widespread adoption in practice. This problem applies to both existing categories of model composition techniques, i.e. specification-based (e.g. Epsilon) and heuristic- based (e.g. IBM RSA) techniques. This paper reports on a controlled experiment that investigates the effort to: (1) apply both categories of model composition techniques, and (2) detect and resolve inconsistencies in the output composed models. The techniques are investigated in 144 evolution scenarios, where 2304 compositions of elements of class diagrams were produced. The results suggest that: (1) the employed heuristic-based techniques require less effort to produce the intended model than the chosen specification-based technique, (2) the cor- rectness of the output composed models generated by the techniques is not sig- nificantly different, and (3) the use of manual heuristics for model composition outperforms their automated counterparts.",
    "keywords": [
      "Model composition effort",
      "empirical studies",
      "effort measurement."
    ]
  },
  {
    "title": "Transition to Model-Driven Engineering What Is Revolutionary, What Remains the Same?",
    "date": 2012,
    "abstract": "A considerable amount of research has been dedicated to bring the vision of model-driven engineering (MDE) to fruition. How- ever, the practical experiences of organizations that transition to MDE are underreported. This paper presents a case study of the organizational consequences experienced by one large organization after transitioning to MDE. We present four ﬁndings from our case study. First, MDE brings development closer to the domain experts, but software engineers are still necessary for many tasks. Second, though MDE presents an opportunity to achieve incremental improvements in productivity, the organizational challenges of software development remain unchanged. Third, switch- ing to MDE may disrupt the balance of the organizational structure, creating morale and power problems. Fourth, the cultural and institu- tional infrastructure of MDE is underdeveloped, and until MDE becomes better established, transitioning organizations need to exert additional adoption eﬀorts. We oﬀer several observations of relevance to researchers and practitioners based on these ﬁndings.",
    "keywords": []
  },
  {
    "title": "Towards an Automatic Service Discovery\nfor UML-Based Rich Service Descriptions",
    "date": 2012,
    "abstract": "Service-oriented computing (SOC) promises to solve many issues in the area of distributed software development, e.g. the realization of the loose coupling pattern in practice through service discovery and in- vocation. For this purpose, service descriptions must comprise structural as well as behavioral information of the services otherwise an accurate service discovery is not possible. We addressed this issue in our previ- ous paper and proposed a UML-based rich service description language (RSDL) providing comprehensive notations to specify service requests and oﬀers.",
    "keywords": []
  },
  {
    "title": "A Product Line Modeling and Configuration \nMethodology to Support Model-Based Testing:  \nAn Industrial Case Study",
    "date": 2012,
    "abstract": "Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to sup- port systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Con- ferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behav- ioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.",
    "keywords": [
      "Aspect-Oriented Modeling",
      "Product Line Engineering",
      "Behavioral  Variability",
      "Model-based Testing",
      "UML State Machine."
    ]
  },
  {
    "title": "Sensitivity Analysis in Model-Driven\nEngineering",
    "date": 2012,
    "abstract": "Sensitivity analysis has been used in scientiﬁc research to ex- plore the validity of models. Software engineering is inherently uncertain; we propose that sensitivity analysis can be used to analyse and quantify the eﬀects of uncertainty when model management operations are applied to models. In this paper, we consider forms and measures of uncertainty in software engineering models. Focusing on data uncertainty, we present a framework for sensitivity analysis, and create an instantiation of the framework for the CATMOS decision-support tool. We show how this can be used to qualify the output of the entailed model management operations and thus improve both the conﬁdence and understanding of models.",
    "keywords": []
  },
  {
    "title": "Modeling and Analysis of CPU Usage in Safety-Critical\nEmbedded Systems to Support Stress Testing",
    "date": 2012,
    "abstract": "Software safety certiﬁcation needs to address non-functional constraints with safety implications, e.g., deadlines, throughput, and CPU and memory usage. In this paper, we focus on CPU usage constraints and provide a framework to support the derivation of test cases that maximize the chances of vi- olating CPU usage requirements. We develop a conceptual model specifying the generic abstractions required for analyzing CPU usage and provide a mapping between these abstractions and UML/MARTE. Using this model, we formulate CPU usage analysis as a constraint optimization problem and provide an imple- mentation of our approach in a state-of-the-art optimization tool. We report an application of our approach to a case study from the maritime and energy do- main. Through this case study, we argue that our approach (1) can be applied with a practically reasonable overhead in an industrial setting, and (2) is effective for identifying test cases that maximize CPU usage.",
    "keywords": []
  },
  {
    "title": "Weaving-Based Conﬁguration and Modular Transformation of Multi-layer Systems⋆",
    "date": 2012,
    "abstract": "In model-driven development of multi-layer systems (e.g. application, platform and infrastructure), each layer is usually described by separate models. When generating analysis models or code, these separate models ﬁrst of all need to be linked. Hence, existing model transformations for single layers cannot be simply re-used.",
    "keywords": []
  },
  {
    "title": "Research-Based Innovation: A Tale of Three\nProjects in Model-Driven Engineering",
    "date": 2012,
    "abstract": "In recent years, we have been exploring ways to foster a closer collaboration between software engineering research and industry both to align our research with practical needs, and to increase awareness about the importance of research for innovation. This paper outlines our expe- rience with three research projects conducted in collaboration with the industry. We examine the way we collaborated with our industry part- ners and describe the decisions that contributed to the eﬀectiveness of the collaborations. We report on the lessons learned from our experience and illustrate the lessons using examples from the three projects. The lessons focus on the applications of Model-Driven Engineering (MDE), as all the three projects we draw on here were MDE projects. Our goal from structuring and sharing our experience is to contribute to a better understanding of how researchers and practitioners can collaborate more eﬀectively and to gain more value from their collaborations.",
    "keywords": []
  },
  {
    "title": "An Industrial System Engineering Process\nIntegrating Model Driven Architecture and\nModel Based Design",
    "date": 2012,
    "abstract": "We present an industrial model-driven engineering process for the design and development of complex distributed embedded systems. We outline the main steps in the process and the evaluation of its use in the context of a radar application. We show the meth- ods and tools that have been developed to allow interoperability among requirements management, SysML modeling and MBD simulation and code generation.",
    "keywords": [
      "System Engineering",
      "Model-Driven Architecture",
      "Model- Based Design",
      "Platform-Based Design."
    ]
  },
  {
    "title": "The Magic of Software",
    "date": 2013,
    "abstract": "Software allows for many models of computation. We cre- ate models to understand and reason about these computations (e.g., did the aircraft change its course because there was a hill in front of it or because a model indicated the presence of a hill?). As computers and software become more and more ubiquitous, the tangible world and computer models of the world are merging. We are re-designing our basic systems from networks, cars and aircrafts, to ﬁnancial and health sys- tems to reduce their costs and increase their eﬀectiveness using software that, by necessity, must incorporate a model of the environment and its characteristics. Models can also take us outside of this reality and let us explore alternative timelines — what we call simulation. Today, pro- gramming languages are the primary way to communicate our intentions of these systems in software. Notation, syntax and semantics make the mental programming language models concrete for us as humans. But the computer does not really need the notation, syntax and semantics models of the software in the same way as we humans do. In this talk, we will trace the magic of software that enabled this progression from Moore’s law, through computer languages, to the Digital Artifacts of today. We will investigate it carefully and come to some surprising con- clusions that question the mainstream thinking around software models. What if we let go of some of our learned beliefs about software models and think diﬀerently about models of instructing computers?",
    "keywords": []
  },
  {
    "title": "Model-Based Development of Software:\nA Panacea or Academic Poppycock",
    "date": 2013,
    "abstract": "In recent years, the use of models in developing complex soft- ware systems has been steadily increasing. Advocates of model-based de- velopment argue that models can help reduce the time, cost, and eﬀort needed to build software systems which satisfy their requirements and that model-based approaches are eﬀective not only in system develop- ment but throughout a system’s life-time. Thus the problem addressed by researchers in software and system modeling encompasses not only the original construction of a complex system but its complete life-cycle. This talk will address signiﬁcant issues in model-based system and software development, including: What is the current and future role of models in software system development? What beneﬁts can we obtain from the use of models not only in development but throughout the system life-cycle? What are the barriers to using models in software system development and evolution? What are the major challenges for system and software modeling researchers during the next decade?",
    "keywords": []
  },
  {
    "title": "Creativity vs Rigor:\nInformal Modeling is OK",
    "date": 2013,
    "abstract": "Single large project courses with clients from industry have been established as capstone courses in many software engineering cur- ricula. They are considered a good way of teaching industry relevant software engineering practices, in particular model-based software devel- opment. One particular challenge is how to balance between modeling and timely delivery. If we focus too much on modeling, the students do not have enough time to deliver the system (“analysis paralysis”). If we focus too much on the delivery of the system, the quality of the models usually goes down the drain. Another challenge is the balance between informal models intended for human communication and speciﬁcation models in- tended for CASE tools. I argue that teachers often put too much weight on the rigor of the models, and less on the creative and iterative aspects of modeling. Modeling should be allowed to be informal, incomplete and inconsistent, especially during the early phases of software development. I have been teaching capstone courses for almost 25 years, initially at the senior and junior level. During this time excellent automatic build and release management tools have been developed. They reduce the need for heroic delivery eﬀorts at the end of a course, especially if they are coupled with agile methods, allowing the teacher to spend more time on the creative aspects of modeling. I will use several examples from my courses to demonstrate how it is possible to include informal mod- eling techniques in project courses with real customers involving a large number of students at the sophomore and even freshmen level without compromising the ideas of model-driven software development.",
    "keywords": []
  },
  {
    "title": "Industrial Adoption of Model-Driven\nEngineering: Are the Tools Really the Problem?",
    "date": 2013,
    "abstract": "An oft-cited reason for lack of adoption of model-driven en- gineering (MDE) is poor tool support. However, studies have shown that adoption problems are as much to do with social and organizational fac- tors as with tooling issues. This paper discusses the impact of tools on MDE adoption and places tooling within a broader organizational con- text. The paper revisits previous data on MDE adoption (19 in-depth interviews with MDE practitioners) and re-analyzes the data through the speciﬁc lens of MDE tools. In addition, the paper presents new data (20 new interviews in two speciﬁc companies) and analyzes it through the same lens. The key contribution of the paper is a taxonomy of tool-related considerations, based on industry data, which can be used to reﬂect on the tooling landscape as well as inform future research on MDE tools.",
    "keywords": [
      "model-driven engineering",
      "modeling tools",
      "organizational change."
    ]
  },
  {
    "title": "Generic Model Assist",
    "date": 2013,
    "abstract": "Model assist is a feature of modelling environments aiding their users with entering well-formed models into an editor. Current implementations of model assist are mostly hard-coded in the editor and duplicate the logic captured in the environment’s validation methods used for post hoc checking of models for well-formedness. We propose a fully declarative approach which computes legal model assists from a modelling language’s well-formedness rules via constraint solving, covering a large array of assistance scenarios with only minor differences in the assistance specifications. We describe an implementation of our approach and evaluate it on 299 small to medium size open source models. Although more research will be needed to explore the boundaries of our approach, first results presented here suggest that it is feasible.",
    "keywords": []
  },
  {
    "title": "Adding Spreadsheets to the MDE Toolkit",
    "date": 2013,
    "abstract": "Spreadsheets are widely used to support software develop- ment activities. They have been used to collect requirements and soft- ware defects, to capture traceability information between requirements and test cases, and in general, to ﬁll in gaps that are not covered satis- factorily by more specialised tools. Despite their widespread use, spread- sheets have received little attention from researchers in the ﬁeld of Model Driven Engineering. In this paper, we argue for the usefulness of model management support for querying and modifying spreadsheets, we iden- tify the conceptual gap between contemporary model management lan- guages and spreadsheets, and we propose an approach for bridging it. We present a prototype that builds atop the Epsilon and Google Drive plat- forms and we evaluate the proposed approach through a case study that involves validating and transforming software requirements captured us- ing spreadsheets.",
    "keywords": []
  },
  {
    "title": "Model-Driven Extraction\nand Analysis of Network Security Policies",
    "date": 2013,
    "abstract": "Firewalls are a key element in network security. They are in charge of ﬁltering the traﬃc of the network in compliance with a number of access-control rules that enforce a given security policy. In an always-evolving context, where security policies must often be up- dated to respond to new security requirements, knowing with precision the policy being enforced by a network system is a critical information. Otherwise, we risk to hamper the proper evolution of the system and compromise its security. Unfortunately, discovering such enforced policy is an error-prone and time consuming task that requires low-level and, often, vendor-speciﬁc expertise since ﬁrewalls may be conﬁgured using diﬀerent languages and conform to a complex network topology. To tackle this problem, we propose a model-driven reverse engineering approach able to extract the security policy implemented by a set of ﬁrewalls in a working network, easing the understanding, analysis and evolution of network security policies.",
    "keywords": []
  },
  {
    "title": "SafetyMet: A Metamodel for Safety Standards",
    "date": 2013,
    "abstract": "In domains such as automotive, avionics, and railway, critical systems must comply with safety standards to allow their operation in a given context. Safety compliance can be an extremely demanding activity as practitioners have to show fulfilment of the safety criteria specified in the standards and thus that a system can be deemed safe. This is usually both costly and time consuming, and becomes even more challenging when, for instance, a system changes or aims to be reused in another project or domain. This paper presents SafetyMet, a metamodel for safety standards targeted at facilitating safety compliance. The metamodel consists of entities and relationships that abstract concepts common to different safety standards from different domains. Its use can help practitioners to show how they have followed the recommendations of a standard, and particularly in evolutionary or cross- domain scenarios. We discuss the benefits of the use of the metamodel, its limitations, and open issues in order to clearly present the aspects of safety compliance that are facilitated and those that are not addressed.",
    "keywords": [
      "safety standard",
      "metamodel",
      "safety compliance",
      "safety assurance",
      "safety certification",
      "SafetyMet",
      "OPENCOSS."
    ]
  },
  {
    "title": "A Generic Fault Model for Quality Assurance",
    "date": 2013,
    "abstract": "Because they are comparatively easy to implement, structural coverage criteria are commonly used for test derivation in model- and code- based testing. However, there is a lack of compelling evidence that they are useful for ﬁnding faults, speciﬁcally so when compared to random testing. This paper challenges the idea of using coverage criteria for test selection and instead proposes an approach based on fault models. We deﬁne a gen- eral fault model as a transformation from correct to incorrect programs and/or a partition of the input data space. Thereby, we leverage the idea of fault injection for test assessment to test derivation. We instantiate the developed general fault model to describe existing fault models. We also show by example how to derive test cases.",
    "keywords": []
  },
  {
    "title": "Towards an Operationalization of the “Physics of Notations” for the Analysis of Visual Languages",
    "date": 2013,
    "abstract": "We attempt to validate the conceptual framework “Physics of Notation” (PoN) as a means for analysing visual languages by ap- plying it to UML Use Case Diagrams. We discover that the PoN, in its current form, is neither precise nor comprehensive enough to be applied in an objective way to analyse practical visual software engineering no- tations. We propose an operationalization of a part of the PoN, highlight conceptual shortcomings of the PoN, and explore ways to address them.",
    "keywords": []
  },
  {
    "title": "Teaching Model Driven Engineering\nfrom a Relational Database Perspective",
    "date": 2013,
    "abstract": "We reinterpret MDE from the viewpoint of relational databases to provide an alternative way to teach, understand, and demonstrate MDE using concepts and technologies that should be familiar to undergraduates. We use (1) relational databases to express models and metamodels, (2) Prolog to express con- straints and M2M transformations, (3) Java tools to implement M2T and T2M transformations, and (4) OO shell-scripting languages to compose MDE transfor- mations. Case studies demonstrate the viability of our approach.",
    "keywords": []
  },
  {
    "title": "Big Metamodels Are Evil Package Unmerge –– A Technique for Downsizing Metamodels",
    "date": 2013,
    "abstract": "While reuse is typically considered a good practice, it may also lead to keeping irrelevant concerns in derived elements. For instance, new metamodels are usually built upon existing metamodels using additive techniques such as profiling and package merge. With such additive techniques, new metamodels tend to become bigger and bigger, which leads to harmful overheads of com- plexity for both tool builders and users. In this paper, we introduce «package unmerge» - a proposal for a subtractive relation between packages - which complements existing metamodel-extension techniques.",
    "keywords": []
  },
  {
    "title": "Integrating Modeling Tools  \nin the Development Lifecycle with OSLC: A Case Study",
    "date": 2013,
    "abstract": "Models play a central role in a model driven development process. They realize requirements, specify system design, abstract source code, drive test cases, etc. However, for a modeling tool to be most effective, it needs to integrate its data and workflows with other tools in the development lifecycle. This is often problematic as these tools are usually disparate. OSLC is an emerging specification for integrating lifecycle tools using the principles of linked data. In this paper, we describe how OSLC can be used to integrate MOF-based modeling tools with other lifecycle tools. We demonstrate this in a case study involving an EMF-based modeling tool. We show how we made the tool conform to the OSLC specification and discuss how this enabled it to integrate seamlessly with other lifecycle tools to support some key end-to-end development lifecycle workflows.",
    "keywords": [
      "Model",
      "Lifecycle",
      "OSLC",
      "Semantic Web",
      "OWL",
      "RDF",
      "UML",
      "MOF."
    ]
  },
  {
    "title": "Recommending Auto-completions\nfor Software Modeling Activities",
    "date": 2013,
    "abstract": "Auto-completion of textual inputs beneﬁts software develop- ers using IDEs. However, graphical modeling tools used to design software do not provide this functionality. The challenges of recommending auto- completions for graphical modeling activities are largely unexplored. Rec- ommending such auto-completions requires detecting meaningful partly completed activities, tolerating variance in user actions, and determining most relevant activities that a user wants to perform. This paper proposes an approach that works in the background while a developer is creating or evolving models and handles all these challenges. Editing operations are analyzed and matched to a predeﬁned but extensible catalog of common modeling activities for structural UML models. In this paper we solely focus on determining recommendations rather than automatically com- pleting activities. We demonstrated the quality of recommendations generated by our approach in a controlled experiment with 16 students evolving models. We recommended 88% of a user’s activities within a short list of ten recommendations.",
    "keywords": []
  },
  {
    "title": "Automatically Searching for Metamodel Well-Formedness Rules in Examples and Counter-Examples",
    "date": 2013,
    "abstract": "Current metamodeling formalisms support the deﬁnition of a metamodel with two views: classes and relations, that form the core of the metamodel, and well-formedness rules, that constraints the set of valid models. While a safe application of automatic operations on mod- els requires a precise deﬁnition of the domain using the two views, most metamodels currently present in repositories have only the ﬁrst one part. In this paper, we propose to start from valid and invalid model examples in order to automatically retrieve well-formedness rules in OCL using Ge- netic Programming. The approach is evaluated on metamodels for state machines and features diagrams. The experiments aim at demonstrating the feasibility of the approach and at illustrating some important design decisions that must be considered when using this technique.",
    "keywords": []
  },
  {
    "title": "Testing M2T/T2M Transformations",
    "date": 2013,
    "abstract": "Testing model-to-model (M2M) transformations is becoming a promi- nent topic in the current Model-driven Engineering landscape. Current approaches for transformation testing, however, assume having explicit model representa- tions for the input domain and for the output domain of the transformation. This excludes other important transformation kinds, such as model-to-text (M2T) and text-to-model (T2M) transformations, from being properly tested since adequate model representations are missing either for the input domain or for the output domain. The contribution of this paper to overcome this gap is extending Tracts, a M2M transformation testing approach, for M2T/T2M transformation testing. The main mechanism we employ for reusing Tracts is to represent text within a generic metamodel. By this, we transform the M2T/T2M transformation spec- iﬁcation problems into equivalent M2M transformation speciﬁcation problems. We demonstrate the applicability of the approach by two examples and present how the approach is implemented for the Eclipse Modeling Framework (EMF). Finally, we apply the approach to evaluate code generation capabilities of several existing UML tools.",
    "keywords": []
  },
  {
    "title": "An Approach to Testing Java Implementation  \nagainst Its UML Class Model",
    "date": 2013,
    "abstract": "Model Driven Engineering (MDE) aims to expedite the software de- velopment process by providing support for transforming models to running systems. Many modeling tools provide forward engineering features that auto- matically translate a model into a skeletal program that developers must com- plete. Inconsistencies between a design model and its implementation can result as a consequence of manually-added code. Manually checking that an imple- mentation conforms to the model is a daunting task. Thus, there is a need for MDE tools that developers can use to check whether an implementation con- forms to a model, especially when generated code is manually modified. This paper presents an approach for testing that an implementation satisfies the con- straints specified in its design model. We also describe a prototypical tool that supports the approach, and we describe how its application to two Eclipse UML2 projects uncovered errors.",
    "keywords": [
      "UML",
      "Class diagram",
      "Java",
      "Model checking."
    ]
  },
  {
    "title": "Automated Test Case Selection Using Feature Model:  \nAn Industrial Case Study",
    "date": 2013,
    "abstract": "Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objec- tive of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodol- ogy using a Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line and a Component Family Model for Testing (CFM_T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the re- pository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM_T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We applied our methodology to a product line of video confe- rencing systems called Saturn developed by Cisco and the results show that our methodology can reduce the selection effort significantly. Moreover, we con- ducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM_T and CFM_T. The results show that test en- gineers are positive about adapting our methodology and models (FM_T and CFM_T) in their current practice.",
    "keywords": [
      "Test Case Selection",
      "Product Line",
      "Feature Model",
      "Component  Family Model."
    ]
  },
  {
    "title": "Customizable Model Migration Schemes for Meta-model Evolutions with Multiplicity Changes⋆",
    "date": 2013,
    "abstract": "Modeling languages tailored to speciﬁc application domains promise to increase the productivity and quality of model-driven soft- ware development. Nevertheless due to, for example, evolving require- ments, modeling languages, and their meta-models evolve which means that existing models have to be migrated accordingly. In our approach, such co-evolutions are speciﬁed as related graph transformations ensur- ing well-typed model migration results. Model migrations are speciﬁed by transformation rules that can be automatically deduced from given meta-model evolution rules and further customized to special needs. Up to now, meta-model constraints have not been taken into account. In this paper, we extend our approach to handle multiplicity constraints and illustrate this extension using several examples.",
    "keywords": [
      "meta-model evolution",
      "model migration",
      "graph transforma- tion."
    ]
  },
  {
    "title": "Fine-Grained Software Evolution\nUsing UML Activity and Class Models",
    "date": 2013,
    "abstract": "Modern software systems that play critical roles in society’s infrastructures are often required to change at runtime so that they can continuously provide essential services in the dynamic environments they operate in. Updating open, distributed software systems at runtime is very challenging. Using runtime models as an interface for updating soft- ware at runtime can help developers manage the complexity of updating software while it is executing. In this work we describe an approach to updating Java software at runtime through the use of runtime models consisting of UML class and activity diagrams. Changes to models are turned into changes on Java source code, which is then propagated to the runtime system using the JavAdaptor technology. In particular, the pre- sented approach permits in-the-small software changes, i.e., changes at the code statement level, as opposed to in-the-large changes, i.e., changes at the component level. We present a case study that demonstrates the major aspects of the approach and its use.",
    "keywords": []
  },
  {
    "title": "Supporting the Co-evolution of Metamodels\nand Constraints through Incremental Constraint\nManagement",
    "date": 2013,
    "abstract": "Design models must abide by constraints that can come from diverse sources, like metamodels, requirements, or the problem domain. Modelers intent to live by these constraints and thus desire automated mechanism that provide instant feedback on constraint violations. How- ever, typical approaches assume that constraints do not evolve over time, which, unfortunately, is becoming increasingly unrealistic. For example, the co-evolution of metamodels and models requires corresponding con- straints to be co-evolved continuously. This demands eﬃcient constraint adaptation mechanisms to ensure that validated constraints are up-to- date. This paper presents an approach based on constraint templates that tackles this evolution scenario by automatically updating constraints. We developed the Cross-Layer Modeler (XLM) approach which relies on in- cremental consistency-checking. As a case study, we performed evolutions of the UML-metamodel and 21 design models. Our approach is sound and the empirical evaluation shows that it is near instant and scales with increasing model sizes.",
    "keywords": [
      "Co-evolution",
      "metamodeling",
      "consistency-checking."
    ]
  },
  {
    "title": "Model Checking of UML-RT Models Using Lazy Composition",
    "date": 2013,
    "abstract": "Formal analysis of models is an important aspect of the Model Driven Development (MDD) paradigm. In this paper we intro- duce a technique to analyze models with hierarchically organized and asynchronously communicating components as found in, e.g., UML-RT. Typically, the more components are composed during analysis, the less scalable it becomes. In our technique we reduce composition by lever- aging the communication topology and the property to be checked. To this end we introduce an extension of Computation Tree Logic (CTL) to express properties of models and we show an algorithm to check such properties. In the algorithm, components are represented by their sym- bolic execution trees and their composition is lazy, i.e., only performed when necessary. To demonstrate some of the beneﬁts of the technique, its implementation for UML-RT models and case studies are discussed.",
    "keywords": []
  },
  {
    "title": "Behavioural Veriﬁcation in Embedded Software, from Model to Source Code",
    "date": 2013,
    "abstract": "To reduce the veriﬁcation costs and to be more conﬁdent on software, static program analysis oﬀers ways to prove properties on source code. Unfortunately, these techniques are diﬃcult to apprehend and to use for non-specialists. Modelling allows users to specify some aspects of software in an easy way. More precisely, in embedded soft- ware, state machine models are frequently used for behavioural design. The aim of this paper is to bridge the gap between model and code by oﬀering automatic generation of annotations from model to source code. These annotations are then veriﬁed by static analysis in order to ensure that the code behaviour conforms to the model-based design. The mod- els we consider are UML state machines with a formal non-ambiguous semantics, the annotation generation and veriﬁcation is implemented in a tool and applied to a case study.",
    "keywords": [
      "Veriﬁcation",
      "UML",
      "Formal Methods",
      "Model Driven Engi- neering."
    ]
  },
  {
    "title": "Formal Veriﬁcation Integration Approach for DSML⋆",
    "date": 2013,
    "abstract": "The application of formal methods (especially, model check- ing and static analysis techniques) for the veriﬁcation of safety critical embedded systems has produced very good results and raised the inter- est of system designers up to the application of these technologies in real size projects. However, these methods usually rely on speciﬁc veriﬁca- tion oriented formal languages that most designers do not master. It is thus mandatory to embed the associated tools in automated veriﬁcation toolchains that allow designers to rely on their usual domain-speciﬁc modeling languages (DSMLs) while enjoying the beneﬁts of these power- ful methods. More precisely, we propose a language to formally express system requirements and interpret veriﬁcation results so that system designers (DSML end-users) avoid the burden of learning some formal veriﬁcation technologies. Formal veriﬁcation is achieved through trans- lational semantics. This work is based on a metamodeling pattern for executable DSML that favors the deﬁnition of generative tools and thus eases the integration of tools for new DSMLs.",
    "keywords": [
      "Domain speciﬁc modeling language",
      "Formal veriﬁcation",
      "Model checking",
      "Translational semantics",
      "Traceability",
      "Veriﬁcation feedback."
    ]
  },
  {
    "title": "Composing Your Compositions\nof Variability Models",
    "date": 2013,
    "abstract": "Modeling and managing variability is a key activity in a growing number of software engineering contexts. Support for composing variability models is arising in many engineering scenarios, for instance, when several subsystems or modeling artifacts, each coming with their own variability and possibly developed by diﬀerent stakeholders, should be combined together. In this paper, we consider the problem of com- posing feature models (FMs), a widely used formalism for representing and reasoning about a set of variability choices. We show that several composition operators can actually be deﬁned, depending on both match- ing/merging strategies and semantic properties expected in the composed FM. We present four alternative forms and their implementations. We discuss their relative trade-oﬀs w.r.t. reasoning, customizability, trace- ability, composability and quality of the resulting feature diagram. We summarize these ﬁndings in a reading grid which is validated by revisiting some relevant existing works. Our contribution should assist developers in choosing and implementing the right composition operators.",
    "keywords": []
  },
  {
    "title": "Constraints: The Core of Supporting Automated Product \nConfiguration of Cyber-Physical Systems*",
    "date": 2013,
    "abstract": "In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration solution, based on our experience of studying three industrial product lines.",
    "keywords": [
      "Product  Line  Engineering",
      "Configuration",
      "Constraints",
      "Classification",
      "Industrial Case Studies",
      "Cyber-Physical Systems."
    ]
  },
  {
    "title": "Defining and Validating a Multimodel Approach  \nfor Product Architecture Derivation and Improvement",
    "date": 2013,
    "abstract": "Software architectures are the key to achieving the non-functional requirements (NFRs) in any software project. In software product line (SPL) development, it is crucial to identify whether the NFRs for a specific product can be attained with the built-in architectural variation mechanisms of the product line architecture, or whether additional architectural transformations are required. This paper presents a multimodel approach for quality-driven product architecture derivation and improvement (QuaDAI). A controlled experiment is also presented with the objective of comparing the effectiveness, efficiency, perceived ease of use, intention to use and perceived usefulness with regard to participants using QuaDAI as opposed to the Architecture Tradeoff Analysis Method (ATAM). The results show that QuaDAI is more efficient and perceived as easier to use than ATAM, from the perspective of novice software architecture evaluators. However, the other variables were not found to be statistically significant. Further replications are needed to obtain more conclusive results.",
    "keywords": [
      "Software Product Lines",
      "Architectural Patterns",
      "Quality Attributes",
      "Model Transformations",
      "Controlled Experiment."
    ]
  },
  {
    "title": "Evolution of the UML Interactions Metamodel",
    "date": 2013,
    "abstract": "UML Interactions represent one of the three different behavior kinds of the UML. In general, they specify the exchange of messages among parts of a system. Although UML Interactions can reside on different level of abstractions, they seem to be sufficiently elaborated for a higher-level of abstraction where they are used for sketching the communication among parts. Its metamodel reveals some fuzziness and imprecision where definitions should be accurate and concise, though. In this paper, we propose improvements to the UML Interactions’ metamodel for Message arguments and Loop CombinedFragments that make them more versatile. We will justify the needs for the improvements by precisely showing the shortcomings of the related parts of the metamodel. We demonstrate the expressiveness of the improvements by applying them to examples that current Interactions definition handles awkwardly.",
    "keywords": [
      "UML",
      "Interactions",
      "Sequence  Diagram",
      "Messages",
      "CombinedFragments."
    ]
  },
  {
    "title": "A Graph-Pattern Based Approach for Meta-Model \nSpecific Conflict Detection in a General-Purpose Model \nVersioning System",
    "date": 2013,
    "abstract": "Model driven engineering is the key paradigm in many large system development efforts today. A good versioning system for models is essential for change management and coordinated development of these systems. Support for conflict detection and reconciliation is one of the key functionalities of a versioning system. A large system uses a large number of different kinds of models, each specifying a different aspect of the system. The notion of conflict is relative to the semantics of a meta-model. Hence conflicts should be detected and reported in a meta-model specific way. In this paper we discuss a general purpose model versioning system that can work with models of any meta-model, and a graph-pattern based approach for specifying conflicts in a meta-model specific way. We also present an efficient algorithm that uses these graph-patterns to detect conflicts at the right level of abstraction.",
    "keywords": [
      "Model driven engineering",
      "Model versioning",
      "Meta-model."
    ]
  },
  {
    "title": "On the Complex Nature of MDE Evolution",
    "date": 2013,
    "abstract": "In Model-Driven Engineering (MDE) the employed setting of languages as well as automated and manual activities has major impact on productivity. Furthermore, such settings for MDE evolve over time. However, currently only the evolution of (modeling) languages, tools, and transformations is studied in research. It is not clear whether these are the only relevant changes that characterize MDE evolution in practice. In this paper we address this lack of knowledge. We ﬁrst discuss possible changes and then report on a ﬁrst study that demonstrates that these forms of evolution can be commonly observed in practice. To investigate the complex nature of MDE evolution in more depth, we captured the evolution of three MDE settings from practice and derive eight observa- tions concerning reasons for MDE evolution. Based on the observations we then identify open research challenge concerning MDE evolution.",
    "keywords": []
  },
  {
    "title": "Simpliﬁcation and Correctness of UML Class Diagrams – Focusing on Multiplicity and Aggregation/Composition Constraints",
    "date": 2013,
    "abstract": "Model-driven Engineering requires eﬃcient powerful methods for verifying model correctness and quality. Class Diagram is the central language within UML. Its main problems involve correctness problems, which include the consistency and the ﬁnite satisﬁability problems, and quality problems, which include the redundancy and incomplete design problems. Two central constraints in class diagrams are the multiplicity and the aggregation/composition constraints. They are essential in mod- eling conﬁguration management, features, biology, computer-aided design and database systems.",
    "keywords": []
  },
  {
    "title": "Speciﬁcation of Cyber-Physical Components\nwith Formal Semantics –\nIntegration and Composition",
    "date": 2013,
    "abstract": "Model-Based Engineering of Cyber-Physical Systems (CPS) needs correct-by-construction design methodologies, hence CPS model- ing languages require mathematically rigorous, unambiguous, and sound speciﬁcations of their semantics. The main challenge is the formaliza- tion of the heterogeneous composition and interactions of CPS systems. Creating modeling languages that support both the acausal and causal modeling approaches, and which has well-deﬁned and sound behavior across the heterogeneous time domains is a challenging task. In this pa- per, we discuss the diﬃculties and as an example develop the formal semantics of a CPS-speciﬁc modeling language called CyPhyML. We formalize the structural semantics of CyPhyML by means of constraint rules and its behavioral semantics by deﬁning a semantic mapping to a language for diﬀerential algebraic equations. The speciﬁcation language is based on an executable subset of ﬁrst-order logic, which facilitates model conformance checking, model checking and model synthesis.",
    "keywords": [
      "Cyber-Physical Systems",
      "formalization",
      "formal speciﬁcation",
      "Model-Based Engineering",
      "heterogeneous composition."
    ]
  },
  {
    "title": "Endogenous Metamodeling Semantics\nfor Structural UML 2 Concepts",
    "date": 2013,
    "abstract": "A lot of work has been done in order to put the Uniﬁed Mod- eling Language (UML) on a formal basis by translating concepts into var- ious formal languages, e.g., set theory or graph transformation. While the abstract UML syntax is deﬁned by using an endogenous approach, i. e., UML describes its abstract syntax using UML, this approach is rarely used for its semantics. This paper shows how to apply an endogenous approach called metamodeling semantics for central parts of the UML standard. To this end, we enrich existing UML language elements with constraints speciﬁed in the Object Constraint Language (OCL) in order to describe a semantic domain model. The UML speciﬁcation explicitly states that complete runtime semantics is not included in the standard because it would be a major amount of work. However, we believe that certain central concepts, like the ones used in the UML standard and in particular property features as subsets, union and derived, need to be explicitly modeled to enforce a common understanding. Using such an endogenous approach enables the validation and veriﬁcation of the UML standard by using oﬀ-the-shelf UML and OCL tools.",
    "keywords": [
      "Metamodeling",
      "Semantics",
      "Validation",
      "UML",
      "OCL."
    ]
  },
  {
    "title": "Computer Assisted Integration of Domain-Specific \nModeling Languages Using Text Analysis Techniques",
    "date": 2013,
    "abstract": "Following the principle of separation of concerns, the Model-driven Engineering field has developed Domain-Specific Modeling Languages (DSML) to address the increasing complexity of the systems design. In this context of heterogeneous modeling languages, engineers and language design- ers are facing the critical problem of language integration. To address this problem, instead of doing a syntactic analysis based on the domain models or metamodels as it is common practice today, we propose to adopt natural lan- guage processing techniques to do a semantic analysis of the language specifi- cations. We evaluate empirically our approach on seven real test cases and compare our results with five state of the art tools. Results show that the seman- tic analysis of textual descriptions that accompany DSMLs can efficiently assist engineers to make well-informed integration choices.",
    "keywords": []
  },
  {
    "title": "Towards the Notation-Driven\nDevelopment of DSMLs",
    "date": 2013,
    "abstract": "Domain-Speciﬁc Modeling Languages (DSML) enable domain experts to leverage Model-Driven Engineering methods and tools through concepts and notations from their own domain. The notation of a DSML is critical because it is the sole interface domain experts will have with their tool. Unfortunately, the current process for the development of DSMLs strongly emphasizes the abstract syntaxes and often treats the notations (concrete syntaxes) as byproducts. Focusing on the case of visual DSMLs, this paper proposes to automatically generate a DSML’s abstract syntax from the speciﬁcation of its concrete syntax. This shift towards the notation-driven development of DSMLs is expected to en- able the production of DSMLs closer to domain experts’ expectations. This approach is validated by its implementation in a prototype, its ap- plication on an industrial case and the results of an empirical study.",
    "keywords": [
      "Domain-Speciﬁc Modeling",
      "Visual Languages."
    ]
  },
  {
    "title": "Validation of Derived Features and Well-Formedness Constraints in DSLs⋆ By Mapping Graph Queries to an SMT-Solver",
    "date": 2013,
    "abstract": "Despite the wide range of existing generative tool support, constructing a design environment for a complex domain-speciﬁc lan- guage (DSL) is still a tedious task as the large number of derived features and well-formedness constraints complementing the domain metamodel necessitate special handling. Incremental model queries as provided by the EMF-IncQuery framework can (i) uniformly specify derived features and well-formedness constraints and (ii) automatically refresh their re- sult set upon model changes. However, for complex domains, derived features and constraints can be formalized incorrectly resulting in in- complete, ambiguous or inconsistent DSL speciﬁcations. To detect such issues, we propose an automated mapping of EMF metamodels enriched with derived features and well-formedness constraints captured as graph queries in EMF-IncQuery into an eﬀectively propositional fragment of ﬁrst-order logic which can be eﬃciently analyzed by the Z3 SMT-solver. Moreover, overapproximations are proposed for complex query features (like transitive closure and recursive calls). Our approach will be illus- trated on analyzing a DSL being developed for the avionics domain.",
    "keywords": [
      "model validation",
      "model queries",
      "SMT-solvers."
    ]
  },
  {
    "title": "Self-adaptation with End-User Preferences:\nUsing Run-Time Models and Constraint Solving⋆",
    "date": 2013,
    "abstract": "This paper presents an approach to developing self-adaptive systems that takes the end users’ preferences into account for adaptation planning, while tolerating incomplete and conﬂicting adaptation goals. The approach transforms adaptation goals, together with the run-time model that describes current system contexts and conﬁgurations, into a constraint satisfaction problem. From that, it diagnoses the conﬂicting adaptation goals to ignore, and determines the required re-conﬁguration that satisﬁes all remaining goals. If users do not agree with the solution, they can revise some conﬁguration values. The approach records their preferences embedded in the revisions by tuning the weights of existing goals, so that subsequent adaptation results will be closer to the users’ preferences. The experiments on a medium-sized simulated smart home system show that the approach is eﬀective and scalable.",
    "keywords": []
  },
  {
    "title": "Runtime Model Based Management  \nof Diverse Cloud Resources",
    "date": 2013,
    "abstract": "Due to the diversity of resources and different management require- ments, Cloud management is faced with great challenges in complexity and dif- ficulty. For constructing a management system to satisfy a specific management requirement, a redevelopment solution based on existing system is usually more practicable than developing the system from scratch. However, the difficulty and workload of redevelopment are very high. In this paper, we present a run- time model based approach to managing diverse Cloud resources. First, we con- struct the runtime model of each kind of Cloud resources. Second, we construct the composite runtime model of all managed resources through model merge. Third, we make Cloud management meet personalized requirements through model transformation from the composite model to the customized models. Fi- nally, all the management tasks can be carried out through executing operating programs on the customized model. The feasibility and efficiency of the ap- proach are validated through a real case study.",
    "keywords": [
      "runtime model",
      "Cloud management",
      "diverse Cloud resources."
    ]
  },
  {
    "title": "The Semantic Web as a Software Modeling Tool:\nAn Application to Citizen Relationship\nManagement",
    "date": 2013,
    "abstract": "The choice of a modeling language in software engineering is traditionally restricted to the tools and meta-models invented specif- ically for that purpose. On the other hand, semantic web standards are intended mainly for modeling data, to be consumed or produced by soft- ware. However, both spaces share enough commonality to warrant an attempt at a uniﬁed solution. In this paper, we describe our experience using Web Ontology Language (OWL) as the language for Model-Driven Development (MDD). We argue that there are beneﬁts of using OWL to formally describe both data and software within an integrated modeling approach by showcasing an e-Government platform that we have built for citizen relationship management. We describe the platform architec- ture, development process and model enactment. In addition, we explain some of the limitations of OWL as an MDD formalism as well as the shortcomings of current tools and suggest practical ways to overcome them.",
    "keywords": [
      "semantic web",
      "owl",
      "model-driven development",
      "e-government",
      "live system",
      "executable models."
    ]
  },
  {
    "title": "Concern-Oriented Software Design",
    "date": 2013,
    "abstract": "There exist many solutions to solve a given design problem, and it is diﬃcult to capture the essence of a solution and make it reusable for future designs. Furthermore, many variations of a given solution may exist, and choosing the best alternative depends on application-speciﬁc high-level goals and non-functional requirements. This paper proposes Concern-Oriented Software Design, a modelling technique that focuses on concerns as units of reuse. A concern groups related models serving the same purpose, and provides three interfaces to facilitate reuse. The variation interface presents the design alternatives and their impact on non-functional requirements. The customization interface of the selected alternative details how to adapt the generic solution to a speciﬁc con- text. Finally, the usage interface speciﬁes the provided behaviour. We illustrate our approach by presenting the concern models of variations of the Observer design pattern, which internally depends on the Association concern to link observers and subjects.",
    "keywords": []
  },
  {
    "title": "Analyzing Enterprise Models\nUsing Enterprise Architecture-Based Ontology",
    "date": 2013,
    "abstract": "Development and maintenance of enterprise systems is becoming more diﬃcult due to change drivers along multiple interconnected dimensions. It is advisable to model the enterprise ﬁrst and analyze it for potential concerns. For modeling enterprises, ontologies have been considered apt and have been used in the past for the same, but application of ontologies for EA analysis based on concepts of enterprise and relations between them have been scarce. We present our ongoing work on analyzing enterprise models using EA-based ontological representation of enterprise. Our contributions are twofold: ﬁrst, we show how an existing EA modeling language can be leveraged to create EA ontology and sec- ond, we show how two known EA analyses can be realized using this ontology. Initial results suggest that ontology representation facilitates basic EA analysis prototyping due to right mix of representation and inference functionalities and is extensible for more involved EA analyses.",
    "keywords": [
      "Ontology",
      "Enterprise Models",
      "Analysis",
      "Enterprise Architecture."
    ]
  },
  {
    "title": "Analyzing the Effort of Composing Design Models  \nof Large-Scale Software in Industrial Case Studies",
    "date": 2013,
    "abstract": "The importance of model composition in model-centric software de- velopment is well recognized by researchers and practitioners. However, little is known about the critical factors influencing the effort that developers invest to combine design models, detect and resolve inconsistencies in practice. This pa- per, therefore, reports on five industrial case studies where the model composi- tion was used to evolve and reconcile large-scale design models. These studies aim at: (1) gathering empirical evidence about the extent of composition effort when realizing different categories of changes, and (2) identifying and analyz- ing their influential factors. A series of 297 evolution scenarios was performed on the target systems, leading to more than 2 million compositions of model elements. Our findings suggest that: the inconsistency resolution effort is much higher than the upfront effort to apply the composition technique and detect in- consistencies; the developer’s reputation significantly influences the resolution of conflicting changes; and the evolutions dominated by additions required less effort.",
    "keywords": [
      "Model composition effort",
      "empirical studies",
      "effort measurement."
    ]
  },
  {
    "title": "Parallel Execution of ATL Transformation Rules",
    "date": 2013,
    "abstract": "Industrial environments that make use of Model-Driven En- gineering (MDE) are starting to see the appearance of very large models, made by millions of elements. Such models are produced automatically (e.g., by reverse engineering complex systems) or manually by a large number of users (e.g., from social networks). The success of MDE in these application scenarios strongly depends on the scalability of model manipulation tools. While parallelization is one of the traditional ways of making computation systems scalable, developing parallel model trans- formations in a general-purpose language is a complex and error-prone task. In this paper we show that rule-based languages like ATL have strong parallelization properties. Transformations can be developed with- out taking into account concurrency concerns, and a transformation engine can automatically parallelize execution. We describe the imple- mentation of a parallel transformation engine for the current version of the ATL language and experimentally evaluate the consequent gain in scalability.",
    "keywords": []
  },
  {
    "title": "Transformation of Models Containing\nUncertainty",
    "date": 2013,
    "abstract": "Model transformation techniques typically operate under the assumption that models do not contain uncertainty. In the presence of uncertainty, this forces modelers to either postpone working or to arti- ﬁcially remove it, with negative impacts on software cost and quality. Instead, we propose a technique to adapt existing model transforma- tions so that they can be applied to models even if they contain un- certainty, thus enabling the use of transformations earlier. Building on earlier work, we show how to adapt graph rewrite-based model transfor- mations to correctly operate on May uncertainty, a technique that allows explicit uncertainty to be expressed in any modeling language. We eval- uate our approach on the classic Object-Relational Mapping use case, experimenting with models of varying levels of uncertainty.",
    "keywords": []
  },
  {
    "title": "Automated Veriﬁcation of Model\nTransformations in the Automotive Industry⋆",
    "date": 2013,
    "abstract": "Many companies have adopted MDD for developing their software systems. Several studies have reported on such industrial expe- riences by discussing the eﬀects of MDD and the issues that still need to be addressed. However, only a few studies have discussed using au- tomated veriﬁcation of industrial model transformations. We previously demonstrated how transformations can be used to migrate GM legacy models to AUTOSAR models. In this study, we investigate using au- tomated veriﬁcation for such industrial transformations. We report on applying an automated veriﬁcation approach to the GM-to-AUTOSAR transformation that is based on checking the satisﬁability of a relational transformation representation, or a transformation model, with respect to well-formedness OCL constraints. An implementation of this approach is available as a prototype for the ATL language. We present the veriﬁ- cation results of this transformation and discuss the practicality of using such tools on industrial size problems.",
    "keywords": [
      "Model Transformation",
      "Automated Veriﬁcation",
      "Automo- tive Industry."
    ]
  },
  {
    "title": "Data-Flow Based Model Analysis\nand Its Applications",
    "date": 2013,
    "abstract": "In this paper we present a data-ﬂow based approach to static model analysis to address the problem of current methods being either limited in their expressiveness or employing formalisms which complicate seamless integration with standards and tools in the modeling domain. By applying data-ﬂow analysis - a technique widely used for static pro- gram analysis - to models, we realize what can be considered a generic “programming language” for context-sensitive model analysis through declarative speciﬁcations. This is achieved by enriching meta models with data-ﬂow attributes which are afterward instantiated for models. The resulting equation system is subjected to a ﬁxed-point computation that yields a static approximation of the model’s dynamic behavior as speciﬁed by the analysis. The applicability of the approach is evaluated in the context of a running example, the examination of viable application domains and a statistical review of the algorithm’s performance.",
    "keywords": []
  },
  {
    "title": "Contract-Aware Slicing of UML Class Models",
    "date": 2013,
    "abstract": "Slicing is a reduction technique that has been applied to class models to support model comprehension, analysis, and other modeling activities. In particular, slicing techniques can be used to produce class model fragments that include only those elements needed to analyze se- mantic properties of interest. In this paper we describe a class model slicing approach that takes into consideration invariants and operation contracts expressed in the Object Constraint Language (OCL). The ap- proach is used to produce model fragments, each of which consists of only the model elements needed to analyze speciﬁed properties. We use the slicing approach to support a technique for analyzing sequences of opera- tion invocations to uncover invariant violations. The slicing technique is used to produce model fragments that can be analyzed separately. The preliminary evaluation we performed provides evidence that the pro- posed slicing technique can signiﬁcantly reduce the time to perform the analysis.",
    "keywords": [
      "Class model slicing",
      "UML/OCL",
      "Contract."
    ]
  },
  {
    "title": "Usability Inspection in Model-Driven Web Development: \nEmpirical Validation in WebML",
    "date": 2013,
    "abstract": "There is a lack of empirically validated usability evaluation methods that can be applied to models in model-driven Web development. Evaluation of these models allows an early detection of usability problems perceived by the end-user. This motivated us to propose WUEP, a usability inspection method which can be integrated into different model-driven Web development processes. We previously demonstrated how WUEP can effectively be used when following the Object-Oriented Hypermedia method. In order to provide evidences about WUEP’s generalizability, this paper presents the operationalization and empirical validation of WUEP into another well-known method: WebML. The effectiveness, efficiency, perceived ease of use, and satisfaction of WUEP were evaluated in comparison to Heuristic Evaluation (HE) from the viewpoint of novice inspectors. The results show that WUEP was more effective and efficient than HE when detecting usability problems on models. Also, inspectors were satisfied when applying WUEP, and found it easier to use than HE.",
    "keywords": [
      "Model-driven Web development",
      "Usability inspections",
      "Measure  operationalization",
      "Empirical validation",
      "WebML."
    ]
  },
  {
    "title": "Model-Driven Approach  \nfor Supporting the Mapping of Parallel Algorithms  \nto Parallel Computing Platforms",
    "date": 2013,
    "abstract": "The trend from single processor to parallel computer architectures has increased the importance of parallel computing. To support parallel compu- ting it is important to map parallel algorithms to a computing platform that consists of multiple parallel processing nodes. In general different alternative mappings can be defined that perform differently with respect to the quality re- quirements for power consumption, efficiency and memory usage. The mapping process can be carried out manually for platforms with a limited number of pro- cessing nodes. However, for exascale computing in which hundreds of thou- sands of processing nodes are applied, the mapping process soon becomes in- tractable. To assist the parallel computing engineer we provide a model-driven approach to analyze, model, and select feasible mappings. We describe the de- veloped toolset that implements the corresponding approach together with the required metamodels and model transformations. We illustrate our approach for the well-known complete exchange algorithm in parallel computing.",
    "keywords": [
      "Model Driven Software Development",
      "Parallel Computing",
      "High  Performance Computing",
      "Domain Specific Language",
      "Tool Support."
    ]
  },
  {
    "title": "Compositional Synthesis of Controllers\nfrom Scenario-Based Assume-Guarantee\nSpeciﬁcations",
    "date": 2013,
    "abstract": "Modern software-intensive systems often consist of multiple components that interact to fulﬁll complex functions in sometimes safety- critical situations. During the design, it is crucial to specify the system’s requirements formally and to detect inconsistencies as early as possi- ble in order to avoid ﬂaws in the product or costly iterations during its development. We propose to use Modal Sequence Diagrams (MSDs), a formal, yet intuitive formalism for specifying the interaction of a system with its environment, and developed a formal synthesis approach that allows us to detect inconsistencies and even to automatically synthesize controllers from MSD speciﬁcations. The technique is suited for speciﬁ- cations of technical systems with real-time constraints and environment assumptions. However, synthesis is computationally expensive. In order to employ synthesis also for larger speciﬁcations, we present, in this pa- per, a novel assume-guarantee-style compositional synthesis technique for MSD speciﬁcations. We provide evaluation results underlining the beneﬁt of our approach and formally justify its correctness.",
    "keywords": [
      "Scenario-Based Speciﬁcation",
      "Compositional Controller Synthesis",
      "Consistency Checking",
      "Assume-Guarantee."
    ]
  },
  {
    "title": "Why Formal Modeling Language\nSemantics Matters",
    "date": 2014,
    "abstract": "The point of modeling languages is not just modeling, but modeling as a powerful means of making software development much more reliable, reusable, automated, and cost eﬀective. For all these pur- poses, model transformations, as a disciplined technique to systematically relate models within a modeling language and across languages, play a crucial role. In particular, automatic code generation from models is one of its great advantages. As in the case of programming languages and compilers for such lan- guages — which can be seen as a speciﬁc, special case of modeling lan- guages and model transformations — there are two ways of going about all this: (i) the usual, engineering way of building and using practical tools, like parsers, compilers, and debuggers and, likewise, modeling tools and model transformations, where the semantics is implicit in the tools themselves and informal; and (ii) a formal semantics based approach, where the diﬀerent languages involved are given a formal semantics and correctness issues, such as the correctness of programs and models, and of compilers and model transformers, can be addressed head-on with powerful methods. It seems fair to say that, both for programming and for modeling languages, the usual engineering approach is at present the prevailing one. But this should not blind us to the existence of intrinsi- cally superior technological possibilities for the future. Furthermore, the reasons for taking formal semantics seriously are even more compelling for modeling languages than for programming languages. Speciﬁcally, the following crucial advantages can be gained: 1. Formal Analysis of Model-Based Designs to uncover costly design errors much earlier in the development cycle. 2. Correct-by-Construction Model Transformations based on formal pat- terns, that can be amortized across many instances. 3. Modeling-Language-Generic Formal Analysis tools that are seman- tics-based and can likewise be amortized across many languages. 4. Correct-by-Construction Code Generators, a burning issue for cyber- physical systems, and a must for high-quality, highly reliable imple- mentations. Although the full potential for enjoying all these advantages has yet to be exploited and much work remains ahead, none of this is some pie-in-the-sky day dreaming. There is already a substantial body of re- search, tools, and case studies demonstrating that a formal semantics based approach to modeling languages is a real possibility. For example, formal approaches to modeling language semantics based on: (i) type theory, (ii) graph transformations, and (iii) rewriting logic, all converge",
    "keywords": []
  },
  {
    "title": "Modeling: A Practical Perspective",
    "date": 2014,
    "abstract": "My talk will explore some of the basic ideas of the modeling approach as they apply to software engineering. I will use the domain of model-based testing, and discuss its foundations and adoption successes and pitfalls. A major focus will be on the bells and whistles which may help with getting modeling into mainstream. I will also discuss opportu- nities and challenges for model-based software development which arise from the cloud computing environment found in most of today’s industry.",
    "keywords": []
  },
  {
    "title": "Towards Data-Driven Models\nof Human Behavior",
    "date": 2014,
    "abstract": "We live in a world of data, of big data, a big part of which has been generated by humans through their interactions with both the physical and digital world. A key element in the exponential growth of human behavioral data is the mobile phone. There are almost as many mobile phones in the world as humans. The mobile phone is the piece of technology with the highest levels of adoption in human history. We carry them with us all through the day (and night, in many cases), leaving digital traces of our physical interactions. Mobile phones have become sensors of human activity in the large scale and also the most personal devices. In my talk, I will present some of the work that we are doing at Tele- fonica Research in the area of modeling humans from large-scale human behavioral data, such as inferring personality, socio-economic status, at- tentiveness to messages or taste. I will highlight opportunities and chal- lenges associated with building data-driven models of human behavior.",
    "keywords": []
  },
  {
    "title": "Model-Driven Development of Mobile\nApplications Allowing Role-Driven Variants⋆",
    "date": 2014,
    "abstract": "Rapidly increasing numbers of applications and users make the development of mobile applications to one of the most promising ﬁelds in software engineering. Due to short time-to-market, diﬀering plat- forms and fast emerging technologies, mobile application development faces typical challenges where model-driven development can help. We present a modeling language and an infrastructure for the model-driven development (MDD) of Android apps supporting the speciﬁcation of dif- ferent app variants according to user roles. For example, providing users may continuously conﬁgure and modify custom content with one app variant whereas end users are supposed to use provided content in their variant. Our approach allows a ﬂexible app development on diﬀerent ab- straction levels: compact modeling of standard app elements, detailed modeling of individual elements, and separate provider models for spe- ciﬁc custom needs. We demonstrate our MDD-approach at two apps: a phone book manager and a conference guide being conﬁgured by confer- ence organizers for participants.",
    "keywords": [
      "model-driven development",
      "mobile application",
      "Android."
    ]
  },
  {
    "title": "A Model-Based System to Automate Cloud Resource \nAllocation and Optimization",
    "date": 2014,
    "abstract": "Cloud computing offers a flexible approach to elastically allocate computing resources for web applications without significant upfront hardware acquisition costs. Although a diverse collection of cloud resources is available, choosing the most optimized and cost-effective set of cloud resources to meet the QoS requirements is not a straightforward task. Manual load testing, monitoring of resource utilization, followed by bottleneck analysis is time consuming and complex due to limitations of the abstractions of load testing tools, challenges characterizing resource utilization, significant manual test orchestration effort, and complexity of selecting resource configurations to test. This paper introduces a model-based approach to simplify, optimize, and automate cloud resource allocation decisions to meet QoS goals for web applications. Given a high-level application description and QoS requirements, the model-based approach automatically tests the application under a variety of load and resources to derive the most cost-effective resource configuration to meet the QoS goals.",
    "keywords": [
      "Cloud Computing",
      "Resource Allocation",
      "Resource Optimization",
      "Model-Based System",
      "Domain-Specific Language."
    ]
  },
  {
    "title": "An Evaluation of the Effectiveness\nof the Atomic Section Model",
    "date": 2014,
    "abstract": "Society increasingly depends on web applications for business and pleasure. As the use of web applications continues to increase, the number of fail- ures, some minor and some major, continues to grow. A signiﬁcant problem is that we still have relatively weak abilities to test web applications. Traditional testing techniques do not adequately model or test these novel technologies. The atomic section model (ASM), models web applications to support design, analysis, and testing. This paper presents an empirical study to evaluate the effectiveness of the ASM. The model was implemented into a tool, WASP, which extracts the ASM from the implementation and supports various test criteria. We studied ten web applications, totaling 156 components and 11,829 lines of code. Using WASP, we generated 207 tests, which revealed 31 faults. Seventeen of those faults exposed internal information about the application and server.",
    "keywords": [
      "Web applications",
      "Test criteria",
      "Model based testing",
      "Atomic section modeling."
    ]
  },
  {
    "title": "Parsing in a Broad Sense",
    "date": 2014,
    "abstract": "Having multiple representations of the same instance is com- mon in software language engineering: models can be visualised as graphs, edited as text, serialised as XML. When mappings between such represen- tations are considered, terms “parsing” and “unparsing” are often used with incompatible meanings and varying sets of underlying assumptions. We investigate 12 classes of artefacts found in software language processing, present a case study demonstrating their implementations and state-of- the-art mappings among them, and systematically explore the technical research space of bidirectional mappings to build on top of the existing body of work and discover as of yet unused relationships.",
    "keywords": [
      "Parsing",
      "unparsing",
      "pretty-printing",
      "model synchronisation",
      "technical space bridging",
      "bidirectional model transformation."
    ]
  },
  {
    "title": "Streaming Model Transformations By Complex Event Processing⋆",
    "date": 2014,
    "abstract": "Streaming model transformations represent a novel class of transformations dealing with models whose elements are continuously produced or modiﬁed by a background process [1]. Executing streaming transformations requires eﬃcient techniques to recognize the activated transformation rules on a potentially inﬁnite input stream. Detecting a series of events triggered by compound structural changes is especially challenging for a high volume of rapid modiﬁcations, a characteristic of an emerging class of applications built on runtime models.",
    "keywords": []
  },
  {
    "title": "On the Use of Signatures for Source Incremental\nModel-to-text Transformation",
    "date": 2014,
    "abstract": "Model-to-text (M2T) transformation is an important model management operation, used to implement code and documentation gen- eration, model serialisation (enabling model interchange), and model vi- sualisation and exploration. Despite the importance of M2T transforma- tion, contemporary M2T transformation languages cannot be used to eas- ily produce transformations that scale well as the size of the input model increases, which limits their applicability in practice. In this paper, we propose an extension to template-based M2T languages that adds sup- port for signatures, lightweight and concise proxies for templates, which are used to reduce the time taken to re-execute a M2T transformation in response to changes to the input model. We report our initial results in applying signatures to two existing M2T transformations, which indicate a reduction of 33-47% in transformation execution time.",
    "keywords": []
  },
  {
    "title": "Modeling Systemic Behavior by State-Based\nHolonic Modular Units",
    "date": 2014,
    "abstract": "The paper explores a vision in modeling the behavior of com- plex systems by modular units hosting state machines arranged in part- whole hierarchies and communicating through event ﬂows. Each modular unit plays at the same time the double role of part and whole, i.e. it is inspired by the philosophical idea of holon, providing both an interface and an implementation by which other component state machines may be controlled in order to achieve a global behavior. It is moreover observed that it is possible to assign a formal characterization to such state mod- ules, due to their part-whole arrangement, since higher-level behaviors can derive formally their meaning from lower-level component behaviors. Such a way of arranging behavioral modules allows to establish directly correct-by-construction safety and liveness properties of state-based sys- tems thus challenging the current approach by which state machines interact at the same level and have to be model-checked for ensuring correctness.",
    "keywords": [
      "state-based modeling",
      "holons",
      "component-based modeling",
      "model checking",
      "correctness by construction."
    ]
  },
  {
    "title": "Semantic Model Differencing Utilizing Behavioral\nSemantics Speciﬁcations",
    "date": 2014,
    "abstract": "Identifying differences among models is a crucial prerequisite for sev- eral development and change management tasks in model-driven engineering. The majority of existing model differencing approaches focus on revealing syn- tactic differences which can only approximate semantic differences among mod- els. Signiﬁcant advances in semantic model differencing have been recently made by Maoz et al. [16] who propose semantic diff operators for UML class and activ- ity diagrams. In this paper, we present a generic semantic differencing approach which can be instantiated to realize semantic diff operators for speciﬁc model- ing languages. Our approach utilizes the behavioral semantics speciﬁcation of the considered modeling language, which enables to execute models and capture execution traces representing the models’ semantic interpretation. Based on this semantic interpretation, semantic differences can be revealed.",
    "keywords": []
  },
  {
    "title": "Formalizing Execution Semantics of UML\nProﬁles with fUML Models",
    "date": 2014,
    "abstract": "UML Proﬁles are not only sets of annotations. They have se- mantics. Executing a model on which a proﬁle is applied requires seman- tics of this latter to be considered. The issue is that in practice semantics of proﬁles are mainly speciﬁed in prose. In this form it cannot be pro- cessed by tools enabling model execution. Although latest developments advocate for a standard way to formalize semantics of proﬁles, no such approach could be found in the literature. This paper addresses this issue with a systematic approach based on fUML to formalize the execution semantics of UML proﬁles. This approach is validated by formalizing the execution semantics of a subset of the MARTE proﬁle. The proposal is compatible with any tool implementing UML and clearly identiﬁes the mapping between stereotypes and semantic deﬁnitions.",
    "keywords": [
      "fUML",
      "Alf",
      "Proﬁle",
      "Semantics",
      "Execution",
      "MARTE."
    ]
  },
  {
    "title": "Who Knows/Uses What of the UML: A Personal Opinion Survey",
    "date": 2014,
    "abstract": "UML is a comprehensive notation, offering a very large set of dia- grams and constructs covering any possible modelling need. As consequence, on one hand, it is difﬁcult and time consuming to master it, and on the other hand, people tend, naturally, to consider only a part of it. In practice, many UML di- agrams/constructs seem scarcely used or even their existence is not known. By means of a study covering any possible source of information (e.g. UML books and tools), we started to assess which part of the UML is considered and used in practice. Here, we present some results about knowledge and usage of the UML diagrams by means of a personal opinion survey with 275 participants from both industry and academy, analysing also the inﬂuence of different factors: work- ing environment (academia vs. industry), working role, seniority, education, and gender.",
    "keywords": [
      "UML Usage and Knowledge",
      "Personal Opinion Survey",
      "Empirical Study."
    ]
  },
  {
    "title": "Assessing the State-of-Practice of Model-Based\nEngineering in the Embedded Systems Domain",
    "date": 2014,
    "abstract": "Model-Based Engineering (MBE) aims at increasing the ef- fectiveness of engineering by using models as key artifacts in the devel- opment process. While empirical studies on the use and the eﬀects of MBE in industry exist, there is only little work targeting the embedded systems domain. We contribute to the body of knowledge with a study on the use and the assessment of MBE in that particular domain. We col- lected quantitative data from 112 subjects, mostly professionals working with MBE, with the goal to assess the current State of Practice and the challenges the embedded systems domain is facing. Our main ﬁndings are that MBE is used by a majority of all participants in the embedded systems domain, mainly for simulation, code generation, and documenta- tion. Reported positive eﬀects of MBE are higher quality and improved reusability. Main shortcomings are interoperability diﬃculties between MBE tools, high training eﬀort for developers and usability issues.",
    "keywords": [
      "Model-Based Engineering",
      "Model-Driven Engineering",
      "Em- bedded Systems",
      "Industry",
      "Modeling",
      "Empirical Study",
      "State-of-Practice."
    ]
  },
  {
    "title": "The Relevance of Model-Driven Engineering  \nThirty Years from Now",
    "date": 2014,
    "abstract": "Although model-driven engineering (MDE) is now an established approach for developing complex software systems, it has not been universally adopted by the software industry. In order to better understand the reasons for this, as well as to identify future opportunities for MDE, we carried out a week-long design thinking experiment with 15 MDE experts. Participants were facilitated to identify the biggest problems with current MDE technologies, to identify grand challenges for society in the near future, and to identify ways that MDE could help to address these challenges. The outcome is a reflection of the current strengths of MDE, an outlook of the most pressing challenges for socie- ty at large over the next three decades, and an analysis of key future MDE re- search opportunities.",
    "keywords": [
      "Model-driven engineering",
      "challenges",
      "research opportunities."
    ]
  },
  {
    "title": "Model-Driven Verifying Compilation\nof Synchronous Distributed Applications⋆",
    "date": 2014,
    "abstract": "We present an approach, based on model-driven verifying compilation, to construct distributed applications that satisfy user- speciﬁed safety speciﬁcations, assuming a ”synchronous network” model of computation. Given a distributed application Pd and a safety speciﬁ- cation ϕ in a domain speciﬁc language dasl (that we have developed), we ﬁrst use a combination of sequentialization and software model checking to verify that Pd satisﬁes ϕ. If veriﬁcation succeeds, we generate an im- plementation of Pd that uses a novel barrier-based synchronizer protocol (that we have also developed) to implement the synchronous network se- mantics. We present the syntax and semantics of dasl. We also present, and prove correctness of, two sequentialization algorithms, and the syn- chronizer protocol. Finally, we evaluate the two sequentializations on a collection of distributed applications with safety-critical requirements.",
    "keywords": []
  },
  {
    "title": "Environment-Centric Contracts\nfor Design of Cyber-Physical Systems",
    "date": 2014,
    "abstract": "A contract splits the responsibilities between a component and its environment into a guarantee that expresses an intended property under the responsibility of the component, given that the environment fulﬁlls the assumptions. Although current contract theories are limited to express contracts over interfaces of components, speciﬁcations that are not limited to interfaces are used in practice and are needed in or- der to properly express safety requirements. A framework is therefore presented, generalizing current contract theory to environment-centric contracts - contracts that are not limited to the interface of components. The framework includes revised deﬁnitions of properties of contracts, as well as theorems that specify exact conditions for when the properties hold. Furthermore, constraints are introduced, limiting the ports over which an environment-centric contract is expressed where the constraints constitute necessary conditions for the guarantee of the contract to hold in an architecture.",
    "keywords": [
      "Environment-Centric",
      "Contracts",
      "Architecture."
    ]
  },
  {
    "title": "Removing Redundancies and Deducing Equivalences in UML Class Diagrams",
    "date": 2014,
    "abstract": "The emerging Model-driven Engineering approach puts mod- els at the heart of the software development process. The Class Diagram language is central within the UML. Automated support for class dia- grams involves identiﬁcation and repair of correctness and quality prob- lems.",
    "keywords": []
  },
  {
    "title": "A Native Versioning Concept to Support\nHistorized Models at Runtime",
    "date": 2014,
    "abstract": "Models@run.time provides semantically rich reﬂection lay- ers enabling intelligent systems to reason about themselves and their surrounding context. Most reasoning processes require not only to ex- plore the current state, but also the past history to take sustainable decisions e.g. to avoid oscillating between states. Models@run.time and model-driven engineering in general lack native mechanisms to eﬃciently support the notion of history, and current approaches usually generate redundant data when versioning models, which reasoners need to nav- igate. Because of this limitation, models fail in providing suitable and sustainable abstractions to deal with domains relying on history-aware reasoning. This paper tackles this issue by considering history as a na- tive concept for modeling foundations. Integrated, in conjunction with lazy load/storage techniques, into the Kevoree Modeling Framework, we demonstrate onto a smart grid case study, that this mechanisms enable a sustainable reasoning about massive historized models.",
    "keywords": [
      "Models@run.time",
      "Model-driven engineering",
      "Modelversion- ing",
      "Historized models."
    ]
  },
  {
    "title": "Modelling Adaptation Policies\nas Domain-Speciﬁc Constraints⋆",
    "date": 2014,
    "abstract": "In order to develop appropriate adaptation policies for self- adaptive systems, developers usually have to accomplish two main tasks: (i) identify the application-level constraints that regulate the desired sys- tem states for the various contexts, and (ii) ﬁgure out how to transform the system to satisfy these constraints. The second task is challenging because typically there is complex interaction among constraints, and a signiﬁcant gap between application domain expertice and state transi- tion expertice. In this paper, we present a model-driven approach that relieves developers from this second task, allowing them to directly write domain-speciﬁc constraints as adaptation policies. We provide a language to model both the domain concepts and the application-level constraints. Our runtime engine transforms the model into a Satisﬁability Modulo Theory problem, optimises it by pre-processing on the current system state at runtime, and computes required modiﬁcations according to the speciﬁed constraints using constraints solving. We evaluate the approach addressing a virtual machine placement problem in cloud computing.",
    "keywords": []
  },
  {
    "title": "Scalable Armies of Model Clones\nthrough Data Sharing",
    "date": 2014,
    "abstract": "Cloning a model is usually done by duplicating all its runtime objects into a new model. This approach leads to memory consumption problems for operations that create and manipulate large quantities of clones (e.g., design space exploration). We propose an original approach that exploits the fact that operations rarely modify a whole model. Given a set of immutable properties, our cloning approach determines the ob- jects and ﬁelds that can be shared between the runtime representations of a model and its clones. Our generic cloning algorithm is parameter- ized with three strategies that establish a trade-oﬀbetween memory savings and the ease of clone manipulation. We implemented the strate- gies within the Eclipse Modeling Framework (EMF) and evaluated mem- ory footprints and computation overheads with 100 randomly generated metamodels and models. Results show a positive correlation between the proportion of shareable properties and memory savings, while the worst median overhead is 9,5% when manipulating the clones.",
    "keywords": []
  },
  {
    "title": "Three Cases of Feature-Based\nVariability Modeling in Industry⋆",
    "date": 2014,
    "abstract": "Large software product lines need to manage complex vari- ability. A common approach is variability modeling—creating and main- taining models that abstract over the variabilities inherent in such systems. While many variability modeling techniques and notations have been proposed, little is known about industrial practices and how indus- try values or criticizes this class of modeling. We attempt to address this gap with an exploratory case study of three companies that apply vari- ability modeling. Among others, our study shows that variability mod- els are valued for their capability to organize knowledge and to achieve an overview understanding of codebases. We observe centralized model governance, pragmatic versioning, and surprisingly little constraint mod- eling, indicating that the eﬀort of declaring and maintaining constraints does not always pay oﬀ.",
    "keywords": []
  },
  {
    "title": "Supporting Multiplicity and Hierarchy\nin Model-Based Conﬁguration:\nExperiences and Lessons Learned",
    "date": 2014,
    "abstract": "When developing large-scale industrial software systems en- gineers need to instantiate, conﬁgure, and deploy diverse reusable compo- nents. The number of component instances required depends on customer requirements only known during conﬁguration and is typically unknown when modeling the systems’ variability. Also, the hierarchy of dynam- ically created component instances leads to complex dependencies be- tween conﬁguration decisions. Dealing with component multiplicity and hierarchy thus requires an approach capable of expressing the depen- dencies among dynamically instantiated components and conﬁguration decisions. Furthermore, users need tool support for navigating the com- plex decision space during conﬁguration. In this experience paper we report on applying a decision-oriented modeling approach for deﬁning component variability, multiplicity, and hierarchy. We further present a conﬁguration tool that guides end users through the complex decision space. We report applications of the approach to industrial software sys- tems and describe patterns and lessons learned.",
    "keywords": [
      "Variability models",
      "multiplicity",
      "hierarchy",
      "conﬁguration tool."
    ]
  },
  {
    "title": "Propagating Decisions to Detect and Explain\nConﬂicts in a Multi-step Conﬁguration Process",
    "date": 2014,
    "abstract": "In conﬁguration processes with multiple stakeholders, con- ﬂicts are very likely because each decision maker has a diﬀerent concerns and expectations about the product. They may not be aware of features selected by others or the restrictions that these selections impose. To help solve the conﬂicts, this paper introduces a new approach to provide explanations about their causes. Our approach is based on representing features from diﬀerent concerns using diﬀerent Feature Models (FMs), and relating them through Feature-Solution Graphs. An FSG contains dependency relationships between two FMs: one feature from the left side forces or prohibits the selection of features in the right side feature model. The strategy to detect and explain conﬂicts is based on propaga- tion of constraints over the FSGs. We claim that our approach is more expressive and eﬃcient than when using a single FM that contains all concerns and SAT solvers to detect conﬂicts.",
    "keywords": [
      "Multi-level conﬁguration processes",
      "Feature Models",
      "Feature-Solution Graphs",
      "Conﬂict explanation."
    ]
  },
  {
    "title": "An MDA Approach for the Generation\nof Communication Adapters Integrating SW\nand FW Components from Simulink",
    "date": 2014,
    "abstract": "We present the tools, metamodels and code generation tech- niques in use at Elettronica SpA for the development of communication adapters for software and ﬁrmware systems from heterogeneous models. The process start from a SysML system model, developed according to the platform-based design (PBD) paradigm, in which a functional model of the system is paired to a model of the execution platform. Subsystems are reﬁned as Simulink models or hand coded in C++. In turn, Simulink models are implemented as software code or ﬁrmware on FPGA, and an automatic generation of the implementation is obtained. Based on the SysML system architecture speciﬁcation, our framework drives the gener- ation of Simulink models with consistent interfaces, allows the automatic generation of the communication code among all subsystems (including the HW-FW interface code).",
    "keywords": [
      "System Engineering",
      "Model-Driven Architecture",
      "Model- Based Design",
      "Platform-Based Design",
      "Automatic Code Generation."
    ]
  },
  {
    "title": "A UML Model-Driven Approach to Eﬃciently\nAllocate Complex Communication Schemes",
    "date": 2014,
    "abstract": "To increase the performance of embedded devices, the cur- rent trend is to shift from serial to parallel and distributed computing with simultaneous instructions execution. The performance increase of parallel computing wouldn’t be possible without eﬃcient transfers of data and control information via complex communication architectures. In UML/SysML/MARTE, diﬀerent solutions exist to describe and map computations onto parallel and distributed systems. However, these lan- guages lack expressiveness to clearly separate computation models from communication ones, thus strongly impacting models’ portability, espe- cially when performing Design Space Exploration. As a solution to this issue, we present Communication Patterns, a novel UML modeling arti- fact and model-driven approach to assist system engineers in eﬃciently modeling and mapping communications for parallel and distributed sys- tem architectures. We illustrate the eﬀectiveness of our approach with the design of a parallel signal processing algorithm mapped to a multi- processor platform with a hierarchical bus-based interconnect.",
    "keywords": [
      "Model Driven Engineering",
      "Hardware-Software Co-Design",
      "Design Space Exploration",
      "Parallel Computing",
      "Embedded Systems."
    ]
  },
  {
    "title": "Model-Integrating Software Components",
    "date": 2014,
    "abstract": "In order to handle complexity of software systems, component- based as well as model-driven approaches have become popular in the past. In a model-driven development process the problem arises that over time model and code may be not aligned. Thus, in order to avoid this steadily increasing distance between models and code, we propose the integration of (executable) models and code at the component level. Redundancy – the source of inconsistencies – is reduced by interpreting models directly. Moreover,variability and adaptivity can beachieved by queryingand trans- forming the embedded models. As the basis for such Model-Integrating Components (MoCos), we introduce a component realization concept that iscompatiblewith existingcomponenttechnologies.Weprovidea reference implementation using Java, OSGi and TGraphs and apply it successfully in a feasibility study on AndroidTM.",
    "keywords": [
      "Model-integrating component",
      "model execution",
      "ﬂexibility."
    ]
  },
  {
    "title": "Experiences in Applying Model Driven Engineering  \nto the Telescope and Instrument Control System Domain",
    "date": 2014,
    "abstract": "The development of control systems for large telescopes is frequent- ly challenged by the combination of research and industrial development processes, the bridging of astronomical and engineering domains, the long de- velopment and maintenance time-line, and the need to support multiple hard- ware and software platforms. This paper illustrates the application of a model driven engineering approach to mitigate some of these recurring issues. It de- scribes the lessons learned from introducing a modeling language and creating model transformations for analysis, documentation, simulation, validation, and code generation.",
    "keywords": [
      "model driven engineering",
      "telescope control systems",
      "model trans- formation",
      "model validation",
      "code generation."
    ]
  },
  {
    "title": "Model Driven Grant Proposal Engineering",
    "date": 2014,
    "abstract": "We demonstrate the application of Model Driven Engineer- ing techniques to support the development of research grant proposals. In particular, we report on using model-to-text transformation and model validation to enhance productivity and consistency in research proposal writing, and present unanticipated opportunities that were revealed after establishing an MDE infrastructure. We discuss the types of models and the technologies used, reﬂect on our experiences, and assess the produc- tivity beneﬁts of our MDE solution through automated analysis of data extracted from the version control repository of a successful grant pro- posal; our evaluation indicates that the use of MDE techniques improved productivity by at least 58%.",
    "keywords": []
  },
  {
    "title": "Agile Model-Driven Engineering in Mechatronic\nSystems - An Industrial Case Study",
    "date": 2014,
    "abstract": "Model-driven engineering focuses on structuring systems as well as permitting domain experts to be directly involved in the soft- ware development. Agile methods aim for fast feedback and providing crucial knowledge early in the project. In our study, we have seen a successful combination of MDE and agile methods to support the devel- opment of complex, software-driven mechatronic systems. We have inves- tigated how combining MDE and agile methods can reduce the number of issues caused by erroneous assumptions in the software of these mecha- tronic systems. Our results show that plant models to simulate mechan- ical systems are needed to enable agile MDE during the mechatronic development. They enable developers to run, verify, and validate mod- els before the mechanical systems are delivered from suppliers. While two case studies conducted at Volvo Car Group conﬁrm that combining MDE and agile works, there are still challenges e.g. how to optimize the development of plant models.",
    "keywords": [
      "Model Driven Engineering",
      "Agile",
      "Mechatronic Software De- velopment",
      "Virtual Testing",
      "Assumptions",
      "Plant Models."
    ]
  },
  {
    "title": "Using UML for Modeling Procedural Legal Rules: Approach and a Study of Luxembourg’s Tax Law",
    "date": 2014,
    "abstract": "Many laws, e.g., those concerning taxes and social beneﬁts, need to be operationalized and implemented into public administration procedures and eGovernment applications. Where such operationaliza- tion is warranted, the legal frameworks that interpret the underlying laws are typically prescriptive, providing procedural rules for ensuring legal compliance. We propose a UML-based approach for modeling pro- cedural legal rules. With help from legal experts, we investigate actual legal texts, identifying both the information needs and sources of com- plexity in the formalization of procedural legal rules. Building on this study, we develop a UML proﬁle that enables more precise modeling of such legal rules. To be able to use logic-based tools for compliance analy- sis, we automatically transform models of procedural legal rules into the Object Constraint Language (OCL). We report on an application of our approach to Luxembourg’s Income Tax Law providing initial evidence for the feasibility and usefulness of our approach.",
    "keywords": []
  },
  {
    "title": "Resolution of Interfering Product Fragments\nin Software Product Line Engineering",
    "date": 2014,
    "abstract": "The Common Variability Language (CVL) allows deriving new products in a software product line by substituting fragments (place- ment) in the base model. Relations between elements of diﬀerent place- ment fragments are an issue. Substitutions involving interfering place- ments may give unexpected and unintended results. However, there is a pragmatic need to deﬁne and execute fragments with interference. The need emerges when several diagrams are views of a single model, such as a placement in one diagram and a placement in another diagram reference the same model elements. We handle the issue by 1) classifying inter- fering fragments, 2) ﬁnding criteria to detect them, and 3) suggesting solutions via transformations. We implement our ﬁndings in the tooling available for downloading.",
    "keywords": [
      "Graph transformations",
      "software product lines",
      "fragment substitutions",
      "adjacent",
      "interference",
      "cvl",
      "conﬂict resolution."
    ]
  },
  {
    "title": "Ontology-Based Modeling\nof Context-Aware Systems",
    "date": 2014,
    "abstract": "Context-aware systems aim to improve the interaction be- tween a computer and a human being by using contextual information about the system itself, the user, and their environment. The number of relevant contextual information is expected to grow rapidly within the next years which tends to result in a complex, error-prone and hence, expensive task of programming context-aware systems. Model-based de- velopment can overcome these issues. Current approaches do not allow to model calculation of reliabilities and do not oﬀer options to handle multiple sources of contextual information. In this paper, we present an approach of modeling contextual in- formation of a context-aware system using the example of a context- aware in-car infotainment system. In particular, we show how develop- ers of context-aware in-car infotainment systems can model reliability calculations of contextual information and handling of multiple sources of contextual information by using a hybrid, ontology-based modeling technique.",
    "keywords": [
      "Context-aware",
      "ontology",
      "infotainment",
      "modeling."
    ]
  },
  {
    "title": "Comprehending Feature Models Expressed in CVL",
    "date": 2014,
    "abstract": "Feature modeling is a common way to present and manage variability of software and systems. As a prerequisite for effective variability management is comprehensible representation, the main aim of this paper is to investigate difficulties in understanding feature models. In particular, we focus on the com- prehensibility of feature models as expressed in Common Variability Language (CVL), which was recommended for adoption as a standard by the Architectur- al Board of the Object Management Group. Using an experimental approach with participants familiar and unfamiliar with feature modeling, we analyzed comprehensibility in terms of comprehension score, time spent to complete tasks, and perceived difficulty of different feature modeling constructs. The re- sults showed that familiarity with feature modeling did not influence the com- prehension of mandatory, optional, and alternative features, although unfamiliar modelers perceived these elements more difficult than familiar modelers. OR relations were perceived as difficult regardless of the familiarity level, while constraints were significantly better understood by familiar modelers. The time spent to complete tasks was higher for familiar modelers.",
    "keywords": [
      "Variability analysis",
      "Software Product Line Engineering",
      "Model  Comprehension."
    ]
  },
  {
    "title": "On the Impact of Layout Quality\nto Understanding UML Diagrams:\nSize Matters",
    "date": 2014,
    "abstract": "Practical experience suggests that usage and understanding of UML diagrams is greatly aﬀected by the quality of their layout. While existing research failed to provide conclusive evidence in support of this hypothesis, our own previous work provided substantial evidence to this eﬀect. When studying diﬀerent factors like diagram type and expertise level, it became apparent that diagram size plays an important role, too. Since we lack an adequate understanding of this notion, in this paper, we deﬁne diagram size metrics and study their impact to modeler performance. We ﬁnd that there is a strong negative correlation between diagram size and modeler performance. Our results are highly signiﬁcant. We utilize these results to derive a recommendation on diagram sizes that are optimal for model understanding.",
    "keywords": []
  },
  {
    "title": "Enabling the Development of Cognitive Eﬀective\nVisual DSLs",
    "date": 2014,
    "abstract": "The development of graphical editors for visual DSLs is far from being a trivial task. There are consequently several tools that pro- vide technical support for this task. However, this paper shows that the analysis of the main characteristics of such tools leaves some space for improvement as regard the cognitive eﬀectiveness of the visual nota- tions produced with them. To deal with this issue, this work introduces CEViNEdit, a GMF-based framework for the development of visual DSLs which takes into account Moody’s principles for the development and evaluation of graphical notations. To that end, CEViNEdit eases the selection of values for the visual variables of which the notation is com- posed, computes a set of metrics to assess the appropriateness of these values and then automates the generation of the graphical editor.",
    "keywords": [
      "Model Driven Engineering (MDE)",
      "Domain Speciﬁc Lan- guage (DSL)",
      "Visual Notation",
      "Cognitive Eﬀectiveness."
    ]
  },
  {
    "title": "JUMP—From Java Annotations to UML Proﬁles⋆",
    "date": 2014,
    "abstract": "The capability of UML proﬁles to serve as annotation mechanism has been recognized in both industry and research. Today’s modeling tools offer pro- ﬁles speciﬁc to platforms, such as Java, as they facilitate model-based engineer- ing approaches. However, the set of available proﬁles is considerably smaller compared to the number of existing Java libraries using annotations. This is be- cause an effective mapping between Java and UML to generate proﬁles from annotation-based libraries is missing. In this paper, we present JUMP to over- come this limitation, thereby continuing existing mapping efforts by emphasiz- ing on annotations and proﬁles. We demonstrate the practical value of JUMP by contributing proﬁles that facilitate reverse-engineering and forward-engineering scenarios for the Java platform. The evaluation of JUMP shows that proﬁles can be automatically generated from Java libraries exhibiting equal or even improved quality compared to proﬁles currently used in practice.",
    "keywords": [
      "Java Annotations",
      "UML Proﬁles",
      "Model-Based Engineering",
      "Forward Engineering",
      "Reverse Engineering."
    ]
  },
  {
    "title": "SIGMA: Scala Internal Domain-Speciﬁc\nLanguages for Model Manipulations",
    "date": 2014,
    "abstract": "Model manipulation environments automate model opera- tions such as model consistency checking and model transformation. A number of external model manipulation Domain-Speciﬁc Languages (DSL) have been proposed, in particular for the Eclipse Modeling Frame- work (EMF). While their higher levels of abstraction result in gains in expressiveness over general-purpose languages, their limitations in ver- satility, performance, and tool support together with the need to learn new languages may signiﬁcantly contribute to accidental complexities. In this paper, we present Sigma, a family of internal DSLs embed- ded in Scala for EMF model consistency checking, model-to-model and model-to-text transformations. It combines the beneﬁts of external model manipulation DSLs with general-purpose programming taking full ad- vantage of Scala versatility, performance and tool support. The DSLs are compared to the state-of-the-art Epsilon languages in non-trivial model manipulation tasks that resulted in 20% to 70% reduction in code size and signiﬁcantly better performance.",
    "keywords": []
  },
  {
    "title": "A Framework to Benchmark NoSQL Data Stores\nfor Large-Scale Model Persistence",
    "date": 2014,
    "abstract": "We present a framework and methodology to benchmark NoSQL stores for large scale model persistence. NoSQL technologies potentially improve performance of some applications and provide schema- less data-structures, so are particularly suited to persisting large and het- erogeneous models. Recent studies consider only a narrow set of NoSQL stores for large scale modelling. Benchmarking many technologies re- quires substantial eﬀort due to the disparate interface each store pro- vides. Our experiments compare a broad range of NoSQL stores in terms of processor time and disc space used. The framework and methodology is evaluated through a case study that involves persisting large reverse- engineered models of open source projects. The results give tool engineers and practitioners a basis for selecting a store to persist large models.",
    "keywords": []
  },
  {
    "title": "Automated Chaining of Model Transformations\nwith Incompatible Metamodels",
    "date": 2014,
    "abstract": "In Model-Driven Engineering (MDE) models are ﬁrst-class entities that are manipulated by means of model transformations. The development of complex and large transformations can beneﬁt from the reuse of smaller ones that can be composed according to user requirements. Composing transforma- tions is a complex problem: typically smaller transformations are discovered and selected by developers from different and heterogeneous sources. Then the iden- tiﬁed transformations are chained by means of manual and error-prone composi- tion processes. In this paper we propose an approach to automatically discover and compose transformations: developers provide the system with the source models and spec- ify the target metamodel. By relying on a repository of model transformations, all the possible transformation chains are calculated. Importantly, in case of in- compatible intermediate target and source metamodels, proper adapters are auto- matically generated in order to chain also transformations that otherwise would be discarded by limiting the reuse possibilities of available transformations.",
    "keywords": []
  },
  {
    "title": "Classiﬁcation of Model Transformation Tools:\nPattern Matching Techniques",
    "date": 2014,
    "abstract": "While comparing diﬀerent model transformation languages (MTLs), it is common to refer to their syntactic and semantic features and overlook their supporting tools’ performance. Performance is one of the aspects that can hamper the application of MDD to industrial scenar- ios. An highly declarative MTL might simply not scale well when using large models due to its supporting implementation. In this paper, we fo- cus on the several pattern matching techniques (including optimization techniques) employed in the most popular transformation tools, and dis- cuss their eﬀectiveness w.r.t. the expressive power of the languages used. Because pattern matching is the most costly operation in a transforma- tion execution, we present a classiﬁcation of the existing model transfor- mation tools according to the pattern matching optimization techniques they implement. Our classiﬁcation complements existing ones that are more focused at syntactic and semantic features of the languages sup- ported by those tools.",
    "keywords": [
      "Model Transformations",
      "Languages Design",
      "Pattern Match- ing Techniques."
    ]
  },
  {
    "title": "Learning Implicit and Explicit Control in Model\nTransformations by Example",
    "date": 2014,
    "abstract": "We propose an evolutionary approach that, in addition to learn model transformation rules from examples, allows to capture im- plicit and explicit control over the transformation rules. The derivation of both transformation and control knowledge is performed through a heuristic search, i.e., a genetic programming algorithm, guided by the conformance with examples of past transformations supplied as pairs of source and target models. Our approach is evaluated on four model transformation problems that require non-trivial control. The obtained results are convincing for three of the four studied problems.",
    "keywords": [
      "Model transformation by example",
      "transformation control",
      "genetic programming."
    ]
  },
  {
    "title": "IncQuery-D: A Distributed Incremental Model Query Framework in the Cloud⋆",
    "date": 2014,
    "abstract": "Queries are the foundations of data intensive applications. In model-driven software engineering (MDE), model queries are core tech- nologies of tools and transformations. As software models are rapidly increasing in size and complexity, traditional tools exhibit scalability issues that decrease productivity and increase costs [17]. While scala- bility is a hot topic in the database community and recent NoSQL ef- forts have partially addressed many shortcomings, this happened at the cost of sacriﬁcing the ad-hoc query capabilities of SQL. Unfortunately, this is a critical problem for MDE applications due to their inherent workload complexity. In this paper, we aim to address both the scal- ability and ad-hoc querying challenges by adapting incremental graph search techniques – known from the EMF-IncQuery framework – to a distributed cloud infrastructure. We propose a novel architecture for distributed and incremental queries, and conduct experiments to demon- strate that IncQuery-D, our prototype system, can scale up from a single workstation to a cluster that can handle very large models and complex incremental queries eﬃciently.",
    "keywords": []
  },
  {
    "title": "Translating OCL to Graph Patterns⋆",
    "date": 2014,
    "abstract": "Model-driven tools use model queries for many purposes, including validation of well-formedness rules and speciﬁcation of de- rived features. The majority of declarative model query corpus avail- able in industry appears to use the OCL language. Graph pattern based queries, however, would have a number of advantages due to their more abstract speciﬁcation, such as performance improvements through ad- vanced query evaluation techniques. As query performance can be a key issue with large models, evaluating graph patterns instead of OCL queries could be useful in practice.",
    "keywords": []
  },
  {
    "title": "Fully Verifying Transformation Contracts for Declarative ATL",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "The Atlas Transformation Language (ATL) is today a de-facto standard in model-driven development. It is understood by the community that methods for exhaustively verifying such transformations provide an important pillar for achieving a stronger adoption of model-driven development in industry. In this paper we propose a method for verifying ATL model transformations by translating them into DSLTrans, a transformation language with limited expressiveness. Pre-/post-condition contracts are then veriﬁed on the resulting DSLTrans speciﬁcation using a symbolic-execution property prover. The technique we present in this paper is exhaustive for the declarative ATL subset, meaning that if a contract holds, it will hold when any input model is passed to the ATL transformation being checked. We explore the scalability of our technique using a set of examples, including a model transformation developed in collaboration with our industrial partner.",
    "keywords": [
      "Model transformation",
      "Formal veriﬁcation",
      "ATL",
      "Contracts",
      "Symbolic execution",
      "Pre-/Post-conditions"
    ],
    "authors": [
      "Bentley James Oakes",
      "Javier Troya",
      "Levi L´ucio",
      "and Manuel Wimmer"
    ],
    "file_path": "data/models/models15/Fully verifying transformation contracts for declarative ATL.pdf"
  },
  {
    "title": "Modeling User Intentions for In-Car Infotainment Systems using Bayesian Networks",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "To support users in operating a computer system with a varying set of functions, it is fundamental to understand their intentions, e.g., within an in-car infotainment system. Although the development of current in-car infotainment systems is already model-based, explicitly gathering and modeling user intentions is currently not supported. However, manually creating software that predicts user intentions is complex, error-prone and expensive. Model-based development can help in overcoming these issues. In this paper, we present an approach for modeling a user’s intention based on Bayesian networks. We support developers of in-car infotainment systems by providing means to model possible intentions of users according to the current situation. We further allow modeling of user preferences and show how the modeled intentions may change during run-time as a result of the user’s behavior. We demonstrate feasibility of our approach using an industrial example of an intention-aware in-car infotainment system.",
    "keywords": [],
    "authors": [
      "Daniel L¨uddecke",
      "Christoph Seidl",
      "Jens Schneider",
      "Ina Schaefer"
    ],
    "file_path": "data/models/models15/Modeling user intentions for in-car infotainment systems using Bayesian networks.pdf"
  },
  {
    "title": "SoSPa: A System of Security Design Patterns for Systematically Engineering Secure Systems",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model-Driven Security (MDS) for secure systems development still has limitations to be more applicable in practice. A recent systematic review of MDS shows that current MDS approaches have not dealt with multiple security concerns systematically. Besides, catalogs of security patterns which can address multiple security concerns have not been applied eﬃciently. This paper presents an MDS approach based on a uniﬁed System of Security design Patterns (SoSPa). In SoSPa, security design patterns are collected, speciﬁed as reusable aspect models to form a coherent system of them that guides developers in systematically addressing multiple security concerns. SoSPa consists of not only interrelated security design patterns but also a reﬁnement process towards their application. We applied SoSPa to design the security of crisis management systems. The result shows that multiple security concerns in the case study have been addressed by systematically integrating diﬀerent security solutions.",
    "keywords": [],
    "authors": [
      "Phu H. Nguyen",
      "Koen Yskout",
      "Thomas Heyman",
      "Jacques Klein",
      "Riccardo Scandariato",
      "Yves Le Traon"
    ],
    "file_path": "data/models/models15/SoSPa A system of Security design Patterns for systematically engineering secure systems.pdf"
  },
  {
    "title": "Performance Prediction upon Toolchain Migration in Model-Based Software",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Changing the development environment can have severe impacts on the system behavior such as the execution-time performance. Since it can be costly to migrate a software application, engineers would like to predict the performance parameters of the application under the new environment with as little effort as possible.\n\nIn this paper, we concentrate on model-driven development and provide a methodology to estimate the execution-time performance of application models under different toolchains. Our approach has low cost compared to the migration effort of an entire application. As part of the approach, we provide methods for characterizing model-driven applications, an algorithm for generating application-speciﬁc microbenchmarks, and results on using different methods for estimating the performance. In the work, we focus on SCADE as the development toolchain and use a Cruise Control and a Water Level application as case studies to conﬁrm the technical feasibility and viability of our technique.",
    "keywords": [
      "Model-based development",
      "Migration",
      "Automated Code Generation",
      "Estimation",
      "Prediction"
    ],
    "authors": [
      "Aymen Ketata",
      "Carlos Moreno",
      "Sebastian Fischmeister",
      "Jia Liang",
      "Krzysztof Czarnecki"
    ],
    "file_path": "data/models/models15/Performance prediction upon toolchain migration in model-based software.pdf"
  },
  {
    "title": "Engineering Tagging Languages for DSLs",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "To keep a DSL clean, readable and reusable in different contexts, it is useful to deﬁne a separate tagging language. A tag model logically adds information to the tagged DSL model while technically keeping the artifacts separated. Using a generic tagging language leads to promiscuous tag models, whereas deﬁning a target DSL-speciﬁc tag language has a high initial overhead. This paper presents a systematic approach to deﬁne a DSL-speciﬁc tag language and a corresponding schema language, combining the advantages of both worlds: (a) the tag language speciﬁcally ﬁts to the DSL, (b) the artifacts are kept separated and enabling reuse with different tag decorations, (c) the tag language follows a deﬁned type schema, and (d) systematic derivation considerably reduces the effort necessary to implement the tag language. An example shows that it can at least partially be realized by a generator and applied for any kind of DSL.",
    "keywords": [
      "Software Engineering",
      "Modeling",
      "MDE",
      "GSE"
    ],
    "authors": [
      "Timo Greifenberg",
      "Markus Look",
      "Sebastian Roidl",
      "Bernhard Rumpe"
    ],
    "file_path": "data/models/models15/Engineering tagging languages for DSLs.pdf"
  },
  {
    "title": "Extracting Frame Conditions from Operation Contracts",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "In behavioral modeling, operation contracts deﬁned by pre- and postconditions describe the effects on model properties (i.e., model elements such as attributes, links, etc.) that are enforced by an operation. However, it is usually omitted which model properties should not be modiﬁed. Deﬁning so-called frame conditions can ﬁll this gap. But, thus far, these have to be deﬁned manually – a time-consuming task. In this work, we propose a methodology which aims to support the modeler in the deﬁnition of the frame conditions by extracting suggestions based on an automatic analysis of operation contracts provided in OCL. More precisely, the proposed approach performs a structural analysis of pre- and postconditions together with invariants in order to categorize which class and object properties are clearly “variable” or “unaffected” – and which are “ambiguous”, i.e. indeed require a more thorough inspection. The developed concepts are implemented as a prototype and evaluated by means of several example models known from the literature.",
    "keywords": [],
    "authors": [
      "Philipp Niemann",
      "Frank Hilken",
      "Martin Gogolla",
      "Robert Wille"
    ],
    "file_path": "data/models/models15/Extracting frame conditions from operation contracts.pdf"
  },
  {
    "title": "State Machine Antipatterns for UML-RT",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Software development guidelines are a set of rules which can help improve the quality of software. These rules are deﬁned on the basis of experience gained by the software development community over time. Software antipatterns are a powerful and effective form of guidelines used for the identiﬁcation of bad design choices and development practices that often lead to poor-quality software. This paper introduces a set of seven state machine antipatterns for the model-based development of real time embedded software systems. Each of these antipatterns is described with a pair of examples: one for the antipattern itself and a second one for improved, refactored solution.",
    "keywords": [],
    "authors": [
      "Tuhin Kanti Das",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models15/State machine antipatterns for UML-RT.pdf"
  },
  {
    "title": "Textual Diagram Layout Language and Visualization Algorithm",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Graphical diagrams are an excellent source of information for understanding models. On the other hand, editing, storing and versioning models are more efficient in textual representations. In order to combine the advantages of these two representations, diagrams have to be generated from models defined in text. The generated diagrams are usually created by autolayout algorithms based on heuristics.\n\nIn this paper we argue that automatically laid out diagrams are not ideal. Instead, we propose a textual layout description language that allows users to define the arrangement of those diagram elements they consider important. The paper also presents algorithms that create diagrams according to the layout description and arrange the underspecified elements automatically.\n\nThe paper reports on the implementation of the proposed layout description language as an embedded language in Java. It is used to generate class and state machine diagrams compatible with the Papyrus UML editor.",
    "keywords": [],
    "authors": [
      "Balázs Gregorics",
      "Tibor Gregorics",
      "Gábor Ferenc Kovács",
      "András Dobreff",
      "Gergely Dévai"
    ],
    "file_path": "data/models/models15/Textual diagram layout language and visualization algorithm.pdf"
  },
  {
    "title": "MODELS 2015 Organization",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models15/Contents.pdf"
  },
  {
    "title": "Reusable Event Types for Models at Runtime to Support the Examination of Runtime Phenomena",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Today’s software is getting more and more complex and harder to understand. Models help to organize knowledge and emphasize the structure of a software at a higher abstraction level. While the usage of model-driven techniques is widely adopted during software construction, it is still an open research topic if models can also be used to make runtime phenomena more comprehensible as well. It is not obvious which models are suitable for manual analysis and which model elements can be related to what type of runtime events. This paper proposes a collection of runtime event types that can be reused for various systems and meta-models. Based on these event types, information can be derived which help human observers to assess the current system state. Our approach is applied in a case study and evaluated regarding generalisability and completeness by relating it to two different meta-models.",
    "keywords": [
      "events",
      "examination",
      "models",
      "runtime"
    ],
    "authors": [
      "Michael Szvetits",
      "Uwe Zdun"
    ],
    "file_path": "data/models/models15/Reusable event types for models at runtime to support the examination of runtime phenomena.pdf"
  },
  {
    "title": "Consistent Co-Evolution of Models and Transformations",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Evolving metamodels are in the center of Model-Driven Engineering, necessitating the co-evolution of dependent artifacts like models and transformations. While model co-evolution has been extensively studied, transformation co-evolution has received less attention up to now. Current approaches for transformation co-evolution provide a ﬁxed, restricted set of metamodel (MM) changes, only. Furthermore, composite changes are treated as monolithic units, which may lead to inconsistent co-evolution for overlapping atomic changes and prohibits extensibility. Finally, transformation co-evolution is considered in isolation, possibly inducing inconsistencies between model and transformation co-evolution. To overcome these limitations, we propose a complete set of atomic MM changes being able to describe arbitrary MM evolutions. Reusability and extensibility are supported by means of change composition, ensuring an intra-artifact consistent co-evolution. Furthermore, each change provides resolution actions for both, models and transformations, ensuring an inter-artifact consistent co-evolution. Based on our conceptual approach, a prototypical implementation is presented.",
    "keywords": [],
    "authors": [
      "Angelika Kusel",
      "Jürgen Etzlstorfer",
      "Elisabeth Kapsammer",
      "Werner Retschitzegger",
      "Wieland Schwinger",
      "Johannes Schönböck"
    ],
    "file_path": "data/models/models15/Consistent co-evolution of models and transformations.pdf"
  },
  {
    "title": "A Model-Based Framework for Probabilistic Simulation of Legal Policies",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Legal policy simulation is an important decision-support tool in domains such as taxation. The primary goal of legal policy simulation is predicting how changes in the law affect measures of interest, e.g., revenue. Currently, legal policies are simulated via a combination of spreadsheets and software code. This poses a validation challenge both due to complexity reasons and due to legal experts lacking the expertise to understand software code. A further challenge is that representative data for simulation may be unavailable, thus necessitating a data generator. We develop a framework for legal policy simulation that is aimed at addressing these challenges. The framework uses models for specifying both legal policies and the probabilistic characteristics of the underlying population. We devise an automated algorithm for simulation data generation. We evaluate our framework through a case study on Luxembourg’s Tax Law.",
    "keywords": [
      "Legal Policies",
      "Simulation",
      "UML Proﬁles",
      "Model-Driven Code Generation",
      "Probabilistic Data Generation"
    ],
    "authors": [
      "Ghanem Soltana",
      "Nicolas Sannier",
      "Mehrdad Sabetzadeh",
      "and Lionel C. Briand"
    ],
    "file_path": "data/models/models15/A model-based framework for probabilistic simulation of legal policies.pdf"
  },
  {
    "title": "A Statistical Analysis Approach to Assist Model Transformation Evolution",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Model Driven Engineering (MDE) is essentially based in metamodel deﬁnition, model edition and the speciﬁcation of model transformations (MT) among these. In many cases the development, evolution and adaptation of these transformations is still carried out without the support of proper methods and tools to reduce the effort and related costs to these activities. In this work, a novel model testing approach speciﬁcally designed to assist the engineer in model transformation evolution is presented. A statistical analysis of the actual behavior of the transformations is performed by means of the computation of well-known information extraction metrics. In order to assist the MT adaptation, a detailed interpretation of the possible results of those metrics is also presented. And ﬁnally, the results of applying this approach on a Model-Driven Reverse Engineering (MDRE) scenario deﬁned in the context of the MIGRARIA project are discussed.",
    "keywords": [
      "Model Transformation",
      "Model Transformation Evolution",
      "Model Transformation Testing",
      "Testing Oracle"
    ],
    "authors": [
      "Roberto Rodriguez-Echeverria",
      "Fernando Macias"
    ],
    "file_path": "data/models/models15/A statistical analysis approach to assist model transformation evolution.pdf"
  },
  {
    "title": "Quick Fixing ATL Model Transformations",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Abstract—The correctness of model transformations is key to\nobtain reliable MDE solutions. However, current transformation\ntools provide limited support to statically detect and correct\nerrors. This way, the identiﬁcation of errors and their correction\nare mostly manual activities. Our aim is to improve this situation.\nBased on a static analyser for ATL model transformations\nwhich we have previously built, we present a method and a system\nto propose quick ﬁxes for transformation errors. The analyser\nis based on a combination of program analysis and constraint\nsolving, and our quick ﬁx generation technique makes use of the\nanalyser features to provide a range of ﬁxes, notably some non-\ntrivial, transformation-speciﬁc ones. Our approach integrates\nseamlessly with the ATL editor. We provide an evaluation based\non an existing faulty transformation, and automatically generated\ntransformation mutants, showing overall good results.",
    "keywords": [
      "Model Transformation",
      "Transformation Static Analysis",
      "ATL",
      "Quick ﬁxes",
      "Veriﬁcation and Testing"
    ],
    "authors": [
      "Jesús Sánchez Cuadrado",
      "Esther Guerra",
      "Juan de Lara"
    ],
    "file_path": "data/models/models15/Quick fixing ATL model transformations.pdf"
  },
  {
    "title": "A-posteriori Typing for Model-Driven Engineering",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model-Driven Engineering is founded on the ability to create and process models conformant to a meta-model. Hence, meta-model classes are used in two ways: as templates to create objects, and as classiﬁers for them. While these two aspects are inherently tied in most meta-modelling approaches, in this paper, we discuss the beneﬁts of their decoupling. Thus, we rely on standard mechanisms for object creation and propose a-posteriori typing as a means to reclassify objects and enable multiple, partial, dynamic typings. This approach enhances ﬂexibility, permitting unanticipated reutilization (as existing model management operations deﬁned for a meta-model can be reused with other models once they get reclassiﬁed), as well as model transformation by reclassiﬁcation. We show the underlying theory behind the introduced concepts, and illustrate its applicability using our METADEPTH meta-modelling tool.",
    "keywords": [
      "A-posteriori typing",
      "Model typing",
      "Partial typing",
      "Dynamic typing",
      "Flexible MDE"
    ],
    "authors": [
      "Juan de Lara",
      "Esther Guerra",
      "Jesús Sánchez Cuadrado"
    ],
    "file_path": "data/models/models15/A-posteriori typing for Model-Driven Engineering.pdf"
  },
  {
    "title": "A Situational Method for Semi-automated Enterprise Architecture Documentation (SoSyM Abstract)",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Large organizations critically rely on their IT infrastructure. So called Enterprise Architecture (EA) models are often created to understand how the IT supports the business and used to optimize the IT and align it with the business. However, the models grow very large and are hard to keep up-to-date. Current approaches focus on automated data collection to tackle this problem, which is not feasible in many situations. In this paper we present a semi-automated EA documentation method and tool support that tackles this problem and takes the organizational contexts into account.",
    "keywords": [],
    "authors": [
      "Matthias Farwick",
      "Christian M. Schweda",
      "Ruth Breu",
      "Inge Hanschke"
    ],
    "file_path": "data/models/models15/A situational method for semi-automated enterprise architecture documentation -SoSyM abstract-.pdf"
  },
  {
    "title": "Identiﬁcation of Simulink Model Antipattern Instances using Model Clone Detection",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "One challenge facing the Model-Driven Engineering community is the need for model quality assurance. Speciﬁcally, there should be better facilities for analyzing models automat-ically. One measure of quality is the presence or absence of good and bad properties, such as patterns and antipatterns, respectively. We elaborate on and validate our earlier idea of detecting patterns in model-based systems using model clone detection by devising a Simulink antipattern instance detector. We chose Simulink because it is prevalent in industry, has mature model clone detection techniques, and interests our industrial partners. We demonstrate our technique using near-miss cross-clone detection to ﬁnd instances of Simulink antipatterns derived from the literature in four sets of public Simulink projects. We present our detection results, highlight interesting examples, and discuss potential improvements to our approach. We hope this work provides a ﬁrst step in helping practitioners improve Simulink model quality and further research in the area.",
    "keywords": [],
    "authors": [
      "Matthew Stephan",
      "James R. Cordy"
    ],
    "file_path": "data/models/models15/Identification of Simulink model antipattern instances using model clone detection.pdf"
  },
  {
    "title": "Automobile: Aircraft or Smartphone? Modeling Challenges and Opportunities in Automotive Systems",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Automotive systems are turning out to be one of the most complex consumer electronic systems being ever built. For the modern day users, they are products like smartphones and tablets but in size, complexity and quality and safety requirements they match if not exceed aircraft, and similar high integrity systems. Many of the major advances in Software engineering like model based development, platform based design and product line engineering have been introduced in the development of automotive electronic and software subsystems, which involve million lines of code and tens of electronic control units interconnected with multiple communication buses. This talk will highlight the challenges, current practices and new developments in the industry in building next generation automotive software from the modeling and analysis perspective. The challenges include traditional issues like system integration and feature interaction arising out of the federated development model, heterogeneity in subsystem behavior, time and space distributed development of software and the recent and rapidly increasing demand for advanced driver assistance features and system level requirements like fault tolerance and security. The talk attempts to outline a set of requirements for modeling from the perspective of system design and analysis. The talk will also touch upon some of the research and developments efforts currently ongoing within and with our external partners to meet these challenges.",
    "keywords": [],
    "authors": [
      "Ramesh S"
    ],
    "file_path": "data/models/models15/Automobile Aircraft or smartphone- Modeling challenges and opportunities in Automotive Systems -keynote-.pdf"
  },
  {
    "title": "Enriching Megamodel Management with Collection-Based Operators",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Megamodels are often used in MDE to describe collections of models and relationships between them. Typical collection-based operations – map, reduce, ﬁlter – cannot be applied directly to megamodels since these operators need to take relationships between models into consideration. In this paper, we propose adapted versions of these operators, demonstrating them on four megamodeling scenarios. We then analyze their applicability for handling industrial-sized megamodels. Finally, we report on a reference implementation of the operators and experimental results using it.",
    "keywords": [],
    "authors": [
      "Rick Salay",
      "Sahar Kokaly",
      "Alessio Di Sandro",
      "Marsha Chechik"
    ],
    "file_path": "data/models/models15/Enriching megamodel management with collection-based operators.pdf"
  },
  {
    "title": "Modelling the Climate System: Is Model-Based Science Like Model-Based Engineering?",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Modern computational science is largely a model-building activity. At first sight, the models that scientists construct seem to differ radically from those used in model-based engineering. Scientists tend to build indicative ('how things are') models of the world using sets of continuous equations, while engineers tend to build optative ('how things should be') models of the world using structural and procedural abstractions. But a closer look reveals many fascinating similarities. In this talk, I will explore the relationship between the two types of modelling, drawing on my field studies of how climate modellers work. I'll begin with an overview of what a climate model is and how it is used. I'll then dive deeper into the engineering challenges of constructing a climate model, including the challenges of coupling disparate model components, dealing with model version-ing and model management issues, and the role that climate models play in enabling collaborative work. In the process, I hope to inspire people to explore how ideas from model-based software engineering might contribute to scientific mod-elling in general, and, more specifically, to the societal grand challenge of climate change.",
    "keywords": [],
    "authors": [
      "Steve Easterbrook"
    ],
    "file_path": "data/models/models15/Modelling the climate system Is model-based science like model-based engineering- -Keynote-.pdf"
  },
  {
    "title": "Formalizing the ISO/IEC/IEEE 29119 Software Testing Standard",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model-based testing (MBT) provides a systematic and automated way to facilitate rigorous testing of software systems. MBT has been an intense area of research and a large number of MBT techniques have been developed in the literature and in the practice. However, all of the techniques have been developed using their own concepts and terminology of MBT, which are very often different than other techniques and at times have conflicting semantics. Moreover, while working on MBT projects with our industrial partners in the last several years, we were unable to find a unified way of defining MBT techniques based on standard terminology. To precisely define MBT concepts with the aim of providing common understanding of MBT terminology across techniques, we formalize a small subset of the recently released ISO/IEC/IEEE 29119 Software Testing Standard as a conceptual model (UML class diagrams) together with OCL constraints. The conceptual model captures all the necessary concepts based on the standard terminology that are mandatory or optional in the context of MBT techniques and can be used to define new MBT tools and techniques. To validate the conceptual model, we instantiated its concepts for various MBT techniques previously developed in the context of our industrial partners. Such instantiation automatically enforces the specified OCL constraints. This type of validation provided us feedback to further refine the conceptual model. Finally, we also provide our experiences and lessons learnt for such formalization and validation.",
    "keywords": [
      "Model-Based Testing",
      "ISO/IEC/IEEE 29119",
      "UML",
      "Test Case Generation",
      "Modeling Methodology"
    ],
    "authors": [
      "Shaukat Ali",
      "Tao Yue"
    ],
    "file_path": "data/models/models15/Formalizing the ISO-IEC-IEEE 29119 Software Testing Standard.pdf"
  },
  {
    "title": "On the Use of UML Documentation in Software Maintenance: Results from a Survey in Industry",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "This paper presents the findings of a survey on the use of UML in software maintenance, carried out with 178 professionals working on software maintenance projects in 12 different countries. As part of long-term research we are carrying out to investigate the benefits of using UML in software maintenance, the main objectives of this survey are: 1) to explore whether UML diagrams are being used in software industry maintenance projects; 2) to see what UML diagrams are the most effective for software maintenance; 3) to find out what the perceived benefits of using UML diagrams are; and 4) to contextualize the kind of companies that use UML documentation in software maintenance. Some complementary results based on the way the documentation is used (whether it is UML-based or not) during software maintenance are also presented.",
    "keywords": [
      "UML",
      "Software Maintenance",
      "Survey"
    ],
    "authors": [
      "Ana M. Fernández-Sáez",
      "DaniloCaivano",
      "Marcela Genero",
      "Michel R.V. Chaudron"
    ],
    "file_path": "data/models/models15/On the use of UML documentation in software maintenance Results from a survey in industry.pdf"
  },
  {
    "title": "Incremental Symbolic Execution of Evolving State Machines",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "This paper introduces two complementary techniques, memoization-based and dependency-based incremental symbolic execution, that aim to optimize the analysis of state machine models that undergo change. We implement the two proposed techniques on IBM Rhapsody Statecharts and present some evaluation results.",
    "keywords": [],
    "authors": [
      "Amal Khalil",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models15/Incremental symbolic execution of evolving state machines.pdf"
  },
  {
    "title": "A Framework for Relating Syntactic and Semantic Model Differences",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model differencing is an important activity in model-based development processes. Differences need to be detected, analyzed, and understood to evolve systems and explore alternatives.\n\nTwo distinct approaches have been studied in the literature: syntactic differencing, which compares the concrete or abstract syntax of models, and semantic differencing, which compares models in terms of their meaning. Syntactic differencing identifies change operations that transform the syntactical representation of one model to the syntactical representation of the other. However, it does not explain their impact on the meaning of the model. Semantic model differencing is independent of syntactic changes and presents differences as elements in the semantics of one model but not the other. However, it does not reveal the syntactic changes causing these semantic differences.\n\nWe define a language independent, abstract framework, which relates syntactic change operations and semantic difference witnesses. We formalize fundamental relations of necessary and sufficient sets of change operations and analyze their properties. We further demonstrate concrete instances of the framework for three different popular modeling languages, namely, class diagrams, activity diagrams, and feature models. The framework provides a novel foundation for combining syntactic and semantic differencing.",
    "keywords": [],
    "authors": [
      "Shahar Maoz and Jan Oliver Ringert"
    ],
    "file_path": "data/models/models15/A framework for relating syntactic and semantic model differences.pdf"
  },
  {
    "title": "Synthesizing Tests for Combinatorial Coverage of\nModal Scenario Speciﬁcations",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Software-intensive systems often consist of many components that interact to fulﬁll complex functionality. Testing these systems is vital, preferably by a minimal set of tests that covers all relevant cases. The behavior is typically speciﬁed by scenarios that describe what the system may, must, or must not do. When designing tests, as in the design of the system itself, the challenge is to consider interactions of scenarios. When doing this manually, critical interactions are easily overlooked. Inspired by Combinatorial Test Design, which exploits that bugs are typically found by regarding the interaction of a small set of parameters, we propose a new test coverage criterion based on scenario interactions. Furthermore, we present a novel technique for automatically synthesizing from Modal Sequence Diagram speciﬁcations a minimal set of tests that ensures a maximal coverage of possible t-wise scenario interactions. The technique is evaluated on an example speciﬁcation from an industrial project.",
    "keywords": [],
    "authors": [
      "Valerio Panzica La Manna",
      "Itai Segall",
      "Joel Greenyer"
    ],
    "file_path": "data/models/models15/Synthesizing tests for combinatorial coverage of modal scenario specifications.pdf"
  },
  {
    "title": "Toward Overcoming Accidental Complexity in Organisational Decision-Making",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "This paper takes a practitioner’s perspective on the problem of organisational decision-making. Industry practice follows a refinement based iterative method for organizational decision-making. However, existing enterprise modelling tools are not complete with respect to the needs of organizational decision-making. As a result, today, a decision maker is forced to use a chain of non-interoperable tools supporting paradigmatically diverse modelling languages with the onus of their co-ordinated use lying entirely on the decision maker. This paper argues the case for a model-based approach to overcome this accidental complexity. A bridge meta-model, specifying relationships across models created by individual tools, ensures integration and a method, describing what should be done when and how, and ensures better tool integration. Validation of the proposed solution using a case study is presented with current limitations and possible means of overcoming them outlined.",
    "keywords": [
      "Organizational decision making",
      "Enterprise modeling tools",
      "Meta modelling",
      "Method"
    ],
    "authors": [
      "Vinay Kulkarni",
      "Souvik Barat",
      "Tony Clark",
      "Balbir Barn"
    ],
    "file_path": "data/models/models15/Toward overcoming accidental complexity in organisational decision-making.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models15/Sponsors.pdf"
  },
  {
    "title": "FRAGMENTA: A Theory of Fragmentation for MDE",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model-Driven Engineering (MDE) promotes models throughout development. However, models may become large and unwieldy even for small to medium-sized systems. This paper tackles the MDE challenges of model complexity and scalability. It proposes FRAGMENTA, a theory of modular design that breaks down overall models into fragments that can be put together to build meaningful wholes, in contrast to classical MDE approaches that are essentially monolithic. The theory is based on an algebraic description of models, fragments and clusters based on graphs and morphisms. The paper’s novelties include: (i) a mathematical treatment of fragments and a seaming mechanism of proxies to enable inter-fragment referencing, (ii) fragmentation strategies, which prescribe a fragmentation structure to model instances, (iii) FRAGMENTA’s support for both top-down and bottom-up design, and (iv) our formally proved result that shows that inheritance hierarchies remain well-formed (acyclic) globally when fragments are composed provided some local fragment constraints are met.",
    "keywords": [
      "Model-driven engineering",
      "meta-modelling",
      "modularity",
      "graphs",
      "scalability",
      "model composition"
    ],
    "authors": [
      "Nuno Amálio",
      "Juan de Lara",
      "Esther Guerra"
    ],
    "file_path": "data/models/models15/Fragmenta A theory of fragmentation for MDE.pdf"
  },
  {
    "title": "An Automated Model Based Testing Approach for Platform Games",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Game development has recently gained a lot of momentum and is now a major software development industry. Platform games are being revived with both their 2D and 3D versions being developed. A major challenge faced by the industry is a lack of automated system-level approaches for game testing. Currently in most game development organizations, games are tested manually or using semi-automated techniques. Such testing techniques do not scale to the industry requirements where more systematic and repeatable approaches are required. In this paper we propose a model-based testing approach for automated black box functional testing of platform games. The paper provides a detailed modeling methodology to support automated system-level game testing. As part of the methodology, we provide guidelines for modeling the platform games for testing using our proposed game test modeling profile. We use domain modeling for representing the game structure and UML state machines for behavioral modeling. We present the details related to automated test case generation, execution, and oracle generation. We demonstrate our model-based testing approach by applying it on two cases studies, a widely referenced and open source implementation of Mario brothers game and an industrial case study of an endless runner game. The proposed approach was able to identify major faults in the open source game implementation. Our results showed that the proposed approach is practical and can be applied successfully on industrial games.",
    "keywords": [
      "Model based testing (MBT)",
      "game testing",
      "black box testing",
      "functional testing",
      "system-level testing",
      "and unified modeling language (UML)"
    ],
    "authors": [
      "Sidra Iftikhar",
      "Muhammad Zohaib Iqbal",
      "Muhammad Uzair Khan",
      "Wardah Mahmood"
    ],
    "file_path": "data/models/models15/An automated model based testing approach for platform games.pdf"
  },
  {
    "title": "Pattern-Based Debugging of Declarative Models",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Pattern-based debugging compares the engineer’s model to a pre-computed library of patterns, and generates discriminating examples that help the engineer decide if the model’s constraints need to be strengthened or weakened. A number of tactics are used to help connect the generated examples to the text of the model. This technique augments existing example/counter-example generators and unsatisﬁable core analysis tools, to help the engineer better localize and understand defects caused by complete overconstraint, partial overconstraint, and underconstraint. The technique is applied to localizing, understanding, and ﬁxing a defect in an Alloy model of Dijkstra’s Dining Philosopher’s problem. Automating the search procedure remains as essential future work.",
    "keywords": [],
    "authors": [
      "Vajih Montaghami and Derek Rayside"
    ],
    "file_path": "data/models/models15/Pattern-based debugging of declarative models.pdf"
  },
  {
    "title": "Enhancing the Communication Value of UML Models with Graphical Layers",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "UML is defined as a visual modeling language for specifying, constructing, and documenting software intensive systems. In that context, UML diagrams play a central role in the whole software engineering process, starting from early analysis, through implementation, to maintenance. Recent surveys of UML use in industry showed that software practitioners use it on a regular basis, and particularly for communication and as a mental-assist tool. However, they also pointed out the following weaknesses: the lack of context, graphical layout problems, and the language’s inadequacy as a facility for communication between technical teams and their clients. In this paper, we present a general approach that addresses these problems by enhancing the effectiveness of UML models as a communication vehicle. Our approach is based on expressing stakeholder-specific viewpoints through the use of secondary notations. This involves the use of auxiliary visual variables (e.g., color, position, size) that are not formally specified in UML. To that end, we extend the traditional concept of layer found in many graphical editors to UML diagram editors. FlipLayers is an implementation of our approach. It is in the form of a plugin for the Papyrus modeling environment. One scenario with several case studies is presented in the paper to demonstrate the benefits of our approach and also to illustrate how to express viewpoints with FlipLayers.",
    "keywords": [],
    "authors": [
      "Yosser El Ahmar",
      "Sébastien Gérard",
      "Cédric Dumoulin",
      "Xavier Le Pallec"
    ],
    "file_path": "data/models/models15/Enhancing the communication value of UML models with graphical layers.pdf"
  },
  {
    "title": "Systematically Deriving Domain-Speciﬁc Transformation Languages",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Model transformations are helpful to evolve, refactor, refine and maintain models. While domain-specific languages are normally intuitive for modelers, common model transformation approaches (regardless of whether they transform graphical or textual models) are based on the modeling language’s abstract syntax requiring the modeler to learn the internal representation of the model to describe transformations. This paper presents a process that allows to systematically derive a textual domain-specific transformation language from the grammar of a given textual modeling language. As example, we apply this systematic derivation to UML class diagrams to obtain a domain-specific transformation language called CDTrans. CDTrans incorporates the concrete syntax of class diagrams which is already familiar to the modeler and extends it with a few transformation operators. To demonstrate the usefulness of the derived transformation language, we describe several refactoring transformations.",
    "keywords": [
      "Model transformation",
      "concrete syntax",
      "domain-specific",
      "language-specific",
      "systematic derivation",
      "generation"
    ],
    "authors": [
      "Katrin Hölldobler",
      "Bernhard Rumpe",
      "Ingo Weisemöller"
    ],
    "file_path": "data/models/models15/Systematically deriving domain-specific transformation languages.pdf"
  },
  {
    "title": "Process Mining in Software Systems\nDiscovering Real-Life Business Transactions and Process Models from Distributed Systems",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "This paper presents a novel reverse engineering technique for obtaining real-life event logs from distributed systems. This allows us to analyze the operational processes of software systems under real-life conditions, and use process mining techniques to obtain precise and formal models. Hence, the work can be positioned in-between reverse engineering and process mining. We present a formal deﬁnition, implementation and an instrumentation strategy based the joinpoint-pointcut model. Two case studies are used to evaluate our approach. These concrete exam- ples demonstrate the feasibility and usefulness of our approach.",
    "keywords": [
      "Reverse Engineering",
      "Process Mining",
      "Event Log",
      "Distributed Systems",
      "Performance Analysis",
      "Process Discovery",
      "Joinpoint-Pointcut Model",
      "Aspect-Oriented Programming"
    ],
    "authors": [
      "Maikel Leemans (m.leemans@tue.nl) and Wil M. P. van der Aalst (w.m.p.v.d.aalst@tue.nl)"
    ],
    "file_path": "data/models/models15/Process mining in software systems Discovering real-life business transactions and process models from distributed systems.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Aalst",
      "Wil M. P. van der",
      "Ali",
      "Shaukat",
      "Almorsy",
      "Mohamed",
      "Amálio",
      "Nuno",
      "Atkinson",
      "Colin",
      "Auguston",
      "Mikhail",
      "Babau",
      "Jean-Philippe",
      "Barat",
      "Souvik",
      "Barn",
      "Balbir",
      "Bastarrica",
      "María Cecilia",
      "Basten",
      "Twan",
      "Breu",
      "Ruth",
      "Briand",
      "Lionel C.",
      "Burgueño",
      "Loli",
      "Caivano",
      "Danilo",
      "Chaudron",
      "Michel R. V.",
      "Chechik",
      "Marsha",
      "Chen",
      "Tieming",
      "Clark",
      "Tony",
      "Combemale",
      "Benoit",
      "Conte",
      "Tayana",
      "Cordy",
      "James R.",
      "Czarnecki",
      "Krzysztof",
      "Das",
      "Tuhin Kanti",
      "DeAntoni",
      "Julien",
      "De Lara",
      "Juan",
      "Dévai",
      "Gergely",
      "Diaz-Pace",
      "J. Andrés",
      "Dingel",
      "Juergen",
      "Di Sandro",
      "Alessio",
      "Dobreff",
      "András",
      "Dong",
      "Jin Song",
      "Drechsler",
      "Rolf",
      "Drira",
      "Khalil",
      "Dumoulin",
      "Cédric",
      "Easterbrook",
      "Steve",
      "Eder",
      "Klaus",
      "Eichler",
      "Cédric",
      "Elaasar",
      "Maged",
      "El Ahmar",
      "Yosser",
      "Etzlstorfer",
      "Jürgen",
      "Farwick",
      "Matthias",
      "Fernández-Sáez",
      "Ana M.",
      "Fischmeister",
      "Sebastian",
      "Fouché",
      "Alexis",
      "Fouquet",
      "Francois",
      "Garmendia",
      "Antonio",
      "Geilen",
      "Marc",
      "Genero",
      "Marcela",
      "Gérard",
      "Sébastien",
      "Gerbig",
      "Ralph",
      "Gogolla",
      "Martin",
      "Goknil",
      "Arda",
      "Greenyer",
      "Joel",
      "Gregorics",
      "Balázs",
      "Gregorics",
      "Tibor",
      "Greifenberg",
      "Timo",
      "Grieco",
      "Alfredo",
      "Grünbacher",
      "Paul",
      "Grundy",
      "John",
      "Guerra",
      "Esther",
      "Hajri",
      "Ines",
      "Hanschke",
      "Inge",
      "Hartmann",
      "Thomas",
      "Heyman",
      "Thomas",
      "Hilken",
      "Christoph",
      "Hilken",
      "Frank",
      "Hölldobler",
      "Katrin",
      "Iftikhar",
      "Sidra",
      "Iqbal",
      "Muhammad Zohaib",
      "Jacobs",
      "Johan",
      "Kapsammer",
      "Elisabeth",
      "Kerboeuf",
      "Mickaël",
      "Ketata",
      "Aymen",
      "Khalil",
      "Amal",
      "Khan",
      "Muhammad Uzair",
      "Kholkar",
      "Deepali",
      "Kienzle",
      "Jörg",
      "Klein",
      "Jacques",
      "Kokaly",
      "Sahar",
      "Kovács",
      "Gábor Ferenc",
      "Kˇrikava",
      "Filip",
      "Kühne",
      "Thomas",
      "Kulkarni",
      "Vinay",
      "Kusel",
      "Angelika",
      "Leemans",
      "Maikel",
      "Le Pallec",
      "Xavier",
      "Le Traon",
      "Yves",
      "Lettner",
      "Daniela",
      "Liang",
      "Jia",
      "Liu",
      "Yang",
      "Look",
      "Markus",
      "Lúcio",
      "Levi",
      "Lüddecke",
      "Daniel",
      "Macias",
      "Fernando",
      "Mahmood",
      "Wardah",
      "Mallet",
      "Frédéric",
      "Maoz",
      "Shahar",
      "Marcos",
      "Claudia",
      "Marczak",
      "Sabrina",
      "Martin",
      "Kevin J. M.",
      "Moawad",
      "Assaad",
      "Montaghami",
      "Vajih",
      "Monteil",
      "Thierry",
      "Moreno",
      "Carlos",
      "Murphy",
      "Gail",
      "Nain",
      "Gregory",
      "Nguyen",
      "Phu H.",
      "Nguyen",
      "Tuong Huan",
      "Niemann",
      "Philipp",
      "Noyrit",
      "Florian",
      "Oakes",
      "Bentley James",
      "Oran",
      "Ana Carolina",
      "Panzica La Manna",
      "Valerio",
      "Peleska",
      "Jan",
      "Perovich",
      "Daniel",
      "Pescador",
      "Ana",
      "Prähofer",
      "Herbert",
      "Przigoda",
      "Nils",
      "Rabelo",
      "Jacilane",
      "Rago",
      "Alejandro",
      "Rayside",
      "Derek",
      "Reniers",
      "Michel",
      "Retschitzegger",
      "Werner",
      "Ringert",
      "Jan Oliver",
      "Rodriguez-Echeverria",
      "Roberto",
      "Roidl",
      "Sebastian",
      "Rouvoy",
      "Romain",
      "Rumpe",
      "Bernhard",
      "S",
      "Ramesh",
      "Sabetzadeh",
      "Mehrdad",
      "Salay",
      "Rick",
      "Sánchez Cuadrado",
      "Jesús",
      "Sanden",
      "Bram van der",
      "Sannier",
      "Nicolas",
      "Scandariato",
      "Riccardo",
      "Schaefer",
      "Ina",
      "Schiffelers",
      "Ramon",
      "Schneider",
      "Jens",
      "Schönböck",
      "Johannes",
      "Schöttle",
      "Matthias",
      "Schweda",
      "Christian M.",
      "Schwinger",
      "Wieland",
      "Segall",
      "Itai",
      "Seidl",
      "Christoph",
      "Seinturier",
      "Lionel",
      "Silvestre",
      "Luis",
      "Simmonds",
      "Jocelyn",
      "Soltana",
      "Ghanem",
      "Song",
      "Songzheng",
      "Stephan",
      "Matthew",
      "Stephany",
      "Thierry",
      "Stolf",
      "Patricia",
      "Sun",
      "Jun",
      "Sunkle",
      "Sagar",
      "Szvetits",
      "Michael",
      "Troya",
      "Javier",
      "Valentim",
      "Natasha M. Costa",
      "Vallecillo",
      "Antonio",
      "Vallejo",
      "Paola",
      "Vara Larsen",
      "Matias Ezequiel",
      "Voeten",
      "Jeroen",
      "Weisemöller",
      "Ingo",
      "Wille",
      "Robert",
      "Wimmer",
      "Manuel",
      "Yskout",
      "Koen",
      "Yue",
      "Tao",
      "Zdun",
      "Uwe"
    ],
    "file_path": "data/models/models15/Author index.pdf"
  },
  {
    "title": "Stream my Models: Reactive Peer-to-Peer Distributed Models@run.time",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "The models@run.time paradigm promotes the use of models during the execution of cyber-physical systems to represent their context and to reason about their runtime behaviour. However, current modeling techniques do not allow to cope at the same time with the large-scale, distributed, and constantly changing nature of these systems. In this paper, we introduce a distributed models@run.time approach, combining ideas from reactive programming, peer-to-peer distribution, and large-scale models@run.time. We deﬁne distributed models as observable streams of chunks that are exchanged between nodes in a peer-to-peer manner. A lazy loading strategy allows to transparently access the complete virtual model from every node, although chunks are actually distributed across nodes. Observers and automatic reloading of chunks enable a reactive programming style. We integrated our approach into the Kevoree Modeling Framework and demonstrate that it enables frequently changing, reactive distributed models that can scale to millions of elements and several thousand nodes.",
    "keywords": [
      "Models@run.time",
      "Distributed models",
      "Reactive programming",
      "Asynchronous programming",
      "Peer-to-peer"
    ],
    "authors": [
      "Thomas Hartmann",
      "Assaad Moawad",
      "Francois Fouquet",
      "Gregory Nain",
      "Jacques Klein",
      "and Yves Le Traon"
    ],
    "file_path": "data/models/models15/Stream my models Reactive peer-to-peer distributed models-run.time.pdf"
  },
  {
    "title": "Concern-Oriented Interfaces for Model-Based Reuse of APIs",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Reuse is essential in modern software engineering, but limited in the context of MDE by the poor availability of reusable models. On the other hand, reusable code artifacts such as frameworks and libraries are abundant. This paper presents an approach to raise reusable code artifacts to the modelling level by modelling their API using concern-oriented techniques, thus enabling their use in the context of MDE. Our API interface models contain additional information, such as the encapsulated features and their impacts, to assist the developer in the reuse process. Once he has speciﬁed his needs, the model interface exposes only the API elements relevant for this speciﬁc reuse at the model level, together with the required usage protocol. We show how this approach is applied by hand to model the interface of a small GUI framework and outline how we envision this process to be performed semi-automatically.",
    "keywords": [],
    "authors": [
      "Matthias Schöttle and Jörg Kienzle"
    ],
    "file_path": "data/models/models15/Concern-oriented interfaces for model-based reuse of APIs.pdf"
  },
  {
    "title": "Applying Product Line Use Case Modeling in an Industrial Automotive Embedded System: Lessons Learned and a Reﬁned Approach",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "In this paper, we propose, apply, and assess Product line Use case modeling Method (PUM), an approach that supports modeling variability at different levels of granularity in use cases and domain models. Our motivation is that, in many software development environments, use case modeling drives interactions among stakeholders and, therefore, use cases and domain models are common practice for requirements elicitation and analysis. In PUM, we integrate and adapt existing product line extensions for use cases and introduce some template extensions for use case speciﬁcations. Variability is captured in use case diagrams while it is reﬂected at a greater level of detail in use case speciﬁcations. Variability in domain concepts is captured in domain models. PUM is supported by a tool relying on Natural Language Processing (NLP). We applied PUM to an industrial automotive embedded system and report lessons learned and results from structured interviews with experienced engineers.",
    "keywords": [],
    "authors": [
      "Ines Hajri",
      "Arda Goknil",
      "Lionel C. Briand",
      "Thierry Stephany"
    ],
    "file_path": "data/models/models15/Applying product line Use case modeling in an industrial automotive embedded system Lessons learned and a refined approach.pdf"
  },
  {
    "title": "Beyond Discrete Modeling: A Continuous and Efﬁcient Model for IoT",
    "submission-date": "2015/MM",
    "publication-date": "2015/MM",
    "abstract": "Internet of Things applications analyze our past habits through sensor measures to anticipate future trends. To yield accurate predictions, intelligent systems not only rely on single numerical values, but also on structured models aggregated from different sensors. Computation theory, based on the discretization of observable data into timed events, can easily lead to millions of values. Time series and similar database structures can efﬁciently index the mere data, but quickly reach computation and storage limits when it comes to structuring and processing IoT data. We propose a concept of continuous models that can handle high-volatile IoT data by deﬁning a new type of meta attribute, which represents the continuous nature of IoT data. On top of traditional discrete object-oriented modeling APIs, we enable models to represent very large sequences of sensor values by using mathematical polynomials. We show on various IoT datasets that this signiﬁcantly improves storage and reasoning efﬁciency.",
    "keywords": [
      "IoT",
      "Continuous modeling",
      "Discrete modeling",
      "Polynomial",
      "Extrapolation",
      "Big Data"
    ],
    "authors": [
      "Assaad Moawad",
      "Thomas Hartmann",
      "Francois Fouquet",
      "Gregory Nain",
      "Jacques Klein",
      "and Yves Le Traon"
    ],
    "file_path": "data/models/models15/Beyond discrete modeling A continuous and efficient model for IoT.pdf"
  },
  {
    "title": "A Megamodel for Software Process Line Modeling and Evolution",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Companies formalize software processes as a way of organizing development projects. Since there are differences in project contexts, a one-size-fits-all approach does not work well in practice. Some companies use a family of a predeﬁned processes, but this approach has a high process maintenance cost. Instead, we deﬁne Software Process Lines (SPrL), where a general process with variability is tailored to project contexts. Model-Driven Engineering (MDE) provides a formal framework for deﬁning the models and transformations required for automated SPrL tailoring. However, this approach requires the deﬁnition and co-evolution of various types of models and tool support beyond the skills of process engineers, making the industrial adoption challenging. This paper shares our experience using a megamodeling approach to the development of the back-end of our toolset. The megamodel provides a uniform mechanism for process deﬁnition, variability, tailoring and evolution, and we hide the MDE complexity through a user-friendly front-end. We report the application of our approach at Mobius, a small Chilean software enterprise.",
    "keywords": [
      "Megamodel",
      "Software Process Line",
      "Variability"
    ],
    "authors": [
      "Jocelyn Simmonds",
      "Daniel Perovich",
      "Mar´ıa Cecilia Bastarrica and Luis Silvestre"
    ],
    "file_path": "data/models/models15/A megamodel for Software Process Line modeling and evolution.pdf"
  },
  {
    "title": "Feature Modeling of Two Large-Scale Industrial Software Systems: Experiences and Lessons Learned",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Feature models are frequently used to capture the knowledge about conﬁgurable software systems and product lines. However, feature modeling of large-scale systems is challenging as many models are needed for diverse purposes. For instance, feature models can be used to reﬂect the perspectives of product management, technical solution architecture, or product conﬁg-uration. Furthermore, models are required at different levels of granularity. Although numerous approaches and tools are available, it remains hard to deﬁne the purpose, scope, and granularity of feature models. In this paper we thus present experiences of developing feature models for two large-scale industrial automation software systems. Speciﬁcally, we extended an existing feature modeling tool to support models for different purposes and at multiple levels. We report results on the characteristics and modularity of the feature models, including metrics about model dependencies. We further discuss lessons learned during the modeling process.",
    "keywords": [
      "feature modeling",
      "industrial software systems",
      "experience report"
    ],
    "authors": [
      "Daniela Lettner",
      "Klaus Eder",
      "Paul Grünbacher",
      "Herbert Prähofer"
    ],
    "file_path": "data/models/models15/Feature modeling of two large-scale industrial software systems Experiences and lessons learned.pdf"
  },
  {
    "title": "Systematic Generation of Standard Compliant Tool Support of Diagrammatic Modeling Languages",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "In the Model-Driven Engineering community, the abstract syntax of modeling languages is usually defined and implemented using metamodeling techniques. However, it is not the case for the concrete syntax of graphical modeling languages. Indeed, this concern is mostly specified by informal means. This practice leaves considerable leeway in the implementation and raises several standards compliance issues. Hence, toolsmiths can only rely on their interpretation of the standard and lack of systematic way to build conforming tool support. In this context, a first normative specification of the concrete syntax of UML 2.5 has been recently released using Diagram Definition. In this paper, we propose an approach that uses those formal specifications to systematically generate modeling language tool support that guarantees compliance to standard notation. We assess the approach on a subset of the UML class diagram implemented within the open-source Papyrus tool.",
    "keywords": [
      "Diagrammatic languages",
      "standard-compliance",
      "tooling support",
      "MDE",
      "UML"
    ],
    "authors": [
      "Alexis Fouché",
      "Florian Noyrit",
      "Sébastien Gérard",
      "Maged Elaasar"
    ],
    "file_path": "data/models/models15/Systematic generation of standard compliant tool support of diagrammatic modeling languages.pdf"
  },
  {
    "title": "Pattern-Based Development of Domain-Speciﬁc Modelling Languages",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Model-Driven Engineering (MDE) promotes the use of models to conduct all phases of software development in an automated way. Models are frequently deﬁned using Domain-Speciﬁc Modelling Languages (DSMLs), which many times need to be developed for the domain at hand. However, while constructing DSMLs is a recurring activity in MDE, there is scarce support for gathering, reusing and enacting knowledge for their design and implementation. This forces the development of every new DSML to start from scratch.\n\nTo alleviate this problem, we propose the construction of DSMLs and their modelling environments aided by patterns which gather knowledge of speciﬁc domains, design alternatives, concrete syntax, dynamic semantics and functionality for the modelling environment. They may have associated services, realized via components. Our approach is supported by a tool that enables the construction of DSMLs through the application of patterns, and synthesizes a graphical modelling environment according to them.",
    "keywords": [
      "Domain-Speciﬁc Modelling Languages",
      "Meta-Modelling",
      "Meta-Modelling Patterns",
      "Modelling Environments"
    ],
    "authors": [
      "Ana Pescador",
      "Antonio Garmendia",
      "Esther Guerra",
      "Jes´us S´anchez Cuadrado",
      "Juan de Lara"
    ],
    "file_path": "data/models/models15/Pattern-based development of Domain-Specific Modelling Languages.pdf"
  },
  {
    "title": "A Controlled Experiment with Usability Inspection Techniques Applied to Use Case Specifications: Comparing the MIT 1 and the UCE Techniques",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "A Use Case Model is composed of use cases that describe software functionalities through Use Case Specifications. The evaluation of the specifications that compose such a model can allow for an early identification of usability defects. We previously proposed MIT 1—Model Inspection Technique for Usability Evaluation that aims to support the identification of usability defects through the evaluation of use cases specifications. In this paper, we present the evaluation of this technique through a controlled experiment that measured its efficiency, effectiveness, perceived ease of use, and perceived usefulness when compared to the Use Case Evaluation (UCE) method. Our quantitative findings indicate that MIT 1 allows users to find more usability defects in less time than UCE. However, UCE was considered easiest to use and more useful than MIT 1, highlighting improvement needs for MIT 1.",
    "keywords": [
      "controlled experiment",
      "use case model",
      "use case specification",
      "early usability",
      "inspection",
      "empirical study"
    ],
    "authors": [
      "Natasha M. Costa Valentim",
      "Jacilane Rabelo",
      "Ana Carolina Oran",
      "Tayana Conte",
      "Sabrina Marczak"
    ],
    "file_path": "data/models/models15/A controlled experiment with Usability Inspection Techniques applied to Use Case Specifications comparing the MIT 1 and the UCE techniques.pdf"
  },
  {
    "title": "Proceedings",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Timothy Lethbridge",
      "Jordi Cabot",
      "and Alexander Egyed"
    ],
    "file_path": "data/models/models15/Front cover.pdf"
  },
  {
    "title": "Checking Concurrent Behavior in UML/OCL Models",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "The Uniﬁed Modeling Language (UML) is a de-facto standard for software development and, together with the Object Constraint Language (OCL), allows for a precise description of a system prior to its implementation. At the same time, these descriptions can be employed to check the consistency and, hence, the correctness of a given UML/OCL model. In the recent past, numerous (automated) approaches have been proposed for this purpose. The behavior of the systems has usually been considered by means of sequence diagrams, state machines, and activity diagrams. But with the increasing popularity of design by contract, also composite structures, classes, and operations are frequently used to describe behavior in UML/OCL. However, for these description means no solution for the validation and veriﬁcation of concurrent behavior is available yet. In this work, we propose such a solution. To this end, we discuss the possible interpretations of “concurrency” which are admissible according to the common UML/OCL interpretation and, afterwards, propose a methodology which exploits solvers for SAT Modulo Theories (i. e., SMT solvers) in order to check the concurrent behavior of UML/OCL models. How to address the resulting problems is described and illustrated by means of a running example. Finally, the application of the proposed method is demonstrated.",
    "keywords": [],
    "authors": [
      "Nils Przigoda",
      "Christoph Hilken",
      "Robert Wille",
      "Jan Peleska",
      "Rolf Drechsler"
    ],
    "file_path": "data/models/models15/Checking concurrent behavior in UML-OCL models.pdf"
  },
  {
    "title": "Integrating Goal-Oriented and Use Case-Based Requirements Engineering: The Missing Link",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Combining goal-oriented and use case modeling has been shown as an effective method of requirements engineering. To ensure the quality of such modeled artifacts, a conceptual foundation is needed to govern the process of determining what types of artifacts to be modeled, and how they should be specified and analyzed for 3Cs problems (completeness, consistency and correctness). However, such a foundation is missing in current goal-use case integration approaches. In this paper, we present GUIMeta, a meta-model, to address this problem. GUIMeta consists of three layers. The artifact layer defines the semantics and classification of artifacts and their relationships. The specification layer offers specification rules for each artifact class. The ontology layer allows semantics to be integrated into the entire model. Our promising evaluation shows the suitability of GUIMeta in modeling goals and use cases.",
    "keywords": [
      "Goal and Use Case",
      "Meta-model",
      "Functional Grammar",
      "Ontology"
    ],
    "authors": [
      "Tuong Huan Nguyen",
      "John Grundy",
      "and Mohamed Almorsy"
    ],
    "file_path": "data/models/models15/Integrating goal-oriented and use case-based requirements engineering The missing link.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Timothy Lethbridge",
      "Jordi Cabot",
      "Alexander Egyed",
      "Yvan Labiche",
      "Gunter Mussbacher",
      "Ana Moreira",
      "Abdelwahab Hamou-Lhadj",
      "Emilio Insfran",
      "Vinay Kulkarni",
      "Omar Badreddin",
      "Benoit Baudry",
      "Benoit Combemale",
      "Tony Clark",
      "Arnon Sturm",
      "Marsha Chechik",
      "Dimitris Kolovos",
      "Martin Gogolla",
      "Mira Balaban",
      "Stéphane Somé",
      "Sahar Kokaly",
      "Michalis Famelis",
      "Manuel Wimmer",
      "Tian Zhang"
    ],
    "file_path": "data/models/models15/MODELS 2015 organization.pdf"
  },
  {
    "title": "A Behavioral Coordination Operator Language (BCOoL)",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "The design of complex systems involves various, possibly heterogeneous, structural and behavioral models. In model-driven engineering, the coordination of behavioral models to produce a single integrated model is necessary to provide support for validation and veriﬁcation. Indeed, it allows system designers to understand and validate the global and emerging behavior of the system. However, the manual coordination of models is tedious and error-prone, and current approaches to automate the coordination are bound to a ﬁxed set of coordination patterns. In this paper, we propose a Behavioral Coordination Operator Language (B-COOL) to reify coordination patterns between speciﬁc domains by using coordination operators between the Domain-Speciﬁc Modeling Languages used in these domains. Those operators are then used to automate the coordination of models conforming to these languages. We illustrate the use of B-COOL with the deﬁnition of coordination operators between timed ﬁnite state machines and activity diagrams.",
    "keywords": [
      "Heterogeneous Modeling",
      "Coordination Languages",
      "DSMLs"
    ],
    "authors": [
      "Matias Ezequiel Vara Larsen",
      "Julien DeAntoni",
      "Benoit Combemale",
      "and Fr´ed´eric Mallet"
    ],
    "file_path": "data/models/models15/A Behavioral Coordination Operator Language -BCOoL-.pdf"
  },
  {
    "title": "Models 2015 – the 18th instance of the International Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "This volume contains the proceedings of Models 2015 – the 18th instance of the International Conference on Model Driven Engineering Languages and Systems. This year we received 216 abstract submissions that materialized in 172 papers, consisting of 132 technical papers (including 22 new ideas papers) and 40 in-practice papers. Of these, the Program Committee and Program Board accepted 35 foundations papers (26.5% acceptance rate) and 11 in-practice papers (28%).",
    "keywords": [],
    "authors": [
      "Tim Lethbridge",
      "Jordi Cabot and Alexander Egyed"
    ],
    "file_path": "data/models/models15/Message from the chairs.pdf"
  },
  {
    "title": "Modular Model-Based Supervisory Controller Design for Wafer Logistics in Lithography Machines",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Development of high-level supervisory controllers is an important challenge in the design of high-tech systems. It has become a significant issue due to increased complexity, combined with demands for verified quality, time to market, ease of development, and integration of new functionality. To deal with these challenges, model-based engineering approaches are suggested as a cost-effective way to support easy adaptation, validation, synthesis, and verification of controllers. This paper presents an industrial case study on modular design of a supervisory controller for wafer logistics in lithography machines. The uncontrolled system and control requirements are modeled independently in a modular way, using small, loosely coupled and minimally restrictive extended finite automata. The multiparty synchronization mechanism that is part of the specification formalism provides clear advantages in terms of modularity, traceability, and adaptability of the model. We show that being able to refer to variables and states of automata in guard expressions and state-based requirements, enabled by the use of extended finite automata, provides concise models. Additionally, we show how modular synthesis allows construction of local supervisors that ensure safety of parts of the system, since monolithic synthesis is not feasible for our industrial case.",
    "keywords": [],
    "authors": [
      "Bram van der Sanden",
      "Michel Reniers",
      "Marc Geilen",
      "Twan Basten",
      "Johan Jacobs",
      "Jeroen Voeten",
      "Ramon Schiffelers"
    ],
    "file_path": "data/models/models15/Modular model-based supervisory controller design for wafer logistics in lithography machines.pdf"
  },
  {
    "title": "A Unifying Approach to Connections for Multi-Level Modeling",
    "submission-date": "2015/09",
    "publication-date": "2015/09",
    "abstract": "Capturing relationships between concepts in a domain is as important as capturing the concepts themselves. Modeling languages reﬂect this by providing connections with rich semantics, such as associations and links, thus providing a key advantage over approaches that support relationships with simple references only. While connections for two-level modeling (e.g. in the UML) have enjoyed a stable design for a considerable time, the same cannot be said for connections in multi-level modeling languages. As interest in multi-level modeling grows, it is important to provide a comprehensive design for connections that not only adheres to multi-level principles such as level-agnosticism and explicit level organization, but also supports deep characterization, i.e., the ability to specify level content beyond one level boundary. In this paper we propose a unifying conceptual model for connections whose expressiveness and scalability does not come at the cost of concept proliferation.",
    "keywords": [],
    "authors": [
      "Colin Atkinson",
      "Ralph Gerbig",
      "Thomas K¨uhne"
    ],
    "file_path": "data/models/models15/A unifying approach to connections for multi-level modeling.pdf"
  },
  {
    "title": "Employing Classifying Terms for Testing Model Transformations",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "This contribution proposes a new technique for developing test cases for UML and OCL models. The technique is based on an approach that automatically constructs object models for class models enriched by OCL constraints. By guiding the construction process through so-called classifying terms, the built test cases in form of object models are classified into equivalence classes. A classifying term can be an arbitrary OCL term on the class model that calculates for an object model a characteristic value. From each equivalence class of object models with identical characteristic values one representative is chosen. The constructed test cases behave significantly different with regard to the selected classifying term. By building few diverse object models, properties of the UML and OCL model can be explored effectively. The technique is applied for automatically constructing relevant source model test cases for model transformations between a source and target metamodel.",
    "keywords": [],
    "authors": [
      "Martin Gogolla",
      "Antonio Vallecillo",
      "Loli Burgueño",
      "Frank Hilken"
    ],
    "file_path": "data/models/models15/Employing classifying terms for testing model transformations.pdf"
  },
  {
    "title": "Identifying Duplicate Functionality in Textual Use Cases by Aligning Semantic Actions",
    "submission-date": "2014/08",
    "publication-date": "2015/00",
    "abstract": "Developing high-quality requirements specifications often demands a thoughtful analysis and an adequate level of expertise from analysts. Although requirements modeling techniques provide mechanisms for abstraction and clarity, fostering the reuse of shared functionality (e.g., via UML relationships for use cases), they are seldom employed in practice. A particular quality problem of textual requirements, such as use cases, is that of having duplicate pieces of functionality scattered across the specifications. Duplicate functionality can sometimes improve readability for end users, but hinders development-related tasks such as effort estimation, feature prioritization and maintenance, among others. Unfortunately, inspecting textual requirements by hand in order to deal with redundant functionality can be an arduous, time-consuming and error-prone activity for analysts. In this context, we introduce a novel approach called ReqAligner that aids analysts to spot signs of duplication in use cases in an automated fashion. To do so, ReqAligner combines several text processing techniques, such as a use-case-aware classifier and a customized algorithm for sequence alignment. Essentially, the classifier converts the use cases into an abstract representation that consists of sequences of semantic actions, and then these sequences are compared pairwise in order to identify action matches, which become possible duplications. We have applied our technique to five real-world specifications, achieving promising results and identifying many sources of duplication in the use cases.",
    "keywords": [],
    "authors": [
      "Alejandro Rago",
      "Claudia Marcos",
      "J. Andrés Diaz-Pace"
    ],
    "file_path": "data/models/models15/Identifying duplicate functionality in textual use cases by aligning semantic actions -SoSyM abstract-.pdf"
  },
  {
    "title": "Model-Driven Regulatory Compliance: A Case Study of “Know Your Customer” Regulations",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.",
    "keywords": [],
    "authors": [
      "Sagar Sunkle",
      "Deepali Kholkar",
      "and Vinay Kulkarni"
    ],
    "file_path": "data/models/models15/Model-driven regulatory compliance A case study of -Know Your Customer- regulations.pdf"
  },
  {
    "title": "Improving Reuse by means of Asymmetrical Model Migrations: An Application to the Orcc Case Study",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "The legacy code of a tool handling domain speciﬁc data gathers valuable expertise. However in many cases, it must be rewritten to make it apply to structurally incompatible data. We investigate a co-evolution approach to avoid this update by making the call context meet the a legacy tool deﬁnition domain. The data conforming to the call context co-evolve into data conforming to the deﬁnition domain. Once processed by the tool, they can be put back into their original context thanks to a speciﬁc reverse transformation which enables the recovery of elements that had been initially removed. This approach is applied to Orcc, a compiler for dataﬂow applications. Orcc requires many common functions that are expected to be adapted to its own context. Our approach is an effective way to reuse them instead of rewriting them.",
    "keywords": [
      "TMM",
      "Refactoring",
      "Migration",
      "Application domain",
      "Legacy tool domain",
      "Co-evolution",
      "Reverse Migration"
    ],
    "authors": [
      "Paola Vallejo",
      "Mickaël Kerboeuf",
      "Kevin J. M. Martin",
      "Jean-Philippe Babau"
    ],
    "file_path": "data/models/models15/Improving reuse by means of asymmetrical model migrations An application to the Orcc case study.pdf"
  },
  {
    "title": "Enhanced Graph Rewriting Systems for Complex Software Domains",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "Methodologies for correct by construction reconﬁgurations can efﬁciently solve consistency issues in dynamic software architecture. Graph-based models are appropriate for designing such architectures and methods. At the same time, they may be unﬁt to characterize a system from a non functional perspective. This stems from efﬁciency and applicability limitations in handling time-varying characteristics and their related dependencies. In order to lift these restrictions, an extension to graph rewriting systems is proposed herein. The suitability of this approach, as well as the restraints of currently available ones, are illustrated, analysed and experimentally evaluated with reference to a concrete example. This investigation demonstrates that the conceived solution can: (i) express any kind of algebraic dependencies between evolving requirements and properties; (ii) signiﬁcantly ameliorate the efﬁciency and scalability of system modiﬁcations with respect to classic methodologies; (iii) provide an efﬁcient access to attribute values; (iv) be fruitfully exploited in software management systems; (v) guarantee theoretical properties of a grammar, like its termination.",
    "keywords": [],
    "authors": [
      "Cédric Eichler",
      "Thierry Monteil",
      "Patricia Stolf",
      "Alfredo Grieco",
      "Khalil Drira"
    ],
    "file_path": "data/models/models15/Enhanced graph rewriting systems for complex software domains -SoSyM abstract-.pdf"
  },
  {
    "title": "Formalizing and Verifying Stochastic System Architectures Using Monterey Phoenix",
    "submission-date": "2014/04",
    "publication-date": "2015/00",
    "abstract": "The analysis of software architecture plays an important role in understanding the system structures and facilitate proper implementation of user requirements. Despite its importance in the software engineering practice, the lack of formal description and veriﬁcation support in this domain hinders the development of quality architectural models. To tackle this problem, in this work, we develop an approach for modeling and verifying software architectures speciﬁed using Monterey Phoenix (MP) architecture description language. MP is capable of modeling system and environment behaviors based on event traces, as well as supporting different architecture composition operations and views. First, we formalize the syntax and operational semantics for MP; therefore, formal veriﬁcation of MP models is feasible. Second, we extend MP to support shared variables and stochastic characteristics, which not only increases the expressiveness of MP, but also widens the properties MP can check, such as quantitative requirements. Third, a dedicated model checker for MP has been implemented, so that automatic veriﬁcation of MP models is supported. Finally, several experiments are conducted to evaluate the applicability and efﬁciency of our approach.",
    "keywords": [],
    "authors": [
      "Songzheng Song",
      "Yang Liu",
      "Mikhail Auguston",
      "Jun Sun",
      "Jin Song Dong",
      "Tieming Chen"
    ],
    "file_path": "data/models/models15/Formalizing and verifying stochastic system architectures using Monterey Phoenix -SoSyM abstract-.pdf"
  },
  {
    "title": "Software Supply Chains (Keynote)",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "It has long been desired to build software systems predominantly through the composition of existing software components. The need for such a production model is growing given the increasing use and reliance on software for almost everything we interact with from toasters to airplanes. For some kinds of systems, we have come a long way towards meeting the production via composition through the use of libraries, frameworks and plugin architectures. But, for other systems that require tight integrations of components produced by different suppliers, we are not yet able to reliably engineer a software supply chain. In this talk, I will outline some achievements in software supply chains and describe some of the challenges that need to be met to productively provide the systems of the future.",
    "keywords": [],
    "authors": [
      "Gail C. Murphy"
    ],
    "file_path": "data/models/models15/Software supply chains -keynote-.pdf"
  },
  {
    "title": "Infrastructure as Runtime Models: Towards Model-Driven Resource Management",
    "submission-date": "2015/00",
    "publication-date": "2015/00",
    "abstract": "The importance of continuous delivery and the emergence of tools allowing to treat infrastructure configurations programmatically have revolutionized the way computing resources and software systems are managed. However, these tools keep lacking an explicit model representation of underlying resources making it difficult to introspect, verify or reconfigure the system in response to external events.\n\nIn this paper, we outline a novel approach that treats system infrastructure as explicit runtime models. A key benefit of using such models@run.time representation is that it provides a uniform semantic foundation for resources monitoring and reconfiguration. Adopting models at runtime allows one to integrate different aspects of system management, such as resource monitoring and subsequent verification into an unified view which would otherwise have to be done manually and require to use different tools. It also simplifies the development of various self-adaptation strategies without requiring the engineers and researchers to cope with low-level system complexities.",
    "keywords": [],
    "authors": [
      "Filip Kˇrikava",
      "Romain Rouvoy",
      "Lionel Seinturier"
    ],
    "file_path": "data/models/models15/Infrastructure as runtime models Towards Model-Driven resource management.pdf"
  },
  {
    "title": "Facilitating Modeling and Simulation of Complex Systems Through Interoperable Software",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Incorporating models into the design, test, and monitoring processes of complex systems can reduce development costs and improve performance and reliability. However, developing appropriate models and calibrating these models with measurement data is often time consuming. The problems are magnified in cases of distributed systems and cyber-physical system. Additionally, real-time test and hardware-in-the-loop applications may require the partitioning of model components on heterogeneous targets with a combination of multi-core processors and field programmable gate arrays. There are various commercial and open-source software options available for developing models but multiple modeling tools may be required for a single application. \nThis talk will review current efforts to overcome these challenges in modeling and simulation. Several successful applications will be discussed as well. Research in this area is continuing and collaboration is a must.",
    "keywords": [],
    "authors": [
      "Dr. Jeannie Falcon"
    ],
    "file_path": "data/models/models17/Keynotes.pdf"
  },
  {
    "title": "A Systematic Mapping Study on Modeling for Industry 4.0",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "Industry 4.0 is a vision of manufacturing in which smart, interconnected production systems optimize the complete value-added chain to reduce cost and time-to-market. At the core of Industry 4.0 is the smart factory of the future, whose successful deployment requires solving challenges from many domains. Model-based systems engineering (MBSE) is a key enabler for such complex systems of systems as can be seen by the increased number of related publications in key conferences and journals. This paper aims to characterize the state of the art of MBSE for the smart factory through a systematic mapping study on this topic. Adopting a detailed search strategy, 1466 papers were initially identiﬁed. Of these, 222 papers were selected and categorized using a particular classiﬁcation scheme. Hence, we present the concerns addressed by the modeling community for Industry 4.0, how these are investigated, where these are published, and by whom. The resulting research landscape can help to understand, guide, and compare research in this ﬁeld. In particular, this paper identiﬁes the Industry 4.0 challenges addressed by the modeling community, but also the challenges that seem to be less investigated.",
    "keywords": [],
    "authors": [
      "Andreas Wortmann",
      "Benoit Combemale",
      "Olivier Barais"
    ],
    "file_path": "data/models/models17/A Systematic Mapping Study on Modeling for Industry 4.0.pdf"
  },
  {
    "title": "Bidirectional Transformations in the Large",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "The model-driven development of systems involves multiple models, metamodels and transformations, and relation-ships between them. A bidirectional transformation (bx) is usually deﬁned as a means of maintaining consistency between “two (or more)” models. This includes cases where one model may be generated from one or more others, as well as more complex (“symmetric”) cases where models record partially overlapping information. In recent years binary bx, those relating two models, have been extensively studied. Multiary1 bx, those relating more than two models, have received less attention. In this paper we consider how a multiary consistency relation may be deﬁned in terms of binary consistency relations, and how consistency restoration may be carried out on a network of models and relationships between them. We relate this to megamodelling and discuss further research that is needed.",
    "keywords": [],
    "authors": [
      "Perdita Stevens"
    ],
    "file_path": "data/models/models17/Bidirectional Transformations in the Large.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Copyright notice.pdf"
  },
  {
    "title": "A Model-Driven Approach to Trace Checking of Pattern-based Temporal Properties",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Trace checking is a procedure for evaluating requirements over a log of events produced by a system. This paper deals with the problem of performing trace checking of temporal properties expressed in TemPsy, a pattern-based speciﬁcation language. The goal of the paper is to present a scalable and practical solution for trace checking, which can be used in contexts where relying on model-driven engineering standards and tools for property checking is a fundamental prerequisite. The main contributions of the paper are: a model-driven trace checking procedure, which relies on the efﬁcient mapping of temporal requirements written in TemPsy into OCL constraints on a meta-model of execution traces; the implementation of this trace checking procedure in the TEMPSY-CHECK tool; the evaluation of the scalability of TEMPSY-CHECK, applied to the veriﬁcation of real properties derived from a case study of our industrial partner, including a comparison with a state-of-the-art alternative technology based on temporal logic. The results of the evaluation show the feasibility of applying our model-driven approach for trace checking in realistic settings: TEMPSY-CHECK scales linearly with respect to the length of the input trace and can analyze traces with one million events in about two seconds.",
    "keywords": [],
    "authors": [
      "Wei Dou",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "file_path": "data/models/models17/A Model-Driven Approach to Trace Checking of Pattern-Based Temporal Properties.pdf"
  },
  {
    "title": "2017 ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Heuristic-Based Recommendation for Metamodel - OCL Coevolution.pdf"
  },
  {
    "title": "Component and Connector Views in Practice: An Experience Report",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Component and Connector (C&C) view speciﬁcations, with corresponding veriﬁcation and synthesis techniques, have been recently suggested as a means for formal yet intuitive structural speciﬁcation of C&C models. In this paper we report on our recent experience in applying C&C views in industrial practice, where we aimed to answer questions such as: could C&C views be practically used in industry, what are challenges of systems engineers that the use of C&C views could address, and what are some of the technical obstacles in bringing C&C views to the hands of systems engineers. We describe our experience in detail and discuss a list of lessons we have learned, including, e.g., a missing abstraction concept in C&C models and C&C views that we have identiﬁed and added to the views language and tool, that engineers can create graphical C&C views quite easily, and how veriﬁcation algorithms scale on real-size industry models. Furthermore, we report on the non-negligible technical effort needed to translate Simulink block diagrams to C&C models. We make all materials mentioned and used in our experience electronically available for inspection and further research.",
    "keywords": [
      "component and connector models",
      "Simulink",
      "architecture",
      "industrial case study"
    ],
    "authors": [
      "Vincent Bertram",
      "Shahar Maoz",
      "Jan Oliver Ringert",
      "Bernhard Rumpe",
      "Michael von Wenckstern"
    ],
    "file_path": "data/models/models17/Component and Connector Views in Practice An Experience Report.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Publisher-s information.pdf"
  },
  {
    "title": "Reusable Speciﬁcation Templates for Deﬁning Dynamic Semantics of DSLs",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "Domain-Speciﬁc Languages (DSLs) are a central concept of Model Driven Engineering (MDE). They are considered to be very effective in software development and are being widely adopted by industry nowadays. A DSL is a programming language specialized to a speciﬁc application domain. This paper proposes a new method for deﬁning the dynamic semantics of DSLs using reusable speciﬁcation templates, bridging the gap between DSL concepts and execution platforms.",
    "keywords": [],
    "authors": [
      "Ulyana Tikhonova"
    ],
    "file_path": "data/models/models17/Reusable Specification Templates for Defining Dynamic Semantics of DSLs.pdf"
  },
  {
    "title": "Tool Support for Live Formal Veriﬁcation",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Despite an increasing interest from industry (e.g.,\nDO333 standard [1]), formal veriﬁcation is still not widely used\nin production for safety critical systems. This has been recognized\nfor a while and various causes have been identiﬁed, one of them\nbeing the lack for scalable and cost effective tools. Many such\ntools exist for formal veriﬁcation, but few of them are user-\nfriendly: using formal veriﬁcation generally still requires such\nan effort that the time spent on the tool prevents the integration\nof the method in an industrial setting. This paper presents a\ntool prototype aiming at supporting non-experts in using formal\nveriﬁcation. The tooling approach is meant to be cost effective\nand change-supportive: user-friendliness is designed not only for\nthe non-expert, but also to require minimum effort so that formal\nveriﬁcation is triggered even for the non-enthusiast who is not\nwilling to push a button. To do so, we trigger, in a background\ntask, pre-deﬁned formal veriﬁcation checks at (almost) every\nchange of the model. We only display error messages in case\nof problem: the user is not disturbed if no problem is detected.\nTo prevent checks to be triggered all the time, we decide to\nconsider only local analyses (i.e., only checks which do not\nrequire knowledge of elements in a remote position in the model).\nThis restricts the sort of formal veriﬁcation that we support,\nbut this is a conscious choice: our motto is ”Let us ﬁrst make\nbasic techniques very user-friendly; more powerful ones will be\nconsidered only when at least the basic techniques have proven\nto be accepted.”",
    "keywords": [
      "tool; cost-effective; formal veriﬁcation; user friendliness; scalable"
    ],
    "authors": [
      "Vincent Aravantinos",
      "Sudeep Kanav"
    ],
    "file_path": "data/models/models17/Tool Support for Live Formal Verification.pdf"
  },
  {
    "title": "Partial Evaluation of OCL Expressions",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "In the academic literature, many uses of the Object Constraint Language (OCL) have been proposed. By contrast, the utilization of OCL in contemporary modelling tools lags behind, suggesting that leverage of OCL remains limited in practice. We consider this undeserved, and present a scheme for partially evaluating OCL expressions that allows one to capitalize on given OCL speciﬁcations for a wide array of purposes using a single implementation: a partial evaluator of OCL.",
    "keywords": [],
    "authors": [
      "Bastian Ulke",
      "Friedrich Steimann",
      "Ralf L¨ammel"
    ],
    "file_path": "data/models/models17/Partial Evaluation of OCL Expressions.pdf"
  },
  {
    "title": "SQL-PL4OCL : An automatic code generator from OCL to SQL Procedural Language",
    "submission-date": "2017/05",
    "publication-date": "2017/05",
    "abstract": "Design models are widely spread as core artifacts in software engineering. Yet, a key problem is how to fulﬁll correctly these blueprint speciﬁcations when code components are developed. The best possible scenario occurs when a source modeling language can be perfectly linked to a target language of election. Namely, a well deﬁned mapping bridges the gap between the source and the target language. Otherwise, manual encoding of the system design is cumbersome and error prone. In this setting, we introduce a SQL-PL1 code generator for OCL expressions that, in contrast to other proposals, is able to map OCL iterate and iterator expressions thanks to our use of stored procedures. More in detail, our source language is the Object Constraint Language (OCL), which nowadays is an ISO standard used to express constraints and queries in a textual notation on UML models. Our target language is the procedural language (PL) extension to the Structured Query Language (SQL). SQL is a special-purpose programming language designed for managing data in relational database management systems (RDBMS). The purpose of PL for SQL is to combine database language and procedural programming language. Although SQL is also an ISO standard, different RDBMS implement certain syntactic variations to the standard SQL notation. Thus, we had to adapt the implementation of our mapping to each of them. As implementation targets we selected MariaDB, PostgreSQL, and MS SQL Server. MariaDB and PostgreSQL were selected because they are open source and widely used by developers. MS SQL server was selected to be able to compare evaluation time from open source to commercial RDBMS. A variety of applications arises for a mapping from OCL to SQL expressions. Among others, there are three prominent types. These are i) evaluation of OCL expressions (analysis queries and metrics) on large model’s instances, ii) identiﬁ-cation of constraints during data modeling that have to be checked as integrity constraints on actual data; iii) automatic code generation from models. Indeed, our implementation was used as a key component of a toolkit that automatically generated ready-to-deploy web applications for secure data management from design models. Our component mapped and evaluated OCL constraints speciﬁed within authorization policies. Our code generator is deﬁned recursively over the structure of OCL expressions and it is implemented in the SQL-PL4OCL tool that is publicly available at [1]. The seminal work of the mapping presented here can be found in [2], [3]. The key idea that enables the mapping from OCL iterator expressions to iterative stored procedures remains the same, but the work detailed in [4] introduces a novel mapping from OCL expressions to SQL-PL stored procedures. In the novel mapping we have taken design decisions which have facilitated the recursive deﬁnition of the code generator and simpliﬁed its deﬁnition. These decisions have also helped to signiﬁcantly decrease the time required for the evaluation of the code generated. Regarding semantics, the new mapping is able to deal properly with the three-valued evaluation semantics of OCL. In addition, our original work and implementation was intended only for the procedural extension of MySQL, while our new deﬁnition eased the implementation of the mapping into other relational database management systems. In turn, we can now evaluate the resulting code using different RDBMS, which permits us to widen our discussion regarding efﬁciency in terms of evaluation-time of the code produced by SQL-PL4OCL tool.",
    "keywords": [],
    "authors": [
      "Marina Egea",
      "Carolina Dania"
    ],
    "file_path": "data/models/models17/SQL-PL4OCL An Automatic Code Generator from OCL to SQL Procedural Language.pdf"
  },
  {
    "title": "How is ATL Really Used? Language Feature Use in the ATL Zoo",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Studies of code repositories have long been used to understand the use of programming languages and to provide insight into how they should evolve. Such studies can highlight features that are rarely used and can safely be removed to simplify the language. Conversely, combinations of features that are frequently used together can be identified and possibly replaced with new features to improve the user experience. Unfortunately, this kind of research has not been as popular in Model Driven Development (MDD). More specifically, using repositories of model transformations (in any language) to understand how the features of these languages are used has not been investigated much, despite its potential benefits. In this paper, we study the use of the ATL model transformation language in an ATL transformation repository. We identify three research questions aimed at providing insight into how ATL’s features are actually used. Using the TXL source transformation language, we implement a parser-based analyzer to extract information from the ATL Zoo. We use this information to answer these research questions and provide additional observations based on manual inspection of ATL artifacts.",
    "keywords": [
      "Model transformations",
      "MDD",
      "ATL",
      "TXL"
    ],
    "authors": [
      "Gehan M. K. Selim",
      "James R. Cordy",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models17/How is ATL Really Used- Language Feature Use in the ATL Zoo.pdf"
  },
  {
    "title": "Co-evolution of Meta-Modeling Syntax and Informal Semantics in Domain-Specific Modeling Environments - A Case Study of AUTOSAR",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "One domain-specific modeling environment is centered around a domain-specific meta-model which defines syntax (modeling elements, e.g., classes) for the domain models. However, in order for the system designers to be able to construct meaningful models, semantics of the domain-specific meta-model needs to be described as well. This semantics is often provided in a form of informal natural language specifications that contain a set of design requirements, each describing the intended use of one or more modeling elements. Intuitively, introduction of new concepts into the modeling environment is expected to require changes in both meta-modeling syntax and informal semantics in such a way that their co-evolution is highly correlated. In order to test this hypothesis, we analyzed the relation between added classes, attributes, and connectors, as meta-modeling syntax, and modified/added design requirements, as meta-modeling semantics, in a case study of the AUTOSAR meta-modeling environment. We found that new AUTOSAR concepts usually require both new modeling elements and new design requirements, but surprisingly adding more elements is not always followed by more requirements. This finding is also validated by the moderately strong correlation between the evolution of these two AUTOSAR meta-modeling artifacts (Spearman’s ρ 0,63 and Kendall’s τ 0,49). For system designers, this means that both meta-modeling syntax and informal semantics is important to be considered in the analysis of domain-specific meta-model evolution, but it may not be enough for understanding the use of all modeling elements. For designers responsible for the maintenance of domain-specific meta-models, this means that more effort shall be put into describing the semantics of all introduced modeling elements.",
    "keywords": [],
    "authors": [
      "Darko Durisic",
      "Corrado Motta",
      "Miroslaw Staron",
      "Matthias Tichy"
    ],
    "file_path": "data/models/models17/Co-Evolution of Meta-Modeling Syntax and Informal Semantics in Domain-Specific Modeling Environments - A Case Study of AUTOSAR.pdf"
  },
  {
    "title": "Revisiting Visitors for Modular Extension of Executable DSMLs",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Executable Domain-Speciﬁc Modeling Languages (xDSMLs) are typically deﬁned by metamodels that specify their abstract syntax, and model interpreters or compilers that deﬁne their execution semantics. To face the proliferation of xDSMLs in many domains, it is important to provide language engineering facilities for opportunistic reuse, extension, and customization of existing xDSMLs to ease the deﬁnition of new ones. Current approaches to language reuse either require to anticipate reuse, make use of advanced features that are not widely available in programming languages, or are not directly applicable to metamodel-based xDSMLs. In this paper, we propose a new language implementation pattern, named REVISITOR, that enables independent extensibility of the syntax and semantics of metamodel-based xDSMLs with incremental compilation and without anticipation. We seamlessly implement our approach alongside the compilation chain of the Eclipse Modeling Framework, thereby demonstrating that it is directly and broadly applicable in various modeling environments. We show how it can be employed to incrementally extend both the syntax and semantics of the fUML language without requiring anticipation or re-compilation of existing code, and with acceptable performance penalty compared to classical handmade visitors.",
    "keywords": [],
    "authors": [
      "Manuel Leduc",
      "Thomas Degueule",
      "Benoit Combemale",
      "Tijs van der Storm",
      "Olivier Barais"
    ],
    "file_path": "data/models/models17/Revisiting Visitors for Modular Extension of Executable DSMLs.pdf"
  },
  {
    "title": "Language Design with Intent",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Software languages have always been an essential component of model-driven engineering. Their importance and popularity has been on the rise thanks to language workbenches, language-oriented development and other methodologies that enable us to quickly and easily create new languages speciﬁc for each domain. Unfortunately, language design is largely a form of art and has resisted most attempts to turn it into a form of science or engineering. In this paper we borrow concepts, techniques and principles from the domain of persuasive technology, or wider yet, design with intent — which was developed as a way to inﬂuence users behaviour for social and environmental beneﬁt. Similarly, we claim, software language designers can make conscious choices in order to inﬂuence the behaviour of language users. The paper describes a process of extracting design components from 24 books of eight categories (dragon books, parsing techniques, compiler construction, compiler design, language implementa-tion, language documentation, programming languages, software languages), as well as from the original set of Design with Intent cards and papers on DSL design. The resulting language design card toolkit can be used by DSL designers to cover important design decisions and make them with more conﬁdence.",
    "keywords": [],
    "authors": [
      "Vadim Zaytsev"
    ],
    "file_path": "data/models/models17/Language Design with Intent.pdf"
  },
  {
    "title": "2017 ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems MODELS 2017",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Table of contents.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Abrahão, Silvia",
      "Faugère, Madeleine",
      "Agner, Luciane T. W.",
      "Fohler, Gerhard",
      "Al-Refai, Mohammed",
      "Fouquet, Francois",
      "Antkiewicz, Michal",
      "Ghosh, Sudipto",
      "Aravantinos, Vincent",
      "Giorgini, Paolo",
      "Barais, Olivier",
      "Greenyer, Joel",
      "Barner, Simon",
      "Guerra, Esther",
      "Batot, Edouard",
      "Gutjahr, Timo",
      "Beckmann, Martin",
      "Hartmann, Thomas",
      "Benelallam, Amine",
      "Hidaka, Sochiro",
      "Bergmann, Gábor",
      "Hutchesson, Stuart",
      "Bertram, Vincent",
      "Ipatiov, Alexandru",
      "Bianculli, Domenico",
      "Izquierdo, Javier Luis Cánovas",
      "Bourcier, Johann",
      "Jouault, Frédéric",
      "Bourdeleau, Francis",
      "Jürjens, Jan",
      "Briand, Lionel",
      "Kanav, Sudeep",
      "Burger, Erik",
      "Kessentini, Wael",
      "Cabot, Jordi",
      "Khalil, Maged",
      "Cazzola, Walter",
      "Klare, Heiko",
      "Chechik, Marsha",
      "Kokaly, Sahar",
      "Cheng, Betty",
      "Kolb, Bernd",
      "Clarisó, Robert",
      "Kolovos, Dimitrios S.",
      "Combemale, Benoit",
      "Kramer, Max",
      "Cordy, James R.",
      "Lämmel, Ralf",
      "Cosentino, Valerio",
      "Langhammer, Michael",
      "Cuadrado, Jesús Sánchez",
      "Le Traon, Yves",
      "Czarnecki, Krzysztof",
      "Leduc, Manuel",
      "Dania, Carolina",
      "Lethbridge, Timothy C.",
      "Dániel, Varró",
      "Liang, Jia Hui",
      "de Lara, Juan",
      "Maoz, Shahar",
      "Debreceni, Csaba",
      "Michalke, Vanessa N.",
      "Degueule, Thomas",
      "Migge, Jörn",
      "Denney, Ewen",
      "Moawad, Assaad",
      "Deursen, Arie van",
      "Motta, Corrado",
      "Diewald, Alexander",
      "Mouline, Ludovic",
      "Dingel, Juergen",
      "Murashkin, Alexandr",
      "Dou, Wei",
      "Pai, Ganesh",
      "Dummann, Kolja",
      "Paige, Richard",
      "Durisic, Darko",
      "Paige, Richard F.",
      "Eder, Johannes",
      "Palomares, Javier",
      "Egea, Marina",
      "Pech, Vaclav",
      "Ernadote, Dominique",
      "Pérez, Daniel Gracia",
      "Famelis, Michalis",
      "Pomerantz, Nitzan",
      "Fohler, Gerhard"
    ],
    "file_path": "data/models/models17/Author index.pdf"
  },
  {
    "title": "The Next Evolution of MDE: A Seamless Integration of Machine Learning into Domain Modeling",
    "submission-date": "2017/03",
    "publication-date": "2017/03",
    "abstract": "Advances in software and sensors have led to a new generation of systems which can help to minimize human intervention in critical infrastructures, like the power grid. However, they have mainly been designed to face predictable situations, in order to react, for example, to a critical over-load. This is called known domain knowledge. However, such systems have also to face events that are unpredictable at design time. For instance, the electric consumption of a house depends on the number of persons living there, their activities, weather conditions, used devices, and so forth. Despite such behaviour is unpredictable at design time, it is identiﬁable and a hypothesis about it can be already formulated and solved later by observing past situations, once data becomes available. Sutcliffe et al., [1] suggest to call this known unknown. Machine learning algorithms are designed to resolve these unknowns, using ﬁne- or coarse-grained learning. Coarse-grained learning means extracting the average behaviour of a large dataset. Conversely, ﬁne-grained learning means specializing learning algorithms only on speciﬁc elements. In cases where datasets are composed of independent and het-erogenous entities, which behave very differently, finding one coarse-grained common behaviour can be difﬁcult or even inappropriate. For example, considering smart grids, the daily consumption of a factory follows a very different pattern than the consumption of an apartment. Thus, coarse-grained learning alone, which is based on the “law of large numbers ”, can be inaccurate for such systems. Additionally, any data changes requires the whole learning process to be recomputed. Instead, following a divide and conquer strategy, learning on ﬁner granularities can be considerably more efﬁcient [2], [3]. In accordance to the pedagogical concept [4], we refer to small ﬁne-grained learning units as “micro learning”. However, applying micro learning on systems, such as the electric grid, can potentially lead to many ﬁne-grained learning units, that need to be combined and synchronised with domain data. Learning frameworks like TensorFlow fo-cus solely on the learning ﬂow without any relation to the domain model. Consequently, domain data and its structure is expressed in different models than learning tasks, using different languages and tools. This leads to a separation of domain data, knowledge, known unknowns, and associated learning methods. Therefore, an appropriate structure to model learning units and their relationships to domain knowledge is required. To tame such complexity, we propose to weave micro machine learning seamlessly into data modeling. Specifically, our approach aims at: (1) Structuring complex learning tasks with reusable, chainable, and independently computable micro learning units. (2) Seamlessly integrating behavioural models which are known at design time, behavioural models that need to be learned at runtime, and domain models using common modeling concepts. (3) Automating the mapping between the mathematical representation expected by a speciﬁc machine learning algorithm and the domain representation [5] and independently updating micro learning units to be fast enough for online learning. As a natural extension of model-driven engineering ap-proaches, we take advantage of relationships between domain data and behavioural elements (learned or known at design time) to implicitly deﬁne a ﬁne-grained mapping of learning units and domain data. We implemented and integrated our approach into the open-source modeling framework GreyCat, which is specifically designed for the requirements of CPSs and IoT. We evaluate our approach on a concrete smart grid case study and show that: (1) Micro machine learning for such scenarios can be more accurate than coarse-grained learning (2) Performance is fast enough to be used for real-time analytics. The full paper has been published in [6].",
    "keywords": [
      "Domain modeling",
      "Live learning",
      "Model-driven engineering",
      "Meta modeling",
      "Cyber-physical systems",
      "Smart grids"
    ],
    "authors": [
      "Thomas Hartmann",
      "Assaad Moawad",
      "Francois Fouquet",
      "and Yves Le Traon"
    ],
    "file_path": "data/models/models17/The Next Evolution of MDE A Seamless Integration of Machine Learning into Domain Modeling.pdf"
  },
  {
    "title": "Translating target to source constraints in model-to-model transformations",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Model transformations are used to automate model manipulation in Model-Driven Engineering (MDE). In particular, model-to-model transformations produce target models (confor-mant to a target meta-model) from source ones (conformant to a source meta-model). While transformation correctness is crucial in MDE, developing transformations is error-prone due to the difficulty in testing them. This problem is further aggravated if the source and target meta-models contain OCL integrity constraints, as every transformed source model should satisfy the target integrity constraints.\n\nIn order to attack this problem, we present a novel method that translates target OCL constraints to the source meta-model using the transformation deﬁnition. This way, if a source model satisﬁes the advanced constraint, the transformed model will satisfy the target constraint. The method has been implemented for the ATL transformation language and integrated with the anATLyzer tool. We show its beneﬁts in combination with model ﬁnders, and the promising results of its validation using mutation techniques and transformations developed by third parties.",
    "keywords": [
      "Model-driven engineering; model transformations; integrity constraints; OCL; quality"
    ],
    "authors": [
      "Jesús Sánchez Cuadrado",
      "Esther Guerra",
      "Juan de Lara",
      "Robert Clarisó",
      "Jordi Cabot"
    ],
    "file_path": "data/models/models17/Translating Target to Source Constraints in Model-to-Model Transformations.pdf"
  },
  {
    "title": "Removal of Redundant Elements within UML Activity Diagrams",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "As the complexity of systems continues to rise, the use of model-driven development approaches becomes more widely applied. Still, many created models are mainly used for documentation. As such, they are not designed to be used in following stages of development, but merely as a means of improved overview and communication. In an effort to use existing UML2 activity diagrams of an industry partner (Daimler AG) as a source for automatic generation of software artifacts, we discovered, that the diagrams often contain multiple instances of the same element. These redundant instances might improve the readability of a diagram. However, they complicate further approaches such as automated model analysis or traceability to other artifacts because mostly redundant instances must be handled as one distinctive element. In this paper, we present an approach to automatically remove redundant ExecutableNodes within activity diagrams as they are used by our industry partner. The removal is implemented by merging the redundant instances to a single element and adding additional elements to maintain the original behavior of the activity. We use reachability graphs to argue that our approach preserves the behavior of the activity. Additionally, we applied the approach to a real system described by 36 activity diagrams. As a result 25 redundant instances were removed from 15 affected diagrams.",
    "keywords": [],
    "authors": [
      "Martin Beckmann",
      "Vanessa N. Michalke",
      "Andreas Vogelsang",
      "Aaron Schlutter"
    ],
    "file_path": "data/models/models17/Removal of Redundant Elements within UML Activity Diagrams.pdf"
  },
  {
    "title": "An Empirical Study on the Maturity of the Eclipse Modeling Ecosystem",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "Since the early days of Model-driven Engineering (MDE), our community has been discussing the reasons why MDE had not quickly became mainstream. It is now clear the answer is a mix of technical and social factors, but among the former, the lack of maturity of MDE tools is often mentioned. The goal of this paper is to explore the question of whether this lack of maturity is actually true. We do so by comparing the maturity of over a hundred modeling and non-modeling projects living together in the Eclipse ecosystem. In both cases, we use the word project to refer to a variety of tools, libraries and other artefacts to build and manipulate software components, either at the model or code level. Our maturity model is based on code-centric and community metrics that we evaluate on the repository data for both kinds of projects. Their incubation status is also considered in the assessment. Results show that there are indeed diﬀerences between modeling and non-modeling projects, though less than we expected when setting up the study. Moreover, while the incu-bation status clearly separates non-modeling projects, the same is not true for modeling projects which seem to remain much more stable across their lifespan. We believe our results help to have a better perspective on maturity of modeling support nowadays and provide ideas for further analysis towards their improvement.",
    "keywords": [],
    "authors": [
      "Javier Luis Cánovas Izquierdo",
      "Valerio Cosentino",
      "Jordi Cabot"
    ],
    "file_path": "data/models/models17/An Empirical Study on the Maturity of the Eclipse Modeling Ecosystem.pdf"
  },
  {
    "title": "DREAMS Toolchain: Model-Driven Engineering of Mixed-Criticality Systems",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Mixed-criticality systems (MCS) aim at boosting the integration density in safety-critical systems, resulting into efficient systems, while simultaneously providing increased performance. The DREAMS project provides a cross-domain architectural style for MCS based on networked, virtualized multi-cores controlled by hierarchical resource managers. However, the availability of a platform is only one side of the coin: deploying mixed-critical applications to shared resources typically requires design-time configurations (e.g., to ensure real-time constraints or separation constraints mandated by safety regulations). These configurations are the outcome of complex optimization problems which are intractable in a manual process that also hardly can guarantee the consistency of all deployable artefacts nor their traceability to the requirements. However, existing toolchains lack support for MCS integration, and particularly DREAMS’ advanced platform capabilities.\nWe present an integrated model-driven toolchain and the underlying metamodels covering all relevant aspects of MCS including applications, timing, platforms, deployments, configurations and annotations for extra-functional properties such as safety. The approach focuses on the left branch of the V-cycle, and ranges from product-line and design space exploration to resource allocation and configuration generation. We report on the integration of exploration tools and a reconfiguration graph synthesizer, and evaluate the resulting toolchains in two use cases consisting of a product-line of wind power control applications and an avionic subsystem respectively.",
    "keywords": [
      "Model-Driven Engineering",
      "Mixed-Criticalitity Systems",
      "Safety",
      "Resource Management",
      "Product-Lines",
      "Design Space Exploration"
    ],
    "authors": [
      "Simon Barner",
      "Alexander Diewald",
      "Jörn Migge",
      "Ali Syed",
      "Gerhard Fohler",
      "Madeleine Faugère",
      "Daniel Gracia Pérez"
    ],
    "file_path": "data/models/models17/DREAMS Toolchain Model-Driven Engineering of Mixed-Criticality Systems.pdf"
  },
  {
    "title": "From Secure Business Process Modeling to Design-Level Security Veriﬁcation",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Tracing and integrating security requirements throughout the development process is a key challenge in security engineering. In socio-technical systems, security requirements for the organizational and technical aspects of a system are currently dealt with separately, giving rise to substantial misconceptions and errors. In this paper, we present a model-based security engineering framework for supporting the system design on the organizational and technical level. The key idea is to allow the involved experts to specify security requirements in the languages they are familiar with: business analysts use BPMN for procedural system descriptions; system developers use UML to design and implement the system architecture. Security requirements are captured via the language extensions SecBPMN2 and UMLsec. We provide a model transformation to bridge the conceptual gap between SecBPMN2 and UMLsec. Using UMLsec policies, various security properties of the resulting architecture can be veriﬁed. In a case study featuring an air trafﬁc management system, we show how our framework can be practically applied.",
    "keywords": [],
    "authors": [
      "Qusai Ramadan",
      "Mattia Salnitri",
      "Daniel Strüber",
      "Jan Jürjens",
      "Paolo Giorgini"
    ],
    "file_path": "data/models/models17/From Secure Business Process Modeling to Design-Level Security Verification.pdf"
  },
  {
    "title": "Model-driven Development of Safety Architectures",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "We describe the use of model-driven development for safety assurance of a pioneering NASA ﬂight operation involving a ﬂeet of small unmanned aircraft systems (sUAS) ﬂying beyond visual line of sight. The central idea is to develop a safety architecture that provides the basis for risk assessment and visualization within a safety case, the formal justiﬁcation of acceptable safety required by the aviation regulatory authority. A safety architecture is composed from a collection of bow tie diagrams (BTDs), a practical approach to manage safety risk by linking the identiﬁed hazards to the appropriate mitigation measures. The safety justiﬁcation for a given unmanned aircraft system (UAS) operation can have many related BTDs. In practice, however, each BTD is independently developed, which poses challenges with respect to incremental development, maintaining consistency across different safety artifacts when changes occur, and in extracting and presenting stakeholder speciﬁc information relevant for decision making. We show how a safety architecture reconciles the various BTDs of a system, and, collectively, provide an overarching picture of system safety, by considering them as views of a uniﬁed model. We also show how it enables model-driven development of BTDs, replete with validations, transformations, and a range of views. Our approach, which we have implemented in our toolset, AdvoCATE, is illustrated with a running example drawn from a real UAS safety case. The models and some of the innovations described here were instrumental in successfully obtaining regulatory ﬂight approval.",
    "keywords": [
      "Bow tie diagram",
      "Model-driven development",
      "Safety architecture",
      "Safety case",
      "Transformation",
      "Unmanned aircraft systems",
      "Views"
    ],
    "authors": [
      "Ewen Denney",
      "Ganesh Pai",
      "and Iain Whiteside"
    ],
    "file_path": "data/models/models17/Model-Driven Development of Safety Architectures.pdf"
  },
  {
    "title": "Raising Time Awareness in Model-Driven Engineering",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "The conviction that big data analytics is a key for the success of modern businesses is growing deeper, and the mobilisation of companies into adopting it becomes increasingly important. Big data integration projects enable companies to capture their relevant data, to efficiently store it, turn it into domain knowledge, and finally monetize it. In this context, historical data, also called temporal data, is becoming increasingly available and delivers means to analyse the history of applications, discover temporal patterns, and predict future trends. Despite the fact that most data that today’s applications are dealing with is inherently temporal current approaches, methodologies, and environments for developing these applications don’t provide sufficient support for handling time. We envision that Model-Driven Engineering (MDE) would be an appropriate ecosystem for a seamless and orthogonal integration of time into domain modelling and processing. In this paper, we investigate the state-of-the-art in MDE techniques and tools in order to identify the missing bricks for raising time-awareness in MDE and outline research directions in this emerging domain.",
    "keywords": [
      "Model-Driven Engineering",
      "Analytics",
      "Big Data",
      "Temporal Data",
      "Internet of Things"
    ],
    "authors": [
      "Amine Benelallam",
      "Thomas Hartmann",
      "Ludovic Mouline",
      "Francois Fouquet",
      "Johann Bourcier",
      "Olivier Barais",
      "and Yves Le Traon"
    ],
    "file_path": "data/models/models17/Raising Time Awareness in Model-Driven Engineering Vision Paper.pdf"
  },
  {
    "title": "On Additivity in Transformation Languages",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Some areas in computer science are characterized\nby a shared base structure for data artifacts (e.g., list, table,\ntree, graph, model), and dedicated languages for transforming\nthis structure. We observe that in several of these languages\nit is possible to identify a clear correspondence between some\nelements in the transformation code and the output they generate.\nConversely given an element in an output artifact it is often\npossible to immediately trace the transformation parts that are\nresponsible for its creation.\nIn this paper we formalize this intuitive concept by deﬁning\na property that characterizes several transformation languages\nin different domains. We name this property additivity: for a\ngiven ﬁxed input, the addition or removal of program elements\nresults in a corresponding addition or removal of parts of\nthe output. We provide a formal deﬁnition for additivity and\nargue that additivity enhances modularity and incrementality\nof transformation engineering activities, by enumerating a set\nof tasks that this property enables or facilitates. Then we\ndescribe how it is instantiated in some well-known transformation\nlanguages. We expect that the development of new formal results\non languages with additivity will beneﬁt from our deﬁnitions.",
    "keywords": [],
    "authors": [
      "Sochiro Hidaka",
      "Fr´ed´eric Jouault",
      "Massimo Tisi"
    ],
    "file_path": "data/models/models17/On Additivity in Transformation Languages.pdf"
  },
  {
    "title": "Property-based Locking in Collaborative Modeling",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Large-scale model-driven engineering projects are carried out collaboratively. Enabling a high degree of concurrency is required to make the traditionally rigid development processes more agile. The increasing number of collaborators increases the probability of introducing conﬂicts which need to be resolved manually by the collaborators. In case of highly interdependent models, avoiding conﬂicts by the use of locks can save valuable time. However, traditional locking techniques such as fragment-based and object-based strategies may impose unnecessary restrictions on editing, which can decrease the efﬁciency of collaboration.\n\nIn this paper, we propose a property-based locking approach that generalizes traditional locking techniques, and further allows more ﬁne-grained locks in order to restrict modiﬁcations only when necessary. A lock is considered to be violated if a match appears or disappears for its associated graph pattern (formula), which captures the property of the model that the upcoming edit transaction can be freely executed. An initial evaluation has been carried out using a case study of the MONDO EU project.",
    "keywords": [],
    "authors": [
      "Csaba Debreceni",
      "G´abor Bergmann",
      "Istv´an R´ath",
      "D´aniel Varr´o"
    ],
    "file_path": "data/models/models17/Property-Based Locking in Collaborative Modeling.pdf"
  },
  {
    "title": "Symbolic Execution for Realizability-Checking of Scenario-based Speciﬁcations",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Scenario-based speciﬁcation with the Scenario Modeling Language (SML) is an intuitive approach for formally specifying the behavior of reactive systems. SML is close to how humans conceive and communicate requirements, yet SML is executable and simulation and formal realizability checking can ﬁnd speciﬁcation ﬂaws early. The realizability checking complexity is, however, exponential in the number of scenarios and variables. Therefore algorithms relying on explicit-state exploration do not scale and, especially when speciﬁcations have message parameters and variables over large domains, fail to unfold their potential. In this paper, we present a technique for the symbolic execution of SML speciﬁcations that interprets integer message parameters and variables symbolically. It can be used for symbolic realizability checking and interactive symbolic simulation. We implemented the technique in SCENARIOTOOLS. Evaluation shows drastic performance improvements over the explicit-state approach for a range of examples. Moreover, sym- bolic checking produces more concise counter examples, which eases the comprehension of speciﬁcation ﬂaws.",
    "keywords": [],
    "authors": [
      "Joel Greenyer",
      "Timo Gutjahr"
    ],
    "file_path": "data/models/models17/Symbolic Execution for Realizability-Checking of Scenario-Based Specifications.pdf"
  },
  {
    "title": "ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Title page iii.pdf"
  },
  {
    "title": "Ecoreiﬁcation: Making Arbitrary Java Code Accessible to Metamodel-Based Tools",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Models are used in software engineering to describe parts of a system that are relevant for the computation of speciﬁc analyses, or the provision of speciﬁc functionality. Metamodeling languages such as Ecore make it possible to realize analyses and functionality with model-driven technology, such as transformation engines. If models conform to a metamodel that was expressed using Ecore, numerous Eclipse-based tools can be reused to directly analyze, display, or transform models. In many software projects, models are, however, realized with objects of plain-old Java classes rather than an explicit metamodel, so these popular tools cannot be used.\n\nIn this new ideas paper, we present an Ecoreiﬁcation approach, which can be used to automatically extract Ecore-conforming metamodels from Java code, and a code generator that combines the beneﬁts of both worlds. The resulting code can be used exactly as before, but it also uses the modeling infrastructure and implements all interfaces for Ecore-based tooling. This way, arbitrary non-standard models can be displayed and modiﬁed, for example using graphical Sirius editors, or transformed with well-proven transformation languages, such as QVT-O or ATL.",
    "keywords": [],
    "authors": [
      "Heiko Klare",
      "Erik Burger",
      "Max Kramer",
      "Michael Langhammer",
      "Timur Sa˘glam",
      "Ralf Reussner"
    ],
    "file_path": "data/models/models17/Ecoreification Making Arbitrary Java Code Accessible to Metamodel-Based Tools.pdf"
  },
  {
    "title": "Experiences with Teaching MPS in Industry\nTowards Bringing Domain Speciﬁc Languages Closer to Practitioners",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "Domain speciﬁc languages (DSLs) bring substantial increase in productivity and quality and thus look very appealing to software engineering practitioners. Because language workbenches can drastically reduce the cost of building and maintaining DSLs and associated tooling, they catch the attention of technical leads and project managers in the industry. Effective use of language engineering technologies for software development requires specific knowledge about building DSLs in general and about language workbenches in particular. Practicing software engineers need to enrich their skills with a new software development approach and the supporting tools. In this paper we present our experiences with training and coaching software practitioners in developing domain specific languages and the associated tooling with Jetbrains’ Meta-Programming System. We distill the experience that we have gained over the last three years while running 16 trainings organized by three different organizations. The trainings were attended by over 50 developers, who work in different business domains and posses a wide variety of technical backgrounds, previous experiences and concrete needs. We present a set of challenges faced while teaching language engineering technologies in the industry. To address these challenges we developed a curriculum containing increasingly complex topics and an approach, which combines classical trainings with continuous coaching either remotely or on site. Based on our experience we distill a set of lessons learnt about the dissemination of language engineering technologies to practitioners. We identify several concrete needs which are key to broader adoption of language engineering in practice.",
    "keywords": [],
    "authors": [
      "Daniel Ratiu",
      "Vaclav Pech",
      "Kolja Dummann"
    ],
    "file_path": "data/models/models17/Experiences with Teaching MPS in Industry Towards Bringing Domain Specific Languages Closer to Practitioners.pdf"
  },
  {
    "title": "Bridging Proprietary Modelling and Open-Source Model Management Tools: The Case of PTC Integrity Modeller and Epsilon",
    "submission-date": "2017/00",
    "publication-date": "2017/00",
    "abstract": "While the majority of research on Model-Based Software Engineering revolves around open-source modelling frameworks such as EMF, the use of commercial and closed-source modelling tools such as RSA, Rhapsody, MagicDraw and PTC Integrity Modeller appears to be the norm in industry at present. This technical gap can prohibit industrial users from reaping the beneﬁts of state-of-the-art research-based tools in their practice. In this paper, we discuss an attempt to bridge a proprietary UML modelling tool (PTC Integrity Modeller), which is used for model-based development of safety-critical systems at Rolls-Royce, with an open-source family of languages for automated model management (Epsilon). We present the architecture of our solution, the challenges we encountered in developing it, and a performance comparison against the tool’s built-in scripting interface.",
    "keywords": [],
    "authors": [
      "Athanasios Zolotas",
      "Horacio Hoyos Rodriguez",
      "Dimitrios S. Kolovos",
      "Richard F. Paige",
      "Stuart Hutchesson"
    ],
    "file_path": "data/models/models17/Bridging Proprietary Modelling and Open-Source Model Management Tools The Case of PTC Integrity Modeller and Epsilon.pdf"
  },
  {
    "title": "A Fuzzy Logic Based Approach for Model-based Regression Test Selection",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Regression testing is performed to verify that previously developed functionality of a software system is not broken when changes are made to the system. Since executing all the existing test cases can be expensive, regression test selection (RTS) approaches are used to select a subset of them, thereby improving the efficiency of regression testing. Model-based RTS approaches select test cases on the basis of changes made to the models of a software system. While these approaches are useful in projects that already use model-driven development methodologies, a key obstacle is that the models are generally created at a high level of abstraction. They lack the information needed to build traceability links between the models and the coverage-related execution traces from the code-level test cases. \nIn this paper, we propose a fuzzy logic based approach named FLiRTS, for UML model-based RTS. FLiRTS automatically refines abstract UML models to generate multiple detailed UML models that permit the identification of the traceability links. The process introduces a degree of uncertainty, which is addressed by applying fuzzy logic based on the refinements to allow the classification of the test cases as retestable according to the probabilistic correctness associated with the used refinement. The potential of using FLiRTS is demonstrated on a simple case study. The results are promising and comparable to those obtained from a model-based approach (MaRTS) that requires detailed design models, and a code-based approach (DejaVu).",
    "keywords": [
      "fuzzy logic",
      "model-based testing",
      "regression test selection",
      "UML models"
    ],
    "authors": [
      "Mohammed Al-Refai\nWalter Cazzola\nSudipto Ghosh"
    ],
    "file_path": "data/models/models17/A Fuzzy Logic Based Approach for Model-Based Regression Test Selection.pdf"
  },
  {
    "title": "User Experience for Model-Driven Engineering: Challenges and Future Directions",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Since its infancy, Model Driven Engineering (MDE) research has primarily focused on technical issues. Although it is becoming increasingly common for MDE research papers to evaluate their theoretical and practical solutions, extensive usability studies are still uncommon. We observe a scarcity of User eXperience (UX)-related research in the MDE community, and posit that many existing tools and languages have room for improvement with respect to UX [26], [44], [37], where UX is a key focus area in the software development industry. We consider this gap a fundamental problem that needs to be addressed by the community if MDE is to gain widespread use. In this vision paper, we explore how and where UX fits into MDE by considering motivating use cases that revolve around different dimensions of integration: model integration, tool integration, and integration between process and tool support. Based on the literature and our collective experience in research and industrial collaborations, we propose future directions for addressing these challenges.",
    "keywords": [],
    "authors": [
      "Silvia Abrahão",
      "Francis Bordeleau",
      "Betty Cheng",
      "Sahar Kokaly",
      "Richard F. Paige",
      "Harald Störrle",
      "Jon Whittle"
    ],
    "file_path": "data/models/models17/User Experience for Model-Driven Engineering Challenges and Future Directions.pdf"
  },
  {
    "title": "Bringing DSE to life: exploring the design space of an industrial automotive use case",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "In order to cope with the rising complexity of today’s systems, model-based development of software-intensive embedded systems has become a de-facto standard in recent years. Such a development approach enables a variety of front-loading methods. Design space exploration is one of those techniques. However, in order to properly perform a valid exploration, a system model has to have a certain quality. This requires dedicated, meaningful models as an input according to well-known design principles, which entails the structuring of models according to different viewpoints and usage of dedicated models for each of these viewpoints.\n\nIn this work, we demonstrate how, based on an industrial application model represented in SysML, design space exploration methods can be efficiently applied to enable the synthesis of deployments from a logical (platform-independent) system models to technical (platform-specific) system models. More-over, we will demonstrate the applicability of this approach by a project conducted with Continental.",
    "keywords": [
      "design space exploration",
      "mbse",
      "deployment"
    ],
    "authors": [
      "Johannes Eder\nSergey Zverlov\nSebastian Voss\nMaged Khalil\nAlexandru Ipatiov"
    ],
    "file_path": "data/models/models17/Bringing DSE to Life Exploring the Design Space of an Industrial Automotive Use Case.pdf"
  },
  {
    "title": "Transformations of Software Product Lines: A Generalizing Framework based on Category Theory",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Software product lines are used to manage the development of highly complex software with many variants. In the literature, various forms of rule-based product line modifications have been considered. However, when considered in isolation, their expressiveness for specifying combined modifications of feature models and domain models is limited. In this paper, we present a formal framework for product line transformations that is able to combine several kinds of product line modifications presented in the literature. Moreover, it defines new forms of product line modifications supporting various forms of product lines and transformation rules. Our formalization of product line transformations is based on category theory, and concentrates on properties of product line relations instead of their single elements. Our framework provides improved expressiveness and flexibility of software product line transformations while abstracting from the considered type of model.",
    "keywords": [],
    "authors": [
      "Gabriele Taentzer",
      "Rick Salay",
      "Daniel Strüber",
      "and Marsha Chechik"
    ],
    "file_path": "data/models/models17/Transformations of Software Product Lines A Generalizing Framework Based on Category Theory.pdf"
  },
  {
    "title": "Software Product Lines with Design Choices: Reasoning about Variability and Design Uncertainty",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "When designing changes to a software product line (SPL), developers are faced with uncertainty about deciding among multiple possible SPL designs. Since each SPL design encodes a set of related products, dealing with multiple designs means that developers must reason about sets of sets of products. The additional degree of multiplicity is not well described by existing product line abstractions. In this paper, we propose an approach for dealing with design uncertainty within SPLs using a novel composition of variability modelling with an abstraction for capturing and managing design uncertainty. This allows developers to accurately describe the decisions involved in making changes to an SPL during the design stage and provides them with a framework for SPL design space exploration by analyzing and enforcing SPL properties.",
    "keywords": [],
    "authors": [
      "Michalis Famelis",
      "Julia Rubin",
      "Krzysztof Czarnecki",
      "Rick Salay",
      "Marsha Chechik"
    ],
    "file_path": "data/models/models17/Software Product Lines with Design Choices Reasoning about Variability and Design Uncertainty.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Organization.pdf"
  },
  {
    "title": "Why Is My Component and Connector Views Speciﬁcation Unsatisﬁable?",
    "submission-date": "2017/10",
    "publication-date": "2017/10",
    "abstract": "Component and connector (C&C) views speciﬁcations, with corresponding veriﬁcation and synthesis techniques, have been recently suggested as a means for formal yet intuitive structural speciﬁcation of component and connector models. One challenge for effective use of C&C views synthesis relates to the case where the speciﬁcation is unsatisﬁable.\n\nIn this work we present an approach to deal with unsatisﬁable C&C views speciﬁcations. First, we deﬁne a notion of a C&C views speciﬁcation core, a locally minimal unsatisﬁable subset of the views speciﬁcation. Second, based on the core, we generate explicit, concrete, structured natural-language report, which explains the cause of unsatisﬁability. Finally, we extend our work to support speciﬁcations with architecture styles, library components, and Boolean formulas beyond simple conjunctions.\n\nOur views core computation relies on a new translation to SAT, via Alloy, which is reﬁned enough to allow the extraction of detailed explanations. We implemented our work and evaluated it using 12 synthetic and real-world C&C views speciﬁcations. The evaluation examines the cost of the core computation and its effectiveness in reducing the size of the speciﬁcation.",
    "keywords": [],
    "authors": [
      "Shahar Maoz",
      "Nitzan Pomerantz",
      "Jan Oliver Ringert",
      "RaﬁShalom"
    ],
    "file_path": "data/models/models17/Why is My Component and Connector Views Specification Unsatisfiable-.pdf"
  },
  {
    "title": "Synthesis and Exploration of Multi-Level, Multi-Perspective Architectures of Automotive Embedded Systems",
    "submission-date": "2017/04",
    "publication-date": "2017/04",
    "abstract": "In industry, evaluating candidate architectures for automotive embedded systems is routinely done during the design process. Today’s engineers, however, are limited in the number of candidates that they are able to evaluate in order to find the optimal architectures. This limitation results from the difficulty in defining the candidates as it is a mostly manual process. In this work, we propose a way to synthesize multilevel, multi-perspective candidate architectures and to explore them across the different layers and perspectives. Using a reference model similar to the EAST-ADL domain model but with a focus on early design, we explore the candidate architectures for two case studies: an automotive power window system and the central door locking system. Further, we provide a comprehensive set of questions, based on the different layers and perspectives, that engineers can ask to synthesize only the candidates relevant to their task at hand. Finally, using the modeling language Clafer, which is supported by automated backend reasoners, we show that it is possible to synthesize and explore optimal candidate architectures for two highly configurable automotive subsystems.",
    "keywords": [
      "Architecture Synthesis; Multi-Level Architectures; Multi-Perspective Architectures; EE Architecture; Architecture Optimization; Candidate Architectures; Early Design"
    ],
    "authors": [
      "Jordan A. Ross",
      "Alexandr Murashkin",
      "Jia Hui Liang",
      "Micha Antkiewicz",
      "Krzysztof Czarnecki"
    ],
    "file_path": "data/models/models17/Synthesis and Exploration of Multi-level- Multi-perspective Architectures of Automotive Embedded Systems -SoSYM Abstract-.pdf"
  },
  {
    "title": "ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Title page i.pdf"
  },
  {
    "title": "A Survey of Tool Use in Modeling Education",
    "submission-date": "2016/12",
    "publication-date": "Not found",
    "abstract": "We present the results of a survey of tool use in software modeling education conducted from December 2016 to March 2017. The survey was conducted among 150 professors who taught modeling in 30 countries from all regions of the world. Professors reported using 32 modeling tools. Top motivations for choosing tools are simplicity of learning and installing, as well as the tools being free and supporting the most important notations. Top complaints about tools included not interacting with other tools, not supporting sufficient modeling aspects, and being complex to use. Seven of the tools were used by more than one professor as their main tools, and we analyzed these in more depth. Among these 7, lack of feedback about models emerged as another key weakness. The tools varied very considerably regarding which of these strengths and weaknesses they exhibited. The key lessons from the paper are a) that tool developers have many opportunities to improve their products, and b) that educators might benefit from introducing students to multiple different tools.",
    "keywords": [
      "modeling tool; survey; education"
    ],
    "authors": [
      "Luciane T. W. Agner",
      "Timothy C. Lethbridge"
    ],
    "file_path": "data/models/models17/A Survey of Tool Use in Modeling Education.pdf"
  },
  {
    "title": "ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems (MODELS 2017)",
    "submission-date": "2017/01",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models17/Preface.pdf"
  },
  {
    "title": "Managing Design-Time Uncertainty",
    "submission-date": "2017/03",
    "publication-date": "2017/03",
    "abstract": "Any software system is the accumulated result of many design decisions taken by its developers. During the course of development, however, developers are often uncertain about how to make these decisions. This uncertainty reﬂects lack of knowledge about the design of the system, rather than about the environment in which the system is intended to operate. It is therefore called design-time uncertainty, and is different from environmental uncertainty [1]. Addressing environmental uncertainty requires using strategies such as self-adaptation [2], which result in fully functional software systems, capable of operating under uncertain conditions, i.e., uncertainty-aware software. In contrast, design-time un- certainty (henceforth, also simply “uncertainty”) cannot be “coded away”. Rather, it must be tackled as part of the process of software development, i.e., using uncertainty-aware software development methodologies. Existing methodologies, languages and tools assume that their inputs do not contain any uncertainty. Thus, uncertainty is rendered an undesirable characteristic that developers should either avoid or remove altogether before resuming their work. This results in either costly delays or potentially premature – and therefore risky – resolutions of uncertainty as developers make provisional decisions and attempt to keep track of them in case they need to be undone. We present an alternative strategy: the explicit management of design time uncertainty as part of the course of software development [3]. Specifically, we build on previously published work for encoding alternative design decisions in partial models which can subsequently be used for tasks such as reasoning, re- finement and transformation [4]. These techniques had been implemented as partial model operators in MU-MMINT, an interactive modelling tool [5]. We combine these point solu- tions into a coherent, tool-supported methodology for tackling design-time uncertainty. This combination allows deferring the resolution of uncertainty for as long as necessary while the development work can continue.",
    "keywords": [],
    "authors": [
      "Michalis Famelis",
      "Marsha Chechik"
    ],
    "file_path": "data/models/models17/Managing Design-Time Uncertainty.pdf"
  },
  {
    "title": "Active Domain-Speciﬁc Languages: making every mobile user a modeller",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "Domain-speciﬁc languages (DSLs) are small languages tailored to a certain application area, like logistics, web application testing or smart city planning. Traditionally, the use of DSLs has been limited to a static setting in desktop or web editors. However, in this paper, we claim that DSLs can be central components of mobile collaborative applications. In our vision, graphical DSLs can be extended to make use of mobility and context, and integrate heterogeneous information gathered from open APIs. We call this new generation languages “active DSLs”. We foresee a range of scenarios where active DSLs can be useful. On the one hand, they can be used more ﬂexibly in remote locations by enabling local collaboration of several mobile devices using their short-range communication capabilities. On the other hand, they can be extended with contextual features like geolocation, allowing the integration of maps and geo-services within the DSL, or the DSL rendering customization in response to contextual information. Active DSLs can also retrieve information from open APIs, in which case, models deﬁned with the DSL become aggregators of heterogeneous data. In this paper, we explain our vision for active DSLs and the ﬁrst steps towards its realization in the DSL-comet tool. The tool permits creating and using mobile graphical DSLs on iOS devices, and their seamless use in desktop environments.",
    "keywords": [
      "active DSL; graphical modelling language; ﬂexible modelling; mobile application; API integration"
    ],
    "authors": [
      "Diego Vaquero-Melchor",
      "Javier Palomares",
      "Esther Guerra",
      "Juan de Lara"
    ],
    "file_path": "data/models/models17/Active Domain-Specific Languages Making Every Mobile User a Modeller.pdf"
  },
  {
    "title": "Ontology-Based Pattern for System Engineering",
    "submission-date": "2017/09",
    "publication-date": "2017/09",
    "abstract": "System engineering is a multi-domain process that encompasses the design, realization, delivery, and management of complex systems or system of systems. The Model-Based System Engineering (MBSE) approach is commonly accepted by the system engineers community that depends up on the creation of centralized models to produce the expected deliverables. Standard metamodels such as UML, SysML, or NMM/NAF are typically used to describe the relevant concepts for these descriptive models. However, there is a need to also use domain speciﬁc languages (aka ontologies) to ease the communication between all the system engineering stakeholders.\nThe author proposed an approach in previous works to reconcile the usage of complex but necessary predeﬁned metamodels with dedicated ontologies. This solution speeds up the creation of model-based documents. However, the imple-mentation of such approach revealed that the modeling users are expecting a solution in-between the frozen metamodel and the speciﬁc ontology approach; a set of predeﬁned modeling features addressing recurrent engineering concerns completed by project speciﬁc concerns. Among the recurrent concerns there are the requirement elicitation, the functional analysis, the system interface deﬁnitions. . . .\nThis paper shows how this balance can be addressed through ontology-based patterns developed as modular mod-eling features blocks. Since these blocks are applied in the context of model-based system engineering we also named them MBSE Enablers. The paper proposes a solution to a new issue raised by this pattern reuse expectations; a dynamic mapping is required between the building blocks and the existing models. The proposed method is based on the category theory which brings a theoretical foundation to ensure models are correctly managed. The global idea of the extended approach is to speed up again the modeling tool customizations letting the system engineers focusing as far as possible on the systems to be designed.",
    "keywords": [
      "MBSE",
      "Model-Based System Engineering",
      "System Engineering",
      "Metamodel",
      "Ontology",
      "Dynamic Ontology Mapping",
      "Ontology Pattern"
    ],
    "authors": [
      "Dr Dominique Ernadote"
    ],
    "file_path": "data/models/models17/Ontology-Based Pattern for System Engineering.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models19/Steering Committee.pdf"
  },
  {
    "title": "Modeling approach and evaluation criteria for adaptable architectural runtime model instances",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "An architectural runtime model is a causally connected abstract representation of a system that allows monitoring the system and adapting its conﬁguration. Since systems are often constructed to operate continuously, the corresponding runtime model instances need to be long-living and available without interruptions. An interruption occurs if a model needs to be re-instantiated with a new version of the modeling language implementation to support other kinds of information. Adaptable runtime models instances can render such interruptions unnecessary and enable changing information demands at runtime. They support multiple abstraction levels for different model parts and allow adjusting over time which details of the system and its environment are represented. This helps to focus the attention for effective and efﬁcient decision making. In this vision paper we present the fundamental idea of a generic modeling language for adaptable architectural runtime model instances and propose requirements and quality characteristics as criteria for its evaluation.",
    "keywords": [],
    "authors": [
      "Thomas Brand and Holger Giese"
    ],
    "file_path": "data/models/models19/Modeling Approach and Evaluation Criteria for Adaptable Architectural Runtime Model Instances.pdf"
  },
  {
    "title": "Model-Based Resource Analysis and Synthesis of Service-Oriented Automotive Software Architectures",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Abstract—Context: Automotive software architectures describe distributed functionality through an interplay of software components. One drawback of today’s architectures is their strong integration into the onboard communication network based on predefined dependencies at design-time. To foster independence, the idea of service-oriented architecture (SOA) provides a suitable prospect as network communication is established dynamically at run-time. Aim: We target to provide a model-based design methodology for analysing and synthesising hardware resources of automotive service-oriented architectures. Approach: For the approach, we apply the concepts of design space exploration and simulation to analyse and synthesise deployment configurations at an early stage of development. Result: We present an architecture candidate for an example function from the domain of automated driving. Based on corresponding simulation results, we gained insights about the feasibility to implement this candidate within our currently considered next E/E architecture generation. Conclusion: The introduction of service-oriented architectures strictly requires early run-time assessments. In order to get there, the usage of models and model transformations depict reasonable ways by additionally accounting quality and development speed.",
    "keywords": [
      "Service-oriented architecture",
      "real-time behaviour",
      "model-based design",
      "automotive architectures"
    ],
    "authors": [
      "Philipp Obergfell",
      "Stefan Kugele",
      "Eric Sax"
    ],
    "file_path": "data/models/models19/Model-Based Resource Analysis and Synthesis of Service-Oriented Automotive Software Architectures.pdf"
  },
  {
    "title": "Towards System-Level Testing with Coverage Guarantees for Autonomous Vehicles",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Since safety-critical autonomous vehicles need to interact with an immensely complex and continuously changing environment, their assurance is a major challenge. While systems engineering practice necessitates assurance on multiple levels, existing research focuses dominantly on component-level assurance while neglecting complex system-level trafﬁc scenarios. In this paper, we aim to address the system-level testing of the situation-dependent behavior of autonomous vehicles by combining various model-based techniques on different levels of abstraction. (1) Safety properties are continuously monitored in challenging test scenarios (obtained in simulators or ﬁeld tests) using graph query and complex event processing techniques. To precisely quantify the coverage of an existing test suite with respect regulations of safety standards, (2) we provide qualitative abstractions of causal, temporal, or geospatial data recorded in individual runs into situation graphs, which allows to systematically measure system-level situation coverage (on an abstract level) wrt. safety concepts captured by domain experts. Moreover, (3) we can systematically derive new challenging (abstract) situations which justiﬁably lead to runtime behavior which has not been tested so far by adapting consistent graph generation techniques, thus increasing situation coverage. Finally, (4) such abstract test cases are concretized so that they can be investigated in a real or simulated context.",
    "keywords": [
      "Model-based testing",
      "Autonomous vehicles",
      "Cyber-Physical Systems",
      "System-level testing",
      "Test coverage"
    ],
    "authors": [
      "Istv´an Majzik",
      "Oszk´ar Semer´ath",
      "Csaba Hajdu",
      "Krist´of Marussy",
      "Zolt´an Szatm´ari",
      "Zolt´an Micskei",
      "Andr´as V¨or¨os",
      "Aren A. Babikian and D´aniel Varr´o"
    ],
    "file_path": "data/models/models19/Towards System-Level Testing with Coverage Guarantees for Autonomous Vehicles.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "2019/00",
    "publication-date": "2019/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models19/Copyright notice.pdf"
  },
  {
    "title": "Automated Classiﬁcation of Metamodel Repositories: A Machine Learning Approach",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Manual classiﬁcation methods of metamodel repositories require highly trained personnel and the results are usually inﬂuenced by the subjectivity of human perception. Therefore, automated metamodel classiﬁcation is very desirable and stringent. In this work, Machine Learning techniques have been employed for metamodel automated classiﬁcation. In particular, a tool implementing a feed-forward neural network is introduced to classify metamodels. An experimental evaluation over a dataset of 555 metamodels demonstrates that the technique permits to learn from manually classiﬁed data and effectively categorize incoming unlabeled data with a considerably high prediction rate: the best performance comprehends 95.40% as success rate, 0.945 as precision, 0.938 as recall, and 0.942 as F1 score.",
    "keywords": [],
    "authors": [
      "Phuong T. Nguyen",
      "Juri Di Rocco",
      "Davide Di Ruscio",
      "Alfonso Pierantonio",
      "Ludovico Iovino"
    ],
    "file_path": "data/models/models19/Automated Classification of Metamodel Repositories A Machine Learning Approach.pdf"
  },
  {
    "title": "Guided Architecture Trade Space Exploration: Fusing Model Based Engineering & Design by Shopping",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Advances in model-based system engineering have greatly increased the predictive power of models and the analyses that can be run on them. At the same time, designs have become more modular and component-based. It can be difficult to manually explore all possible system designs due to the sheer number of possible architectures and configurations; design space exploration has arisen as a solution to this challenge.\nIn this work, we present the Guided Architecture Trade Space Explorer (GATSE), software which connects an existing model based engineering language (AADL) and tool (OSATE) to an existing design space exploration tool (ATSV). GATSE, AADL, and OSATE are all designed to be easily extended by users, which enables relatively straightforward domain-customizations. ATSV, combined with these customizations, lets system designers “shop” for candidate architectures and interactively explore the architectural trade space according to any quantifiable quality attribute or system characteristic. We evaluate GATSE according to an established framework for variable system architectures, and demonstrate its use on an avionics subsystem.",
    "keywords": [
      "Design Space Exploration",
      "Search-Based System Engineering",
      "Model-Based Engineering",
      "Guided Optimization"
    ],
    "authors": [
      "Sam Procter",
      "Lutz Wrage"
    ],
    "file_path": "data/models/models19/Guided Architecture Trade Space Exploration Fusing Model Based Engineering - Design by Shopping.pdf"
  },
  {
    "title": "RaM: Causally-connected and Requirements-aware Runtime Models using Bayesian Learning",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "A model at runtime can be defined as an abstract representation of a system, including its structure and behaviour, which exist alongside with the running system. Runtime models provide support for decision-making and reasoning based on design-time knowledge but, also based on information that may emerge at runtime and which was not foreseen before execution. A challenge that persists is the update of runtime models during the execution to support up-to-date information for reasoning and decision-making. New techniques based on machine learning (ML) and Bayesian Learning offer great potential to support the update of runtime models during execution. Runtime models can be updated using these new techniques to, therefore, offer better-informed decision-making based on evidence collected at runtime. The techniques we use in this paper are based on a novel implementation of Partially Observable Markov Decision Processes (POMDPs). In this paper, we demonstrate how given the requirements specification, a Requirements-aware runtime model based on POMDPs (RaM-POMDP) is defined. We study in detail the nature of such runtime models coupled with consideration of the Bayesian inference algorithms and tools that provide evidence of unexpected/surprising changes in the environment. We show how the RaM-POMDPs and the MAPE-K loop offer the basis of the software architecture presented and how the required casual connection of runtime models is realized. Specifically, we demonstrate how according to evidence of changes in the systems, collected by the monitoring infrastructure and using Bayesian inference, the runtime models are updated and inferred (i.e. the first aspect of the causal connection). We also demonstrate how the running system changes its runtime model, producing therefore the corresponding self-adaptations. These self-adaptations are reflected on the managed system (i.e. the second aspect of the causal connection) to better satisfy the requirements specifications and improve conformance to its service level agreements (SLAs). The experiments have been applied to a real case study for the networking application domain.",
    "keywords": [
      "Runtime models",
      "causal connection",
      "decision-making",
      "uncertainty",
      "POMDPs",
      "Bayesian inference/learning"
    ],
    "authors": [
      "Nelly Bencomo",
      "Luis H. Garcia-Paucar"
    ],
    "file_path": "data/models/models19/RaM Causally-Connected and Requirements-Aware Runtime Models using Bayesian Learning.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Alexander Pretschner",
      "Sebastian Voss",
      "Loli Burgueño"
    ],
    "file_path": "data/models/models19/Organizing Committee.pdf"
  },
  {
    "title": "An LSTM-Based Neural Network Architecture for Model Transformations",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Model transformations are a key element in any model-driven engineering approach. But writing them is a time-consuming and error-prone activity that requires specific knowledge of the transformation language semantics. We propose to take advantage of the advances in Artificial Intelligence and, in particular Long Short-Term Memory Neural Networks (LSTM), to automatically infer model transformations from sets of input-output model pairs. Once the transformation mappings have been learned, the LSTM system is able to autonomously transform new input models into their corresponding output models without the need of writing any transformation-specific code. We evaluate the correctness and performance of our approach and discuss its advantages and limitations.",
    "keywords": [
      "MDE",
      "model transformations",
      "LSTM ANN"
    ],
    "authors": [
      "Loli Burgueño",
      "Jordi Cabot",
      "Sébastien Gérard"
    ],
    "file_path": "data/models/models19/An LSTM-Based Neural Network Architecture for Model Transformations.pdf"
  },
  {
    "title": "Model-based, Platform-independent Logging for Heterogeneous Targets",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "A recurring issue in generative approaches, in particular if they generate code for multiple target languages, is logging. How to ensure that logging is performed consistently for all the supported languages? How to ensure that the specific semantics of the source language, e.g. a modeling language or a domain-specific language, is reflected in the logs? How to expose logging concepts directly in the source language, so as to let developers specify what to log? This paper reports on our experience developing a concrete logging approach for ThingML, a textual modeling language built around asynchronous components, statecharts and a first-class action language, as well as a set of “compilers” targeting C, Go, Java and JavaScript.",
    "keywords": [],
    "authors": [
      "Brice Morin and Nicolas Ferry"
    ],
    "file_path": "data/models/models19/Model-Based- Platform-Independent Logging for Heterogeneous Targets.pdf"
  },
  {
    "title": "CONDEnSe: Contract-Based Design Synthesis",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "It is difﬁcult to maintain consistency between artifacts produced during the development of mechatronic systems, and to ensure the successful integration of independently developed parts. The difﬁculty stems from the complex, multidisciplinary nature of the problem, with multiple artifacts produced by each engineering domain, throughout the design process, and across supplier chains.\n\nIn this work, we develop a methodology and a tool, CONDEnSe, that given a set of Assume/Guarantee (A/G) contracts that capture the system requirements, and a high-level decomposition of the system model, automatically generates design variants that respect the requirements and exports those variants to different engineering tools for analysis.\n\nOur methodology makes use of a contract-based design algebra to ensure that generated artifacts for all design variants are consistent by construction, even when the process is modularized and independently developed parts are only later integrated. In contrast with earlier work, our approach reduces the search space to models that comply with the captured design requirements.",
    "keywords": [
      "contracts",
      "synthesis",
      "mbse",
      "integration"
    ],
    "authors": [
      "C´esar Augusto Santos",
      "Amr Hany Saleh",
      "Tom Schrijvers",
      "Mike Nicolai"
    ],
    "file_path": "data/models/models19/CONDEnSe Contract Based Design Synthesis.pdf"
  },
  {
    "title": "Bootstrapping MDE Development from ROS\nManual Code - Part 2: Model Generation",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "In principle, Model-Driven Engineering (MDE) addresses central aspects of robotics software development. Domain experts could leverage the expressiveness of models; implementation details over different hardware could be handled by automatic code generation. In practice, most evidence points to manual code development as the norm, despite several MDE efforts in robotics. Possible reasons for this disconnect are the wide ranges of applications and target platforms making all-encompassing MDE IDEs hard to develop and maintain, with developers reverting to writing code manually. Acknowledging this, and given the opportunity to leverage a large corpus of open-source software widely adopted by the robotics community, we pursue modeling as a complement, rather than an alternative, to manually written code. Our previous work introduced metamodels to describe components, their interactions, and their resulting composition, as inspired by, but not limited to, the de-facto standard Robot Operating System (ROS). In this paper we put such metamodels into use through two contributions [1]. First, we automate the generation of models from manually written artifacts through extraction from source code and runtime system monitoring. Second, we make available an easy-to-use web infrastructure to perform the extraction, together with a growing database of models so generated. Our aim with this tooling, publicly available both as-a-service and as source code, is to lower the MDE barrier for practitioners and leverage models to 1) improve the understanding of manually written code; 2) perform correctness checks; and 3) systematize the deﬁnition and adoption of best practices through large-scale generation of models from existing code. A comprehensive example is provided as a walk-through for robotics software practitioners.",
    "keywords": [
      "ROS",
      "models",
      "development environments"
    ],
    "authors": [
      "Nadia Hammoudeh Garcia",
      "Ludovic Delval",
      "Mathias L¨udtke",
      "Andre Santos",
      "Bj¨orn Kahl and Mirko Bordignon"
    ],
    "file_path": "data/models/models19/Bootstrapping MDE Development from ROS Manual Code - Part 2 Model Generation.pdf"
  },
  {
    "title": "Domain-Level Observation and Control for Compiled Executable DSLs",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Executable Domain-Specific Languages (DSLs) are commonly defined with either operational semantics (i.e., interpretation) or translational semantics (i.e., compilation). An interpreted DSL relies on domain concepts to specify the possible execution states and steps, which enables the observation and control of executions using the very same domain concepts. In contrast, a compiled DSL relies on a transformation to an arbitrarily different target language. This creates a conceptual gap, where the execution can only be observed and controlled through target domain concepts, to the detriment of experts or tools that only understand the source domain. To address this problem, we propose a language engineering architecture for compiled DSLs that enables the observation and control of executions using source domain concepts. The architecture requires the definition of the source domain execution steps and states, along with a feedback manager that translates steps and states of the target domain back to the source domain. We evaluate the architecture with two different compiled DSLs, and show that it does enable domain-level observation and control while increasing execution time by 2× in the worst observed case.",
    "keywords": [
      "Software Language Engineering",
      "Domain-Specific Languages",
      "Executable DSL",
      "Compilation",
      "Feedback"
    ],
    "authors": [
      "Erwan Bousse",
      "Manuel Wimmer"
    ],
    "file_path": "data/models/models19/Domain-Level Observation and Control for Compiled Executable DSLs.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Alferez",
      "Mauricio; Atlee",
      "Joanne M.; Auffinger",
      "Yuri; Babikian",
      "Aren A.; Bencomo",
      "Nelly; Besnard",
      "Valentin; Bordignon",
      "Mirko; Bousse",
      "Erwan; Brand",
      "Thomas; Briand",
      "Lionel; Brun",
      "Matthias; Bucchiarone",
      "Antonio; Búr",
      "Márton; Burdusel",
      "Alexandru; Burgueño",
      "Loli; Cabot",
      "Jordi; Cheng",
      "Betty; Cicchetti",
      "Antonio; de Lara",
      "Juan; Deval",
      "Ludovic; DeVries",
      "Byron; Dhaussy",
      "Philippe; Dingel",
      "Juergen; Di Rocco",
      "Juri; Di Ruscio",
      "Davide; Elkhatib",
      "Yehia; Eric",
      "Sax; Ferry",
      "Nicolas; Fouquet",
      "Francois; García-Domínguez",
      "Antonio; Garcia Paucar",
      "Luis H.; García-Paucar",
      "Luis Hernán; Gérard",
      "Sébastien; Ghezzi",
      "Carlo; Giese",
      "Holger; Goes",
      "Peter; Guerra",
      "Esther; Hajdu",
      "Csaba; Hammoudeh Garcia",
      "Nadia; Hany Saleh",
      "Amr; Hartmann",
      "Thomas; Hassan",
      "Ahmed E.; Hoyos Rodriguez",
      "Horacio; Hu",
      "Zhenjiang; Iovino",
      "Ludovico; Iqbal",
      "Muhammad Zohaib; John",
      "Stefan; Jouault",
      "Frédéric; Jumagaliyev",
      "Assylbek; Jürjens",
      "Jan; Kahl",
      "Björn; Khan",
      "Muhammad Uzair; Kneisel",
      "Peter; Kolovos",
      "Dimitris; Kusmenko",
      "Evgeny; Le Traon",
      "Yves; Lüdtke",
      "Mathias; Majzik",
      "István; Marcony",
      "Annapaola; Marussy",
      "Kristóf; Micskei",
      "Zoltán; Moawad",
      "Assaad; Morin",
      "Brice; Nguyen",
      "Phuong T.; Nickels",
      "Sebastian; Nicolai",
      "Mike; Oliva",
      "Gustavo Ansaldi; Paige",
      "Richard; Parra-Ullauri",
      "Juan Marcelo; Pastore",
      "Fabrizio; Pavlitskaya",
      "Svetlana; Peldszus",
      "Sven; Philipp",
      "Obergfell"
    ],
    "file_path": "data/models/models19/Author Index.pdf"
  },
  {
    "title": "Pitfalls Analyzer: Quality Control for Model-Driven Data Science Pipelines",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Data science pipelines are a sequence of data processing steps that aim to derive knowledge and insights from raw data. Data science pipeline tools simplify the creation and automation of data science pipelines by providing reusable building blocks that users can drag and drop into their pipelines. Such a graphical, model-driven approach enables users with limited data science expertise to create complex pipelines. However, recent studies show that there exist several data science pitfalls that can yield spurious results and, consequently, misleading insights. Yet, none of the popular pipeline tools have built-in quality control measures to detect these pitfalls. Therefore, in this paper, we propose an approach called Pitfalls Analyzer to detect common pitfalls in data science pipelines. As a proof-of-concept, we implemented a prototype of the Pitfalls Analyzer for KNIME, which is one of the most popular data science pipeline tools. Our prototype is model-driven, since the detection of pitfalls is accomplished using pipelines that were created with KNIME building blocks. To showcase the effectiveness of our approach, we run our prototype on 11 pipelines that were created by KNIME experts for 3 Internet-of-Things (IoT) projects. The results indicate that our prototype ﬂags all and only those instances of the pitfalls that we were able to ﬂag while manually inspecting the pipelines.",
    "keywords": [
      "Data science pipelines",
      "model-driven engineering",
      "quality control",
      "data science pitfalls"
    ],
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Gustavo Ansaldi Oliva",
      "Ahmed E. Hassan",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models19/Pitfalls Analyzer Quality Control for Model-Driven Data Science Pipelines.pdf"
  },
  {
    "title": "Using Models to Enable Compliance Checking Against the GDPR: An Experience Report",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Damiano Torre",
      "Ghanem Soltana",
      "Mehrdad Sabetzadeh",
      "Lionel C. Briand",
      "Yuri Auffinger",
      "and Peter Goes"
    ],
    "file_path": "data/models/models19/Table of contents.pdf"
  },
  {
    "title": "Model-Driven Design of City Spaces via Bidirectional Transformations",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Technological advances enable new kinds of smart environments exhibiting complex behaviors; smart cities are a notable example. Smart functionalities heavily depend on space and need to be aware of entities typically found in the spatial domain, e.g. roads, intersections or buildings in a smart city. We advocate a model-based development, where the model of physical space, coming from the architecture and civil engineering disciplines, is transformed into an analyzable model upon which smart functionalities can be embedded. Such models can then be formally analyzed to assess a composite system design. We focus on how a model of physical space speciﬁed in the CityGML standard language can be transformed into a model amenable to analysis and how the two models can be automatically kept in sync after possible changes. This approach is essential to guarantee safe model-driven development of composite systems inhabiting physical spaces. We showcase transformations of real CityGML models in the context of scenarios concerning both design time and runtime analysis of space-dependent systems.",
    "keywords": [
      "Bidirectional Model Transformations",
      "Model-driven Engineering",
      "CityGML",
      "Cyber-physical spaces"
    ],
    "authors": [
      "Ennio Visconti",
      "Christos Tsigkanos",
      "Zhenjiang Hu",
      "Carlo Ghezzi"
    ],
    "file_path": "data/models/models19/Model-Driven Design of City Spaces via Bidirectional Transformations.pdf"
  },
  {
    "title": "Applying MDD in the Content Management System Domain: Scenarios and Empirical Assessment",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Content Management Systems (CMSs) such as Joomla and WordPress dominate today’s web. Enabled by standardized extensions, administrators can build powerful web applications for diverse customer demands. However, developing CMS extensions requires sophisticated technical knowledge, and the highly schematic code structure of an extension gives rise to errors during typical development and migration scenarios. Model-driven development (MDD) seems to be a promising paradigm to address these challenges, however it has not found adoption in the CMS domain yet. Systematic evidence of the benefit of applying MDD in this domain could facilitate its adoption; however, an empirical investigation of this benefit is currently lacking.\n\nIn this paper, we present a mixed-method empirical investigation of applying MDD in the CMS domain, based on an interview suite, a controlled experiment, and a field experiment. We consider three scenarios of developing new (both independent and dependent) CMS extensions and of migrating existing ones to a new major platform version. The experienced developers in our interviews acknowledge the relevance of these scenarios and report on experiences that render them suitable candidates for a successful application of MDD. We found a particularly high relevance of the migration scenario. Our experiments largely confirm the potentials and limits of MDD as identified for other domains. In particular, we found a productivity increase up to factor 17 during the development of CMS extensions. Furthermore, our observations highlight the importance of good tooling that seamlessly integrates with already used tool environments and processes.",
    "keywords": [
      "Model-Driven Development",
      "Content Management Systems",
      "Empirical Assessment"
    ],
    "authors": [
      "Dennis Priefer",
      "Peter Kneisel",
      "Wolf Rost",
      "Daniel Str¨uber",
      "Gabriele Taentzer"
    ],
    "file_path": "data/models/models19/Applying MDD in the Content Management System Domain Scenarios and Empirical Assessment.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Alfonso Pierantonio",
      "Antonio Cicchetti",
      "Birgit Demuth",
      "Daniel Amyot",
      "Davide Di Ruscio",
      "Daniel Varro",
      "Dimitris Kolovos",
      "Don Batory",
      "Esther Guerra",
      "Fiona Polack",
      "Friedrich Steimann",
      "Gregor Engels",
      "Hong Mei",
      "Houari Sahraoui",
      "Ileana Ober",
      "Iris Reinhartz-Berger",
      "Jocelyn Simmonds",
      "Jörg Kienzle",
      "Manuel Wimmer",
      "Michalis Famelis",
      "Mira Balaban",
      "Nelly Bencomo",
      "Peter Clarke",
      "Pieter van Gorp",
      "Regina Hebig",
      "Thomas Kühne",
      "Timothy Lethbridge",
      "Yu Jiang"
    ],
    "file_path": "data/models/models19/Program Committee.pdf"
  },
  {
    "title": "A Modelling Language to Support the Evolution of Multi-Tenant Cloud Data Architectures",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Multi-tenant data architectures enable efﬁcient resource utilization in cloud applications, but are currently being implemented in industry and research using manual coding techniques that tend to be time consuming and error prone. We propose a novel domain-speciﬁc modeling language, CadaML, to automatically manage the development and evolution of cloud data architectures that (a) adopt multi-tenancy and/or (b) comprise of a combination of different storage solutions such as relational and non-relational databases, and blob storage. CadaML provides concepts and notations to support abstract modelling of a multi-tenant data architecture, and also provides tools to validate the data architecture and automatically produce application code. We rigorously evaluate CadaML through a user experiment where developers of various capabilities are asked to re-architect the data layer of an industrial business process analysis application. We observe that CadaML users required 3.5x less development time than manual coders. In addition to improved productivity, CadaML users highlighted other beneﬁts gained in terms of reliability of generated code and usability.",
    "keywords": [
      "Domain-Speciﬁc modeling",
      "Model-Driven Engineering",
      "Cloud Computing",
      "Multi-tenancy",
      "Software Evolution",
      "Code Generation"
    ],
    "authors": [
      "Assylbek Jumagaliyev",
      "Yehia Elkhatib"
    ],
    "file_path": "data/models/models19/A Modelling Language to Support the Evolution of Multi-tenant Cloud Data Architectures.pdf"
  },
  {
    "title": "Automatic Generation of Atomic Consistency Preserving Search Operators for Search-Based Model Engineering",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Recently there has been increased interest in combining the fields of Model-Driven Engineering (MDE) and Search-Based Software Engineering (SBSE). Such approaches use meta-heuristic search guided by search operators (model mutators and sometimes breeders) implemented as model transformations. The design of these operators can substantially impact the effectiveness and efficiency of the meta-heuristic search. Currently, designing search operators is left to the person specifying the optimisation problem. However, developing consistent and efficient search-operator rules requires not only domain expertise but also in-depth knowledge about optimisation, which makes the use of model-based meta-heuristic search challenging and expensive. In this paper, we propose a generalised approach to automatically generate atomic consistency preserving search operators (aCPSOs) for a given optimisation problem. This reduces the effort required to specify an optimisation problem and shields optimisation users from the complexity of implementing efficient meta-heuristic search mutation operators. We evaluate our approach with a set of case studies, and show that the automatically generated rules are comparable to, and in some cases better than, manually created rules at guiding evolutionary search towards near-optimal solutions.",
    "keywords": [
      "model driven engineering",
      "search based optimisation",
      "search based software engineering"
    ],
    "authors": [
      "Alexandru Burdusel",
      "Steffen Zschaler",
      "Stefan John"
    ],
    "file_path": "data/models/models19/Automatic Generation of Atomic Consistency Preserving Search Operators for Search-Based Model Engineering.pdf"
  },
  {
    "title": "Towards effective mutation testing for ATL",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "The correctness of model transformations is crucial to obtain high-quality solutions in model-driven engineering. Testing is a common approach to detect errors in transformations, which requires having methods to assess the effectiveness of the test cases and improve their quality. Mutation testing permits assessing the quality of a test suite by injecting artiﬁcial faults in the system under test. These emulate common errors made by competent developers and are modelled using mutation operators. Some researchers have proposed sets of mutation operators for transformation languages like ATL. However, their suitability for an effective mutation testing process has not been investigated, and there is no automated mechanism to generate test models that increase the quality of the tests. In this paper, we use transformations created by third parties to evaluate the effectiveness ATL mutation operators proposed in the literature, and other operators that we have devised based on empirical evidence on real errors made by developers. Likewise, we evaluate the effectiveness of commonly used test model generation techniques. For the cases in which a test suite does not detect an injected fault, we synthesize test models able to detect it. As a technical contribution, we make available a framework that automates this process for ATL.",
    "keywords": [
      "Model transformations",
      "Mutation testing",
      "ATL"
    ],
    "authors": [
      "Esther Guerra",
      "Jesus Sanchez Cuadrado",
      "Juan de Lara"
    ],
    "file_path": "data/models/models19/Towards Effective Mutation Testing for ATL.pdf"
  },
  {
    "title": "Querying and annotating model histories with time-aware patterns",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Models are not static entities: they evolve over time due to changes. Changes may inadvertently and surprisingly violate constraints imposed. Therefore, the models need to be monitored for compliance. On the one hand, in traditional design-time applications, new and evolving requirements impose changes on a model over time. These changes may accidentally break design rules. Further, the growing complexity of the models may need to be tracked for manageability. On the other hand, newer applications use models at runtime; building runtime abstractions that are used to control a system. Adopters of these approaches will need to query the history of the system to check if the models evolved as expected, or to find out the reasons for a particular behavior. Changes over models at runtime are more frequent than changes over design models. To cover these demands, we argue that a flexible and scalable approach for querying the history of the models is needed to study the evolution and for compliance sake. This paper presents a set of extensions to a model query language inspired in the Object Constraint Language (the Epsilon Object Language) for traversing the history of a model, and for making temporal assertions that will allow the elicitation of historic information. As querying long histories may be costly, the paper presents an approach that annotates versions of interest as they are observed, in order to provide efficient recalls in possible future queries. The approach has been implemented in a model indexing tool, and is demonstrated through a case study from the autonomous and self-adaptive systems domain.",
    "keywords": [
      "Model querying",
      "model versioning",
      "temporal graph databases",
      "model indexing",
      "scalable model-driven engineering"
    ],
    "authors": [
      "Antonio García-Domínguez",
      "Nelly Bencomo",
      "Juan Marcelo Parra-Ullauri",
      "Luis Hernán García-Paucar"
    ],
    "file_path": "data/models/models19/Querying and Annotating Model Histories with Time-Aware Patterns.pdf"
  },
  {
    "title": "Goal-Based Modeling and Analysis of Non-Functional Requirements",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Non-functional goals specify a quality attribute of the functional goals for the system-to-be (e.g., cost, performance, security, and safety). However, non-functional goals are often cross-cutting and do not naturally ﬁt within the default decomposition expressed by a functional goal model. Further, any functional mitigations that ensure the satisfaction of a non-functional goal, or occur in the event a non-functional goal is violated, are conditionally applicable to the remainder of the system-to-be. Rather than modeling non-functional goals and their associated mitigations as a part of the system-to-be goal model, we introduce a method of modeling and analyzing non-functional goals and their associated mitigation as separate models. We illustrate our approach by applying our method to model non-functional goals related to an industry-based automotive braking system and analyzing for non-functional violations.",
    "keywords": [
      "non-functional",
      "requirements",
      "goal model"
    ],
    "authors": [
      "Byron DeVries",
      "Betty H.C. Cheng"
    ],
    "file_path": "data/models/models19/Goal-Based Modeling and Analysis of Non-Functional Requirements.pdf"
  },
  {
    "title": "Verifying and Monitoring UML Models with Observer Automata\nA Transformation-free Approach",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "The increasing complexity of embedded systems renders veriﬁcation of software programs more complex and may require applying monitoring and formal techniques, like model-checking. However, to use such techniques, system engineers usually need formal experts to express software requirements in a formal language. To facilitate the use of model-checking tools by system engineers, our approach consists of using a UML model interpreter with which the software requirements can directly be expressed as observer automata in UML as well. These observer automata are synchronously composed with the system, and can be used unchanged both for model veriﬁcation and runtime monitoring. Our approach has been evaluated on the user interface model of a cruise control system. The observer veriﬁcation results are in line with the veriﬁcation of equivalent LTL properties. The runtime overhead of the monitoring infrastructure is 6.5%, with only 1.2% memory overhead.",
    "keywords": [
      "Observer Automata",
      "Monitoring",
      "Model Interpretation",
      "Embedded Systems"
    ],
    "authors": [
      "Valentin Besnard\nCiprian Teodorov\nFrédéric Jouault\nMatthias Brun\nPhilippe Dhaussy"
    ],
    "file_path": "data/models/models19/Verifying and Monitoring UML Models with Observer Automata A Transformation-Free Approach.pdf"
  },
  {
    "title": "Proceedings 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Marouane Kessentini",
      "Tao Yue",
      "Alexander Pretschner",
      "Sebastian Voss",
      "Loli Burgueño"
    ],
    "file_path": "data/models/models19/Title page iii.pdf"
  },
  {
    "title": "A Focus+Context Approach to Alleviate Cognitive Challenges of Editing and Debugging UML Models",
    "submission-date": "2019/00",
    "publication-date": "2019/00",
    "abstract": "Model-Driven Engineering has been proposed to increase the productivity of developing a software system. Despite its beneﬁts, it has not been fully adopted in the software industry. Research has shown that modelling tools are amongst the top barriers for the adoption of MDE by industry. Recently, researchers have conducted empirical studies to identify the most-severe cognitive difﬁculties of modellers when using UML model editors. Their analyses show that users’ prominent challenges are in remembering the contextual information when performing a particular modelling task; and locating, understanding, and ﬁxing errors in the models. To alleviate these difﬁculties, we propose two Focus+Context user interfaces that provide enhanced cognitive support and automation in the user’s interaction with a model editor. Moreover, we conducted two empirical studies to assess the effectiveness of our interfaces on human users. Our results reveal that our interfaces help users 1) improve their ability to successfully fulﬁl their tasks, 2) avoid unnecessary switches among diagrams, 3) produce more error-free models, 4) remember contextual information, and 5) reduce time on tasks.",
    "keywords": [
      "User-Centric Software Development",
      "Empirical Study",
      "UML",
      "Modelling Tools",
      "Modelling Challenges"
    ],
    "authors": [
      "Parsa Pourali",
      "Joanne M. Atlee"
    ],
    "file_path": "data/models/models19/A Focus-Context Approach to Alleviate Cognitive Challenges of Editing and Debugging UML Models.pdf"
  },
  {
    "title": "Exploiting Multi-Level Modelling for Designing and Deploying Gameful Systems",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Gamiﬁcation is increasingly used to build solutions for driving the behaviour of target users’ populations. Gameful systems are typically exploited to keep users’ involvement in certain activities and/or to modify an initial behaviour through game-like elements, such as awarding points, submitting challenges and/or fostering competition and cooperation with other players. Gamiﬁcation mechanisms are well-deﬁned and composed of different ingredients that have to be correctly amalgamated together; among these we ﬁnd single/multi-player challenges targeted to reach a certain goal and providing an adequate award for compensation. Since the current approaches are largely based on hand-coding/tuning, when the game grows in its complex- ity, keeping track of all the mechanisms and maintaining the implementation can become error-prone and tedious activities. In this paper, we describe a multi-level modelling approach for the deﬁnition of gamiﬁcation mechanisms, from their design to their deployment and runtime adaptation. The approach is implemented by means of JetBrains MPS, a text-based meta- modelling framework, and validated using two gameful systems in the Education and Mobility domains.",
    "keywords": [
      "Multi-Level Modelling",
      "Model-Driven Engineering",
      "MPS",
      "Gamiﬁcation Engine"
    ],
    "authors": [
      "Antonio Bucchiarone",
      "Antonio Cicchetti",
      "Annapaola Marconi"
    ],
    "file_path": "data/models/models19/Exploiting Multi-level Modelling for Designing and Deploying Gameful Systems.pdf"
  },
  {
    "title": "On-the-ﬂy Translation and Execution of OCL-like Queries on Simulink Models",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "MATLAB/Simulink is a tool for dynamic system modelling. Model management languages such as OCL, ATL and the languages of the Epsilon platform tend to focus on the Eclipse Modelling Framework (EMF), a de facto standard for domain specific modelling. As Simulink models are built on an entirely different technical stack, the current solution to manipulate them using such languages requires their transformation into an EMF-compatible representation. This approach is expensive as the cost of the transformation can be crippling for large models, it requires the synchronisation of the native Simulink model and its EMF counterpart, and the EMF-representation may be an incomplete copy of the model. In this paper we propose an alternative approach that uses the MATLAB API to bridge Simulink models with existing model management languages that relies on the “on-the-ﬂy” translation of model management language constructs into MATLAB commands. Our approach eliminates the cost of the transformation and of the co-evolution of the EMF-compatible representation while enabling full access to the Simulink model details. We evaluate the performance of both approaches using a set of model validation constraints executed on a sample of the largest Simulink models available on GitHub. Our evaluation suggests that the translation approach can reduce the model validation time up to 80%.",
    "keywords": [
      "Eclipse Modelling Framework",
      "MATLAB Simulink",
      "Model Driven Engineering",
      "Epsilon"
    ],
    "authors": [
      "Beatriz A. Sanchez",
      "Athanasios Zolotas",
      "Horacio Hoyos Rodriguez",
      "Dimitris S. Kolovos",
      "Richard F. Paige"
    ],
    "file_path": "data/models/models19/On-the-Fly Translation and Execution of OCL-Like Queries on Simulink Models.pdf"
  },
  {
    "title": "A Model-based Testing Approach for Cockpit Display Systems of Avionics",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Avionics are highly critical systems that require extensive testing governed by international safety standards. Cockpit Display Systems (CDS) are an essential component of modern aircraft cockpits and display information from the user application (UA) using various widgets. A signiﬁcant step in the testing of avionics is to evaluate whether these CDS are displaying the correct information. A common industrial practice is to manually test the information on these CDS by taking the aircraft into different scenarios during the simulation. Such testing is required very frequently and at various changes in the avionics. Given the large number of scenarios to test, manual testing of such behavior is a laborious activity. In this paper, we propose a model-based strategy for automated testing of the information displayed on CDS. Our testing approach focuses on evaluating that the information from the user applications is being displayed correctly on the CDS. For this purpose, we develop a proﬁle for capturing the details of different widgets of the display screens using models. The proﬁle is based on the ARINC 661 standard for Cockpit Display Systems. The expected behavior of the CDS visible on the screens of the aircraft is captured using constraints written in Object Constraint Language. We apply our approach on an industrial case study of a Primary Flight Display (PFD) developed for an aircraft. Our results showed that the proposed approach is able to automatically identify faults in the simulation of PFD. Based on the results, it is concluded that the proposed approach is useful in ﬁnding display faults on avionics CDS.",
    "keywords": [
      "Model-based Testing; Cockpit Display Systems; Safety-critical Systems; ARINC 661; Object Constraint Language (OCL)"
    ],
    "authors": [
      "Muhammad Zohaib Iqbal",
      "Hassan Sartaj",
      "Muhammad Uzair Khan",
      "Fitash Ul Haq",
      "Ifrah Qaisar"
    ],
    "file_path": "data/models/models19/A Model-Based Testing Approach for Cockpit Display Systems of Avionics.pdf"
  },
  {
    "title": "Meta-Modelling Meta-Learning",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Although artiﬁcial intelligence and machine learning are currently extremely fashionable, applying machine learning on real-life problems remains very challenging. Data scientists need to evaluate various learning algorithms and tune their numerous parameters, based on their assumptions and experience, against concrete problems and training data sets. This is a long, tedious, and resource expensive task. Meta-learning is a recent technique to overcome, i.e. automate this problem. It aims at using machine learning itself to automatically learn the most appropriate algorithms and parameters for a machine learning problem. As it turns out, there are many parallels between meta-modelling—in the sense of model-driven engineering—and meta-learning. Both rely on abstractions, the meta data, to model a predeﬁned class of problems and to deﬁne the variabilities of the models conforming to this deﬁnition. Both are used to deﬁne the output and input relationships and then ﬁtting the right models to represent that behaviour. In this paper, we envision how a meta-model for meta-learning can look like. We discuss possible variabilities, for what types of learning it could be appropriate for, how concrete learning models can be generated from it, and how models can be ﬁnally selected. Last but not least, we discuss a possible integration into existing modelling tools.",
    "keywords": [
      "meta-learning",
      "meta-modelling",
      "AutoML",
      "modelling framework"
    ],
    "authors": [
      "Thomas Hartmann",
      "Assaad Moawad",
      "Cedric Schockaert",
      "Francois Fouquet",
      "Yves Le Traon"
    ],
    "file_path": "data/models/models19/Meta-Modelling Meta-Learning.pdf"
  },
  {
    "title": "Towards WCET Estimation of Graph Queries@Run.time",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "Recent approaches in runtime monitoring and live data analytics have started to use expressive graph queries at runtime to capture and observe properties of interest at a high level of abstraction. However, in a critical context, such applications often require timeliness guarantees, which have not been investigated yet for query-based solutions due to limitations of existing static worst-case execution time (WCET) analysis techniques. One limitation is the lack of support for dynamic memory allocation, which is required by the dynamically evolving runtime models on which the queries are evaluated. Another open challenge is to compute WCET for asynchronously communicating programs such as distributed monitors. This paper introduces our vision about how to assess such timeliness properties and how to provide tight WCET estimates for query execution at runtime over a dynamic model. Furthermore, we present an initial solution that combines state-of-the-art parametric WCET estimations with model statistics and search plans of queries.",
    "keywords": [],
    "authors": [
      "Márton Búr",
      "Dániel Varró"
    ],
    "file_path": "data/models/models19/Towards WCET Estimation of Graph Queries-Run.time.pdf"
  },
  {
    "title": "Bridging the Gap between Requirements Modeling and Behavior-driven Development",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "Acceptance criteria (AC) are implementation agnostic conditions that a system must meet to be consistent with its requirements and be accepted by its stakeholders. Each acceptance criterion is typically expressed as a natural-language statement with a clear pass or fail outcome. Writing AC is a tedious and error-prone activity, especially when the requirements speciﬁcations evolve and there are different analysts and testing teams involved. Analysts and testers must iterate multiple times to ensure that AC are understandable and feasible, and accurately address the most important requirements and workﬂows of the system being developed. In many cases, analysts express requirements through models, along with natural language, typically in some variant of the UML. AC must then be derived by developers and testers from such models. In this paper, we bridge the gap between requirements models and AC by providing a UML-based modeling methodology and an automated solution to generate AC. We target AC in the form of Behavioral Speciﬁcations in the context of Behavioral-Driven Development (BDD), a widely used agile practice in many application domains. More specially we target the well-known Gherkin language to express AC, which then can be used to generate executable test cases. We evaluate our modeling methodology and AC generation solution through an industrial case study in the ﬁnancial domain. Our results suggest that (1) our methodology is feasible to apply in practice, and (2) the additional modeling effort required by our methodology is outweighed by the beneﬁts the methodology brings in terms of automated and systematic AC generation and improved model precision.",
    "keywords": [
      "Software testing",
      "BDD",
      "modeling",
      "requirements engineering",
      "text generation",
      "Gherkin",
      "and FinTech."
    ],
    "authors": [
      "Mauricio Alferez",
      "Fabrizio Pastore",
      "Mehrdad Sabetzadeh",
      "Lionel C. Briand",
      "Jean-Richard Riccardi"
    ],
    "file_path": "data/models/models19/Bridging the Gap between Requirements Modeling and Behavior-Driven Development.pdf"
  },
  {
    "title": "MODELS 2019",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models19/Title page i.pdf"
  },
  {
    "title": "Preface to the 22nd International ACM/IEEE Conference on Model Driven Engineering Languages and Systems",
    "submission-date": "2019/09",
    "publication-date": "2019/09",
    "abstract": "This document is a preface to the 22nd International ACM/IEEE Conference on Model Driven Engineering Languages and Systems (MODELS 2019), held September 15-20, 2019 in Munich, Germany. It provides information about the conference location, program, submission and acceptance rates, and acknowledges the contributions of various individuals and organizations involved in its organization.",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models19/Preface.pdf"
  },
  {
    "title": "Modeling and Training of Neural Processing Systems",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "The ﬁeld of deep learning has become more and more pervasive in the last years as we have seen varieties of problems being solved using neural processing techniques. Image analysis and detection, control, speech recognition, translation are only a few prominent examples tackled successfully by neural networks. Thereby, the discipline imposes a completely new problem solving paradigm requiring a rethinking of classical software development methods. The high demand for deep learning technology has led to a large amount of competing frameworks mostly having a Python interface - a quasi standard in the community. Although, existing tools often provide great ﬂexibility and high performance, they still lack to deliver a completely domain oriented problem view. Furthermore, using neural networks as reusable building blocks with clear interfaces in productive systems is still a challenge. In this work we propose a domain speciﬁc modeling methodology tackling design, training, and integration of deep neural networks. Thereby, we distinguish between three main modeling concerns: architecture, training, and data. We integrate our methodology in a component-based modeling toolchain allowing one to employ and reuse neural networks in large software architectures.",
    "keywords": [
      "deep learning",
      "neural networks",
      "model-driven software engineering"
    ],
    "authors": [
      "Evgeny Kusmenko",
      "Sebastian Nickels",
      "Svetlana Pavlitskaya",
      "Bernhard Rumpe",
      "Thomas Timmermanns"
    ],
    "file_path": "data/models/models19/Modeling and Training of Neural Processing Systems.pdf"
  },
  {
    "title": "Using Models to Enable Compliance Checking against the GDPR: An Experience Report",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "The General Data Protection Regulation (GDPR) harmonizes data privacy laws and regulations across Europe. Through the GDPR, individuals are able to better control their personal data in the face of new technological developments. While the GDPR is highly advantageous to individuals, complying with it poses major challenges for organizations that control or process personal data. Since no automated solution with broad industrial applicability currently exists for GDPR compliance checking, organizations have no choice but to perform costly manual audits to ensure compliance. In this paper, we share our experience building a UML representation of the GDPR as a ﬁrst step towards the development of future automated methods for assessing compliance with the GDPR. Given that a concrete implementation of the GDPR is affected by the national laws of the EU member states, GDPR’s expanding body of case law and other contextual information, we propose a two-tiered representation of the GDPR: a generic tier and a specialized tier. The generic tier captures the concepts and principles of the GDPR that apply to all contexts, whereas the specialized tier describes a speciﬁc tailoring of the generic tier to a given context, including the contextual variations that may impact the interpretation and application of the GDPR. We further present the challenges we faced in our modeling endeavor, the lessons we learned from it, and future directions for research.",
    "keywords": [
      "General Data Protection Regulation",
      "Regulatory Compliance",
      "UML",
      "OCL"
    ],
    "authors": [
      "Damiano Torre",
      "Ghanem Soltana",
      "Mehrdad Sabetzadeh",
      "Lionel C. Briand",
      "Yuri Aufﬁnger",
      "Peter Goes"
    ],
    "file_path": "data/models/models19/Using Models to Enable Compliance Checking Against the GDPR An Experience Report.pdf"
  },
  {
    "title": "Secure Data-Flow Compliance Checks between Models and Code based on Automated Mappings",
    "submission-date": "2019/10",
    "publication-date": "2019/10",
    "abstract": "During the development of security-critical software, the system implementation must capture the security properties postulated by the architectural design. This paper presents an approach to support secure data-ﬂow compliance checks between design models and code. To iteratively guide the developer in discovering such compliance violations we introduce automated mappings. These mappings are created by searching for correspondences between a design-level model (Security Data Flow Diagram) and an implementation-level model (Program Model). We limit the search space by considering name similarities between model elements and code elements as well as by the use of heuristic rules for matching data-ﬂow structures. The main contributions of this paper are three-fold. First, the automated mappings support the designer in an early discovery of implementation absence, convergence, and divergence with respect to the planned software design. Second, the mappings also support the discovery of secure data-ﬂow compliance violations in terms of illegal asset ﬂows in the software implementation. Third, we present our implementation of the approach as a publicly available Eclipse plugin and its evaluation on ﬁve open source Java projects (including Eclipse secure storage).",
    "keywords": [
      "Security-by-design",
      "Security compliance",
      "Data Flow Diagram (DFD)",
      "Model-to-Model Transformation (M2M)"
    ],
    "authors": [
      "Sven Peldszus",
      "Katja Tuma",
      "Daniel Strüber",
      "Jan Jürjens",
      "Riccardo Scandariato"
    ],
    "file_path": "data/models/models19/Secure Data-Flow Compliance Checks between Models and Code Based on Automated Mappings.pdf"
  },
  {
    "title": "Leveraging Model-Driven Technologies for JSON Artefacts: The Shipyard Case Study",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "With JSON’s increasing adoption, the need for structural constraints and validation capabilities led to JSON Schema, a dedicated meta-language to specify languages which are in turn used to validate JSON documents. Currently, the standardisation process of JSON Schema and the implementation of adequate tool support (e.g., validators and editors) are work in progress. However, the periodic issuing of newer JSON Schema drafts makes tool development challenging. Nevertheless, many JSON Schemas as language deﬁnitions exist, but JSON documents are still mostly edited in basic text-based editors. To tackle this challenge, we investigate in this paper how Model-Driven Engineering (MDE) methods for language engineering can help in this area. Instead of re-inventing the wheel of building up particular technologies directly for JSON, we study how the existing MDE infrastructures may be utilized for JSON. In particular, we present a bridge between the JSONware and Modelware technical spaces to exchange languages and documents. Based on this bridge, our approach supports language engineers, domain experts, and tool providers in editing, validating, and generating tool support with enhanced capabilities for JSON schemas and their documents. We evaluate our approach with Shipyard, a JSON Schema-based language for the workﬂow speciﬁcation for Keptn, an open-source tool for DevOps automation of cloud-native applications. The results of the case study show that proper editors and language evolution support from MDE can be reused and, at the same time, the surface syntax of JSON is maintained.",
    "keywords": [
      "JSON",
      "JSON Schema",
      "MDE",
      "DevOps",
      "Tool Interoperability"
    ],
    "authors": [
      "Alessandro Colantoni",
      "Antonio Garmendia",
      "Luca Berardinelli",
      "Manuel Wimmer",
      "Johannes Br¨auer"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a250/349500a250.pdf"
  },
  {
    "title": "Towards Reinforcement Learning for In-Place Model Transformations",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Model-driven optimization has gained much interest in the last years which resulted in several dedicated extensions for in-place model transformation engines. The main idea is to exploit domain-speciﬁc languages to deﬁne models which are optimized by applying a set of model transformation rules. Objectives are guiding the optimization processes which are currently mostly realized by meta-heuristic searchers such as different kinds of Genetic Algorithms. However, meta-heuristic search approaches are currently challenged by reinforcement learning approaches for solving optimization problems.\n\nIn this new ideas paper, we apply for the ﬁrst time reinforce-ment learning for in-place model transformations. In particular, we extend an existing model-driven optimization approach with reinforcement learning techniques. We experiment with value-based and policy-based techniques. We investigate several case studies for validating the feasibility of using reinforcement learning for model-driven optimization and compare the perfor-mance against existing approaches. The initial evaluation shows promising results but also helped in identifying future research lines for the whole model transformation community.",
    "keywords": [
      "Model Transformations",
      "Reinforcement-Learning",
      "Model-based Optimization"
    ],
    "authors": [
      "Martin Eisenberg",
      "Hans-Peter Pichler",
      "Antonio Garmendia",
      "Manuel Wimmer"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a082/349500a082.pdf"
  },
  {
    "title": "A Concept for a Qualiﬁable (Meta)-Modeling Framework Deployable in Systems and Tools of Safety-critical and Cyber-physical Environments",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "The development of cyber-physical systems can significantly benefit from domain-specific modeling and requires adequate (meta)-modeling frameworks. If such systems are designed for the safety-critical area, the systems must undergo qualiﬁcation processes deﬁned and monitored by a certiﬁcation authority. To use the resulting artifacts of modeling tools without further qualiﬁcation activities, the modeling tool must be additionally qualiﬁed. Tool qualiﬁcation has to be conducted by the tool user and can be assisted by the tool developer by providing qualiﬁcation artifacts. However, state-of-the-art domain-specific modeling frameworks barely support the user in the qualiﬁcation process, which results in an extensive manual effort. To reduce this effort and to avoid modeling constructs that can hardly be implemented in a qualiﬁable way, we propose the development of an open source (meta)-modeling framework that inherently considers qualiﬁcation issues. Based on the functionality of existing frameworks, we have identiﬁed components that necessarily need to be rethought or changed. This leads to the consideration of the following six cornerstones for our framework: (1) an essential meta-language, (2) a minimal runtime, (3) deterministic transformations, (4) a qualiﬁcation artifact generation, (5) a sophisticated visualization, and (6) a decoupled interaction of framework components. All these cornerstones consider the aspect of a safety-critical (meta)-modeling framework in their own manner. This combination leads to a holistic framework usable in the safety-critical system development domain.",
    "keywords": [],
    "authors": [
      "Vanessa Tietz",
      "Julian Schoepf",
      "Andreas Waldvogel",
      "Bjoern Annighoefer"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a163/349500a163.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Zhenjiang Hu",
      "Tomoji Kishi",
      "Naoyasu Ubayashi",
      "Daniel Varro",
      "Shiva Nejati",
      "Xiaoxing Ma",
      "Huseyin Ergin",
      "Shaukat Ali"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z012/349500z012.pdf"
  },
  {
    "title": "Execution Trace Analysis for a Precise Understanding of Latency Violations",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Despite the amount of proposed works for the veriﬁcation of diverse model properties, under-standing the root cause of latency requirements viola-tion in execution traces is still an open-issue especially for complex HW/SW system-level designs: is it due to an unfavorable real-time scheduling, to contentions on buses, to the characteristics of functional algorithms or hardware components? This identiﬁcation is particu-larly at stake when adding new features in a model, e.g., a new security countermeasure. The paper introduces PLAN, a new trace analysis technique whose objective is to classify execution transactions according to their impact on latency. To do so, we rely ﬁrst on a model transformation that builds up a dependency graph from an allocation model, thus including hardware and software aspects of a system model. Then, from this graph and an execution trace, our analysis can highlight how software or hardware elements contributed to the latency violation. The paper ﬁrst formalizes the problem before applying our approach to simulation traces of SysML models. A case study deﬁned in the AQUAS European project illustrates the interest of our approach.",
    "keywords": [
      "Embedded Systems",
      "Execution Trace Analysis",
      "Dependency Graph",
      "MBSE",
      "Timing analysis",
      "Simulation"
    ],
    "authors": [
      "Maysam Zoor",
      "Ludovic Apvrille",
      "Renaud Pacalet"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a123/349500a123.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Shaukat Ali",
      "Mira Balaban",
      "Olivier Barais",
      "Thorsten Berger",
      "Gábor Bergmann",
      "Marco Brambilla",
      "Loli Burgueño",
      "Michel Chaudron",
      "Juergen Dingel",
      "Jeff Gray",
      "Esther Guerra",
      "Xiao He",
      "Marianne Huchard",
      "Fuyuki Ishikawa",
      "Gabor Karsai",
      "Dimitris Kolovos",
      "Sébastien Mosser",
      "Ileana Ober",
      "Alfonso Pierantonio",
      "Gianna Reggio",
      "Riccardo Scandariato",
      "Andy Schürr",
      "Jocelyn Simmonds",
      "Daniel Strüber",
      "Matthias Tichy",
      "Massimo Tisi",
      "Antonio Vallecillo",
      "Andreas Wortmann",
      "Andrzej Wąsowski",
      "Tao Yue",
      "Steffen Zschaler"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z021/349500z021.pdf"
  },
  {
    "title": "Applying Declarative Analysis to Software Product Line Models: An Industrial Study",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Software Product Lines (SPLs) are families of related software products developed from a common set of artifacts. Most existing analysis tools can be applied to a single product at a time, but not to an entire SPL. Some tools have been redesigned/re-implemented to support the kind of variability exhibited in SPLs, but this usually takes a lot of effort, and is error-prone. Declarative analyses written in languages like Datalog have been collectively lifted to SPLs in prior work [1], which makes the process of applying an existing declarative analysis to a product line more straightforward.\nIn this paper, we take an existing declarative analysis (behaviour alteration) and apply it to a set of automotive software product lines from General Motors. We discuss the design of the analysis pipeline used in this process, present its scalability results, and provide a means to visualize the analysis results for a subset of products ﬁltered by feature expression. We also reﬂect on some of the lessons learned throughout this project.",
    "keywords": [],
    "authors": [
      "Ramy Shahin",
      "Robert Hackman",
      "Rafael Toledo",
      "Ramesh S.",
      "Joanne M. Atlee",
      "Marsha Chechik"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a145/349500a145.pdf"
  },
  {
    "title": "Model-Driven Simulation-Based Analysis for Multi-Robot Systems",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Multi-robot systems are increasingly deployed to provide services and accomplish missions whose complexity or cost is too high for a single robot to achieve on its own. Although multi-robot systems offer increased reliability via redundancy and enable the execution of more challenging missions, engineering these systems is very complex. This complexity affects not only the architecture modelling of the robotic team but also the modelling and analysis of the collaborative intelligence enabling the team to complete its mission. Existing approaches for the development of multi-robot applications do not provide a systematic mechanism for capturing these aspects and assessing the robustness of multi-robot systems. We address this gap by introducing ATLAS, a novel model-driven approach supporting the systematic robustness analysis of multi-robot systems in simulation. The ATLAS domain-speciﬁc language enables modelling the architecture of the robotic team and its mission, and facilitates the speciﬁcation of the team’s intelligence. We evaluate ATLAS and demonstrate its effectiveness on two oceanic exploration missions performed by a team of unmanned underwater vehicles developed using the MOOS-IvP robotic simulator.",
    "keywords": [
      "model-driven engineering",
      "robotics",
      "simulation"
    ],
    "authors": [
      "James Harbin",
      "Simos Gerasimou",
      "Nicholas Matragkas",
      "Athanasios Zolotas and Radu Calinescu"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a331/349500a331.pdf"
  },
  {
    "title": "Monte Carlo Tree Search and\nGR(1) Synthesis for Robot Tasks Planning in\nAutomotive Production Lines",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "In automotive production cells, complex processes\ninvolving multiple robots must be optimized for cycle time.\nWe investigated using symbolic GR(1) controller synthesis for\nautomating multi-robot task planning. Given a speciﬁcation of\nthe order of tasks and states to avoid, often multiple valid\nstrategies can be computed; in many states there are multiple\nchoices to satisfy the speciﬁcation, such as choosing different\nrobots to perform a certain task. To determine the best choices\nunder the consideration of movement times and probabilities\nthat robots may be interrupted for repairs or corrections, we\ncombine the execution of the synthesized controller with Monte\nCarlo Tree Search (MCTS), a heuristic AI-planning technique.\nThe result is a model-at-run-time approach that we present by\nthe example of a multi-robot spot welding cell. We report on\nexperiments showing that the approach (1) can reduce cycle\ntimes by choosing time-efﬁcient movement sequences and (2)\ncan choose executions that react efﬁciently to interruptions by\nchoosing to delay tasks that, if an interruption of one robot\nshould occur later, can be reallocated to another robot. Most\ninterestingly, we found, however, that (3) in some cases there is a\nconﬂict between time-efﬁcient movement sequences and ones that\nmay react efﬁciently to probable future interruptions—and when\ninterruption probabilities are low, increasing the time allocated\nfor MCTS, i.e., increasing the number of sample simulations\nmade by MCTS, does not improve cycle time.",
    "keywords": [
      "Robot tasks planning",
      "Reactive systems",
      "Monte\nCarlo Tree Search"
    ],
    "authors": [
      "Eric Wete",
      "Joel Greenyer",
      "Andreas Wortmann",
      "Oliver Flegel",
      "Martin Klein"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a320/349500a320.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Silvia Abrahão",
      "Richard Paige",
      "Don Batory",
      "Benoit Baudry",
      "Nelly Bencomo",
      "Ruth Breu",
      "Jordi Cabot",
      "Silvia Ceballos"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z016/349500z016.pdf"
  },
  {
    "title": "MoDALAS: Model-Driven Assurance for Learning-Enabled Autonomous Systems",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Increasingly, safety-critical systems include artificial intelligence and machine learning components (i.e., Learning-Enabled Components (LECs)). However, when behavior is learned in a training environment that fails to fully capture real-world phenomena, the response of an LEC to untrained phenomena is uncertain, and therefore cannot be assured as safe. Automated methods are needed for self-assessment and adaptation to decide when learned behavior can be trusted. This work introduces a model-driven approach to manage self-adaptation of a Learning-Enabled System (LES) to account for run-time contexts for which the learned behavior of LECs cannot be trusted. The resulting framework enables an LES to monitor and evaluate goal models at run time to determine whether or not LECs can be expected to meet functional objectives. Using this framework enables stakeholders to have more confidence that LECs are used only in contexts comparable to those validated at design time.",
    "keywords": [
      "goal-based modeling",
      "self-adaptive systems",
      "artificial intelligence",
      "machine learning",
      "models at run time",
      "cyber physical systems",
      "behavior oracles",
      "autonomous vehicles"
    ],
    "authors": [
      "Michael Austin Langford",
      "Kenneth H. Chan",
      "Jonathon Emil Fleck",
      "Philip K. McKinley",
      "Betty H.C. Cheng"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a182/349500a182.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Ali, Shaukat",
      "Amundson, Isaac",
      "Annighoefer, Bjoern",
      "Apvrille, Ludovic",
      "Aslam, Kousar",
      "Atlee, Joanne M.",
      "Babaei, Majid",
      "Babar, Junaid",
      "Belharbi, Khalid",
      "Bennett, Michael",
      "Berardinelli, Luca",
      "Bhatambrekar, Sachin",
      "Bittner, Paul Maximilian",
      "Boletsis, Costas",
      "Borum, Holger Stadel",
      "Bräeuer, Johannes",
      "Brown, Caroline",
      "Calinescu, Radu",
      "Carlson, Jan",
      "Chan, Kenneth H.",
      "Chechik, Marsha",
      "Cheng, Betty H.C.",
      "Chouki, Tibermacine",
      "Cicchetti, Antonio",
      "Ciccozzi, Federico",
      "Cofer, Darren",
      "Colantoni, Alessandro",
      "Combemale, Benoît",
      "Cooper, Justin",
      "Costa Seco, João",
      "Damasceno, Carlos Diego Nascimento",
      "David, Istvan",
      "De La Vega, Alfonso",
      "Dingel, Juergen",
      "Di Rocco, Juri",
      "Di Ruscio, Davide",
      "Di Sandro, Alessio",
      "Di Sipio, Claudio",
      "Dorofeev, Kirill",
      "Dumitrescu, Roman",
      "Ege, Florian",
      "Eisenberg, Martin",
      "Elyes, Cherfa",
      "Engels, Gregor",
      "Faridmoayer, Sogol",
      "Ferreira, Carla",
      "Fischbach, Jannik",
      "Fleck, Jonathon Emil",
      "Flegel, Oliver",
      "Galasso, Jessie",
      "Garcia-Ceja, Enrique",
      "Garmendia, Antonio",
      "Gerasimou, Simos",
      "Gorissen, Simon",
      "Greenyer, Joel",
      "Gross-Amblard, David",
      "Grunske, Lars",
      "Hackman, Robert",
      "Halvorsrud, Ragnhild",
      "Harbin, James",
      "Hardin, David",
      "Hernández López, José Antonio",
      "Hoyos Rodriguez, Horacio",
      "Jaskolka, Monika",
      "Jézéquel, Jean-Marc",
      "Jongeling, Robbert",
      "Kehrer, Timo",
      "Klein, Martin",
      "Kolovos, Dimitris",
      "Lago, Patricia",
      "Langford, Michael Austin",
      "Lawford, Mark",
      "Lofberg, Anders",
      "Lourenço, Hugo"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a343/349500a343.pdf"
  },
  {
    "title": "A GNN-based Recommender System to Assist the Speciﬁcation of Metamodels and Models",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Nowadays, while modeling environments provide users with facilities to specify different kinds of artifacts, e.g., metamodels, models, and transformations, the possibility of learning from previous modeling experiences and being assisted during modeling tasks remains largely unexplored. In this paper, we propose MORGAN, a recommender system based on a graph neural network (GNN) to assist modelers in performing the speciﬁcation of metamodels and models. The (meta)model being speciﬁed, and the training data are encoded in a graph-based format by exploiting natural language processing (NLP) techniques. Afterward, a graph kernel function uses the extracted graphs to provide modelers with relevant recommendations to complete the partially speciﬁed (meta)models. We evaluated MORGAN on real-world datasets using various quality metrics, i.e., precision, recall, and F-measure. The experimental results are encouraging and demonstrate the feasibility of our tool to support modelers while specifying metamodels and models.",
    "keywords": [],
    "authors": [
      "Juri Di Rocco",
      "Claudio Di Sipio",
      "Davide Di Ruscio",
      "Phuong T. Nguyen"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a070/349500a070.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z023/349500z023.pdf"
  },
  {
    "title": "Identifying manual changes to generated code: Experiences from the industrial automation domain",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "In this paper, we report on a case study in an industrial setting where code is generated from models, and, for various reasons, that generated code is then manually modified. To enhance the maintainability of both models and code, consistency between them is imperative. A first step towards establishing that consistency is to identify the manual changes that were made to the code after it was generated and deployed. Identifying the delta is not straightforward and requires pre-processing of the artifacts. The main mechanics driving our solution are higher-order transformations, which make the implementation scalable and robust to small changes in the modeling language. We describe the specific industrial setting of the problem, as well as the experiences and lessons learned from developing, implementing, and validating our solution together with our industrial partner.",
    "keywords": [
      "Model-based development",
      "round-trip engineering",
      "higher-order transformations",
      "domain-specific modeling languages",
      "industrial case study"
    ],
    "authors": [
      "Robbert Jongeling",
      "Sachin Bhatambrekar",
      "Anders Lofberg",
      "Antonio Cicchetti",
      "Federico Ciccozzi",
      "Jan Carlson"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a035/349500a035.pdf"
  },
  {
    "title": "Model-Based Development of Engine Control Systems: Experiences and Lessons Learnt",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Rolls-Royce Control Systems supplies engine control and monitoring systems for aviation applications, and is required to design, certify, and deliver these to the highest level of safety assurance. To allow Rolls-Royce to develop safe and robust systems, which continue to increase in complexity, model-based techniques are now a critical part of the software development process. In this paper, we discuss the experiences, challenges and lessons learnt when developing a bespoke domain-speciﬁc modelling workbench based on open-source modelling technologies including the Eclipse Modelling Framework (EMF), Xtext, Sirius and Epsilon. This modelling workbench will be used to architect and integrate the software for all future Rolls-Royce engine control and monitoring systems.",
    "keywords": [
      "Domain Speciﬁc Language",
      "Component Oriented Architecture",
      "Graphical Modelling Workbench",
      "Xtext",
      "Sirius",
      "EMF"
    ],
    "authors": [
      "Justin Cooper",
      "Alfonso de la Vega",
      "Richard Paige",
      "Dimitris Kolovos",
      "Michael Bennett",
      "Caroline Brown",
      "Beatriz Sanchez Pi˜na",
      "Horacio Hoyos Rodriguez"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a308/349500a308.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z004/349500z004.pdf"
  },
  {
    "title": "Collaborative Model-Driven Software Engineering: A Systematic Update",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "Current software engineering practices rely on highly heterogeneous and distributed teams working in a collaborative setting. Between 2013–2020, the publication output in the ﬁeld of collaborative Model-Driven Software Engineering (MDSE) has signiﬁcantly increased. However, the only systematic mapping study available is limited to studies published until 2015. In this paper, we provide an update on that study for the complementing 2016–2020 period, and report the latest results, challenges, and trends. Our analysis led to selecting 29 clusters of 54 new peer-reviewed publications on collaborative MDSE. Based on the novel developments in the ﬁeld, we have extended and improved the original classiﬁcation framework, making it applicable to recent and future research contributions on collaborative MDSE. The insights in this paper relate to the changing trends in the ﬁeld and present new relevant information.",
    "keywords": [
      "Model-driven engineering",
      "collaborative modeling",
      "systematic mapping study",
      "systematic update"
    ],
    "authors": [
      "Istvan David",
      "Kousar Aslam",
      "Sogol Faridmoayer",
      "Ivano Malavolta",
      "Eugene Syriani",
      "Patricia Lago"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a273/349500a273.pdf"
  },
  {
    "title": "24th International Conference on Model-Driven Engineering Languages and Systems",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z001/349500z001.pdf"
  },
  {
    "title": "Automated Patch Generation for Fixing Semantic Errors in ATL Transformation Rules",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "With the growing popularity of the MDE paradigm, model transformations are becoming more and more complex. ATL transformations, in particular, are error-prone due to the declarative nature of the language and the dependency towards the involved metamodels. To alleviate the burden of developers, we propose, in this paper, an approach for ﬁxing semantic errors in ATL transformation rules without predeﬁned patch templates for speciﬁc error types. In a ﬁrst step, our approach determines the rules that are likely to contain errors starting from the discrepancy between the expected and produced outputs of test cases. Then, a second step allows to generate candidate patches for these errors using a multiobjective optimization algorithm, guided by the same test cases. In a preliminary evaluation, we show that our approach can ﬁx most of the errors for transformations with one or two errors. For those with multiple errors, more iterations are necessary to ﬁx some of the errors.",
    "keywords": [
      "Model transformation",
      "Program repair",
      "Multi-objective optimization"
    ],
    "authors": [
      "Zahra VaraminyBahnemiry",
      "Jessie Galasso",
      "Khalid Belharbi",
      "Houari Sahraoui"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a013/349500a013.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Silvia Abrahão",
      "Joanne M. Atlee",
      "Nelly Bencomo",
      "Jordi Cabot",
      "Betty H.C. Cheng",
      "Benoit Combemale",
      "Davide Di Ruscio",
      "Gregor Engels",
      "Martin Gogolla",
      "Jörg Kienzle",
      "Ana Moreira",
      "Richard Paige",
      "Eugene Syriani",
      "Gabriele Taentzer",
      "Manuel Wimmer",
      "Juan de Lara"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z020/349500z020.pdf"
  },
  {
    "title": "DataTime: a Framework to smoothly Integrate Past, Present and Future into Models",
    "submission-date": "2021/09",
    "publication-date": "2021/09",
    "abstract": "Models at runtime have been initially investigated for adaptive systems. Models are used as a reﬂective layer of the current state of the system to support the implementation of a feedback loop. More recently, models at runtime have also been identiﬁed as key for supporting the development of full-ﬂedged digital twins. However, this use of models at runtime raises new challenges, such as the ability to seamlessly interact with the past, present and future states of the system. In this paper, we propose a framework called DataTime to implement models at runtime which capture the state of the system according to the dimensions of both time and space, here modeled as a directed graph where both nodes and edges bear local states (ie. values of properties of interest). DataTime provides a unifying interface to query the past, present and future (predicted) states of the system. This unifying interface provides i) an optimized structure of the time series that capture the past states of the system, possibly evolving over time, ii) the ability to get the last available value provided by the system’s sensors, and iii) a continuous micro-learning over graph edges of a predictive model to make it possible to query future states, either locally or more globally, thanks to a composition law. The framework has been developed and evaluated in the context of the Intelligent Public Transportation Systems of the city of Rennes (France). This experimentation has demonstrated how DataTime can deprecate the use of heterogeneous tools for managing data from the past, the present and the future, and facilitate the development of digital twins.",
    "keywords": [],
    "authors": [
      "Gauthier LYAN",
      "Jean-Marc J´EZ´EQUEL",
      "David GROSS-AMBLARD",
      "Benoˆıt COMBEMALE"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a134/349500a134.pdf"
  },
  {
    "title": "24th International Conference on Model-Driven Engineering Languages and Systems",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Zhenjiang Hu",
      "Tomoji Kishi",
      "Naoyasu Ubayashi",
      "Daniel Varro",
      "Shiva Nejati"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z003/349500z003.pdf"
  },
  {
    "title": "Designing a Modeling Language for Customer Journeys: Lessons Learned from User Involvement",
    "submission-date": "2021/09",
    "publication-date": "2021/09",
    "abstract": "Although numerous methods have been formalized for handling the technical aspects of developing domain-speciﬁc modeling languages (DSMLs), user needs and usability aspects are often addressed in ad hoc manners and late in the development process. Working in this context, this paper presents the development of the customer journey modeling language (CJML), a DSML for modeling service processes from the end-user’s perspective. CJML targets a wide and heterogeneous group of users, making it especially challenging regarding usability. This paper describes how an industry-relevant DSML was systematically improved by using a variety of user-centered design techniques in close collaboration with the target group and how their feedback was used to reﬁne and evolve the syntax and semantics of CJML. We also suggest how a service-providing organization may beneﬁt from adopting CJML as a unifying language for documentation purposes, compliance analysis, and service innovation. Finally, we generalize the experience gained into lessons learned and methodological guidelines.",
    "keywords": [
      "DSML",
      "customer journey",
      "user involvement",
      "user-centered design"
    ],
    "authors": [
      "Ragnhild Halvorsrud",
      "Costas Boletsis",
      "Enrique Garcia-Ceja"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a239/349500a239.pdf"
  },
  {
    "title": "Collaborative Software Modeling in Virtual Reality",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Modeling is a key activity in conceptual design and system design. Through collaborative modeling, end-users, stakeholders, experts, and entrepreneurs are able to create a shared understanding of a system representation. While the Uni-fied Modeling Language (UML) is one of the major conceptual modeling languages in object-oriented software engineering, more and more concerns arise from the modeling quality of UML and its tool-support. Among them, the limitation of the two-dimensional presentation of its notations and lack of natural collaborative modeling tools are reported to be signiﬁcant. In this paper, we explore the potential of using Virtual Reality (VR) technology for collaborative UML software design by comparing it with classical collaborative software design using conventional devices (Desktop PC / Laptop). For this purpose, we have developed a VR modeling environment that offers a natural collaborative modeling experience for UML Class Diagrams. Based on a user study with 24 participants, we have compared collaborative VR modeling with conventional modeling with regard to efﬁciency, effectiveness, and user satisfaction. Results show that the use of VR has some disadvantages concerning efﬁciency and effectiveness, but the user’s fun, the feeling of being in the same room with a remote collaborator, and the naturalness of collaboration were increased.",
    "keywords": [
      "Collaborative Modeling",
      "Virtual Reality",
      "UML"
    ],
    "authors": [
      "Enes Yigitbas",
      "Simon Gorissen",
      "Nils Weidmann",
      "Gregor Engels"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a261/349500a261.pdf"
  },
  {
    "title": "Towards the Characterization of Realistic Model Generators using Graph Neural Networks",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "The automatic generation of software models is an important element in many software and systems engineering scenarios such as software tool certiﬁcation, validation of cyber-physical systems, or benchmarking graph databases. Several model generators are nowadays available, but the topic of whether they generate realistic models has been little studied. The state-of-the-art approach to check the realistic property in software models is to rely on simple comparisons using graph metrics and statistics. This generates a bottleneck due to the compression of all the information contained in the model into a small set of metrics. Furthermore, there is a lack of interpretation in these approaches since there are no hints of why the generated models are not realistic. Therefore, in this paper, we tackle the problem of assessing how realistic a generator is by mapping it to a classiﬁcation problem in which a Graph Neural Network (GNN) will be trained to distinguish between the two sets of models (real and synthetic ones). Then, to assess how realistic a generator is we perform the Classiﬁer Two-Sample Test (C2ST). Our approach allows for interpretation of the results by inspecting the attention layer of the GNN. We use our approach to assess four state-of-the-art model generators applied to three different domains. The results show that none of the generators can be considered realistic.",
    "keywords": [
      "Model generators",
      "Realistic models",
      "Graph neural networks",
      "Two-Sample Test"
    ],
    "authors": [
      "Jos´e Antonio Hern´andez L´opez",
      "Jes´us S´anchez Cuadrado"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a058/349500a058.pdf"
  },
  {
    "title": "On Designing Applied DSLs for Non-programming Experts in Evolving Domains",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Domain-speciﬁc languages (DSLs) have emerged as a plausible way for non-programming experts to efﬁciently express their domain knowledge. Recent DSL research has taken a technical perspective on how and why to create DSLs, resulting in a wealth of innovative tools, frameworks and technical approaches. Less attention has been paid to the design process. Namely, how can it ensure that the created DSL realises the expected beneﬁts? This paper seeks to answer this question when designing DSLs for highly specialised domains subject to resource constraints, an evolving application domain, and scarce user participation. We propose an iteration of alternating activities in a human-centred design method that seeks to minimise the need for expensive implementation and user involvement. The method moves from a low-validity exploration of highly diverse language designs towards a higher-validity exploration of more homogeneous designs. We give an in-depth case study of designing an actuarial DSL called MAL, or Management Action Language, which allows actuaries to model so-called future management actions in asset/liability projections in life insurance and pension companies. The proposed human-centred design method was synthesised from this case study, where we found it useful for iteratively identifying and removing usability problems during the design.",
    "keywords": [
      "Model-driven engineering",
      "Domain-speciﬁc language",
      "Human-centred design"
    ],
    "authors": [
      "Holger Stadel Borum",
      "Henning Niss",
      "Peter Sestoft"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a227/349500a227.pdf"
  },
  {
    "title": "Repository Mining for Changes in Simulink Models",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Model-Based Development (MBD) is widely used for\nembedded controls development, with MATLAB/Simulink being\none of the most used environments in the automotive industry.\nSimulink models are the primary design artifact and as with all\nsoftware, must be constantly maintained and evolved over their\nlifetime. It is necessary to develop models that support likely\nchanges in order to assist with evolution/maintenance processes.\nIn order to do so, the types of frequently performed changes\nmust be understood and appropriate language mechanisms must\nbe available to support these changes. However, Simulink model\nchanges are currently not well understood. We analyze a real\nindustrial software repository of our industrial partner and its\nversion control system to provide insights into the likely changes\nfor Simulink. The intent with this analysis includes providing\nguidance on how Simulink is used in industrial practice and\nhow particular model changes can impact system evolution.",
    "keywords": [
      "Simulink",
      "model-based development",
      "model change",
      "repository mining",
      "software evolution",
      "version control system"
    ],
    "authors": [
      "Monika Jaskolka",
      "Vera Pantelic",
      "Alan Wassyng",
      "Mark Lawford",
      "Richard Paige"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a046/349500a046.pdf"
  },
  {
    "title": "A Lean Approach to Building Valid Model-Based Safety Arguments",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "In recent decades, cyber-physical systems developed using Model-Driven Engineering (MDE) techniques have become ubiquitous in safety-critical domains. Safety assurance cases (ACs) are structured arguments designed to comprehensively show that such systems are safe; however, the reasoning steps, or strategies, used in AC arguments are often informal and difficult to rigorously evaluate. Consequently, AC arguments are prone to fallacies, and unsafe systems have been deployed as a result of fallacious ACs. To mitigate this problem, prior work [32] created a set of provably valid AC strategy templates to guide developers in building rigorous ACs. Yet instantiations of these templates remain error-prone and still need to be reviewed manually. In this paper, we report on using the interactive theorem prover Lean to bridge the gap between safety arguments and rigorous model-based reasoning. We generate formal, model-based machine-checked AC arguments, taking advantage of the traceability between model and safety artifacts, and mitigating errors that could arise from manual argument assessment. The approach is implemented in an extended version of the MMINT-A model management tool [10]. Implementation includes a conversion of informal claims into formal Lean properties, decomposition into formal sub-properties and generation of correctness proofs. We demonstrate the applicability of the approach on two safety case studies from the literature.",
    "keywords": [],
    "authors": [
      "Torin Viger",
      "Logan Murphy",
      "Alessio Di Sandro",
      "Ramy Shahin",
      "Marsha Chechik"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a194/349500a194.pdf"
  },
  {
    "title": "Restricted Natural Language and Model-based Adaptive Test Generation for Autonomous Driving",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "With the aim to reduce car accidents, autonomous driving attracted a lot of attentions these years. However, recently reported crashes indicate that this goal is far from being achieved. Hence, cost-effective testing of autonomous driving systems (ADSs) has become a prominent research topic. The classical model-based testing (MBT), i.e., generating test cases from test models followed by executing the test cases, is ineffective for testing ADSs, mainly because of the constant exposure to ever-changing operating environments, and uncertain internal behaviors due to employed AI techniques. Thus, MBT must be adaptive to guide test case generation based on test execution results in a step-wise manner. To this end, we propose a natural language and model-based approach, named LiveTCM, to automatically execute and generate test case speciﬁcations (TCSs) by interacting with an ADS under test and its environment. LiveTCM is evaluated with an open-source ADS and two test generation strategies: Deep Q-Network (DQN)-based and Random. Results show that LiveTCM with DQN can generate TCSs with 56 steps on average in 60 seconds, leading to 6.4 test oracle violations and covering 14 APIs per TCS on average.",
    "keywords": [
      "Natural Language and Model-based Testing",
      "Adaptive Test Generation",
      "Autonomous Driving"
    ],
    "authors": [
      "Yize Shi",
      "Chengjie Lu",
      "Man Zhang",
      "Huihui Zhang",
      "Tao Yue",
      "Shaukat Ali"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a101/349500a101.pdf"
  },
  {
    "title": "OSTRICH - A Type-safe Template Language for Low-code Development",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Low-code platforms aim at allowing non-experts to develop complex systems and knowledgeable developers to improve their productivity in orders of magnitude. The greater gain comes from (re)using components developed by experts capturing common patterns across all layers of the application, from the user interface to the data layer and integration with external systems. Often, cloning sample code fragments is the only alternative in such scenarios, requiring extensive adaptation to reach the intended use. Such customization activities require deep knowledge outside of the comfort zone of low-code. To effectively speed up the reuse, composition, and adaptation of pre-deﬁned components, low-code platforms need to provide safe and easy-to-use language mechanisms.\nThis paper introduces OSTRICH, a strongly-typed rich tem-plating language for a low-code platform (OutSystems) that builds on metamodel annotations and allows the correct in-stantiation of templates. We conservatively extend the existing metamodel and ensure that the resulting code is always well-formed. The results we present include a novel type safety veriﬁ-cation of template deﬁnitions, and template arguments, providing model consistency across application layers. We implemented this template language in a prototype of the OutSystems platform and ported nine of the top ten most used sample code fragments, thus improving the reuse of professionally designed components.",
    "keywords": [
      "metamodel templating",
      "typechecking templates",
      "low-code",
      "development productivity",
      "model reuse"
    ],
    "authors": [
      "Hugo Lourenço",
      "Carla Ferreira",
      "João Costa Seco"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a216/349500a216.pdf"
  },
  {
    "title": "Scalable N-Way Model Matching using Multi-dimensional Search Trees",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Alexander Schultheiß",
      "Paul Maximilian Bittner",
      "Lars Grunske",
      "Thomas Thüm",
      "and Timo Kehrer"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z005/349500z005.pdf"
  },
  {
    "title": "Identifying Metamodel Inaccurate Structures During Metamodel/Constraint Co-Evolution",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "Metamodels are subject to evolution over their lifetime. UML metamodel for instance evolved through different versions, ranging from 0.8 to 2.5 minors. These metamodels are sometimes accompanied with constraints deﬁned using OCL (Object Constraint Language). Many works in the literature developed methods for managing and assisting the co-evolution of metamodels and their constraints. These methods enable a developer to update, in an automated (or semi-automated) way, the constraints associated to a metamodel starting from the deltas identiﬁed between versions of this metamodel. In this work we complement this assistance by notifying the developer with potential inaccurate structures in the metamodel that may be introduced during evolution. We introduce in this paper an original evolution assistance method which focuses rather on the problem (notifying metamodel inaccurate structures) than on the solution (generating OCL constraints using patterns of them). The ultimate goal of this assistance is not only to enable the developer to complete existing/updated constraints with new ones, but also to accompany her/him to further check existing constraints and to test whether they still hold. A case study is presented to show the relevance of the method.",
    "keywords": [
      "Model-driven Engineering",
      "Metamodelling",
      "OCL",
      "Co-Evolution"
    ],
    "authors": [
      "Elyes Cherfa",
      "Soraya Mesli-Kesraoui",
      "Chouki Tibermacine",
      "Salah Sadou",
      "R´egis Fleurquin"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a024/349500a024.pdf"
  },
  {
    "title": "Quality Guidelines for Research Artifacts in Model-Driven Engineering",
    "submission-date": "2021/00",
    "publication-date": "2021/00",
    "abstract": "Sharing research artifacts is known to help people to build upon existing knowledge, adopt novel contributions in practice, and increase the chances of papers receiving attention. In Model-Driven Engineering (MDE), openly providing research artifacts plays a key role, even more so as the community targets a broader use of AI techniques, which can only become feasible if large open datasets and conﬁdence measures for their quality are available. However, the current lack of common discipline-speciﬁc guidelines for research data sharing opens the opportunity for misunderstandings about the true potential of research artifacts and subjective expectations regarding artifact quality. To address this issue, we introduce a set of guidelines for artifact sharing specifically tailored to MDE research. To design this guidelines set, we systematically analyzed general-purpose artifact sharing practices of major computer science venues and tailored them to the MDE domain. Subsequently, we conducted an online survey with 90 researchers and practitioners with expertise in MDE. We investigated our participants’ experiences in developing and sharing artifacts in MDE research and the challenges encountered while doing so. We then asked them to prioritize each of our guidelines as essential, desirable, or unnecessary. Finally, we asked them to evaluate our guidelines with respect to clarity, completeness, and relevance. In each of these dimensions, our guidelines were assessed positively by more than 92% of the participants. To foster the reproducibility and reusability of our results, we make the full set of generated artifacts available in an open repository at https://mdeartifacts.github.io/",
    "keywords": [
      "Software artifacts",
      "Open Science",
      "Model-Driven Engineering",
      "Quality Management"
    ],
    "authors": [
      "Carlos Diego Nascimento Damasceno and Daniel Str¨uber"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a285/349500a285.pdf"
  },
  {
    "title": "Scalable N-Way Model Matching Using Multi-Dimensional Search Trees",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Model matching algorithms are used to identify common elements in input models, which is a fundamental pre-condition for many software engineering tasks, such as merging software variants or views. If there are multiple input models, an n-way matching algorithm that simultaneously processes all models typically produces better results than the sequential application of two-way matching algorithms. However, existing algorithms for n-way matching do not scale well, as the computational effort grows fast in the number of models and their size. We propose a scalable n-way model matching algorithm, which uses multi-dimensional search trees for efficiently finding suitable match candidates through range queries. We implemented our generic algorithm named RaQuN (Range Queries on N input models) in Java, and empirically evaluate the matching quality and runtime performance on several datasets of different origin and model type. Compared to the state-of-the-art, our experimental results show a performance improvement by an order of magnitude, while delivering matching results of better quality.",
    "keywords": [
      "Model-driven engineering",
      "n-way model matching",
      "clone-and-own development",
      "software product lines",
      "multi-view integration",
      "variability mining."
    ],
    "authors": [
      "Alexander Schultheiß",
      "Paul Maximilian Bittner",
      "Lars Grunske",
      "Thomas Thüm and Timo Kehrer"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a001/349500a001.pdf"
  },
  {
    "title": "Towards Control Flow Analysis of Declarative Graph Transformations with Symbolic Execution",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "The declarative graph transformation language Henshin transforms instance models represented as graphs by applying a series of basic steps that match and replace structural patterns on parts of models. These simple transformation rules are then combined into control ﬂow constructs similar to those of imperative programming languages to create more complex transformations. However, defects in the structure of control ﬂow or in transformation rules might misschedule the application of operations, resulting in basic steps to be inapplicable or produce incorrect output. Understanding and ﬁxing these bugs is complicated by the fact that pattern matching in rules is non-deterministic. Moreover, some control ﬂow structures employ a nondeterministic choice of alternatives. This makes it challenging for developers to keep track of all the possible execution paths and interactions between them.\nFor conventional programming languages, techniques have been developed to execute a program symbolically. By abstracting over the concrete values of variables in any actual run, generalized knowledge is gained about the possible behavior of the program. This can be useful in understanding problems and fixing bugs. In this paper, we present an approach to symbolically execute graph transformations for a subset of Henshin, using symbolic path constraints based on the cardinalities of graph pattern occurrences in the model.",
    "keywords": [
      "model driven software engineering",
      "declarative graph transformations",
      "control ﬂow analysis",
      "symbolic execution"
    ],
    "authors": [
      "Florian Ege",
      "Matthias Tichy"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a156/349500a156.pdf"
  },
  {
    "title": "Efﬁcient Replay-based Regression Testing for Distributed Reactive Systems in the Context of Model-driven Development",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "As software evolves, regression testing techniques are typically used to ensure the new changes are not adversely affecting the existing features. Despite recent advances, regression testing for distributed systems remains challenging and extremely costly. Existing techniques often require running a failing system several time before detecting a regression. As a result, conven-tional approaches that use re-execution without considering the inherent non-determinism of distributed systems, and providing no (or low) control over execution are inadequate in many ways. In this paper, we present MRegTest, a replay-based regression testing framework in the context of model-driven development to facilitate deterministic replay of traces for detecting regressions while offering sufﬁcient control for the purpose of testing over the execution of the changed system. The experimental results show that compared to the traditional approaches that annotate traces with timestamps and variable values MRegTest detects almost all regressions while reducing the size of the trace signiﬁcantly and incurring similar runtime overhead.",
    "keywords": [
      "MDD",
      "Distributed Systems",
      "Regression Testing"
    ],
    "authors": [
      "Majid Babaei",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a089/349500a089.pdf"
  },
  {
    "title": "Integrated and Iterative Requirements Analysis and Test Speciﬁcation: A Case Study at Kostal",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Currently, practitioners follow a top-down approach in automotive development projects. However, recent studies have shown that this top-down approach is not suitable for the implementation and testing of modern automotive systems. Specifically, practitioners increasingly fail to specify requirements and tests for systems with complex component interactions (e.g., e-mobility systems). In this paper, we address this research gap and propose an integrated and iterative scenario-based technique for the speciﬁcation of requirements and test scenarios. Our idea is to combine both a top-down and a bottom-up integration strategy. For the top-down approach, we use a behavior-driven development (BDD) technique to drive the modeling of high-level system interactions from the user’s perspective. For the bottom-up approach, we discovered that natural language processing (NLP) techniques are suited to make textual speciﬁcations of existing components accessible to our technique. To integrate both directions, we support the joint execution and automated analysis of system-level interactions and component-level behavior. We demonstrate the feasibility of our approach by conducting a case study at Kostal (Tier1 supplier). The case study corroborates, among other things, that our approach supports practitioners in improving requirements and test speciﬁcations for integrated system behavior.",
    "keywords": [
      "Requirements Analysis",
      "Test Speciﬁcation",
      "Natural Language Processing",
      "Scenario-based Requirements Engineering",
      "Model-based Testing",
      "Scenario-based Testing"
    ],
    "authors": [
      "Carsten Wiecher",
      "Jannik Fischbach",
      "Joel Greenyer",
      "Andreas Vogelsang",
      "Carsten Wolff",
      "Roman Dumitrescu"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a112/349500a112.pdf"
  },
  {
    "title": "Exploring Architectural Design Decisions in Industry 4.0: A Literature Review and Taxonomy",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Architectural design decisions, such as service de-\nployment and composition, plant layout synthesis, or production\nplanning, are an indispensable and overarching part of an\nindustrial manufacturing system design. In the fourth industrial\nrevolution (Industry 4.0), frequent production changes trigger\ntheir synthesis, and preferably optimization. Yet, knowledge\non architecture synthesis and optimization has been scattered\naround other domains, such as generic software engineering.\nWe take a step towards synthesizing current knowledge on\narchitectural design decisions in Industry 4.0. We developed a\ntaxonomy describing architectural models, design decisions, and\noptimization possibilities. The developed taxonomy serves as a\nguideline for comparing different possibilities (e.g., application\nof different optimization algorithms) and selecting appropriate\nones for a given context. Furthermore, we reviewed and mapped\n30 relevant research works to the taxonomy, identifying research\ntrends and gaps. We discuss interesting, and yet uncovered topics\nthat emerged from our review.",
    "keywords": [
      "architecture synthesis",
      "optimization",
      "taxonomy",
      "design space exploration",
      "model-based development",
      "Industry 4.0"
    ],
    "authors": [
      "Tarik Terzimehi´c",
      "Kirill Dorofeev",
      "Sebastian Voss"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a170/349500a170.pdf"
  },
  {
    "title": "Synthesizing Veriﬁed Components for Cyber Assured Systems Engineering",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Cyber-physical systems, such as avionics, must be tolerant to cyber-attacks in the same way they are tolerant to random faults: they either gracefully recover or safely shut down as requirements dictate. The DARPA Cyber Assured Systems Engineering program is developing tools for design, analysis, and veriﬁcation that enable systems engineers to design-in cyber-resiliency in a Model-Based Systems Engineering environment. This paper describes automated model transformations that introduce high-assurance cyber-resiliency components into a system, in particular ﬁlters and monitors that prevent malicious input and detect supply chain attacks, respectively. A formal speciﬁcation deﬁnes each high-assurance component, and is used to verify that the component addresses system level cyber requirements. Implementations for these high-assurance components are directly synthesized from their speciﬁcations, and are automatically proven to preserve the exact meaning of the speciﬁcations all the way down to the binary code level. The model transformations are integrated into the Open Source AADL Tool Environment (OSATE). The paper further reports on a case study applying security-enhancing model transformations to a UAV system that uses the Air Force Research Laboratory’s OpenUxAS services for route planning. In the case study, the model transformations add ﬁlters to guard against malformed input, as well as monitors to guard against ground station spooﬁng and malicious ﬂight plans from OpenUxAS.",
    "keywords": [],
    "authors": [
      "Eric Mercer",
      "Konrad Slind",
      "Isaac Amundson",
      "Darren Cofer",
      "Junaid Babar",
      "David Hardin"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a205/349500a205.pdf"
  },
  {
    "title": "Assessing the Usefulness of a Visual Programming IDE for Large-Scale Automation Software",
    "submission-date": "2021/10",
    "publication-date": "2021/10",
    "abstract": "Industrial control applications are usually designed by domain experts instead of software engineers. These experts frequently use visual programming languages based on standards such as IEC 61131-3 and IEC 61499. The standards apply model-based engineering concepts to abstract from hardware and low-level communication. Developing industrial control software is challenging due the fact that such systems are usually one-of-a-kind systems that have to be maintained for many years. These challenges, together with the growing complexity of control software, require very usable model-based development environments for visual programming languages. However, so far only little empirical research exists on the practical usefulness of such environments, i.e., their usability and utility. In this paper, we discuss common control software maintenance tasks and tool capabilities based on existing research and show the realization of these capabilities in 4diac IDE. We ﬁrst performed a walkthrough of the demonstrated capabilities using the cognitive dimensions of notations framework from the ﬁeld of human-computer interaction. We then improved the tool and conducted a user study involving ten industrial automation engineers, who used 4diac IDE in a realistic control software maintenance scenario. Our ﬁndings demonstrate how the usefulness of IDEs can be successfully investigated using a multi-phase approach that includes a walkthrough and a user study. We discuss lessons learned and derive general implications with respect to large-scale applications for developers of IDEs that we deem applicable in the context of (visual) model-based engineering tools.",
    "keywords": [
      "Usefulness study",
      "Open source software",
      "IEC 61499",
      "Modeling tools",
      "Model-driven engineering"
    ],
    "authors": [
      "Bianca Wiesmayr",
      "Alois Zoitl",
      "Rick Rabiser"
    ],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500a297/349500a297.pdf"
  },
  {
    "title": "Preface to the 24th International ACM/IEEE Conference on Model Driven Engineering Languages and Systems (MoDELS)",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "This paper is a preface to the 24th International ACM/IEEE Conference on Model Driven Engineering Languages and Systems (MoDELS). It describes the conference, its history, the challenges faced due to the COVID-19 pandemic, and the organization of the conference, including the review process and acceptance rates for the Foundations and Practice & Innovation tracks.",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models21/MODELS2021-vcEQLsxHBZ4L3NxxjGCoP/349500z010/349500z010.pdf"
  },
  {
    "title": "MoDLF – A Model-Driven Deep Learning Framework for Autonomous Vehicle Perception (AVP)",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Modern vehicles are extremely complex embedded systems that integrate software and hardware from a large set of contributors. Modeling standards like EAST-ADL have shown promising results to reduce complexity and expedite system development. However, such standards are unable to cope with the growing demands of the automotive industry. A typical example of this phenomenon is autonomous vehicle perception (AVP) where deep learning architectures (DLA) are required for computer vision (CV) tasks like real-time object recognition and detection. However, existing modeling standards in the automotive industry are unable to manage such CV tasks at a higher abstraction level. Consequently, system development is currently accomplished through modeling approaches like EAST-ADL while DLA-based CV features for AVP are implemented in isolation at a lower abstraction level. This significantly compromises productivity due to integration challenges. In this article, we introduce MoDLF - A Model-Driven Deep learning Framework to design deep convolutional neural network (DCNN) architectures for AVP tasks. Particularly, Model Driven Architecture (MDA) is leveraged to propose a metamodel along with a conformant graphical modeling workbench to model DCNNs for CV tasks in AVP at a higher abstraction level. Furthermore, Model-To-Text (M2T) transformations are provided to generate executable code for MATLAB® and Python. The framework is validated via two case studies on benchmark datasets for key AVP tasks. The results prove that MoDLF effectively enables model-driven architectural exploration of deep convnets for AVP system development while supporting integration with renowned existing standards like EAST-ADL.",
    "keywords": [
      "Model-Driven Architecture",
      "Model transformation",
      "Low code",
      "Autonomous vehicles perception",
      "Deep learning",
      "Computer vision"
    ],
    "authors": [
      "Aon Safdar",
      "Farooque Azam",
      "Muhammad Waseem Anwar",
      "Usman Akram and Yawar Rasheed"
    ],
    "file_path": "data/models/models22/main/papers/p187-safdar.pdf"
  },
  {
    "title": "Incremental Causal Connection for Self-Adaptive Systems Based on Relational Reference Attribute Grammars",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Even though model-driven engineering reduces complexity during the development of self-adaptive systems and models@run.time enables using them during runtime, connecting models to different external systems still involves manual work. Those connections are essential to the complete system, as they enable external systems to react to changes in the internal model and vice versa. In our case, the model is based on Relational Reference Attribute Grammars, an extension of Attribute Grammars to enable conceptual models at runtime while retaining their benefits of modular specification and an incremental evaluation scheme. We present an approach to enable concise specification of the causal connection and needed transformations to match required formats or semantics. To show its applicability, a case study showing the coordination of multiple industrial robot arms using models is presented. We show that using our approach, connections can be specified more concisely while maintaining the same efficiency as hand-written code. The artefact comprising all source code and an executable version of the case studies is available at https://doi.org/10.5281/zenodo.7009758.",
    "keywords": [
      "Reference Attribute Grammar",
      "Cyber-physical System",
      "Causal Connection",
      "Models@run.time",
      "Model-Driven Software Engineering"
    ],
    "authors": [
      "René Schöne",
      "Johannes Mey",
      "Sebastian Ebert",
      "Sebastian Götz",
      "Uwe Aßmann"
    ],
    "file_path": "data/models/models22/main/papers/p1-schoene.pdf"
  },
  {
    "title": "Feedback on the Formal Verification of UML Models in an Industrial Context: The Case of a Smart Device Life Cycle Management System",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "This paper presents experience feedback on how we managed to formally verify properties on semi-formal models of a Life Cycle Management System (LCMS) for smart devices. These devices are typically structured around a System on Chip (SoC), which can provide built-in hardware security. They can offer the possibility to make the deployment of Product-Service Systems (PSSs) to consumers easier, through traceability and collaborative consumption rule enforcement. A PSS is a business model in which products and services are tightly connected. One of the main advantages of such a PSS is that it optimizes product use, with a positive environmental impact. Associating the LCMS with a blockchain-based protocol makes it possible to avoid centralization. Semi-formal UML models of such a LCMS, as well as the informal properties it must comply with, were defined in order to explore its design space and evaluate the outcomes of specific design choices. However, the security of the LCMS implementation must be guaranteed, including protocols and architecture. For that purpose, these models and properties were later improved to be formally verifiable, which ensures the security of their implementation at the expense of added complexity. The verification was carried out using two available software tools: VerifPal for the protocol model, and AnimUML (developed by one of the authors) for the architecture model. This makes the procedure accessible for non-specialists in formal verification. Finally, our feedback on the whole process as well as on VerifPal is also provided.",
    "keywords": [
      "Formally verifiable models",
      "Formal verification tools",
      "UML",
      "Cryptographic protocol",
      "Life cycle management system"
    ],
    "authors": [
      "Maxime Méré",
      "Frédéric Jouault",
      "Loïc Pallardy",
      "Richard Perdriau"
    ],
    "file_path": "data/models/models22/main/papers/p121-mere.pdf"
  },
  {
    "title": "Modelling Program Verification Tools for Software Engineers",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "In software engineering, models are used for many different things. In this paper, we focus on program verification, where we use models to reason about the correctness of systems. There are many different types of program verification techniques which provide different correctness guarantees. We investigate the domain of program verification tools, and present a concise megamodel to distinguish these tools. We also present a data set of almost 400 program verification tools. This data set includes the category of verification tool according to our megamodel, practical information such as input/output format, repository links, and more. The categorisation enables software engineers to find suitable tools, investigate similar alternatives and compare them. We also identify trends for each level in our megamodel based on the categorisation. Our data set, publicly available at https://doi.org/10.4121/20347950, can be used by software engineers to enter the world of program verification and find a verification tool based on their requirements.",
    "keywords": [
      "Formal Methods; Program Verification; Megamodelling."
    ],
    "authors": [
      "Sophie Lathouwers and Vadim Zaytsev"
    ],
    "file_path": "data/models/models22/main/papers/p98-lathouwers.pdf"
  },
  {
    "title": "Quantifying the Variability Mismatch Between Problem and Solution Space",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "A software product line allows to derive individual software products based on a configuration. As the number of configurations is an indicator for the general complexity of a software product line, automatic #SAT analyses have been proposed to provide this information. However, the number of configurations does not need to match the number of derivable products. Due to this mismatch, using the number of configurations to reason about the software complexity (i.e., the number of derivable products) of a software product line can lead to wrong assumptions during implementation and testing. How to compute the actual number of derivable products, however, is unknown. In this paper, we mitigate this problem and present a concept to derive a solution-space feature model which allows to reuse existing #SAT analyses for computing the number of derivable products of a software product line. We apply our concept to a total of 119 subsystems of three industrial software product lines. The results show that the derivation scales for real world software product lines and confirm the mismatch between the number of configurations and the number of products.",
    "keywords": [
      "Product lines",
      "variability mismatch",
      "solution-space analyses"
    ],
    "authors": [
      "Marc Hentze",
      "Chico Sundermann",
      "Thomas Thüm",
      "Ina Schaefer"
    ],
    "file_path": "data/models/models22/main/papers/p322-hentze.pdf"
  },
  {
    "title": "Addressing the Uncertainty Interaction Problem in Software-intensive Systems: Challenges and Desiderata",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Software-intensive systems are increasingly used to support tasks that are typically characterized by high degrees of uncertainty. The modeling notations employed to design, verify, and operate such systems have increasingly started to capture different types of uncertainty, so that they can be explicitly considered when systems are developed and deployed. While these modeling paradigms consider different sources of uncertainty individually, these sources are rarely independent, and their interactions affect the achievement of system goals in subtle and often unpredictable ways. This vision paper describes the problem of uncertainty interaction in software-intensive systems, illustrating it on examples from relevant application domains. We then identify key open challenges and define desiderata that future modeling notations and model-driven engineering research should consider to address these challenges.",
    "keywords": [
      "Uncertainty interaction",
      "Modeling notations",
      "Patterns"
    ],
    "authors": [
      "Javier Cámara",
      "Radu Calinescu",
      "Betty H.C. Cheng",
      "David Garlan",
      "Bradley Schmerl",
      "Javier Troya",
      "Antonio Vallecillo"
    ],
    "file_path": "data/models/models22/main/papers/p24-camara.pdf"
  },
  {
    "title": "Machine Learning-based Incremental Learning in Interactive Domain Modelling",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "In domain modelling, practitioners manually transform informal requirements written in natural language (problem descriptions) to more concise and analyzable domain models expressed with class diagrams. With automated domain modelling support using existing approaches, manual modifications may still be required in extracted domain models and problem descriptions to make them more accurate and concise. For example, educators teaching software engineering courses at universities usually use an incremental approach to build modelling exercises to restrict students in using intended modelling patterns. These modifications result in the evolution of domain modelling exercises over time. To assist practitioners in this evolution, a synergy between interactive support and automated domain modelling is required. In this paper, we propose a bot-assisted approach to allow practitioners perform domain modelling quickly and interactively. Furthermore, we provide an incremental learning strategy empowered by machine learning to improve the accuracy of the bot’s suggestions and extracted domain models by analyzing practitioners’ decisions over time. We evaluate the performance of our bot using test problem descriptions which shows that practitioners can expect to get useful support from the bot when applied to exercises of similar size and complexity, with precision, recall, and F2 scores over 85%. Finally, we evaluate our incremental learning strategy where we observe a reduction in the required manual modifications by 70% and an improvement of F2 scores of extracted domain models by 4.2% when using our proposed approach and learning strategy together.",
    "keywords": [
      "Domain Models",
      "Natural Language Processing (NLP)",
      "Machine Learning (ML)",
      "Bot",
      "Evolution",
      "Decisions",
      "Incremental Learning"
    ],
    "authors": [
      "Rijul Saini",
      "Gunter Mussbacher",
      "Jin L.C. Guo",
      "Jörg Kienzle"
    ],
    "file_path": "data/models/models22/main/papers/p176-saini.pdf"
  },
  {
    "title": "Digital Twin as Risk-Free Experimentation Aid for Techno-socio-economic Systems",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Environmental uncertainties and hyperconnectivity force techno-socio-economic systems to introspect and adapt to succeed and survive. Current practices in decision-making are predominantly intuition-driven with attendant challenges for precision and rigor. We propose to use the concept of digital twins by combining results from Modelling & Simulation, Artificial Intelligence, and Control Theory to create a risk free ‘in silico’ experimentation aid to help: (i) understand why a system is the way it is, (ii) be prepared for possible outlier conditions, and (iii) identify plausible solutions for mitigating the outlier conditions in an evidence-backed manner. We use reinforcement learning to systematically explore the digital twin solution space. Our proposal is significant because it advances the effective use of digital twins to new problem domains that have new potential for impact. Our approach contributes an original meta model for simulatable digital twin of industry scale techno-socio-economic systems, agent-based implementation of the digital twin, and an architecture that serves as a risk-free experimentation aid to support simulation-based evidence-backed decision-making. We also discuss the rigor of our validation of the proposed approach and associated technology infrastructure through a representative sample of industry-scale real-world use cases.",
    "keywords": [
      "Digital Twin",
      "Decision Making",
      "Simulatable Model",
      "Agent Model"
    ],
    "authors": [
      "Souvik Barat",
      "Tony Clark",
      "Vinay Kulkarni",
      "Balbir Barn"
    ],
    "file_path": "data/models/models22/main/papers/p66-barat.pdf"
  },
  {
    "title": "Model-Checking Legal Contracts with SymboleoPC",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Legal contracts specify requirements for business transactions. As\nany other requirements specification, contracts may contain errors\nand violate properties expected by contracting parties. Symboleo\nwas recently proposed as a formal specification language for legal\ncontracts. This paper presents SymboleoPC, a tool for analyzing\nSymboleo contracts using model checking. It highlights the architec-\nture, implementation and testing of the tool, as well as a scalability\nevaluation with respect to the size of contracts and properties to\nbe checked through a series of experiments. The results suggest\nthat SymboleoPC can be usefully applied to the analysis of formal\nspecifications of contracts with real-life sizes and structures.",
    "keywords": [
      "Legal contracts",
      "smart contracts",
      "software requirements specifications",
      "formal specification languages",
      "model checking",
      "performance analysis",
      "nuXmv"
    ],
    "authors": [
      "Alireza Parvizimosaed",
      "Marco Roveri",
      "Aidin Rasti",
      "Daniel Amyot",
      "Luigi Logrippo",
      "John Mylopoulos"
    ],
    "file_path": "data/models/models22/main/papers/p278-parvizimosaed.pdf"
  },
  {
    "title": "Assisting in Requirements Goal Modeling: A Hybrid Approach based on Machine Learning and Logical Reasoning",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Goal modeling plays an imperative role in early requirements engineering, which has been investigated for decades. There have been many studies that show the usefulness of requirements goal models. However, the establishment of goal models is typically done manually, which is time-consuming and has a steep learning curve. In this paper, we propose a semi-automatic framework for constructing iStar models, which is a well-known goal modeling language. Specifically, we first investigate the practical needs of iStar modelers on the automation of iStar modeling by holding interviews, based on which we propose an interactive and iterative modeling process. Our proposal takes advantage of human decisions and artificial intelligence algorithms, respectively, aiming at achieving low modeling costs while maintaining the quality of models. We then propose a hybrid approach for automatically extracting goal model snippets from requirements text, which implements the automatic tasks of our proposed process. The proposed method combines logical reasoning with deep learning techniques so as to unleash the power of domain knowledge to assist with automation tasks. We have performed a series of experiments for evaluation. The experimental results show that our method achieves the F1-measure of 90.34% for actor entity extraction, 93.14% for intention entity extraction, and 83.18% for actor relation extraction, which can efficiently establish high-quality goal models. The artifacts are available at Zenodo1.",
    "keywords": [
      "goal modeling",
      "requirements engineering",
      "natural language processing",
      "machine learning"
    ],
    "authors": [
      "Qixiang Zhou",
      "Tong Li",
      "Yunduo Wang"
    ],
    "file_path": "data/models/models22/main/papers/p199-zhou.pdf"
  },
  {
    "title": "Automatic Test Amplification for Executable Models",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Behavioral models are important assets that must be thoroughly veri-\nfied early in the design process. This can be achieved with manually-\nwritten test cases that embed carefully hand-picked domain-specific\ninput data. However, such test cases may not always reach the de-\nsired level of quality, such as high coverage or being able to localize\nfaults efficiently. Test amplification is an interesting emergent ap-\nproach to improve a test suite by automatically generating new test\ncases out of existing manually-written ones. Yet, while ad-hoc test\namplification solutions have been proposed for a few programming\nlanguages, no solution currently exists for amplifying the test cases\nof behavioral models.\nIn this paper, we fill this gap with an automated and generic\napproach. Given an executable DSL, a conforming behavioral model,\nand an existing test suite, our approach generates new regression\ntest cases in three steps: (i) generating new test inputs by applying\na set of generic modifiers on the existing test inputs; (ii) running\nthe model under test with new inputs and generating assertions from\nthe execution traces; and (iii) selecting the new test cases that\nincrease the mutation score. We provide tool support for the approach\natop the Eclipse GEMOC Studio1 and show its applicability in an\nempirical study. In the experiment, we applied the approach to 71\ntest suites written for models conforming to two different DSLs, and\nfor 67 of the 71 cases, it successfully improved the mutation score\nbetween 3.17 % and 54.11 % depending on the initial setup.",
    "keywords": [
      "Test Amplification",
      "Regression Testing",
      "Executable Model",
      "Executable DSL"
    ],
    "authors": [
      "Faezeh Khorram",
      "Erwan Bousse",
      "Jean-Marie Mottu",
      "Gerson Sunyé",
      "Pablo Gómez-Abajo",
      "Pablo C. Cañizares",
      "Esther Guerra",
      "Juan de Lara"
    ],
    "file_path": "data/models/models22/main/papers/p109-khorram.pdf"
  },
  {
    "title": "Schema Inference for Multi-Model Data",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "The knowledge of a structural schema of data is a crucial aspect of most data management tasks. Unfortunately, in many real-world scenarios, the data is not accompanied by it, and schema-inference approaches need to be utilised.\nIn this paper, we focus on a specific and complex use case of multi-model data where several often contradictory features of the combined models must be considered. Hence, single-model approaches cannot be applied straightforwardly. In addition, the data often reach the scale of Big Data, and thus a scalable solution is inevitable. In our approach, we reflect all these challenges. In addition, we can also infer local integrity constraints as well as intra- and inter-model references. Last but not least, we can cope with cross-model data redundancy. Using a set of experiments, we prove the advantages of the proposed approach and we compare it with related work.",
    "keywords": [
      "schema inference",
      "multi-model data",
      "cross-model references",
      "data redundancy"
    ],
    "authors": [
      "Pavel Koupil",
      "Sebastián Hricko",
      "Irena Holubová"
    ],
    "file_path": "data/models/models22/main/papers/p13-koupli.pdf"
  },
  {
    "title": "Finding with NEMO: A Recommender System to Forecast the Next Modeling Operations",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Nowadays, while modeling environments provide users with facilities to specify different kinds of artifacts, e.g., metamodels, models, and transformations, the possibility of learning from previous modeling experiences and being assisted during modeling tasks remains largely unexplored. In this paper, we propose NEMO, a recommender system based on an Encoder-Decoder neural network to assist modelers in performing model editing operations. NEMO learns from past modeling activities and performs predictions employing a deep learning technique. Such an algorithm has been successfully applied in machine translation to convert a text from a language to another foreign language and vice versa. An empirical evaluation on a dataset of BPMN change-based persistent model demonstrates that the technique permits learning from existing operations and effectively predicting the next editing operations with considerably high prediction accuracy. In particular, NEMO gets 0.977 as precision/recall and 0.992 as success rate score by the best performance.",
    "keywords": [],
    "authors": [
      "Juri Di Rocco",
      "Claudio Di Sipio",
      "Phuong T. Nguyen",
      "Davide Di Ruscio",
      "Alfonso Pierantonio"
    ],
    "file_path": "data/models/models22/main/papers/p154-rocco.pdf"
  },
  {
    "title": "Survey of Established Practices in the Life Cycle of Domain-Specific Languages",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Domain-specific languages (DSLs) have demonstrated their usefulness within many domains such as finance, robotics, and telecommunication. This success has been exemplified by the publication of a wide range of articles regarding specific DSLs and their merits in terms of improved software quality, programmer efficiency, security, etc. However, there is little public information on what happens to these DSLs after they are developed and published. The lack of information makes it difficult for a DSL practitioner or tool creator to identify trends, current practices, and issues within the field. In this paper, we seek to establish the current state of a DSL’s life cycle by analysing 30 questionnaire answers from DSL authors on the design and development, launch, evolution, and end of life of their DSL. On this empirical foundation, we make six recommendations to DSL practitioners, scholars, and tool creators on the subjects of user involvement in the design process, DSL evolution, and the end of life of DSLs.",
    "keywords": [
      "Domain-specific languages",
      "Survey"
    ],
    "authors": [
      "Holger Stadel Borum",
      "Christoph Seidl"
    ],
    "file_path": "data/models/models22/main/papers/p266-borum.pdf"
  },
  {
    "title": "Nested OSTRICH: Hatching Compositions of Low-code Templates",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Low-code frameworks strive to simplify and speed-up application\ndevelopment. Native support for the reuse and composition of\nparameterised coarse-grain components (templates) is essential\nto achieve these goals. OSTRICH — a rich template language for\nthe OutSystems platform — was designed to simplify the use and\ncreation of such templates. However, without a built-in composition\nmechanism, OSTRICH templates are hard to create and maintain.\nThis paper presents a template composition mechanism and its\ntyping and instantiation algorithms for model-driven low-code de-\nvelopment environments. We evolve OSTRICH to support nested\ntemplates and allow the instantiation (hatching) of templates in\nthe definition of other templates. Thus, we observe a significant\nincrease code reuse potential, leading to a safer evolution of appli-\ncations. The present definition seamlessly extends the existing Out-\nSystems metamodel with template constructs expressed by model\nannotations that maintain backward compatibility with the existing\nlanguage toolchain. We present the metamodel, its annotations, and\nthe corresponding validation and instantiation algorithms. In par-\nticular, we introduce a type-based validation procedure that ensures\nthat using a template inside a template produces valid models.\nThe work is validated using the OSTRICH benchmark. Our proto-\ntype is an extension of the OutSystems IDE allowing the annotation\nof models and their use to produce new models. We also analyse\nwhich existing OutSystems sample screens templates can be im-\nproved by using and sharing nested templates.",
    "keywords": [],
    "authors": [
      "João Costa Seco",
      "Hugo Lourenço",
      "Joana Parreira",
      "Carla Ferreira"
    ],
    "file_path": "data/models/models22/main/papers/p210-seco.pdf"
  },
  {
    "title": "Verification of Railway Network Models with EVEREST",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Models – at different levels of abstraction and pertaining to different\nengineering views – are central in the design of railway networks, in\nparticular signalling systems. The design of such systems must fol-\nlow numerous strict rules, which may vary from project to project\nand require information from different views. This renders manual\nverification of railway networks costly and error-prone.\nThis paper presents EVEREST, a tool for automating the verifica-\ntion of railway network models that preserves the loosely coupled\nnature of the design process. To achieve this goal, EVEREST first\ncombines two different views of a railway network model – the\ntopology provided in signalling diagrams containing the functional\ninfrastructure, and the precise coordinates of the elements pro-\nvided in technical drawings (CAD) – in a unified model stored in the\nrailML standard format. This railML model is then verified against\na set of user-defined infrastructure rules, written in a custom modal\nlogic that simplifies the specification of spatial constraints in the\nnetwork. The violated rules can be visualized both in the signalling\ndiagrams and technical drawings, where the element(s) responsible\nfor the violation are highlighted.\nEVEREST is integrated in a long-term effort of EFACEC to im-\nplement industry-strong tools to automate and formally verify the\ndesign of railway solutions.",
    "keywords": [
      "railway engineering",
      "railway network model verification",
      "formal infrastructure rule specification",
      "railML"
    ],
    "authors": [
      "João Martins",
      "José M. Fonseca",
      "Rafael Costa",
      "José C. Campos",
      "Alcino Cunha",
      "Nuno Macedo",
      "José N. Oliveira"
    ],
    "file_path": "data/models/models22/main/papers/p345-martins.pdf"
  },
  {
    "title": "Validating the Correctness of Reactive Systems Specifications Through Systematic Exploration",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. While the synthesized system is guaranteed to be correct w.r.t. the specification, the specification itself may be incorrect w.r.t. the engineers’ intention or w.r.t. the requirements or the environment in which the system should execute in. It thus requires validation. Combinatorial coverage (CC) is a well-known coverage criterion. Its rationale and key for effectiveness is the empirical observation that in many cases, the presence of a defect depends on the interaction between a small number of features of the system at hand. In this work we propose a validation approach for a reactive system specification, based on a systematic combinatorial exploration of the behaviors of a controller that was synthesized from it. Specifically, we present an algorithm to generate and execute a small scenario suite that covers all tuples of given variable value combinations over the reachable states of the controller. We have implemented our work in the Spectra synthesis en-vironment. We evaluated it over benchmarks from the literature using a mutation approach, specifically tailored for evaluating scenario suites of temporal specifications for reactive synthesis. The evaluation shows that for pairwise coverage, our CC algorithms are feasible and provide a 1.7 factor of improvement in mutation score compared to random scenario generation. We further report on a user study with students who have participated in a work-shop class at our university and have used our tool to validate their specifications. The user study results demonstrate the potential effectiveness of our work in helping engineers detect real bugs in the specifications they write.",
    "keywords": [],
    "authors": [
      "Dor Ma’ayan",
      "Shahar Maoz",
      "Roey Rozi"
    ],
    "file_path": "data/models/models22/main/papers/p132-maayan.pdf"
  },
  {
    "title": "Solving the Instance Model-View Update Problem in AADL",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "The Architecture Analysis and Design Language (AADL) is a rich\nlanguage for modeling embedded systems through several con-\nstructs such as component extension and refinement to promote\nmodularity of component declarations. To ease processing AADL\nmodels, OSATE, the reference tool for AADL, defines another model\n(namely ‘instance’ model) computed from a base ‘declarative’ mod-\nels. An instance model is a simple object tree where all information\nfrom the declarative model is flattened so that tools can easily use\nthis information to analyze the system. However for modifications,\nthey have to make changes in the complex declarative model since\nthere is no automated backward transformation (deinstantiation)\nfrom instance to declarative models. Since the instance model is a\n‘view’ of the declarative model, this is a view-update problem. In\nthis paper, we propose the OSATE Declarative-Instance Mapping\nTool (OSATE-DIM1), an Eclipse plugin for deinstantiation of AADL\nmodels implementing a solution of this view-update problem. We\nevaluate OSATE-DIM with a benchmark of existing AADL model\nprocessing tools and verify the correctness of our deinstantiation\ntransformations. We also discuss how our approach could be use-\nful for decompilation of Object-Oriented languages’ intermediate\nrepresentations.",
    "keywords": [
      "Model-Driven Engineering",
      "Cyber-Physical Systems",
      "Embedded\nSystems",
      "View-Update Problem",
      "AADL"
    ],
    "authors": [
      "Rakshit Mittal",
      "Dominique Blouin",
      "Anish Bhobe",
      "Soumyadip Bandyopadhyay"
    ],
    "file_path": "data/models/models22/main/papers/p55-mittal.pdf"
  },
  {
    "title": "Editing Support for Software Languages: Implementation Practices in Language Server Protocols",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Effectively using software languages, be it programming or domain-specific languages, requires effective editing support. Modern IDEs, modeling tools, and code editors typically provide sophisticated support to create, comprehend, or modify instances—programs or models—of particular languages. Unfortunately, building such edit-ing support is challenging. While the engineering of languages is well understood and supported by modern model-driven tech-niques, there is a lack of engineering principles and best prac-tices for realizing their editing support. Especially domain-specific languages—often created by smaller organizations or individual developers, sometimes even for single projects—would benefit from better methods and tools to create proper editing support. We study practices for implementing editing support in 30 so-called language servers—implementations of the language server protocol (LSP). The latter is a recent de facto standard to realize editing support for languages, separated from the editing tools (e.g., IDEs or modeling tools), enhancing the reusability and quality of the editing support. Witnessing the LSP’s popularity—a whopping 121 language servers are in existence today—we take this opportunity to analyze the implementations of 30 language servers, some of which support multiple languages. We identify concerns that developers need to take into account when developing editing support, and we synthesize implementation practices to address them, based on a systematic analysis of the servers’ source code. We hope that our results shed light on an important technology for software language engineering, that facilitates language-oriented programming and systems development, including model-driven engineering.",
    "keywords": [
      "Language engineering",
      "code assistance",
      "source code editor",
      "implementation practices"
    ],
    "authors": [
      "Djonathan Barros",
      "Sven Peldszus",
      "Wesley K. G. Assunção",
      "Thorsten Berger"
    ],
    "file_path": "data/models/models22/main/papers/p232-barros.pdf"
  },
  {
    "title": "Accelerating Similarity-Based Model Matching Using On-The-Fly Similarity Preserving Hashing",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Similarity-based model matching is the foundation of model versioning. It pairs model elements based on a distance metric (e.g., edit distance). Because it is expensive to calculate the distance between two elements, a similarity-based matcher usually suffers from performance issues when the model size increases. This paper proposes a hash-based approach to accelerate similarity-based model matching. Firstly, we design a novel similarity-preserving hash function that maps a model element to a 64-bit hash value. If two elements are similar, their hashes are also very close. Secondly, we propose a 3-layer index structure and a query algorithm to quickly filter out impossible candidates for the element to be matched based on their hashes. For the remaining candidates, we employ the classical similarity-based matching algorithm to determine the final matches. Our approach has been realized and integrated into EMF Compare. The evaluation results show that our hash function is effective to preserve the similarity between model elements and our matching approach reduces 16%–72% of time costs while assuring the matching results consistent with EMF Compare.",
    "keywords": [
      "model matching",
      "similarity-preserving hashing",
      "distance function",
      "model merging"
    ],
    "authors": [
      "Xiao He",
      "Letian Tang",
      "Yutong Li"
    ],
    "file_path": "data/models/models22/main/papers/p244-he.pdf"
  },
  {
    "title": "A Comprehensive Framework for the Analysis of Automotive Systems",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Analysis models, technologies and tools are extensively used in the automotive domain to validate and optimize the design and implementation of SW systems. This is especially true for modern systems including advanced autonomous (and complex) features. The range of analysis methods that can be applied is extremely wide and goes from functional correctness to functional safety to timing (and schedulability), security, and possibly even more. The AUTOSAR automotive standard has been defined with the purpose of standardizing the SW architecture of automotive systems and enable the construction of systems by composing SW components that are portable and abstract with respect to the underlying HW/SW platform. However, AUTOSAR was originally developed with portability of code in mind, and even if it quickly evolved to include a system-level modeling language (with its metamodel) and later extensions to deal with the needs of analysis methods (and tools), it is hardly comprehensive and still affected by several omissions and limitations. To fix the limitations with respect to timing and schedulability analysis Bosch developed the Amalthea (later App4MC) metamodel and tools. In Huawei, a more general (and ambitious) approach was undertaken to support not only timing analysis, but also model checking (or other types of formal verification), safety analysis and even design optimization. The approach is based on the concepts of a unified (modular) metamodel and a framework based on Eclipse to integrate analysis methods and tools. In this paper we describe the framework and the results obtained with respect to the objectives of functional verification and timing analysis.",
    "keywords": [
      "AUTOSAR SW Systems",
      "Model-Based Development",
      "Timing Analysis",
      "Formal Verification"
    ],
    "authors": [
      "Alessandro Cimatti",
      "Sara Corfini",
      "Luca Cristoforetti",
      "Marco Di Natale",
      "Alberto Griggio",
      "Stefano Puri",
      "Stefano Tonetta"
    ],
    "file_path": "data/models/models22/main/papers/p379-cimatti.pdf"
  },
  {
    "title": "System Architecture Synthesis for Performability by Logic Solvers",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "In model-based systems engineering, system architectures often have to make compromises to meet hard constraints of functional and extra-functional requirements while optimizing for a target objective. Design space exploration (DSE) techniques have been developed to automatically propose candidate architectures over an extremely large design and configuration space. (1) Meta-heuristic exploration algorithms are often used to provide practical, best-effort solutions for DSE, but they lack any guarantees of completeness or optimality. (2) Logic synthesis based approaches may offer strong theoretical guarantees, but frequently face scalability issues. In the paper, we propose two logic solver-based approaches to evaluate complex design spaces by using partial models in order to find an optimal solution with respect to performability objectives. One approach uses performability analysis as a post-filtering of valid system architecture candidates, while the other approach uses performability analysis for guiding the actual search over partial models. We evaluate both approaches on an interferometry mission architecture case study using view transformations for performability analysis and compare our approach with a well-known DSE framework based on meta-heuristic search.",
    "keywords": [
      "performability",
      "design-space exploration",
      "logic solver",
      "model generator",
      "partial models"
    ],
    "authors": [
      "Máté Földiák",
      "Kristóf Marussy",
      "Dániel Varró",
      "István Majzik"
    ],
    "file_path": "data/models/models22/main/papers/p43-foldiak.pdf"
  },
  {
    "title": "Practical Multiverse Debugging through User-defined Reductions: Application to UML Models",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Multiverse debugging is an extension of classical debugging methods, particularly adapted to non-deterministic systems. Recently, a language-independent formalization was proposed. Moreover, multiverse debugging is particularly beneficial for specification and design languages, such as UML. However, this method suffers from scalability issues during breakpoint lookup. This problem arises due to the exhaustive exploration performed on the potentially infinite state-space of the system.\n\nIn this paper, we tackle this problem by introducing Reduced Multiverse Debugging, an extension proposing a way for the user to define reduction policies used during breakpoint lookup. We enrich the formalization of multiverse debugging with a modular breakpoint lookup strategy, which allows the integration of the reduction policy. We validate our approach by implementing a practical UML Statechart debugger in the AnimUML web framework. We show several ways the reduction can be applied, using methods such as predicate abstraction for breakpoint lookup on an infinite state-space, removing irrelevant variables, or creating classes of equivalent values. Moreover, we show the possibility to integrate probabilistic reduction strategies. Relying on hash collisions, these strategies can be iteratively refined to increase precision.",
    "keywords": [
      "multiverse debugging",
      "model analysis",
      "concurrency",
      "abstraction"
    ],
    "authors": [
      "Matthias Pasquier",
      "Ciprian Teodorov",
      "Frédéric Jouault",
      "Matthias Brun",
      "Luka Le Roux",
      "Loïc Lagadec"
    ],
    "file_path": "data/models/models22/main/papers/p87-pasquier.pdf"
  },
  {
    "title": "Towards Model-based Bias Mitigation in Machine Learning",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Models produced by machine learning are not guaranteed to be free from bias, particularly when trained and tested with data produced in discriminatory environments. The bias can be unethical, mainly when the data contains sensitive attributes, such as sex, race, age, etc. Some approaches have contributed to mitigating such biases by providing bias metrics and mitigation algorithms. The challenge is users have to implement their code in general/statistical programming languages, which can be demanding for users with little programming and fairness in machine learning experience. We present FairML, a model-based approach to facilitate bias measure- ment and mitigation with reduced software development effort. Our evaluation shows that FairML requires fewer lines of code to produce comparable measurement values to the ones produced by the baseline code.",
    "keywords": [
      "Model-Driven Engineering",
      "Generative Programming",
      "Bias Mitigation",
      "Bias Metrics",
      "Machine Learning"
    ],
    "authors": [
      "Alfa Yohannis and Dimitris Kolovos"
    ],
    "file_path": "data/models/models22/main/papers/p143-yohannis.pdf"
  },
  {
    "title": "Advanced Visualization and Interaction in GLSP-based Web Modeling: Realizing Semantic Zoom and Off-Screen Elements",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Conceptual modeling is widely adopted in industrial practices, e.g., process, software, and systems modeling. Providing adequate and usable modeling tools is essential for the efficient adoption of modeling. Metamodeling platforms provide a rich set of functionalities and maturely realize state-of-the-art modeling tools. However, despite their maturity and stability, most of these platforms only slowly – if at all – leverage the full extent of functionalities and the ease of exploitation and integration enabled by web technologies. With the Graphical Language Server Protocol (GLSP), it is now possible to realize much richer, advanced opportunities for visualizing and interacting with conceptual models. This paper presents a concept and a prototypical implementation of two advanced model visualization and interaction functionalities with the Eclipse GLSP platform: Semantic Zoom and Off-Screen Elements. We believe such advanced functionalities pave the way for a prosperous modeling future and spark innovation in modeling tool development.",
    "keywords": [
      "Modeling tools",
      "Web Modeling",
      "Language Server Protocol",
      "Visualization"
    ],
    "authors": [
      "Giuliano De Carlo",
      "Philip Langer",
      "Dominik Bork"
    ],
    "file_path": "data/models/models22/main/papers/p221-carlo.pdf"
  },
  {
    "title": "Symboleo2SC: From Legal Contract Specifications to Smart Contracts",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Smart contracts (SCs) are software systems that monitor and control the execution of legal contracts to ensure compliance with the contracts’ terms and conditions. They often exploit Internet-of-Things technologies to support their monitoring functions, and blockchain technology to ensure the integrity of their data. Ethereum and business blockchain platforms, such as Hyperledger Fabric, are popular choices for SC development. However, there is a gap in the knowledge of SCs between developers and legal experts. Symboleo is a formal specification language for legal contracts that was introduced to address this issue. Symboleo specifications directly encode legal concepts such as parties, obligations, and powers. In this paper, we propose a tool-supported method for translating Symboleo specifications into smart contracts. We have extended the current Symboleo IDE, implemented the ontology and semantics of Symboleo into a reusable library, and developed the Sym-boleo2SC tool to generate Hyperledger Fabric code exploiting this library. Symboleo2SC was evaluated with three sample contracts. The results shows that legal contract specifications in Symboleo can be fully converted to SCs for monitoring purposes. Moreover, Symboleo2SC helps simplify the SC development process, saves development effort, and helps reduce risks of coding errors.",
    "keywords": [
      "Smart contracts",
      "code generation",
      "blockchain",
      "domain-specific languages",
      "legal ontology"
    ],
    "authors": [
      "Aidin Rasti",
      "Daniel Amyot",
      "Alireza Parvizimosaed",
      "Marco Roveri",
      "Luigi Logrippo",
      "Amal Ahmed Anda",
      "John Mylopoulos"
    ],
    "file_path": "data/models/models22/main/papers/p300-rasti.pdf"
  },
  {
    "title": "A Domain-Specific Language for Simulation-Based Testing of IoT Edge-to-Cloud Solutions",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "The Internet of things (IoT) is increasingly prevalent in domains such as emergency response, smart cities and autonomous vehicles. Simulation plays a key role in the testing of IoT systems, noting that field testing of a complete IoT product may be infeasible or prohibitively expensive. In this paper, we propose a domain-specific language (DSL) for generating edge-to-cloud simulators. An edge-to-cloud simulator executes the functionality of a large array of edge devices that communicate with cloud applications. Our DSL, named IoTECS, is the result of a collaborative project with an IoT analytics company, Cheetah Networks. The industrial use case that motivates IoTECS is ensuring the scalability of cloud applications by putting them under extreme loads from IoT devices connected to the edge. We implement IoTECS using Xtext and empirically evaluate its usefulness. We further reflect on the lessons learned.",
    "keywords": [
      "Domain-Specific Languages",
      "IoT",
      "Simulation",
      "Stress Testing",
      "Xtext"
    ],
    "authors": [
      "Jia Li",
      "Shiva Nejati",
      "Mehrdad Sabetzadeh",
      "Michael McCallen"
    ],
    "file_path": "data/models/models22/main/papers/p367-li.pdf"
  },
  {
    "title": "Bug Localization in Game Software Engineering: Evolving Simulations to Locate Bugs in Software Models of Video Games",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Video games have characteristics that differentiate their development and maintenance from classic software development and maintenance. These differences have led to the coining of the term Game Software Engineering to name the emerging subfield that intersects Software Engineering and video games. One of these differences is that video game developers perceive more difficulties than other non-game developers when it comes to locating bugs. Our work proposes a novel way to locate bugs in video games by means of evolving simulations. As the baseline, we have chosen BLiMEA, which targets classic software engineering and uses bug reports and the defect localization principle to locate bugs. We also include Random Search as a sanity check in the evaluation. We evaluate the approaches in a commercial video game (Kromaia). The results for F-measure range from 46.80%. to 70.28% for five types of bugs. Our approach improved the results of the baseline by 20.29% in F-measure. To the best of our knowledge, this is the first approach that is designed specifically for bug localization in video games. A focus group with professional video game developers has confirmed the acceptance of our approach. Our approach opens a new research direction for bug localization for both game software engineering and possibly classic software engineering.",
    "keywords": [
      "Bug Localization",
      "Video Games",
      "Search-Based Software Engineering",
      "Model-Driven Engineering"
    ],
    "authors": [
      "Rodrigo Casamayor",
      "Lorena Arcega",
      "Francisca Pérez",
      "Carlos Cetina"
    ],
    "file_path": "data/models/models22/main/papers/p356-casamayor.pdf"
  },
  {
    "title": "A Declarative Modelling Framework for the Deployment and Management of Blockchain Applications",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "The deployment and management of Blockchain applications require non-trivial efforts given the unique characteristics of their infrastructure (i.e., immutability) and the complexity of the software systems being executed. The operation of Blockchain applications is still based on ad-hoc solutions that are error-prone, difficult to maintain and evolve, and do not manage their interactions with other infrastructures (e.g., a Cloud backend). This paper proposes KATENA, a framework for the deployment and management of Blockchain applications. In particular, it focuses on applications that are compatible with Ethereum, a popular general-purpose Blockchain technology. KATENA provides i) a metamodel for defining Blockchain applications, ii) a set of processes to automate the deployment and management of defined models, and iii) an implementation of the approach based on TOSCA, a standard language for Infrastructure-as-Code, and xOpera, a TOSCA-compatible orchestrator. To evaluate the approach, we applied KATENA to model and deploy three real-world Blockchain applications, and showed that our solution reduces the amount of code required for their operations up to 82.7%.",
    "keywords": [
      "blockchain",
      "dApp",
      "decentralized applications",
      "orchestration",
      "devops",
      "infrastructure-as-code",
      "iac",
      "smart contract",
      "ethereum",
      "TOSCA",
      "deployment"
    ],
    "authors": [
      "Luciano Baresi",
      "Giovanni Quattrocchi",
      "Damian Andrew Tamburri",
      "Luca Terracciano"
    ],
    "file_path": "data/models/models22/main/papers/p311-baresi.pdf"
  },
  {
    "title": "Reactive Links Across Multi-Domain Engineering Models",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "As the engineering world moves towards collaborative model-driven development, it is becoming increasingly difficult to keep all model artifacts synchronized and consistent across a myriad of tools and domains. The existing literature proposes a variety of solutions, from passive trace links to computing change propagation paths. However, these solutions require manual propagation and the use of a limited set of tools, while also lacking the efficiency and granularity required during the development of complex systems. To overcome these limitations, this paper proposes a solution based on reactive propagation links between property values across multi-domain models managed in different tools. As opposed to the traditional passive links, the propagation links automatically react to changes during engineering to assure the synchronization and consistency of the models. The feasibility and performance of our solution were evaluated in two practical scenarios. We identified a set of change propagation cases, all of which could be resolved using our solution, while also rendering a great improvement in terms of efficiency as compared to manual propagation. The contribution of our solution to the state of the practice is to enhance the engineering process by reducing the burden of manually keep-ing models synchronized, eliminating inconsistencies that can be originated in artifacts managed in a variety of tool from different domains.",
    "keywords": [],
    "authors": [
      "Cosmina Cristina Rat,iu",
      "Wesley K. G. Assunção",
      "Rainer Haas",
      "Alexander Egyed"
    ],
    "file_path": "data/models/models22/main/papers/p76-tatiu.pdf"
  },
  {
    "title": "The Influence of Software Design Representation on the Design Communication of Teams with Diverse Personalities",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Software is the main driver of added-value in many of the systems that surround us. While its complexity is increasing, so is the diversity of systems driven by software. To meet the challenges emerging from this combination, it is necessary to mobilize increasingly large and heterogeneous multidisciplinary teams, comprising software experts, as well as experts from various domains related to the systems driven by software. Hence, the quality of communication about software between stakeholders of different domains and with different personalities is becoming a key issue for successfully engineering software-intensive systems. The goal of this study, thus, is to investigate the effect of the representation of software design models on the communication of design decisions between stakeholders with diverse personality traits. As a result, this study finds that graphical representations of software design models are better than textual representations in enhancing the communication and increasing the productivity of stakeholders with diverse personalities.",
    "keywords": [
      "Software Engineering",
      "Software Design",
      "Human Aspects",
      "Personality Traits",
      "Communication"
    ],
    "authors": [
      "Rodi Jolak",
      "Maxime Savary-Leblanc",
      "Manuela Dalibor",
      "Juraj Vincur",
      "Regina Hebig",
      "Xavier Le Pallec",
      "Michel Chaudron",
      "Sébastien Gérard",
      "Ivan Polasek",
      "and Andreas Wortmann"
    ],
    "file_path": "data/models/models22/main/papers/p255-jolak.pdf"
  },
  {
    "title": "Predicate Abstractions for Smart Contract Validation",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Smart contracts are immutable programs deployed on the blockchain that can manage significant assets. Because of this, verification and validation of smart contracts is of vital importance. Indeed, it is industrial practice to hire independent specialized companies to audit smart contracts before deployment. Auditors typically rely on a combination of tools and experience but still fail to identify problems in smart contracts before deployment, causing significant losses. In this paper, we propose using predicate abstraction to construct models which can be used by auditors to explore and validate smart contact behaviour at the function call level by proposing predicates that expose different aspects of the contract. We propose predicates based on requires clauses and enum-type state variables as a starting point for contract validation and report on an evaluation on two different benchmarks.",
    "keywords": [],
    "authors": [
      "Javier Godoy",
      "Juan Pablo Galeotti",
      "Diego Garbervetsky",
      "Sebastian Uchitel"
    ],
    "file_path": "data/models/models22/main/papers/p289-godoy.pdf"
  },
  {
    "title": "Precomputing Reconfiguration Strategies based on Stochastic Timed Game Automata",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Many modern software systems continuously reconfigure themselves to (self-)adapt to ever-changing environmental contexts. Selecting presumably best-fitting next configurations is, however, very challenging, depending on functional and non-functional criteria like real-time constraints as well as inherently uncertain future contexts which makes greedy one-step decision heuristics ineffective. In addition, the computational overhead caused by reconfiguration planning at run-time should not outweigh its benefits. On the other hand, completely pre-planning reconfiguration decisions at design time is also infeasible due to the lack of knowledge about the context behavior. In this paper, we propose a game-theoretic setting for precomputing reconfiguration decisions under partially uncertain real-time behavior. We employ stochastic timed game automata as reconfiguration model to derive winning strategies which enable the first player (the system) to make fast look-ups for presumably best-fitting reconfiguration decisions satisfying the second player (the context). To cope with the high computational complexity of finding winning strategies, our tool implementation1 utilizes the statistical model-checker Uppaal Stratego to approximate near-optimal solutions. In our evaluation, we investigate efficiency/effectiveness trade-offs by considering a real-world example consisting of a reconfigurable robot support system for the construction of aircraft fuselages.",
    "keywords": [
      "Stochastic Timed Game Automata",
      "Proactive Self-Adaptation",
      "Strategy Synthesis",
      "Statistical Model-Checking"
    ],
    "authors": [
      "Hendrik Göttmann",
      "Birte Caesar",
      "Lasse Beers",
      "Malte Lochau",
      "Andy Schürr",
      "Alexander Fay"
    ],
    "file_path": "data/models/models22/main/papers/p31-goettmann.pdf"
  },
  {
    "title": "Machine Learning Methods for Model Classification: A Comparative Study",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "In the quest to reuse modeling artifacts, academics and industry have proposed several model repositories over the last decade. Different storage and indexing techniques have been conceived to facilitate searching capabilities to help users find reusable artifacts that might fit the situation at hand. In this respect, machine learning (ML) techniques have been proposed to categorize and group large sets of modeling artifacts automatically. This paper reports the results of a comparative study of different ML classification techniques employed to automatically label models stored in model repositories. We have built a framework to systematically compare different ML models (feed-forward neural networks, graph neural networks, 𝑘−nearest neighbors, support version machines, etc.) with varying model encodings (TF-IDF, word embeddings, graphs and paths). We apply this framework to two datasets of about 5,000 Ecore and 5,000 UML models. We show that specific ML models and encodings perform better than others depending on the characteristics of the available datasets (e.g., the presence of duplicates) and on the goals to be achieved.",
    "keywords": [
      "Model classification",
      "Model-Driven Engineering",
      "Machine learning"
    ],
    "authors": [
      "José Antonio Hernández López",
      "Riccardo Rubei",
      "Jesús Sánchez Cuadrado",
      "Davide di Ruscio"
    ],
    "file_path": "data/models/models22/main/papers/p165-lopez.pdf"
  },
  {
    "title": "Modular Language Product Lines: A Graph Transformation Approach",
    "submission-date": "2022/10",
    "publication-date": "2022/10",
    "abstract": "Modelling languages are intensively used in paradigms like model-driven engineering to automate all tasks of the development process. These languages may have variants, in which case the need arises to deal with language families rather than with individual languages. However, specifying the syntax and semantics of each language variant separately is costly, hinders reuse across variants, and may yield inconsistent semantics between variants.\nTo attack this problem, we propose a novel, modular way to describe product lines of modelling languages. Our approach is compositional, enabling the incremental definition of language families by means of modules comprising meta-model fragments, graph transformation rules, and rule extensions. Language variants are configured by selecting the desired modules, which entails the composition of a language meta-model and a set of rules defining its semantics. This paper describes a theory able to check consistent semantics among all languages within the family, an implementation as an Eclipse plugin, and an evaluation reporting drastic specification size reduction w.r.t. an enumerative approach.",
    "keywords": [
      "Model-driven engineering",
      "Graph transformation",
      "Product lines",
      "Software language engineering"
    ],
    "authors": [
      "Juan de Lara",
      "Esther Guerra",
      "Paolo Bottoni"
    ],
    "file_path": "data/models/models22/main/papers/p334-lara.pdf"
  },
  {
    "title": "EvoSL: A Large Open-Source Corpus of Changes in Simulink Models & Projects",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Having readily available corpora is crucial for performing replication, reproduction, extension, and verification studies of existing research tools and techniques. MATLAB/Simulink is a de-facto standard tool in several safety-critical industries for system modeling and analysis, compiling models to code, and deploying code to embedded hardware. There is no commonly used corpus for large-scale model change studies because there is no readily available corpus. EvoSL is the first large corpus of Simulink projects that includes model and project changes and allows redistribution. EvoSL is available under a permissive open-source license and contains its collection and analysis tools. Using a subset of EvoSL, we replicated a case study of model changes on a single closed-source industrial project.",
    "keywords": [
      "reproducibility",
      "replication",
      "Simulink",
      "open science",
      "Simulink model changes",
      "corpus",
      "evolution"
    ],
    "authors": [
      "Sohil Lal Shrestha",
      "Alexander Boll",
      "Shafiul Azam Chowdhury",
      "Timo Kehrer",
      "Christoph Csallner"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a273/248000a273.pdf"
  },
  {
    "title": "MODELS 2023",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "This document is the preface to the MODELS 2023 conference. It details the conference's history, location, submission process, acceptance rates, and program highlights.",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z010/248000z010.pdf"
  },
  {
    "title": "Experience in Specializing a Generic Realization Language for SPL Engineering at Airbus",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "In software product line (SPL) engineering, feature models are the de facto standard for modeling variability. A user can derive products out of a base model by selecting features of interest. Doing it automatically, however, requires a realization model, which is a description of how a base model should be modiﬁed when a given feature is selected/unselected. A realization model then necessarily depends on the base metamodel, asking for ad hoc solutions that have ﬂourished in recent years. In this paper, we propose Greal, a generic solution to this problem in the form of (1) a generic declarative realization language that can be automatically composed with one or more base metamodels to yield a domain-speciﬁc realization language and (2) a product derivation algorithm applying a realization model to a base model and a resolved model to yield a derived product. We describe how, on top of Greal, we specialized a realization language to support both positive and negative variability, ﬁt the syntax and semantics of the targeted language (BPMN) and take into account modeling practices at Airbus. We report on lessons learned of applying this approach on Program Development Plans based on business process models and discuss open problems.",
    "keywords": [],
    "authors": [
      "Damien Foures",
      "Mathieu Acher",
      "Olivier Barais",
      "Benoit Combemale",
      "Jean-Marc J´ez´equel",
      "J¨org Kienzle"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a319/248000a319.pdf"
  },
  {
    "title": "Automated Domain Modeling with Large Language Models: A Comparative Study",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Domain modeling is an essential part of software engineering and serves as a way to represent and understand the concepts and relationships in a problem domain. Typically, software engineers interpret the problem description written in natural language and manually translate it into a domain model. Domain modeling can be time-consuming and highly depends on the expertise of software engineers. Recently, Large Language Models (LLMs) have exhibited remarkable ability in language understanding, generation, and reasoning. In this paper, we conduct a comprehensive, comparative study of using LLMs for fully automated domain modeling. We assess two powerful LLMs, GPT3.5 and GPT4, employing various prompt engineering techniques on a data set containing ten diverse domain modeling examples with reference solutions created by modeling experts. Our findings reveal that while LLMs demonstrate impressive domain understanding capabilities, they are still impractical for full automation, with the top-performing LLM achieving F1 scores of 0.76 for class generation, 0.61 for attribute generation, and 0.34 for relationship generation. Moreover, the F1 score is characterized by higher precision and lower recall; thus, domain elements retrieved by LLMs are often reliable, but there are many missing elements. Furthermore, modeling best practices are rarely followed in auto-generated domain models. Our data set and evaluation provide a valuable baseline for future research in automated LLM-based domain modeling.",
    "keywords": [
      "domain modeling",
      "large language models",
      "few-shot learning",
      "chain-of-thought prompting",
      "prompt engineering"
    ],
    "authors": [
      "Kua Chen",
      "Yujing Yang",
      "Boqi Chen",
      "Jos´e Antonio Hern´andez L´opez",
      "Gunter Mussbacher",
      "D´aniel Varr´o"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a162/248000a162.pdf"
  },
  {
    "title": "Automated Grading of Use Cases",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Use cases (UCs) play a crucial role in software engineering courses, with students frequently using them in assignments, projects, and exams. However, as the number of students enrolling in Computer Science and Software Engineering programs continues to rise, manual grading of these models is becoming increasingly time-consuming. While automated grading tools for class diagrams exist, the automation of grading use case models has received limited attention.\nThis paper proposes an approach for automatically grading use cases. To compare a student’s solution to the teacher’s solution our approach uses structural matching, syntactic and semantic word matching, natural language processing for sentence matching, and ﬂattening of use case hierarchies. The grading algorithm is evaluated on three actual undergraduate and graduate assignments that involve modeling a Gas Station ﬁll-up scenario, a Supermarket checkout scenario, as well as the interactions involved in playing the board game Elfenroads. The results show that with some tuning our automatically determined grades lie within 7% difference of the instructor’s manual grades.",
    "keywords": [
      "use cases",
      "automated grading",
      "model comparison"
    ],
    "authors": [
      "Mohsen Hosseinibaghdadabadi",
      "Omar Alam",
      "Nicolas Almerge",
      "Jörg Kienzle"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a106/248000a106.pdf"
  },
  {
    "title": "OCL Rebuilt, From the Ground Up",
    "submission-date": "2023/09",
    "publication-date": "2023/09",
    "abstract": "The Object Constraint Language (OCL) serves the expression of complex conditions and queries over UML-based models in an object-oriented style. We note that OCL’s grounding in object-orientation leads to a number of issues, including subtle inconsistencies and unsafe navigation. To address these issues, we present OCL♯, a new formal foundation for OCL with borrowings from Alloy. We provide OCL♯’s syntax and semantics, prove type safety, and present a prototype implementation.",
    "keywords": [
      "OCL",
      "semantics",
      "relational language",
      "Alloy"
    ],
    "authors": [
      "Friedrich Steimann",
      "Robert Clarisó",
      "Martin Gogolla"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a194/248000a194.pdf"
  },
  {
    "title": "MODELS 2023",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Antonio Cicchetti",
      "Alfonso Pierantonio",
      "Federico Ciccozzi",
      "Thomas Kühne",
      "Gabriele Taentzer",
      "Davide Di Ruscio",
      "Leen Lambers",
      "Hugo Bruneliere",
      "Fiona Polack",
      "Nelly Bencomo",
      "Sebastian Götz",
      "Ivano Malavolta",
      "Judith Michael",
      "Juri Di Rocco",
      "Matthias Tichy",
      "Jan Carlson",
      "Maria Spichkova"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z012/248000z012.pdf"
  },
  {
    "title": "Integrating Testing into the Alloy Model Development Workﬂow",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Software models help improve the reliability of software systems: models can convey requirements, and can analyze design and implementation properties. A key strength of Alloy, a commonly used modeling language, is the Alloy Analyzer toolset. The Analyzer is an automated analysis engine that searches for all valid instances, which are assignments to the sets of the model such that all executed formulas hold, up to a user-provided scope. Unfortunately, despite the Analyzer, writing correct models remains a difﬁcult and error-prone task. To address this, a unit testing framework, AUnit, was created for Alloy. Since then, several traditional imperative testing practices, including mutation testing, fault localization and repair, have been established for Alloy models. Prior work has introduced the feasibility of these approaches and produced command line prototype tools. This paper highlights the effort to translate these research products into the Analyzer, the main model development tool for Alloy, to produce one consolidated integrated development environment that provides robust testing support.",
    "keywords": [
      "Alloy",
      "SAT Solver",
      "Software Testing"
    ],
    "authors": [
      "Allison Sullivan"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a117/248000a117.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Richard Paige",
      "Daniel Varró",
      "Silvia Abrahão",
      "Don Batory",
      "Nelly Bencomo",
      "Jordi Cabot",
      "Marsha Chechik",
      "Juergen Dingel",
      "Alexander Egyed",
      "Jeff Gray",
      "Øystein Haugen",
      "Zhenjiang Hu",
      "Marouane Kessentini",
      "Jörg Kienzle",
      "Thomas Kühne",
      "Vinay Kulkarni",
      "Timothy C. Lethbridge",
      "Shiva Nejati",
      "Kathy Park",
      "Alfonso Pierantonio",
      "Alexander Pretschner",
      "Houari Sahraoui",
      "Wolfram Schulte",
      "Eugene Sirjani",
      "Gabriele Taentzer",
      "Manuel Wimmer",
      "Andrzej Wąsowski",
      "Tao Yue",
      "Juan de Lara"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z014/248000z014.pdf"
  },
  {
    "title": "Word Embeddings for Model-Driven Engineering",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Model-Driven Engineering practitioners have to deal\nwith the construction of modelling evironments by devising meta-\nmodels, grammars, editors, etc. One of the goals of the application\nof Machine Learning to MDE is to use ML algorithms to assist\nthe MDE expert in these tasks. These algorithms cannot directly\nreceive raw models or meta-models as input, but they typically\nhave to be transformed into a numeric representation, i.e., a\nvector. In this context, a common approach is to use pre-trained\nWord Embeddings, which deﬁne mapping functions that associate\nwords to semantic vectors. However, current word embeddings\nare trained with general texts and lack the technical words which\ntypically arise in the modelling domain. To tackle this issue, we\nhave collected a corpus of modelling texts from well-known mod-\nelling venues, and we have trained two types of word embedding\nmodels. The resulting embeddings (named WordE4MDE) are\nspecialised to address ML tasks in the MDE domain. We have\nperformed an extensive evaluation using the Ecore models of\nthe ModelSet dataset and two state-of-the-art word embeddings\n(GloVe and Word2Vec) as baselines. We show that WordE4MDE\noutperforms these two baselines in three meta-modelling tasks,\nnamely meta-model classiﬁcation, meta-model clustering, and\nmeta-model concept recommendation. WordE4MDE embeddings\nare available at https://github.com/models-lab/worde4mde and\ncan be loaded using standard Python libraries for their use in\nML pipelines.",
    "keywords": [
      "Model-Driven Engineering",
      "Machine Learning",
      "Word Embeddings"
    ],
    "authors": [
      "Jos´e Antonio Hern´andez L´opez",
      "Carlos Dur´a",
      "Jes´us S´anchez Cuadrado"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a151/248000a151.pdf"
  },
  {
    "title": "Model-Driven Approach for Knowledge-Based Engineering of Industrial Digital Twins",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Digital twins are heralding a new paradigm in the process and manufacturing industries by providing near real-time decisions for a range of problems. Engineering digital twin solutions is a knowledge and effort intensive activity. Currently, this is not an easily reproducible process. For each type of industry and for each specific plant, the digital twin design and development process has to start all over, and the effort needs to be reinvested. This is not a scalable proposition. To address this, we need a systematic approach that captures and reuses knowledge such that each new problem is solved significantly more efficiently than the previous problems. We propose a knowledge modeling and implementation methodology to systematically model and capture knowledge pertaining to the industrial manufacturing plant domain, problem domain and solution domain, and a knowledge guided process that reasons with this knowledge to provide intelligent decision support in the design and development of digital twin-based solutions for problems in manufacturing industries.",
    "keywords": [
      "Digital Twins",
      "Model Driven Engineering",
      "Knowledge Modeling",
      "Industry 4.0"
    ],
    "authors": [
      "Sushant Vale",
      "Sreedhar Reddy",
      "Sivakumar Subramanian",
      "Subhrojyoti Roy Chowdhury",
      "Sri Harsha Nistala",
      "Anirudh Deodhar",
      "Venkatraman Runkan"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a013/248000a013.pdf"
  },
  {
    "title": "Lessons Learned Building a Tool for Workﬂow+",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "As automotive manufacturers continue to release more advanced autonomous features, the effort required to ensure safety is increasing. This is a result of the growing complexity of automotive systems, and the increased level of safety assurance required for higher levels of autonomy. The Workﬂow+ model-based framework was developed in response to these challenges, to provide a way for safety assurance to be developed rigorously and with automated tool support. In this paper we discuss our experiences and lessons learned while developing Eclipse-based tooling for Workﬂow+ during a collaborative research project with a large automotive OEM.",
    "keywords": [
      "Model-Based Safety Assurance",
      "Change Impact Analysis",
      "Tool Development"
    ],
    "authors": [
      "Nicholas Annable",
      "Thomas Chiang",
      "Mark Lawford",
      "Richard F. Paige",
      "Alan Wassyng"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a140/248000a140.pdf"
  },
  {
    "title": "An Experimental Evaluation of Conformance Testing Techniques in Active Automata Learning",
    "submission-date": "2023/00",
    "publication-date": "2023/00",
    "abstract": "Active automata learning is a technique for dynamically learning finite state machine models of black-box systems. Conformance testing is a well-known bottleneck during learning. While multiple conformance testing techniques (CTTs) for Finite State Machines have been proposed, there is a lack of empirical studies that assess the effects of these CTTs during learning. In this work, we compare the performance of eight different CTTs (W, Wp, HSI, H-ADS, H, SPY, SPY-H, I-ADS) while learning 46 models from different communication protocols. Moreover, we propose APFDL as a metric for characterizing the efficiency of automata learning experiments in terms of fault detection capacity. This metric allows identifying CTTs with a lower total cost regarding the number of symbols and resets and a higher rate of state discovery during learning. Our results indicate that while the total cost entailed by CTTs in learning tends to be negligible, we found a significant difference in fault detection rate in learning. Nevertheless, the differences in fault detection rates become negligible when CTTs are applied in randomized mode. These findings reveal the positive role that randomness can have in improving learning efficiency, despite compromising test completeness.",
    "keywords": [],
    "authors": [
      "Bharat Garhewal",
      "Carlos Diego N. Damasceno"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a217/248000a217.pdf"
  },
  {
    "title": "An extended model-based characterization of fine-grained access control for SQL queries",
    "submission-date": "2023/00",
    "publication-date": "2023/00",
    "abstract": "In the context of a project in model-driven security that focuses on the development of model-driven techniques for building secure data-centric (web) applications, we extend, in three (inter-related) dimensions, a recently proposed model-based characterization of fine-grained access control (FGAC) authorization for SQL queries. First, we extend the FGAC policies’ underlying data models by considering association-classes. Secondly, we extend the FGAC policies’ security modeling language by considering, as protected resources, the classes and the (explicit and implicit) associations introduced by the association-classes. Thirdly, we extend the clauses that define whether a user is authorized by an FGAC policy to execute a SQL query, to cover the case of queries retrieving information related to the association-classes. To illustrate our extensions and to demonstrate their applicability, we provide examples of authorization decisions for SQL queries with respect to FGAC policies. The artefact comprising the implementation of this model-based characterization and an executable version of the example is available at https://doi.org/10.5281/zenodo.8176237.",
    "keywords": [
      "Model-Driven Security",
      "Fine-Grained Access Control",
      "Secure Database Queries",
      "SecureUML"
    ],
    "authors": [
      "Hoang Nguyen",
      "Manuel Clavel"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a095/248000a095.pdf"
  },
  {
    "title": "Manual Abstraction in the Wild: A Multiple-Case Study on OSS Systems’ Class Diagrams and Implementations",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Models are a useful tool for software design, analysis, and to support the onboarding of new maintainers. However, these beneﬁts are often lost over time, as the system implementation evolves and the original models are not updated. Reverse engineering methods and tools could help to keep models and implementation code in sync; however, automatically reverse-engineered models are typically not abstract and contain extensive information that prevents understanding. Recent advances in AI-based content generation make it likely that we will soon see reverse engineering tools with support for human-grade abstraction. To inform the design and validation of such tools, we need a principled understanding of what manual abstraction is, a question that has received little attention in the literature so far. Towards this goal, in this paper, we present a multiple-case study of model-to-code differences, investigating ﬁve substantial open-source software projects retrieved via repository mining. To explore characteristics of model-to-code differences, we, all in all, manually matched 466 classes, 1352 attributes, and 2634 operations from source code to 338 model elements (classes, attributes, operations, and relationships). These mappings precisely capture the differences between a provided class diagram design and implementation codebase. Studying all differences in detail allowed us to derive a taxonomy of difference types and to provide a sorted list of cases corresponding to the identiﬁed types of differences. As we discuss, our contributions pave the way for improved reverse engineering methods and tools, new mapping rules for model-to-code consistency checks, and guidelines for avoiding over-abstraction and over-speciﬁcation during design.",
    "keywords": [
      "software design",
      "modeling"
    ],
    "authors": [
      "Wenli Zhang",
      "Weixing Zhang",
      "Daniel Str¨uber",
      "Regina Hebig"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a036/248000a036.pdf"
  },
  {
    "title": "Mutation Testing for Temporal Alloy Models",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Writing declarative models has numerous beneﬁts, ranging from automated reasoning and correction of design-level properties before systems are built, to automated testing and debugging of their implementations after they are built. Alloy is a declarative modeling language that is well-suited for verifying system designs. A key strength of Alloy is its scenario-ﬁnding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model’s constraints up to a user-provided scope. Despite the Analyzer, writing correct Alloy models remains a difﬁcult task, partly due to Alloy’s expressive operators, which allow for succinct formulations of complex properties but can be difﬁcult to reason over manually. To further add to the complexity, Alloy’s grammar was recently expanded to support linear temporal logic, increasing both the expressibility of Alloy as well as the burden for accurately expressing properties. To address this, this paper presents μAlloyτ, an extension to Alloy’s mutation testing framework that accounts for the newly introduced temporal logic, including updating μAlloyτ’s test generation capability to produce temporal test cases. Experimental results reveal μAlloyτ is efﬁcient at generating and checking mutations and μAlloyτ’s automatically generated tests are effective at detecting faulty temporal models.",
    "keywords": [
      "Alloy",
      "Mutation Testing",
      "Test Generation"
    ],
    "authors": [
      "Ana Jovanovic",
      "Allison Sullivan"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a228/248000a228.pdf"
  },
  {
    "title": "SkeMo: Sketch Modeling for Real-Time Model Component Generation",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Software modeling is a powerful tool in the design and implementation of high-quality software systems. Models can be used from high-level design to formal code generation, with various applications in between. Often, software models are initially created informally, by sketching on a whiteboard or paper during the early design phase of the system, and eventually converted into formal models using advanced modeling tools. The formalization of sketches into actual model components can be time-consuming, error-prone, and laborious. To address these shortcomings, we present SkeMo, an environment for real-time model component generation from sketch-based inputs. We curated a sketch dataset of 3000 images of various class diagram components and implemented a powerful Convolution Neural Network to classify input sketches as model components. We integrated our sketch classiﬁer into an existing web-based model editor and added a touch interface to support sketch-based modeling. We evaluated the SkeMo environment in two ways: through ten-fold cross-validation of the image classiﬁer and collection of metrics and feedback from a 20-participant user study. Based on our results, sketch-based modeling demonstrates signiﬁcant promise as an intuitive interface that is both easy to use and allows for faster model creation among most users.",
    "keywords": [
      "model-driven software engineering",
      "machine learning",
      "deep neural network",
      "convolution neural network",
      "image recognition",
      "sketch recognition",
      "class diagrams",
      "classiﬁers",
      "interface design",
      "touch interface",
      "collaborative modeling",
      "assistive modeling",
      "user studies"
    ],
    "authors": [
      "Alisha Sharma Chapai and Eric J. Rapos"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a173/248000a173.pdf"
  },
  {
    "title": "Digital Twins for Cyber-Biophysical Systems: Challenges and Lessons Learned",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Digital twinning is gaining popularity in domains outside of traditional engineered systems, including cyber-physical systems (CPS) with biological modalities, or cyber-biophysical systems (CBPS) in short. While digital twinning has well-established practices in CPS settings, it raises special challenges in the context of CBPS. In this paper, we identify such challenges and lessons learned through an industry case of a digital twin for CBPS in controlled environment agriculture.",
    "keywords": [
      "controlled environment agriculture",
      "industry",
      "model-driven",
      "report",
      "simulation"
    ],
    "authors": [
      "Istvan David",
      "Pascal Archambault",
      "Quentin Wolak",
      "Cong Vinh Vu",
      "Timoth´e Lalonde",
      "Kashif Riaz",
      "Eugene Syriani",
      "Houari Sahraoui"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a001/248000a001.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "2023/00",
    "publication-date": "2023/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z004/248000z004.pdf"
  },
  {
    "title": "Rapid-Prototyping and Early Validation of Software Models through Uniform Integration of Hardware",
    "submission-date": "2023/09",
    "publication-date": "2023/09",
    "abstract": "Model-driven software engineering (MDSE) uses software models to make the complexity of cyber-physical and mechatronic systems (CPMS) manageable. For the validation of CPMS software models, closed-loop simulations are typically used. Since the system’s environment is part of the simulation, the software model is directly affected by the surroundings, which enables a more realistic evaluation. In early development phases, the expected target hardware platform for these software models is usually not considered, although such CPMS have a strong hardware dependency. This paper outlines a novel approach to couple these software models with hardware systems to improve the quality of these models and shorten the development cycle. The presented method allows the evaluation of functional and non-functional requirements. For this, a new in-the-loop concept is introduced where the hardware access is transparently performed using a remote procedure call mechanism. Moreover, the achieved modeling language and tool independence makes the novel approach suitable for various applications. The provided evaluation is based on two distinct modeling languages and tools to demonstrate the feasibility and performance of the new concept.",
    "keywords": [
      "model-driven software engineering",
      "model-in-the-loop",
      "cyber-physical systems",
      "remote procedure call"
    ],
    "authors": [
      "Michael Uelschen\nMarco Schaarschmidt\nJannis Budde"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a250/248000a250.pdf"
  },
  {
    "title": "Proceedings ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems MODELS 2023",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z003/248000z003.pdf"
  },
  {
    "title": "184\n2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS)",
    "submission-date": "2023/00",
    "publication-date": "2023/00",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a184/248000a184.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Acher",
      "Mathieu\nAlam",
      "Omar\nAlmerge",
      "Nicolas\nAnnable",
      "Nicholas\nArchambault",
      "Pascal\nAtlee",
      "Joanne M.\nBagherzadeh",
      "Mojtaba\nBarais",
      "Olivier\nBarat",
      "Souvik\nBarkowsky",
      "Matthias\nBeermann",
      "Laura\nBenzarti",
      "Imen\nBerger",
      "Bernhard J.\nBoll",
      "Alexander\nBork",
      "Dominik\nBudde",
      "Jannis\nCabot",
      "Jordi\nChen",
      "Boqi\nChen",
      "Kua\nChen",
      "Xiang\nChiang",
      "Thomas\nChowdhury",
      "Shafiul Azam\nChrszon",
      "Philipp\nClarisó",
      "Robert\nClavel",
      "Manuel\nCombemale",
      "Benoit\nCsallner",
      "Christoph\nDarif",
      "Ikram\nDavid",
      "Istvan\nde Lara",
      "Juan\nDíez",
      "Pablo\nDingel",
      "Juergen\nDurá",
      "Carlos\nDutta",
      "Jaya\nEl Boussaidi",
      "Ghizlane\nFelderer",
      "Michael\nFischer",
      "Philipp M.\nFoures",
      "Damien\nGarhewal",
      "Bharat\nGerndt",
      "Andreas\nGiese",
      "Holger\nGogolla",
      "Martin\nGuerra",
      "Esther\nHamann",
      "Arne\nHebig",
      "Regina\nHeldal",
      "Rogardt\nHendriks",
      "Dennis\nHernández López",
      "José Antonio\nHosseinibaghdadabadi",
      "Mohsen\nIovino",
      "Ludovico\nJézéquel",
      "Jean-Marc\nJongeling",
      "Robbert\nJovanovic",
      "Ana\nKahani",
      "Nafiseh\nKehrer",
      "Timo\nKienzle",
      "Jörg\nKotte",
      "Oliver\nKpodjedo",
      "Sègla\nKulkarni",
      "Vinay\nLalonde",
      "Timothé\nLawford",
      "Mark\nLima",
      "Keila\nMartínez-Lasaca",
      "Francisco\nMaurer",
      "Paulina\nMussbacher",
      "Gunter\nN. Damasceno",
      "Carlos Diego\nNguyễn",
      "Hoàng\nNistala",
      "Sri Harsha\nOortwijn",
      "Wytse"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a331/248000a331.pdf"
  },
  {
    "title": "Leveraging modeling concepts and techniques to address challenges in network management",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Managing a large enterprise network is a challenging task that involves configuring and monitoring a large number of networking devices from different vendors. To simplify network management, modeling techniques have been extensively applied to model network configurations and monitoring data. The most recent proposed solution in this context are OpenConﬁg models, which enable vendor-neutral automation. However, adopting networking models requires significant effort and cooperation from various stakeholders. The focus of this paper is to explore the challenges associated with adopting networking models, specifically OpenConﬁg models, from three primary viewpoints: network engineers, internet service/content providers, and networking software/hardware vendors. We also discuss possible solutions via application of software modeling techniques to aid in the successful adoption of networking models.",
    "keywords": [
      "OpenConﬁg",
      "YANG",
      "Model-based Network Management",
      "NETCONF",
      "gNMI"
    ],
    "authors": [
      "Naﬁseh Kahani",
      "Mojtaba Bagherzadeh",
      "Reza Ahmadi",
      "Juergen Dingel"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a055/248000a055.pdf"
  },
  {
    "title": "Digital Twins for Cyber-Biophysical Systems: Challenges and Lessons Learned",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Istvan David",
      "Pascal Archambault",
      "Quentin Wolak",
      "Cong Vinh Vu",
      "Timothé Lalonde",
      "Kashif Riaz",
      "Eugene Syriani",
      "Houari Sahraoui"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z005/248000z005.pdf"
  },
  {
    "title": "Marine Data Observability using KPIs: An MDSE Approach",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "The 2023 climate change report states that the current temperature rise has led to recurring and hazardous weather events, devastating communities and the planet. Ocean observation systems and marine data generated by them are crucial for predicting these extreme events, understanding the ecosystem states, and regulating marine industries. Many regional and global initiatives have been supporting the collection and sharing of more data, filling gaps in ocean observation. However, some challenges can impact the quality of marine data at different points of data delivery pipelines: from acquisition and transmission at the Internet-of-Underwater-Things (IoUT) level up to storage and sharing. IoUT devices can have challenges due to limited battery, rough underwater terrain, error-prone wireless underwater communication, or low communication bandwidth to the cloud. Thus, mechanisms must be put in place to allow monitoring of data quality throughout the delivery pipeline, to optimize the usage of data and improve decision-making based on the data. This study explores observation of marine data quality on a data platform using Key Performance Indicators (KPIs). We have created a model of the platform and specified KPIs. Both are fulfilled by platform-collected data quality metrics, with the purpose to infer the state of the data in the platform over different periods. Our results show that the model-based implementation is able to function as a semantic translator between a metric monitoring toolkit and the platform objectives, integrating it into an observable subsystem for the overall middleware data platform.",
    "keywords": [
      "data observability",
      "data quality",
      "smart ocean",
      "MDSE"
    ],
    "authors": [
      "Keila Lima",
      "Ludovico Iovino",
      "Maria Teresa Rossi",
      "Rogardt Heldal",
      "Tosin Daniel Oyetoyan",
      "Martina De Sanctis"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a024/248000a024.pdf"
  },
  {
    "title": "Model Sensemaking Strategies: Exploiting Meta-Model Patterns to Understand Large Models",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "The increasing popularity of model-based and low-code platforms has raised the need to understand large models – especially in industrial settings. However, current approaches mainly rely on graph-based visual metaphors, which do not scale well with large model sizes. To address this issue, we introduce model sensemaking strategies: purposeful model visualisations based on alternative visual metaphors. We define them as reusable patterns that yield tailored visualisations when applied to meta-models. This paper presents a catalogue of domain-specific and domain-agnostic sensemaking strategies, and a recommender that suggests suitable strategies for a given meta-model. To showcase the framework’s applicability, we have implemented some of these strategies in Dandelion, an industrial, low-code graphical language workbench for the cloud. Using this platform, we have evaluated the effectiveness of the strategies to visualise large industrial models by the UGROUND company.",
    "keywords": [
      "model sensemaking strategies",
      "large model visualisation",
      "model-driven engineering",
      "low-code platforms"
    ],
    "authors": [
      "Francisco Mart´ınez-Lasaca",
      "Pablo D´ıez",
      "Esther Guerra",
      "Juan de Lara"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a261/248000a261.pdf"
  },
  {
    "title": "Incremental Model Transformations with Triple Graph Grammars for Multi-version Models",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Like conventional software projects, projects in model-driven software engineering require adequate management of multiple versions of development artifacts, importantly allowing living with temporary inconsistencies. In previous work, we have introduced multi-version models for model-driven software engineering, which allow checking well-formedness and finding merge conflicts for multiple versions of a model at once. However, also for multi-version models, situations where different artifacts, that is, different models, are linked via automatic model transformations have to be handled.\n\nIn this paper, we propose a technique for jointly handling the transformation of multiple versions of a source model into corresponding versions of a target model, which enables the use of a more compact representation that may afford improved execution time of both the transformation and further analysis operations. Our approach is based on the well-known formalism of triple graph grammars and the aforementioned encoding of model version histories called multi-version models. In addition to batch transformation of an entire model version history, the technique also covers incremental synchronization of changes in the framework of multi-version models.\n\nWe show the correctness of our approach with respect to the standard semantics of triple graph grammars and conduct an empirical evaluation to investigate the performance of our technique regarding execution time and memory consumption. Our results indicate that the proposed technique affords lower memory consumption and may improve execution time for batch transformation of large version histories, but can also come with computational overhead in unfavorable cases.",
    "keywords": [
      "Multi-version Models",
      "Triple Graph Grammars",
      "Incremental Model Transformation"
    ],
    "authors": [
      "Matthias Barkowsky",
      "Holger Giese"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a296/248000a296.pdf"
  },
  {
    "title": "Model-Driven Prompt Engineering",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Generative artificial intelligence (AI) systems are capable of synthesizing complex content such as text, source code or images according to the instructions described in a natural language prompt. The quality of the output depends on crafting a suitable prompt. This has given rise to prompt engineering, the process of designing natural language prompts to best take advantage of the capabilities of generative AI systems.\nThrough experimentation, the creative and research communities have created guidelines and strategies for creating good prompts. However, even for the same task, these best practices vary depending on the particular system receiving the prompt. Moreover, some systems offer additional features using a custom platform-speciﬁc syntax, e.g., assigning a degree of relevance to speciﬁc concepts within the prompt.\nIn this paper, we propose applying model-driven engineering to support the prompt engineering process. Using a domain-speciﬁc language (DSL), we deﬁne platform-independent prompts that can later be adapted to provide good quality outputs in a target AI system. The DSL also facilitates managing prompts by providing mechanisms for prompt versioning and prompt chaining. Tool support is available thanks to a Langium-based Visual Studio Code plugin.",
    "keywords": [
      "prompt engineering",
      "model-driven engineering",
      "domain-speciﬁc language",
      "generative AI",
      "large language models"
    ],
    "authors": [
      "Robert Clarisó\nJordi Cabot"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a047/248000a047.pdf"
  },
  {
    "title": "Automatic Security-Flaw Detection\nReplication and Comparison",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Threat Modeling is an essential step in secure\nsoftware system development. It is a manual, attacker-centric\napproach for identifying architecture-level security flaws during\nthe planning phase of software systems. In the last years,\nacademia presented two methods to automate threat detection\nthat do not focus on a particular class of security flaws but offer\ngeneral-purpose means to describe security flaws.\nThis paper compares both approaches on an equal data\nfoundation that was published with one of the approaches. There-\nfore, we specify a model-to-model transformation for converting\nbetween the approaches to allow this conceptual replication.\nAdditionally, we provide security flaw patterns for the second\napproach that any user of the approach can use. We then\nreplicate the detection with the second security flaw detection\napproach to compare both approaches. We focus our analysis\non differences between automation-specific and approach-specific\nfinding misclassifications on identifying whether some flaws are\nharder to find with an automated approach than others.\nWe find that missed flaws usually stem from the imprecise\ndefinition of security flaws, while incorrectly identified flaws\nare approach-dependent. Despite that, both approaches perform\nsimilarly. The knowledge base, the transformation scripts and the\nevaluation script are publicly available to support the research\ncommunity.",
    "keywords": [
      "threat modeling",
      "dataflow diagrams",
      "security\nflaw detection",
      "automation",
      "interoperability",
      "comparison"
    ],
    "authors": [
      "Bernhard J. Berger\nChristina Plump"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a084/248000a084.pdf"
  },
  {
    "title": "A Model-driven and Template-based Approach for Requirements Speciﬁcation",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Requirements speciﬁcation and veriﬁcation play an important role in the certiﬁcation of safety-critical software (SCS). These activities are costly and error-prone because SCS exhibit a high number of requirements and most SCS manufacturers are still using natural language to specify these requirements. On one hand, natural language can introduce ambiguity and inconsistency. On the other hand, formal languages add an overhead to the requirements speciﬁcation because of their complexity. Controlled Natural Languages (CNLs) ﬁll these gaps by offering a middle-ground solution, although not yet well adopted by the industry. In this paper, we introduce an approach that combines CNLs and model-driven engineering (MDE) for requirements speciﬁcation. The approach was proposed to support an industrial partner in the certiﬁcation process of a SCS. Our approach uses templates and relies on two types of models: models that specify the templates, and a model of the domain of the system at hand. Using models of the templates enables to automate some requirements analysis tasks. Using a domain model allows the auto-completion and veriﬁcation of requirements speciﬁed using the templates. We implemented the approach and validated it using three case studies and more than a thousand requirements. We observed that our approach and underlying templates are applicable across domains and that the templates yield requirements with better quality in terms of necessity, ambiguity, completeness, singularity, and veriﬁability.",
    "keywords": [
      "Model-driven engineering",
      "Requirements engineering",
      "Requirements speciﬁcation",
      "Controlled natural language",
      "Requirement templates",
      "Safety critical systems",
      "Domain models"
    ],
    "authors": [
      "Ikram Darif",
      "Cristiano Politowski",
      "Ghizlane El Boussaidi",
      "Imen Benzarti and S`egla Kpodjedo"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a239/248000a239.pdf"
  },
  {
    "title": "Proceedings ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems MODELS 2023",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z001/248000z001.pdf"
  },
  {
    "title": "gLTSdiff: A Generalized Framework for Structural Comparison of Software Behavior",
    "submission-date": "2023/00",
    "publication-date": "2023/00",
    "abstract": "State machine models, such as labeled transition systems and (extended) finite automata, can be structurally compared, for instance to find potential behavioral regressions in new software versions, to evaluate the accuracy of different model learning algorithms, and to fingerprint software for security applications. The state-of-the-art LTSDiff structural comparison algorithm has limited assumptions, making it broadly applicable. However, representation-specific information is not taken into account, requiring adaptations to prevent sub-optimal or even invalid results. We propose gLTSdiff, which generalizes and extends LTSDiff, allowing a wide range of state machine models to be compared, by recursively comparing the structure of state and transition labels. Additional challenges that we faced while applying LTSDiff in industrial practice are also addressed by gLTSdiff, as it rewrites undesired difference patterns, supports comparison of any number of input models, and allows for an effort/quality trade-off. gLTSdiff is implemented as an extensible open source library for structural model comparison. Using multiple large-scale industrial and open source case studies, we evaluate both its practical value and its various improvements.",
    "keywords": [],
    "authors": [
      "Dennis Hendriks",
      "Wytse Oortwijn"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a285/248000a285.pdf"
  },
  {
    "title": "Not found",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z017/248000z017.pdf"
  },
  {
    "title": "On Developing and Operating GLSP-based Web Modeling Tools: Lessons Learned from BIGUML",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "The development of web-based modeling tools still poses significant challenges for developers. The Graphical Language Server Platform (GLSP) reduced some of these challenges by providing the necessary frameworks to efficiently create web modeling tools. However, more knowledge and experience are required regarding developing GLSP-based web modeling tools. This paper discusses the challenges and lessons learned after working with GLSP and realizing several GLSP-based modeling tools. More concretely, experiences, concepts, steps to be followed to develop and operate a GLSP-based web modeling tool, and the advantages and disadvantages of working with GLSP are discussed. As a proof of concept, we will report on the realization of a GLSP-based UML editor called BIGUML. Through BIGUML, we show that our procedure and the reference architecture we developed resulted in a scalable and flexible GLSP-based web modeling tool. The lessons learned, the procedural approach, the reference architecture, and the critical reflection on the challenges and opportunities of using GLSP provide valuable insights to the community and shall ease the decision of whether or not to use GLSP for future tool development projects.",
    "keywords": [
      "Modeling tool",
      "GLSP",
      "web modeling",
      "lessons learned",
      "LSP",
      "eclipse"
    ],
    "authors": [
      "Haydar Metin",
      "Dominik Bork"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a129/248000a129.pdf"
  },
  {
    "title": "Variability-aware Neo4j for Analyzing a Graphical Model of a Software Product Line",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "Comprehensive analysis of a software product line (SPL) is expensive because the number of products to be analyzed is exponential in the number of the SPL’s features. To compensate, we analyze a model of the SPL rather than the source code, thereby reducing the size of the artifact under analysis. In this paper, we facilitate SPL analysis by lifting the Neo4j query engine to apply to an SPL model, so that a Neo4j query returns variability-aware results that cover all the SPL’s products. We used the lifted Neo4j to analyze five nontrivial SPLs (with respect to dataflows, control-flows, component interactions, etc.) and found that the overhead for returning variability-aware results for the full SPL, versus the results for just one product, ranges from 1.88% to 456%. In comparison to related work V-Souffl´e (a lifted Datalog engine), lifted Neo4j is able to report complete path results whereas V-Souffl´e reports only endpoints of paths. When both analyzers report the same results (e.g., endpoints of paths), lifted Neo4j is usually more efficient.",
    "keywords": [
      "Graphical software models",
      "Software product line models",
      "Lifted analyses",
      "Neo4j"
    ],
    "authors": [
      "Xiang Chen",
      "David R. Cheriton",
      "Joanne M. Atlee"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a307/248000a307.pdf"
  },
  {
    "title": "Timing-Aware Software-in-the-Loop Simulation of Automotive Applications with FMI 3.0",
    "submission-date": "2023/10",
    "publication-date": "2023/10",
    "abstract": "In embedded real-time automotive systems, Software-in-the-Loop (SiL) represents the state-of-the-art for testing software code at design time. SiL environments focus on testing the functional software behaviour, typically neglecting the timing non-idealities introduced by the target embedded hardware. This separation of concerns prevents a credible virtual testing and validation of time-critical systems. In this paper, we propose an industry-viable modular co-simulation architecture based on the Functional Mock-up Interface (FMI) 3.0 standard, coupling timing simulation and functional simulations to obtain a timing-aware functional simulation of automotive applications. The proposed method enables an evaluation of the behaviour of functional software on the target hardware earlier in the development process. Also, our solution allows for the co-simulation of submodels generated with different tools, with minimal modifications required. Ultimately, this approach enables front-loading of development efforts, leading to reduced costs and time to market. A case study is presented to show a detailed examination of the proposed architecture.",
    "keywords": [
      "Software-in-the-Loop",
      "timing-aware simulation",
      "Functional Mock-up Interface",
      "Discrete-Event Co-Simulation"
    ],
    "authors": [
      "Srivathsan Ravi",
      "Laura Beermann",
      "Oliver Kotte",
      "Paolo Pazzaglia",
      "Mythreya Vinnakota",
      "Dirk Ziegenbein",
      "Arne Hamann"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a062/248000a062.pdf"
  },
  {
    "title": "Applicability of Model Checking for Verifying Spacecraft Operational Designs",
    "submission-date": "2023/03",
    "publication-date": "2023/03",
    "abstract": "Guaranteeing safety and correctness is one of the main objectives during the development of space systems. This is a challenging task, since many different engineering disciplines are involved in the development and the constituent parts of a spacecraft are highly interconnected and interdependent. Increasingly, formal methods such as model checking are applied to verify safety-critical parts of spacecraft designs and also implementation, since they may prove the absence of design errors. Generally, a major challenge for adopting model checking into the design process is its scalability. Usually, the whole state space of a system, which grows exponentially with, e.g., the number of parallel processes, must be explored.\nIn this paper, we consider operational designs of spacecraft as they may occur during early development phases and systematically evaluate the scalability of model checking for verifying such models. For this, we created an arbitrarily scalable operational design describing the mode management of a satellite. Transformations of the models into the modeling languages of different model-checking tools enables a comparative scalability study of various model-checking algorithms. The evaluation shows promising results for symbolic model-checking approaches. A comparatively low analysis time and memory usage suggest that model checking for early operational designs can be incorporated into existing design processes.",
    "keywords": [
      "Aerospace",
      "Formal Models",
      "Formal Methods",
      "Model Checking"
    ],
    "authors": [
      "Philipp Chrszon",
      "Paulina Maurer",
      "George Saleip",
      "Sascha M¨uller",
      "Philipp M. Fischer",
      "Andreas Gerndt",
      "Michael Felderer"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a206/248000a206.pdf"
  },
  {
    "title": "Uncertainty-aware consistency checking in industrial settings",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "In this work, we explore how we can assist engineers in managing, in a lightweight way, both consistency and design uncertainty during the creation and maintenance of models and other development artifacts. We propose annotating degrees of doubt to indicate design uncertainties on elements of development artifacts. To combine multiple opinions, we use the fusion operators of subjective logic. We show how these annotations can be used to identify, prioritize, and resolve uncertainty and inconsistency. To do so, we identify the types of design uncertainty and inconsistency to be addressed in two concrete industrial settings and show a prototype implementation of our approach to calculating the uncertainty and inconsistency in these cases. We show how making design uncertainty explicit could be used to tolerate inconsistencies with high uncertainty, prioritize inconsistencies with low associated uncertainty, and uncover previously hidden potential inconsistencies.",
    "keywords": [
      "Uncertainty",
      "Consistency management",
      "Model-Based Development"
    ],
    "authors": [
      "Robbert Jongeling",
      "Antonio Vallecillo"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000a073/248000a073.pdf"
  },
  {
    "title": "MODELS 2023",
    "submission-date": "Not found",
    "publication-date": "Not found",
    "abstract": "Not found",
    "keywords": [],
    "authors": [
      "Mohammed Rizwan Ali",
      "Oussama Ben Sghaier",
      "Paul Bittner",
      "Beatriz Cabrero-Daniel",
      "Robert Clarisó",
      "Renzo Degiovanni",
      "Khanh-Hoang Doan",
      "Flo Drux",
      "Sebastian Ehmes",
      "Josselin Enet",
      "Lars Fritsche",
      "Sandra Greiner",
      "Hendrik Göttmann",
      "Liping Han",
      "Alexander Hellwig",
      "José Antonio Hernández López",
      "Matthieu Jimenez",
      "Aton Kamanda",
      "Hendrik Kausch",
      "Faezeh Khorram",
      "Yves Kirschner",
      "Max Kratz",
      "Tim Kräuter",
      "Lars König",
      "Louis-Edouard Lafontant",
      "Sami Lazreg",
      "Alexander Lieb",
      "Lukas Netz",
      "Bentley Oakes",
      "Mathias Pfeiffer",
      "Sreedhar Reddy",
      "Lucas Sakizloglou",
      "Alexander Schultheiss",
      "Mazyar Seraj",
      "Karsten Sohr",
      "Max Stachon"
    ],
    "file_path": "data/models/models23/MODELS2023-5xtY4b9zCM5QafXrwgQTzw/248000z015/248000z015.pdf"
  },
  {
    "title": "EditQL: A Textual Query Language for Evolving Models",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Context: Technically sophisticated systems are the result of the\njoint work of several domain experts. However, the more people\ncollaborate, the more important it becomes to make the model evo-\nlution and its single edit operations accessible and comprehensible\nfor involved stakeholders. Objective: We developed the textual and\nsemantic aware query language EditQL. It enables domain experts\nto search for model versions, changes, and causing edit operations\nwithin a model’s edit history. Based on an operation-based ver-\nsioning system, the query language covers both edit operations\nand all model states. Method: We systematically elaborate the re-\nquirements of a query language for edit histories. Based on this,\nwe present a DSL integrated into an existing modeling tool. We\nconducted a mixed-methods usability study with 15 participants\nin which they had to answer various questions about a model’s\nevolution using EditQL. Results: All participants agreed on the\nusefulness of the query language, particularly the possibility of\nquerying for semantic changes in the model. The measured System\nUsability Scale (SUS) scores range from OK to good. In addition,\nwe identified a set of possible improvements. Conclusion: The study\nconfirmed that EditQL and the underlying concepts are suitable\ntools to help domain experts understand the evolution of a model.",
    "keywords": [
      "versioning",
      "operation-based",
      "query language",
      "model evolution",
      "usability study",
      "collaboration"
    ],
    "authors": [
      "Jakob Pietron",
      "Benedikt Jutz",
      "Alexander Raschke",
      "Matthias Tichy"
    ],
    "file_path": "data/models/models24/3640310.3674101.pdf"
  },
  {
    "title": "Towards Automated Test Scenario Generation for Assuring COLREGs Compliance of Autonomous Surface Vehicles",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "International maritime traffic is controlled by collision-avoidance regulations (COLREGs) with 41 standardized rules describing how a vessel should navigate in the proximity of other vessels. Since some rules can be overridden by human judgement when resolving critical encounters of vessels, justifying COLREGs compliance has become a significant challenge in the increasing presence of autonomous surface vehicles (ASVs) operated without (or with only remote) human control. This paper provides a high-level framework and long-term research agenda towards the automated synthesis of test scenarios to assure COLREGs compliance for ASVs by exploiting various model-driven engineering techniques. By adapting ideas from testing self-driving cars, we envisage a multi-layered test scenario generation approach involving functional, logical and concrete scenarios. In the current paper, we demonstrate how functional scenarios of COLREGs situations between given vessels can be precisely formalized by using metamodels, domain-specific graph models and first-order logic graph constraints. By using automated model generation techniques, we derive a complete set of functional-level test scenarios, which includes all possible COLREGs situations that may arise between given vessels. As initial result, we provide several dangerous situations involving only three vessels where a potential collision may occur even when all vessels follow the COLREGs, which showcases that some COLREGs rules need further clarification for the safe regulation of ASVs.",
    "keywords": [
      "autonomous surface vehicles",
      "COLREGs",
      "test scenario generation",
      "consistent model generation",
      "qualitative abstraction"
    ],
    "authors": [
      "Ulf Kargén",
      "Dániel Varró"
    ],
    "file_path": "data/models/models24/3640310.3674098.pdf"
  },
  {
    "title": "Modeling Languages for Automotive Digital Twins: A Survey Among the German Automotive Industry",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "The demand for digital twins and suitable modeling techniques in the automotive industry is increasing rapidly. Yet, there is no common understanding of digital twins in automotive, nor are there modeling techniques established to create automotive digital twins. Recent studies on digital twins focus on the analysis of the literature on digital twins for automotive or in general and, thus, neglect the industrial perspective of automotive practitioners. To mitigate this gap between scientific literature and the industrial perspective, we conducted a questionnaire survey among experts in the German automotive industry to identify i) the desired purposes for and capabilities of digital twins and ii) the modeling techniques related to engineering and operating digital twins across the phases of automotive development. To this end, we contacted 189 members of the Software-Defined Car research project and received 96 responses. The results show that digital twins are considered most useful in the usage and support phase of automotive development, representing vehicles as-operated. Moreover, simulation models, source code, and business process models are currently considered the most important models to be integrated into a digital twin alongside the associated, established tools.",
    "keywords": [
      "modeling languages",
      "digital twins",
      "automotive",
      "survey"
    ],
    "authors": [
      "Dominik Fuchß",
      "Thomas Kühn",
      "Dirk Neumann",
      "Christer Neimöck",
      "Jérôme Pfeiffer",
      "Robin Liebhart",
      "Christian Seiler",
      "Anne Koziolek",
      "Andreas Wortmann"
    ],
    "file_path": "data/models/models24/3640310.3674100.pdf"
  },
  {
    "title": "Meta-Modelling Kindness",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Kindness is a psycho-social phenomenon that is also recognized as\nan important pro-social behaviour. The use of digital technology\nprovides opportunities to promote kindness in various ways, such\nas in social media campaigns and online communities. In princi-\npale, software engineers are well positioned to develop automated\nsystems that can facilitate software-mediated kindness. However,\nin practice, incorporating kindness concerns explicitly in the de-\nvelopment and use of software systems is challenging: kindness is\nhighly context dependent, affected by a range of factors such as\nintentions and opportunity.\n\nIn this paper, we explore systematic ways in which kindness\nconcerns can be considered by software engineers. We propose a\nnovel meta-model that captures essential entities and relations as-\nociated with kindness. The meta-model enables the representation\nof possible instances or opportunities for performing acts of kind-\nness, by considering the actors involved (such as giver, receiver, and\nobserver), their psychological and social attributes that promote\nkindness (such as emotional states and social relatedness), the acts\nneeded to fulfil kindness opportunities (such as motivation, ability,\nand timeliness), and other contextual factors (such as location and\ntime). Our meta-model is demonstrated through two software ap-\nplication scenarios that enable charitable donations and kindness in\nbusiness. Overall, our proposal offers a first, tentative, but concrete\nstep towards enabling kind computing, and promoting kindness in\nsoftware systems.",
    "keywords": [
      "Kindness",
      "Meta-Modelling",
      "Software Engineering",
      "Kind Computing"
    ],
    "authors": [
      "Faeq Alrimawi",
      "Bashar Nuseibeh"
    ],
    "file_path": "data/models/models24/3640310.3674095.pdf"
  },
  {
    "title": "AlloyASG: Alloy Predicate Code Representation as a Compact Structurally Balanced Graph",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Writing declarative models has numerous benefits, ranging from automated reasoning and correction of design-level properties to automated testing and debugging of system implementations. Unfortunately, the model itself needs to be correct to gain these benefits. Alloy is a commonly used modeling language that has several existing efforts to repair faulty models automatically. Currently, these efforts are search-based methods that use an Abstract Syntax Tree (AST) representation of the model and do not scale, as ASTs suffer from exponential growth in their data size due to duplicate nodes. To address this issue, we introduce a novel code representation schema, Complex Structurally Balanced Abstract Semantic Graph (CSBASG), which represents code as a complex-weighted directed graph that lists a semantic element as a node in the graph and ensures its structural balance for almost finitely enumerable code segments. We evaluate the efficiency of our CSBASG representation for Alloy models in terms of it’s compactness compared to ASTs, and we explore if a CSBASG can ease the process of comparing two Alloy predicates. Lastly, we identify several future applications of CSBASG, including Alloy code generation and automated repair.",
    "keywords": [],
    "authors": [
      "Guanxuan Wu",
      "Allison Sullivan"
    ],
    "file_path": "data/models/models24/3640310.3674088.pdf"
  },
  {
    "title": "Mutation Testing of Java Bytecode: A Model-Driven Approach",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Mutation testing is an approach to checking the robustness of test suites. The program code is slightly changed by mutations to inject bugs. A test suite is robust enough if it finds such bugs. Mutation testing tools typically integrate sets of mutation operators such as, for example, swapping arithmetic operators; modern tools typically work with compiled code such as Java bytecode. The mutations must be defined in such a way that the mutated program can still be loaded and executed. The results of mutation tests depend directly on the possible mutations. More advanced mutations and even domain-specific mutations can pose another challenge to the test suite. Since the classical, non-model-based mutation testing tools do not support the specification of advanced mutation operators well, we propose a model-driven approach where mutations of Java bytecode can be flexibly defined by model transformation. Our approach also provides advanced mutation operators for modifying object-oriented structures, Java-specific properties and API method calls, making it the only mutation testing tool for Java bytecode that supports such mutations. To further improve the effectiveness of mutation testing, mutants are generated only for bytecode that is covered by tests. Our approach is implemented in the MMT tool. It has been evaluated against non-model-based mutation testing tools for its ability to generate mutants close to real bugs. The experiments make use of Defects4J, a well-established collection of real-world Java projects with reproducible bugs.",
    "keywords": [
      "Mutation testing",
      "Java bytecode",
      "Model transformation"
    ],
    "authors": [
      "Christoph Bockisch",
      "Deniz Eren",
      "Sascha Lehmann",
      "Daniel Neufeld",
      "Gabriele Taentzer"
    ],
    "file_path": "data/models/models24/3640310.3674103.pdf"
  },
  {
    "title": "EpiMDE: A Model-Driven Engineering Platform for Epidemiological Modeling",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Modeling is a critical step in studying epidemics. It allows us to better understand and predict the progression of a disease, design interventions such as vaccination, and assess their impact. Current epidemics are modeled using compartmental and mathematical models. While these are enough to achieve the primary goal of modeling, they suffer from shortcomings with respect to communicating and sharing the models, comparison and validation, and reproducibility. In this work, we propose the use of model-driven software engineering principles, to better represent disease models and facilitate the model management operations. We present an extensible metamodel for epidemics and an integrated development environment to allow epidemiologists to create and manage their models and simulations. We present the use of our platform on a COVID-19 model, where we show that the resulting model is more concise yet structurally and functionally equivalent to the original.",
    "keywords": [
      "epidemiological modeling",
      "integrated development environment",
      "reproducibility",
      "extensibility",
      "metamodeling"
    ],
    "authors": [
      "Bruno Curzi-Laliberté",
      "Marios Fokaefs",
      "Michalis Famelis",
      "Mohammad Hamdaqa"
    ],
    "file_path": "data/models/models24/3640310.3674104.pdf"
  },
  {
    "title": "Requirement-Driven Generation of Distributed Ledger Architectures",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Cross-organizational, blockchain-based distributed ledger networks in general, and those based on Hyperledger Fabric in particular, have an architecture which can be adapted to specific application requirements. However, network design can be a particularly challenging task, as the connection between architectural and deployment decisions and extra-functional properties can be subtle and the requirements may contradict each other, requiring trade-offs. In this paper, we propose a model-based distributed ledger architecture design approach which enables expert exploration of design options. We capture key requirements and define architecture fragments using partial modelling. We enumerate qualitatively different architectural candidates by graph generation. We evaluate and rank order candidates in logic solver tooling. As a result, our approach provides generative architectures for distributed ledger networks by enabling efficient exploration of design alternatives.",
    "keywords": [
      "Model Generation",
      "Partial Modelling",
      "Blockchain",
      "HyperLedger Fabric",
      "Design-space Exploration",
      "Generative Architecture"
    ],
    "authors": [
      "Noor Mohammed Sabr Al-Gburi",
      "András Földvári",
      "Kristóf Marussy",
      "Oszkár Semeráth",
      "Imre Kocsis"
    ],
    "file_path": "data/models/models24/3640310.3674097.pdf"
  },
  {
    "title": "Tree-Based versus Hybrid Graphical-Textual Model Editors: An Empirical Study of Testing Specifications",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Tree-based model editors and hybrid graphical-textual model editors have advantages and limitations when editing domain mod-els. Data is displayed hierarchically in tree-based model editors, whereas hybrid graphical-textual model editors capture high-level domain concepts graphically and low-level domain details textu-ally. We conducted an empirical user study with 22 participants to evaluate the implicit assumption of system modellers that hybrid notations are superior, and to investigate the tradeoffs between the default EMF-based tree model editor and a Sirius/Xtext-based hybrid model editor. The results of the user study indicate that users largely prefer the hybrid editor and are more confident with hybrid notations for understanding the meaning of conditions. Further-more, we found that the tree editor provided superior performance for analysing ordered lists of model elements, whereas activities requiring the comprehension or modelling of complex conditions were carried out faster through the hybrid editor.",
    "keywords": [
      "Hybrid Notations",
      "Model Editors",
      "Fuzz Testing",
      "Empirical Study"
    ],
    "authors": [
      "Ionut Predoaia",
      "James Harbin",
      "Simos Gerasimou",
      "Christina Vasiliou",
      "Dimitris Kolovos",
      "Antonio García-Domínguez"
    ],
    "file_path": "data/models/models24/3640310.3674102.pdf"
  },
  {
    "title": "Towards Runtime Monitoring for Responsible Machine Learning using Model-driven Engineering",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Machine learning (ML) components are used heavily in many current software systems, but developing them responsibly in practice remains challenging. ‘Responsible ML’ refers to developing, deploying and maintaining ML-based systems that adhere to human-centric requirements, such as fairness, privacy, transparency, safety, accessibility, and human values. Meeting these requirements is essential for maintaining public trust and ensuring the success of ML-based systems. However, as changes are likely in production environments and requirements often evolve, design-time quality assurance practices are insufficient to ensure such systems’ responsible behavior. Runtime monitoring approaches for ML-based systems can potentially offer valuable solutions to address this problem. Many currently available ML monitoring solutions overlook human-centric requirements due to a lack of awareness and tool support, the complexity of monitoring human-centric requirements, and the effort required to develop and manage monitors for changing requirements. We believe that many of these challenges can be addressed by model-driven engineering. In this new ideas paper, we present an initial meta-model, model-driven approach, and proof of concept prototype for runtime monitoring of human-centric requirements violations, thereby ensuring responsible ML behavior. We discuss our prototype, current limitations and propose some directions for future work.",
    "keywords": [
      "Runtime monitoring",
      "Responsible ML",
      "Human-centric requirements",
      "Machine learning components",
      "Model-driven engineering"
    ],
    "authors": [
      "Hira Naveed",
      "John Grundy",
      "Chetan Arora",
      "Hourieh Khalajzadeh",
      "Omar Haggag"
    ],
    "file_path": "data/models/models24/3640310.3674092.pdf"
  },
  {
    "title": "Text2VQL: Teaching a Model Query Language to Open-Source Language Models with ChatGPT",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "While large language models (LLMs) like ChatGPT has demonstrated impressive capabilities in addressing various software engineering tasks, their use in a model-driven engineering (MDE) context is still in an early stage. Since the technology is proprietary and accessible solely through an API, its use may be incompatible with the strict protection of intellectual properties in industrial models. While there are open-source LLM alternatives, they often lack the power of proprietary models and require extensive data fine-tuning to realize their full potential. Furthermore, open-source datasets tailored for MDE tasks are scarce, posing challenges for training such models effectively.\n\nIn this work, we introduce Text2VQL, a framework that generates graph queries captured in the VIATRA Query Language (VQL) from natural language specifications using open-source LLMs. Initially, we create a high-quality synthetic dataset comprising pairs of queries and their corresponding natural language descriptions using ChatGPT and VIATRA parser. Leveraging this dataset, we use parameter-efficient tuning to specialize three open-source LLMs, namely, DeepSeek Coder 1b, DeepSeek Coder 7b, and CodeLlama 7b for VQL query generation. Our experimental evaluation demonstrates that the fine-tuned models outperform the base models in query generation, highlighting the usefulness of our synthetic dataset. Moreover, one of the fine-tuned models achieves performance comparable to ChatGPT.",
    "keywords": [
      "large language model (LLM)",
      "model query language",
      "query generation",
      "VIATRA Query Language (VQL)",
      "ChatGPT"
    ],
    "authors": [
      "José Antonio Hernández López",
      "Máté Földiák",
      "Dániel Varró"
    ],
    "file_path": "data/models/models24/3640310.3674091.pdf"
  },
  {
    "title": "A Comparative Analysis of Energy Consumption Between Visual Scripting models and C++ in Unreal Engine: Raising Awareness on the importance of Green MDD",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Video game engines are used in most modern video games because they simplify and speed up development. In addition, some of the most popular engines, such as Unreal Engine 5 (UE5), also integrate visual scripting tools. Visual scripting in UE5, through Blueprints, is a model-driven development approach that replaces text code, like C++, with a visual language of interconnected nodes representing functions and data flows, forming a flowchart-like logic diagram. This approach simplifies game development by abstracting complex code into intuitive, visual models, enabling creators to construct and iterate game components without extensive programming knowl-edge. Although Blueprint models usually decrease the complexity of implementing components, thus accelerating the development, they might lead to less energy-efficient runtime performance than C++. In this work, we evaluate the energy consumption of three relevant video game components (health system management, in-puts processing, and collections operations for an inventory), each implemented with Blueprint models and C++. The results show that the energy consumption per frame when using C++ is up to 48% lower than when using Blueprint models. The combination of artistic and technical profiles in video game developments has favoured the adoption of Blueprint models. However, there is a lack of works analyzing the energy consumption. Until this work, there was no evidence that the success of models for developing video games, like the one under study in this work, was accompanied by a cost in energy consumption for certain situations. Given the huge popularity of video games, this cost in energy might reach up to the equivalent of the energy consumption of 28 million European households.",
    "keywords": [
      "Energy consumption",
      "Video Games",
      "Green software",
      "Green Video Games",
      "Software sustainability",
      "Game Engines",
      "Unreal Engine",
      "Soft-ware Models",
      "Visual Scripting",
      "Blueprints",
      "C++",
      "Game Software Engineering"
    ],
    "authors": [
      "Javier Verón",
      "Carlos Pérez",
      "Coral Calero",
      "MªÁngeles Moraga",
      "Francisca Pérez",
      "Carlos Cetina"
    ],
    "file_path": "data/models/models24/3640310.3674099.pdf"
  },
  {
    "title": "A DSL for Testing LLMs for Fairness and Bias",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Large language models (LLMs) are increasingly integrated into software systems to enhance them with generative AI capabilities. But LLMs may reflect a biased behavior, resulting in systems that could discriminate against gender, age or ethnicity, among other ethical concerns. Society and upcoming regulations will force companies and development teams to ensure their AI-enhanced software is ethically fair. To facilitate such ethical assessment, we propose Lang-BiTe, a model-driven solution to specify ethical requirements, and customize and automate the testing of ethical biases in LLMs. The evaluation can raise awareness on the biases of the LLM-based components of the system and/or trigger a change in the LLM of choice based on the requirements of that particular application. The model-driven approach makes both the requirements specification and the test generation platform-independent, and provides end-to-end traceability between the requirements and their assessment. We have implemented an open-source tool set, available on GitHub, to support the application of our approach.",
    "keywords": [
      "Model-Driven Engineering",
      "Domain-Specific Language",
      "Testing",
      "Ethics",
      "Bias",
      "Red Teaming",
      "Large Language Models"
    ],
    "authors": [
      "Sergio Morales",
      "Robert Clarisó",
      "Jordi Cabot"
    ],
    "file_path": "data/models/models24/3640310.3674093.pdf"
  },
  {
    "title": "10 years of Model Federation with Openflexo: Challenges and Lessons Learned",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "In the context of complex system development, heterogeneous\nmodeling responds to the need to integrate several domains. This\nneed requires the use of the most appropriate formalism and tooling\nfor each domain to be efficient. Model federation promotes the\nsemantic interoperability of heterogeneous models by providing the\nmeans to reify correspondences between different model elements,\nadd custom behaviors and bridge the gap between technological\nspaces. As such, it can be used as an infrastructure to address many\ndifferent system engineering problems. This is what we have been\ndoing for over a decade, as part of a close collaboration between\na small software engineering startup and academia. This paper\nreports on this experience.\nConcretely, we discuss the context, ambitions, and challenges\nthat led to the inception of our practice of model federation, and we\npresent five use cases experiences, stemming from real industrial\nand academic needs, and elaborate on lessons learned. In addition,\nwe also report on challenges and lessons learned regarding the\ndevelopment and maintenance of a model-driven model federation\ntool, the Openflexo framework. Finally, we set up a road map for\nthe future of model federation and Openflexo.",
    "keywords": [
      "Model federation",
      "Model management",
      "Experience report"
    ],
    "authors": [
      "Jean-Christophe Bach",
      "Antoine Beugnard",
      "Joël Champeau",
      "Fabien Dagnat",
      "Sylvain Guérin",
      "Salvador Martínez"
    ],
    "file_path": "data/models/models24/3640310.3674084.pdf"
  },
  {
    "title": "Partial Bidirectionalization of Model Transformation Languages",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "While most model-transformation languages in Model-Driven Engineering are unidirectional, bidirectionality is valuable when artifacts need two-way synchronization. Although several bidirectional transformation engines have been developed, their behavior is generally considered more difficult to formulate and predict compared to the unidirectional case. In the bidirectionalization approach, users write the forward direction of their transformations in the same unidirectional language they are used to, and obtain a system that (besides performing the complete forward transformation) can automatically propagate in the backward direction the target updates. When possible, full bidirectionalization is desirable, but far from trivial.\n\nIn this paper we propose a partial bidirectionalization approach, by partial compilation of a unidirectional language into a bidirectional language, and coupled execution of the two language engines. Forward transformation is still complete, whereas the target updates that can be back-propagated are deletions and modifications of a well-defined part of the target model. While the extent of the bidirectionalization depends on the two coupled systems, in this paper we provide a general combination scheme and we briefly discuss its well-behavedness. Then we use our technique to bidirectionalize the ATL model-transformation language on top of the GRoundTram bidirectional graph-transformation system.",
    "keywords": [
      "Model Transformation",
      "Bidirectional Transformation",
      "Bidirectionalization",
      "Runtime Interoperation",
      "Transformation Engines"
    ],
    "authors": [
      "Soichiro Hidaka and Massimo Tisi"
    ],
    "file_path": "data/models/models24/3640310.3674083.pdf"
  },
  {
    "title": "Automated Derivation of UML Sequence Diagrams from User Stories: Unleashing the Power of Generative AI vs. a Rule-Based Approach",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "User stories are informal, non-technical descriptions of features from a user’s perspective that guide collaboration and iterative development in Agile projects. However, ambiguities in user stories can lead to miscommunication among stakeholders. Design models, such as UML sequence diagrams, are essential for enhancing communication, clarifying system behavior, and improving the development process. This paper presents an automated approach for generating behavioral models specifically sequence diagrams from natural language requirements expressed as user stories. We also investigate the effectiveness of a Large Language Model (LLM) in using generative AI for this task. By applying our approach and ChatGPT to two benchmark datasets with the same set of user stories, we generated corresponding sequence diagrams for comparison. Expert evaluations in Software Engineering reveal that our approach effectively produces relevant, simplified diagrams for straightforward user stories, whereas the LLM tends to create more complex diagrams that sometimes go beyond the simplicity of the original user stories.",
    "keywords": [
      "User Story",
      "Sequence Diagram",
      "Generative Model",
      "Large Language Model",
      "Model Generation",
      "Natural Language Processing",
      "Rule-based approach"
    ],
    "authors": [
      "Munima Jahan",
      "Mohammad Mahdi Hassan",
      "Reza Golpayegani",
      "Golshid Ranjbaran",
      "Chanchal Roy",
      "Banani Roy",
      "Kevin Schneider"
    ],
    "file_path": "data/models/models24/3640310.3674081.pdf"
  },
  {
    "title": "AutoMW: Model-based Automated Medical Writing",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Medical Writing is an art of writing scientific documents which includes regulatory and research-related content. To obtain approval for marketing new medicines, pharmaceutical companies are obligated to provide drug authorities with a huge volume of documents related to clinical trials. Creating these clinical trial documents is a time, effort, and skill-intensive process as the required information exists in fragmented form distributed across various information sources. To overcome these challenges in medical writing, we propose Automated Medical Writing tool (AutoMW).  AutoMW enables the digitalization of information from different sources of information using a meta-model-based approach and leverages these models for the automated generation of clinical trial documents as per the regulatory authority document templates. This paper describes the approach and illustrates its utility and efficacy in real-world clinical trial application of two use cases - breast cancer, and diabetes.",
    "keywords": [
      "MDE",
      "Medical Writing",
      "Automated Content Generation",
      "NLP",
      "Clinical Trial Documentation"
    ],
    "authors": [
      "Asha Rajbhoj",
      "Ajim Pathan",
      "Tanay Sant",
      "Vinay Kulkarni",
      "Padmalata Nistala",
      "Rajesh Pandey",
      "Sabarinathan Narasimhan",
      "Geetha Thiagarajan"
    ],
    "file_path": "data/models/models24/3640310.3674096.pdf"
  },
  {
    "title": "Enhancing Automata Learning with Statistical Machine Learning: A Network Security Case Study",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Intrusion detection systems are crucial for network security. Verification of these systems is complicated by various factors, including the heterogeneity of network platforms and the continuously changing landscape of cyber threats. In this paper, we use automata learning to derive state machines from network-traffic data with the objective of supporting behavioural verification of intrusion detection systems. The most innovative aspect of our work is addressing the inability to directly apply existing automata learning techniques to network-traffic data due to the numeric nature of such data. Specifically, we use interpretable machine learning (ML) to partition numeric ranges into intervals that strongly correlate with a system’s decisions regarding intrusion detection. These intervals are subsequently used to abstract numeric ranges before automata learning. We apply our ML-enhanced automata learning approach to a commercial network intrusion detection system developed by our industry partner, RabbitRun Technologies. Our approach results in an average 67.5% reduction in the number of states and transitions of the learned state machines, while achieving an average 28% improvement in accuracy compared to using expertise-based numeric data abstraction. Furthermore, the resulting state machines help practitioners in verifying system-level security requirements and exploring previously unknown system behaviours through model checking and temporal query checking. We make our implementation and experimental data available online.",
    "keywords": [
      "State-machine learning; Intrusion detection; Decision trees; Denial of Service (DoS) attacks; Model checking; Query checking."
    ],
    "authors": [
      "Negin Ayoughi",
      "Shiva Nejati",
      "Mehrdad Sabetzadeh",
      "Patricio Saavedra"
    ],
    "file_path": "data/models/models24/3640310.3674087.pdf"
  },
  {
    "title": "Advancing Domain-Specific High-Integrity Model-Based Tools: Insights and Future Pathways",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Rolls-Royce Control Systems supplies engine control and monitoring systems for aviation applications, and is required to design, certify, and deliver these with the highest level of safety assurance. To allow Rolls-Royce to develop these systems, which continue to increase in complexity, model-based techniques are now a critical part of the software development process. At MODELS 2021 we presented early experiences with using and maintaining a bespoke domain-specific modelling workbench based on open-source modelling technologies, including the Eclipse Modelling Framework (EMF), Xtext, Sirius, and Epsilon. In this paper, we build on our previous paper with further insights, new challenges and lessons learnt as we have advanced and matured our domain-specific solution. We also discuss our experiences with moving towards web based modelling tools based on open-source technologies including Sirius Web, Eclipse GLSP and Eclipse Theia. Rolls-Royce intends to use a selection of these technologies to build a web-based modelling workbench, which will be used to architect and integrate the software for future Rolls-Royce engine control and monitoring systems in a collaborative way.",
    "keywords": [
      "Domain specific languages",
      "component oriented architecture",
      "web based modelling",
      "GLSP",
      "EMF"
    ],
    "authors": [
      "Qurat ul ain Ali",
      "Dimitris Kolovos",
      "Antonio Garcia-Dominguez",
      "Michael Bennett",
      "Joe Newton",
      "Piotr Zacharzewski"
    ],
    "file_path": "data/models/models24/3640310.3674094.pdf"
  },
  {
    "title": "Product Lines of Graphical Modelling Languages",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Modelling languages are essential in many disciplines to express\nknowledge in a precise way. Furthermore, some domains require\nfamilies of notations (rather than individual languages) that account\nfor variations of a language. Some examples of language families\ninclude those to define automata, Petri nets, process models or\nsoftware architectures. Several techniques have been proposed to\nengineer families of languages, but they often neglect the language’s\nconcrete syntax, especially if it is graphical.\nTo fill this gap, we propose a modular method to build product\nlines of graphical modelling languages. Language features are de-\nfined in modules, which comprise both the abstract and graphical\nconcrete syntax of the feature. A language variant is selected by\nchoosing a valid configuration of modules, from which the abstract\nand concrete syntax of the variant is synthesised. Our approach per-\nmits composition and overriding of graphical elements (e.g., symbol\nstyles, visualisation layers), the injection of pre-defined graphi-\ncal styles into language families (e.g., to obtain a high-intensity\ncontrast variant for accessibility), and the analysis of graphical con-\nflicts at the product line level. We report on an implementation atop\nEclipse/Sirius, and demonstrate its benefits by an evaluation which\nshows a substantial specification size reduction of our product line\nmethod with respect to a case-by-case specification approach.",
    "keywords": [
      "Software Language Engineering",
      "Model-driven Engineering",
      "Graphical Concrete Syntax",
      "Product Lines"
    ],
    "authors": [
      "Antonio Garmendia",
      "Esther Guerra",
      "Juan de Lara"
    ],
    "file_path": "data/models/models24/3640310.3674082.pdf"
  },
  {
    "title": "AI-Driven Consistency of SysML Diagrams",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Graphical modeling languages, expected to simplify systems analysis and design, present a challenge in maintaining consistency across their varied views. Traditional rule-based methods for ensuring consistency in languages like UML often fall short in addressing complex semantic dimensions. Moreover, the integration of Large Language Models (LLMs) into Model Driven Engineering (MDE) introduces additional consistency challenges, as LLM’s limited output contexts requires the integration of responses. This paper presents a new framework that automates the detection and correction of inconsistencies across different views, leveraging formally defined rules and incorporating OpenAI’s GPT, as implemented in TTool. Focusing on the consistency between use case and block diagrams, the framework is evaluated through its application to three case studies, highlighting its potential to significantly enhance consistency management in graphical modeling.",
    "keywords": [],
    "authors": [
      "Bastien Sultan",
      "Ludovic Apvrille"
    ],
    "file_path": "data/models/models24/3640310.3674079.pdf"
  },
  {
    "title": "ModelMate: A recommender for textual modeling languages based on pre-trained language models",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Current DSL environments lack smart editing facilities intended\nto enhance modeler productivity and cannot keep pace of current\ndevelopments of integrated development environments based on AI.\nIn this paper, we propose an approach to address this shortcoming\nthrough a recommender system specifically tailored for textual\nDSLs based on the fine-tuning of pre-trained language models. We\nidentify three main tasks: identifier suggestion, line completion,\nand block completion, which we implement over the same fine-\ntuned model and we propose a workflow to apply these tasks to\nany textual DSL. We have evaluated our approach with different\npre-trained models for three DSLs: Emfatic, Xtext and a DSL to\nspecify domain entities, showing that the system performs well\nand provides accurate suggestions. We compare it against existing\napproaches in the feature name recommendation task showing that\nour system outperforms the alternatives. Moreover, we evaluate\nthe inference time of our approach obtaining low latencies, which\nmakes the system adequate for live assistance. Finally, we contribute\na concrete recommender, named ModelMate, which implements\nthe training, evaluation and inference steps of the workflow as well\nas providing integration into Eclipse-based textual editors.",
    "keywords": [
      "Recommendation",
      "Meta-modeling",
      "Model-Driven Engineering",
      "Machine learning"
    ],
    "authors": [
      "Carlos Durá Costa",
      "José Antonio Hernández López",
      "Jesús Sánchez Cuadrado"
    ],
    "file_path": "data/models/models24/3640310.3674089.pdf"
  },
  {
    "title": "Extensions and Scalability Experiments of a Generic Model-Driven Architecture for Variability Model Reasoning",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Until recently, the state-of-the-art of Software Product Line (SPL) configuration and verification automation consisted of a collection of ad-hoc approaches tightly coupling a single input Variability Modeling Language (VML) with a single constraint solver. To remedy this situation, a novel generic model-driven architecture was then proposed that enables using a variety of VMLs and solvers. The key ideas of this proposal were (a) the use of a standard logical language (CLIF) as a pivot between VMLs and solvers, and (b) the use of a standard data exchange format (JSON) to explicilty and declaratively specify the abstract syntax and semantics of the VMLs to be used in an SPL engineering project and the automated reasoning task to be performed by the solvers.\nIn this article, we overcome the limitations of this initial proposal in three key ways: (1) we add the ability to reason on textual or hybrid VMLs, rather than only on diagrammatic VMLs, enhancing the versatility of the architecture on the input side; (2) we enable the use of solvers from a third paradigm, enhancing the versatility of the architecture on the output side; and, (3) we present the results of scalability performance experiments of an implementation of this architecture. These results have been achieved without signifi-cantly altering the architecture, demonstrating its agnosticism with respect to specific VMLs and solvers. It also shows that it can under-lie the implementation of practical variability reasoning tools that scale up to real sized variability model analysis and configuration needs.",
    "keywords": [
      "Software Product Lines",
      "Automated Reasoning",
      "Generic Architecture",
      "Configuration Automation"
    ],
    "authors": [
      "Camilo Correa Restrepo",
      "Jacques Robin",
      "Raul Mazo"
    ],
    "file_path": "data/models/models24/3640310.3674090.pdf"
  },
  {
    "title": "Toward Intelligent Generation of Tailored Graphical Concrete Syntax",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "In model-driven engineering, the concrete syntax of a domain-specific modeling language (DSML) is fundamental as it constitutes the primary point of interaction between the user and the DSML. Nevertheless, the conventional one-size-fits-all approach to concrete syntax often undermines the effectiveness of DSMLs, as it fails to accommodate the diverse constraints and specific requirements inherent to diverse users and usage contexts. Such shortcomings can lead to a significant decline in the performance, usability, and efficiency of DSMLs. This vision paper proposes a conceptual framework to generate concrete syntax intelligently. Our framework considers multiple concerns of users and aims to align the concrete syntax with the context of the DSML usage. Additionally, we detail a baseline process to employ our framework in practice, leveraging large language models to expedite the generation of tailored concrete syntax. We illustrate the potential of our vision with two concrete examples and discuss the shortcomings and research challenges of current intelligent generation techniques.",
    "keywords": [
      "Domain-specific Modeling Languages",
      "Concrete Syntax",
      "Artificial Intelligence",
      "Large Language Models"
    ],
    "authors": [
      "Meriem Ben Chaaben",
      "Oussama Ben Sghaier",
      "Mouna Dhaouadi",
      "Nafisa Elrasheed",
      "Ikram Darif",
      "Imen Jaoua",
      "Bentley Oakes",
      "Eugene Syriani",
      "Mohammad Hamdaqa"
    ],
    "file_path": "data/models/models24/3640310.3674085.pdf"
  },
  {
    "title": "Model Everything but with Intellectual Property Protection — The Deltachain Approach",
    "submission-date": "2024/09",
    "publication-date": "2024/09",
    "abstract": "Many organizations are involved in the development of complex systems, e.g., cyber-physical systems. Organizations work collabo-ratively to describe these systems, using models, which are devel-oped using multiple languages and tools. The models may contain intellectual property that must be protected from other parties, including other contributors. To enable the ongoing exchange of models and to ensure intellectual property protection, our new idea is to use encrypted deltas, i.e., arbitrary changes made to a model. These encrypted deltas are stored on a chain, which we call Deltachain. Encryption enables free exchange of the Deltachain, e.g., on third-party commercial file storage servers. Collaborators involved in the development of the model can access the encrypted Deltachain, decrypt the parts to which they have access, and then work with those decrypted parts which are created by applying the deltas. Subsequently, the collaborators can encrypt their deltas to the model parts and append the encrypted deltas to the Deltachain. Our vision is the use of this Deltachain by collaborating organiza-tions as a single source of truth.",
    "keywords": [
      "Collaborative Software Engineering",
      "Model-Driven Engineering",
      "Cross-Organisational Collaboration",
      "Data Structures",
      "Applied Cryp-tography",
      "Deltachain"
    ],
    "authors": [
      "Thomas Weber",
      "Sebastian Weber"
    ],
    "file_path": "data/models/models24/3640310.3674086.pdf"
  }
]
